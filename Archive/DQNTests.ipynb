{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6627a9dc-1dee-4862-9b02-31241760898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e99fdc78-7e74-40ac-ada9-22044f3c02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c8980-4660-4c3a-9b69-2a78a13fac12",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a009e3ca-32ed-4c66-b8e6-2454db6b1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.OED import OED, OEDGymConfig\n",
    "from src.DQN import DQN_OED\n",
    "\n",
    "from pde.AdvectionEquation import *\n",
    "from pde.Burgers2D import *\n",
    "from pde.AdvectionDiffusionReaction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b62ece-cf98-4b9d-a459-0bef84f54561",
   "metadata": {},
   "source": [
    "## Advection Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4aa2439a-8f20-48f0-a1b9-f90ccbbdfc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "adv_config = Adv2dModelConfig()\n",
    "adv_eq = Advection2D(adv_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc4eaa4d-072e-40c2-b00a-2214a6076aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "gym_config = OEDGymConfig()\n",
    "adv_dqn = DQN_OED(seed, pde_system=adv_eq, gym_config=gym_config, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6bb9eae-0284-43dc-99ce-319c6a0aa7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f5bba9faca0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(adv_dqn.env.pde_field[:, :, -1].T, origin='lower', extent=[0, 1, 0, 1], interpolation='bilinear')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffca744-7b60-4f1f-9a81-1cf39ee33b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1950d8cb-ab66-4c04-a257-161aede36230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tensorboard/DQN_17\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 27.4     |\n",
      "|    ep_rew_mean      | -359     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 10       |\n",
      "|    fps              | 273      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 274      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 13       |\n",
      "|    n_updates        | 43       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | -315     |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 481      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 12       |\n",
      "|    n_updates        | 95       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.9     |\n",
      "|    ep_rew_mean      | -355     |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 30       |\n",
      "|    fps              | 516      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 806      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 12.3     |\n",
      "|    n_updates        | 176      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.1     |\n",
      "|    ep_rew_mean      | -343     |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1046     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 12.2     |\n",
      "|    n_updates        | 236      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | -329     |\n",
      "|    exploration_rate | 0.761    |\n",
      "| time/               |          |\n",
      "|    episodes         | 50       |\n",
      "|    fps              | 611      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 1256     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 11.7     |\n",
      "|    n_updates        | 288      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | -326     |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 639      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 1473     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 12       |\n",
      "|    n_updates        | 343      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | -308     |\n",
      "|    exploration_rate | 0.69     |\n",
      "| time/               |          |\n",
      "|    episodes         | 70       |\n",
      "|    fps              | 655      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 1631     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 12.6     |\n",
      "|    n_updates        | 382      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | -311     |\n",
      "|    exploration_rate | 0.641    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 677      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 1890     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 11.7     |\n",
      "|    n_updates        | 447      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | -310     |\n",
      "|    exploration_rate | 0.595    |\n",
      "| time/               |          |\n",
      "|    episodes         | 90       |\n",
      "|    fps              | 692      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 2132     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 11.3     |\n",
      "|    n_updates        | 507      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | -300     |\n",
      "|    exploration_rate | 0.565    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 699      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 2289     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 10.6     |\n",
      "|    n_updates        | 547      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | -311     |\n",
      "|    exploration_rate | 0.494    |\n",
      "| time/               |          |\n",
      "|    episodes         | 110      |\n",
      "|    fps              | 703      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 2661     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.46     |\n",
      "|    n_updates        | 640      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | -303     |\n",
      "|    exploration_rate | 0.467    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 2806     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.5      |\n",
      "|    n_updates        | 676      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | -291     |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 130      |\n",
      "|    fps              | 712      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 3042     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.8      |\n",
      "|    n_updates        | 735      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | -278     |\n",
      "|    exploration_rate | 0.396    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 715      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 3178     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.02     |\n",
      "|    n_updates        | 769      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | -270     |\n",
      "|    exploration_rate | 0.369    |\n",
      "| time/               |          |\n",
      "|    episodes         | 150      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 3323     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.57     |\n",
      "|    n_updates        | 805      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | -266     |\n",
      "|    exploration_rate | 0.328    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 3539     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 859      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | -270     |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    episodes         | 170      |\n",
      "|    fps              | 719      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 3721     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.982    |\n",
      "|    n_updates        | 905      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | -266     |\n",
      "|    exploration_rate | 0.251    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 719      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 3940     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 959      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | -257     |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    episodes         | 190      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 4102     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.685    |\n",
      "|    n_updates        | 1000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | -257     |\n",
      "|    exploration_rate | 0.19     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 4264     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.803    |\n",
      "|    n_updates        | 1040     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | -237     |\n",
      "|    exploration_rate | 0.152    |\n",
      "| time/               |          |\n",
      "|    episodes         | 210      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 4462     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.529    |\n",
      "|    n_updates        | 1090     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | -239     |\n",
      "|    exploration_rate | 0.122    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 4619     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.766    |\n",
      "|    n_updates        | 1129     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | -235     |\n",
      "|    exploration_rate | 0.0832   |\n",
      "| time/               |          |\n",
      "|    episodes         | 230      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 4825     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.624    |\n",
      "|    n_updates        | 1181     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | -241     |\n",
      "|    exploration_rate | 0.0508   |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 718      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 4996     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.509    |\n",
      "|    n_updates        | 1223     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | -240     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 250      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 5136     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.395    |\n",
      "|    n_updates        | 1258     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | -230     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 716      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 5263     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.57     |\n",
      "|    n_updates        | 1290     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | -225     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 270      |\n",
      "|    fps              | 716      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 5419     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.73     |\n",
      "|    n_updates        | 1329     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.1     |\n",
      "|    ep_rew_mean      | -214     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 716      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 5546     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.53     |\n",
      "|    n_updates        | 1361     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -213     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 290      |\n",
      "|    fps              | 715      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 5698     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.597    |\n",
      "|    n_updates        | 1399     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | -213     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 715      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 5855     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.185    |\n",
      "|    n_updates        | 1438     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -213     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 310      |\n",
      "|    fps              | 714      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 6058     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.478    |\n",
      "|    n_updates        | 1489     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | -213     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 714      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 6217     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.361    |\n",
      "|    n_updates        | 1529     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | -207     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 330      |\n",
      "|    fps              | 710      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 6377     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.378    |\n",
      "|    n_updates        | 1569     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | -222     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 710      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 6650     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.299    |\n",
      "|    n_updates        | 1637     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | -237     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 350      |\n",
      "|    fps              | 711      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 6900     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.297    |\n",
      "|    n_updates        | 1699     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | -249     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 710      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 7114     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.191    |\n",
      "|    n_updates        | 1753     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.4     |\n",
      "|    ep_rew_mean      | -248     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 370      |\n",
      "|    fps              | 710      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 7257     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 1789     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | -257     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 710      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 7464     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.353    |\n",
      "|    n_updates        | 1840     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | -258     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 390      |\n",
      "|    fps              | 709      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 7628     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.439    |\n",
      "|    n_updates        | 1881     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | -254     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 7759     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 1914     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | -250     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 410      |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 7933     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.21     |\n",
      "|    n_updates        | 1958     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | -253     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 8112     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.241    |\n",
      "|    n_updates        | 2002     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | -255     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 430      |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 8281     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 2045     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.3     |\n",
      "|    ep_rew_mean      | -245     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 8476     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 2093     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | -231     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 450      |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 8628     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.312    |\n",
      "|    n_updates        | 2131     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | -220     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 706      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 8756     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.14     |\n",
      "|    n_updates        | 2163     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | -229     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 470      |\n",
      "|    fps              | 705      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 8984     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.178    |\n",
      "|    n_updates        | 2220     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | -224     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 705      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 9137     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.125    |\n",
      "|    n_updates        | 2259     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | -224     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 490      |\n",
      "|    fps              | 705      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 9306     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0954   |\n",
      "|    n_updates        | 2301     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | -228     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 705      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 9461     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 2340     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | -226     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 510      |\n",
      "|    fps              | 705      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 9617     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.213    |\n",
      "|    n_updates        | 2379     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | -224     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 701      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 9782     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.234    |\n",
      "|    n_updates        | 2420     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | -223     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 530      |\n",
      "|    fps              | 701      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 9948     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 2461     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | -222     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 694      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 10151    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.84     |\n",
      "|    n_updates        | 2512     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.6     |\n",
      "|    ep_rew_mean      | -221     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 550      |\n",
      "|    fps              | 694      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 10291    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.5      |\n",
      "|    n_updates        | 2547     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | -225     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 694      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 10442    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.75     |\n",
      "|    n_updates        | 2585     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.1     |\n",
      "|    ep_rew_mean      | -216     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 570      |\n",
      "|    fps              | 694      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 10591    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 2622     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | -221     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 10786    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 2671     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | -223     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 590      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 10978    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.592    |\n",
      "|    n_updates        | 2719     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | -234     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 11223    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.702    |\n",
      "|    n_updates        | 2780     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | -249     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 610      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 11487    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 2846     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | -253     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 696      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 11681    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.978    |\n",
      "|    n_updates        | 2895     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | -261     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 630      |\n",
      "|    fps              | 696      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 11921    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.941    |\n",
      "|    n_updates        | 2955     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | -266     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 696      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 12157    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.764    |\n",
      "|    n_updates        | 3014     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | -273     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 650      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 12360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.589    |\n",
      "|    n_updates        | 3064     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | -280     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 12580    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.133    |\n",
      "|    n_updates        | 3119     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | -294     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 670      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 12846    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.316    |\n",
      "|    n_updates        | 3186     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | -292     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 13038    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.691    |\n",
      "|    n_updates        | 3234     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | -291     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 690      |\n",
      "|    fps              | 694      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 13218    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 3279     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | -274     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 694      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 13338    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.793    |\n",
      "|    n_updates        | 3309     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | -267     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 710      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 13554    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.629    |\n",
      "|    n_updates        | 3363     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | -271     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 13798    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 3424     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | -264     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 730      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 13971    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.947    |\n",
      "|    n_updates        | 3467     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | -272     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 696      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 14266    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 3541     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | -273     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 750      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 14472    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 3592     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | -280     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 14723    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.869    |\n",
      "|    n_updates        | 3655     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | -282     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 770      |\n",
      "|    fps              | 696      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 15012    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.617    |\n",
      "|    n_updates        | 3727     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | -299     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 696      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 15328    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.2      |\n",
      "|    n_updates        | 3806     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | -307     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 790      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 15560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.836    |\n",
      "|    n_updates        | 3864     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | -317     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 15757    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 3914     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | -324     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 810      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 16011    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 3977     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | -319     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 16195    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 4023     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | -321     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 830      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 16386    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 4071     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | -315     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 16648    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.489    |\n",
      "|    n_updates        | 4136     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.4     |\n",
      "|    ep_rew_mean      | -320     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 850      |\n",
      "|    fps              | 696      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 16911    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.59     |\n",
      "|    n_updates        | 4202     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.3     |\n",
      "|    ep_rew_mean      | -317     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 696      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 17152    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.53     |\n",
      "|    n_updates        | 4262     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | -305     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 870      |\n",
      "|    fps              | 696      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 17337    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.33     |\n",
      "|    n_updates        | 4309     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | -306     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 17682    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 4395     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | -307     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 890      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 17925    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.595    |\n",
      "|    n_updates        | 4456     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | -301     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 18067    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 4491     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | -291     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 910      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 18255    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26     |\n",
      "|    n_updates        | 4538     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | -294     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 18466    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 4591     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | -294     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 930      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 18654    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.61     |\n",
      "|    n_updates        | 4638     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | -280     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 18800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 4674     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | -280     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 950      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 19036    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.992    |\n",
      "|    n_updates        | 4733     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | -276     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 19238    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.505    |\n",
      "|    n_updates        | 4784     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | -277     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 970      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 19409    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.177    |\n",
      "|    n_updates        | 4827     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | -268     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 19668    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.2      |\n",
      "|    n_updates        | 4891     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | -259     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 990      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 19849    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 4937     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | -258     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 19980    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 4969     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | -258     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1010     |\n",
      "|    fps              | 699      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 20159    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.76     |\n",
      "|    n_updates        | 5014     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | -259     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 20373    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.68     |\n",
      "|    n_updates        | 5068     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | -264     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1030     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 20609    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.93     |\n",
      "|    n_updates        | 5127     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | -264     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 20756    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 5163     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | -253     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1050     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 20912    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.3      |\n",
      "|    n_updates        | 5202     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | -243     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 21039    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.499    |\n",
      "|    n_updates        | 5234     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | -239     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1070     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 21198    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 5274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -228     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 21374    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.76     |\n",
      "|    n_updates        | 5318     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | -223     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1090     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 21515    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.98     |\n",
      "|    n_updates        | 5353     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -229     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 21688    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.338    |\n",
      "|    n_updates        | 5396     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -228     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1110     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 21870    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.51     |\n",
      "|    n_updates        | 5442     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | -225     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 22073    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 5493     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | -220     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1130     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 22260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.71     |\n",
      "|    n_updates        | 5539     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | -221     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 22405    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.955    |\n",
      "|    n_updates        | 5576     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | -219     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1150     |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 22548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.72     |\n",
      "|    n_updates        | 5611     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | -233     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 673      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 22786    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.314    |\n",
      "|    n_updates        | 5671     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | -237     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1170     |\n",
      "|    fps              | 515      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 22962    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 5715     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | -239     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 23146    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.14     |\n",
      "|    n_updates        | 5761     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | -249     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1190     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 23368    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.56     |\n",
      "|    n_updates        | 5816     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | -256     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 23615    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.275    |\n",
      "|    n_updates        | 5878     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | -264     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1210     |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 23857    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.405    |\n",
      "|    n_updates        | 5939     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | -269     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 324      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 24102    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.81     |\n",
      "|    n_updates        | 6000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | -269     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1230     |\n",
      "|    fps              | 325      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 24294    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1      |\n",
      "|    n_updates        | 6048     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | -268     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 326      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 24441    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.338    |\n",
      "|    n_updates        | 6085     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | -268     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1250     |\n",
      "|    fps              | 327      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 24581    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.45     |\n",
      "|    n_updates        | 6120     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | -265     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 24788    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.38     |\n",
      "|    n_updates        | 6171     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | -262     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1270     |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 24949    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 6212     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | -262     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 330      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 25135    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.52     |\n",
      "|    n_updates        | 6258     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | -258     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1290     |\n",
      "|    fps              | 332      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 25313    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.815    |\n",
      "|    n_updates        | 6303     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | -259     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 333      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 25558    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.958    |\n",
      "|    n_updates        | 6364     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | -257     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1310     |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 25792    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 6422     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | -261     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 336      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 26053    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.9      |\n",
      "|    n_updates        | 6488     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | -264     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1330     |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 26273    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.329    |\n",
      "|    n_updates        | 6543     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | -267     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 26434    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.86     |\n",
      "|    n_updates        | 6583     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | -282     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1350     |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 26699    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 6649     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | -288     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 26933    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.19     |\n",
      "|    n_updates        | 6708     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | -291     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1370     |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 27123    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.907    |\n",
      "|    n_updates        | 6755     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | -300     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 27373    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.353    |\n",
      "|    n_updates        | 6818     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | -310     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1390     |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 27642    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 6885     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | -308     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 27879    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 6944     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | -313     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1410     |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 28134    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.53     |\n",
      "|    n_updates        | 7008     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | -303     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 28324    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.907    |\n",
      "|    n_updates        | 7055     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | -302     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1430     |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 28523    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 7105     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | -309     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 28738    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.262    |\n",
      "|    n_updates        | 7159     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | -306     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1450     |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 28976    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.5      |\n",
      "|    n_updates        | 7218     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | -293     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 29128    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.57     |\n",
      "|    n_updates        | 7256     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | -301     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1470     |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 29368    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 7316     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | -286     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 29505    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.35     |\n",
      "|    n_updates        | 7351     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | -283     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1490     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 29745    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.64     |\n",
      "|    n_updates        | 7411     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | -274     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 359      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 29914    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.38     |\n",
      "|    n_updates        | 7453     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | -270     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1510     |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 30141    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.85     |\n",
      "|    n_updates        | 7510     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | -262     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 30281    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.94     |\n",
      "|    n_updates        | 7545     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | -253     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1530     |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 30411    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.49     |\n",
      "|    n_updates        | 7577     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | -244     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 30554    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.806    |\n",
      "|    n_updates        | 7613     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | -235     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1550     |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 30718    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.63     |\n",
      "|    n_updates        | 7654     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | -238     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 30892    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.3      |\n",
      "|    n_updates        | 7697     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | -235     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1570     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 31116    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.06     |\n",
      "|    n_updates        | 7753     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | -239     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 31285    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.336    |\n",
      "|    n_updates        | 7796     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | -237     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1590     |\n",
      "|    fps              | 367      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 31504    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.74     |\n",
      "|    n_updates        | 7850     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | -243     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 31727    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.98     |\n",
      "|    n_updates        | 7906     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | -242     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1610     |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 31939    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.53     |\n",
      "|    n_updates        | 7959     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | -252     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 32140    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.82     |\n",
      "|    n_updates        | 8009     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | -260     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1630     |\n",
      "|    fps              | 371      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 32327    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.63     |\n",
      "|    n_updates        | 8056     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | -270     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 32540    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.43     |\n",
      "|    n_updates        | 8109     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | -273     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1650     |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 32721    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.49     |\n",
      "|    n_updates        | 8155     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | -276     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 32922    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.7      |\n",
      "|    n_updates        | 8205     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | -263     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1670     |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 33043    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.35     |\n",
      "|    n_updates        | 8235     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | -261     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1680     |\n",
      "|    fps              | 375      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 33189    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 8272     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | -264     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1690     |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 33447    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.45     |\n",
      "|    n_updates        | 8336     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | -256     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 33610    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 8377     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | -252     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1710     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 33791    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.569    |\n",
      "|    n_updates        | 8422     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | -243     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1720     |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 33933    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 8458     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | -238     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1730     |\n",
      "|    fps              | 378      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 34082    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.87     |\n",
      "|    n_updates        | 8495     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | -229     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1740     |\n",
      "|    fps              | 379      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 34256    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.4      |\n",
      "|    n_updates        | 8538     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | -234     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1750     |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 34496    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.8      |\n",
      "|    n_updates        | 8598     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | -227     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1760     |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 34649    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.35     |\n",
      "|    n_updates        | 8637     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | -232     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1770     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 34806    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59     |\n",
      "|    n_updates        | 8676     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | -230     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1780     |\n",
      "|    fps              | 382      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 34951    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.76     |\n",
      "|    n_updates        | 8712     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | -219     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1790     |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 35099    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 8749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | -223     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 35289    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.54     |\n",
      "|    n_updates        | 8797     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | -219     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1810     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 35443    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.42     |\n",
      "|    n_updates        | 8835     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | -220     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1820     |\n",
      "|    fps              | 385      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 35585    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.54     |\n",
      "|    n_updates        | 8871     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | -231     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1830     |\n",
      "|    fps              | 386      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 35824    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.34     |\n",
      "|    n_updates        | 8930     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | -233     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1840     |\n",
      "|    fps              | 387      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 35995    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.51     |\n",
      "|    n_updates        | 8973     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | -228     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1850     |\n",
      "|    fps              | 388      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 36182    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.527    |\n",
      "|    n_updates        | 9020     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -231     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1860     |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 36356    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 9063     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -231     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1870     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 36514    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.67     |\n",
      "|    n_updates        | 9103     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -231     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1880     |\n",
      "|    fps              | 390      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 36658    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.59     |\n",
      "|    n_updates        | 9139     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | -233     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1890     |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 36832    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.86     |\n",
      "|    n_updates        | 9182     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -230     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 37002    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.352    |\n",
      "|    n_updates        | 9225     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | -235     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1910     |\n",
      "|    fps              | 393      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 37195    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.64     |\n",
      "|    n_updates        | 9273     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | -237     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1920     |\n",
      "|    fps              | 394      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 37367    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.56     |\n",
      "|    n_updates        | 9316     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | -237     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1930     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 37605    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.58     |\n",
      "|    n_updates        | 9376     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | -232     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1940     |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 37749    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.57     |\n",
      "|    n_updates        | 9412     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -227     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1950     |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 37890    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.67     |\n",
      "|    n_updates        | 9447     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | -234     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1960     |\n",
      "|    fps              | 397      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 38102    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.48     |\n",
      "|    n_updates        | 9500     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | -241     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1970     |\n",
      "|    fps              | 398      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 38331    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.49     |\n",
      "|    n_updates        | 9557     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | -250     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1980     |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 38541    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 9610     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | -247     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1990     |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 38695    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.407    |\n",
      "|    n_updates        | 9648     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | -260     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 400      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 38963    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.97     |\n",
      "|    n_updates        | 9715     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | -268     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2010     |\n",
      "|    fps              | 402      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 39217    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.33     |\n",
      "|    n_updates        | 9779     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | -264     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2020     |\n",
      "|    fps              | 402      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 39365    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.305    |\n",
      "|    n_updates        | 9816     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | -256     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2030     |\n",
      "|    fps              | 403      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 39547    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 9861     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | -258     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2040     |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 39702    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 9900     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | -256     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2050     |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 39837    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.51     |\n",
      "|    n_updates        | 9934     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | -250     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2060     |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 40004    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 13.8     |\n",
      "|    n_updates        | 9975     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | -244     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2070     |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 40177    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.2      |\n",
      "|    n_updates        | 10019    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | -236     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2080     |\n",
      "|    fps              | 406      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 40317    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.02     |\n",
      "|    n_updates        | 10054    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | -242     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2090     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 40511    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.75     |\n",
      "|    n_updates        | 10102    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -228     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 40669    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.377    |\n",
      "|    n_updates        | 10142    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | -235     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2110     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 40967    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 10216    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | -234     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2120     |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 41100    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.08     |\n",
      "|    n_updates        | 10249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | -238     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2130     |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 41292    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.89     |\n",
      "|    n_updates        | 10297    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | -243     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2140     |\n",
      "|    fps              | 411      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 41493    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.4      |\n",
      "|    n_updates        | 10348    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | -252     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2150     |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 41707    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.48     |\n",
      "|    n_updates        | 10401    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | -255     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2160     |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 41908    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.01     |\n",
      "|    n_updates        | 10451    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | -255     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2170     |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 42075    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.99     |\n",
      "|    n_updates        | 10493    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | -251     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2180     |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 42198    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.37     |\n",
      "|    n_updates        | 10524    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | -250     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2190     |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 42388    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.2      |\n",
      "|    n_updates        | 10571    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | -254     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 42557    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.28     |\n",
      "|    n_updates        | 10614    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | -231     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2210     |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 42689    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.53     |\n",
      "|    n_updates        | 10647    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | -231     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2220     |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 42818    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.04     |\n",
      "|    n_updates        | 10679    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | -228     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2230     |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 43011    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.514    |\n",
      "|    n_updates        | 10727    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | -226     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2240     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 43194    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.61     |\n",
      "|    n_updates        | 10773    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.6     |\n",
      "|    ep_rew_mean      | -221     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2250     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 43367    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.93     |\n",
      "|    n_updates        | 10816    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.2     |\n",
      "|    ep_rew_mean      | -217     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2260     |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 43533    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.321    |\n",
      "|    n_updates        | 10858    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.6     |\n",
      "|    ep_rew_mean      | -221     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2270     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 43738    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.57     |\n",
      "|    n_updates        | 10909    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | -236     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2280     |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 43974    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.98     |\n",
      "|    n_updates        | 10968    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | -231     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2290     |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 44120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.78     |\n",
      "|    n_updates        | 11004    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -225     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 44266    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.7      |\n",
      "|    n_updates        | 11041    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | -237     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2310     |\n",
      "|    fps              | 419      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 44490    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.52     |\n",
      "|    n_updates        | 11097    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | -248     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2320     |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 44696    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.98     |\n",
      "|    n_updates        | 11148    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | -253     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2330     |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 44918    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.25     |\n",
      "|    n_updates        | 11204    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | -250     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2340     |\n",
      "|    fps              | 421      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 45073    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.19     |\n",
      "|    n_updates        | 11243    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | -260     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2350     |\n",
      "|    fps              | 422      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 45325    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.408    |\n",
      "|    n_updates        | 11306    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | -268     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2360     |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 45552    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.97     |\n",
      "|    n_updates        | 11362    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | -271     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2370     |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 45784    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.54     |\n",
      "|    n_updates        | 11420    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | -266     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2380     |\n",
      "|    fps              | 424      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 45985    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.52     |\n",
      "|    n_updates        | 11471    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | -263     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2390     |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 46113    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.16     |\n",
      "|    n_updates        | 11503    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | -266     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 425      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 46278    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.97     |\n",
      "|    n_updates        | 11544    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | -254     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2410     |\n",
      "|    fps              | 426      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 46404    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.94     |\n",
      "|    n_updates        | 11575    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | -248     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2420     |\n",
      "|    fps              | 426      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 46580    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.77     |\n",
      "|    n_updates        | 11619    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | -237     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2430     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 46727    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 11656    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.4     |\n",
      "|    ep_rew_mean      | -242     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2440     |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 46914    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.436    |\n",
      "|    n_updates        | 11703    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | -225     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2450     |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 47038    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.91     |\n",
      "|    n_updates        | 11734    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | -221     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2460     |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 47230    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.73     |\n",
      "|    n_updates        | 11782    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.2     |\n",
      "|    ep_rew_mean      | -215     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2470     |\n",
      "|    fps              | 429      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 47403    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.16     |\n",
      "|    n_updates        | 11825    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | -220     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2480     |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 47627    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.18     |\n",
      "|    n_updates        | 11881    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | -227     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2490     |\n",
      "|    fps              | 430      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 47795    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.34     |\n",
      "|    n_updates        | 11923    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | -227     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 47971    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.75     |\n",
      "|    n_updates        | 11967    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | -235     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2510     |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 48167    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.16     |\n",
      "|    n_updates        | 12016    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.8     |\n",
      "|    ep_rew_mean      | -237     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2520     |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 48355    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.448    |\n",
      "|    n_updates        | 12063    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | -243     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2530     |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 48539    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.217    |\n",
      "|    n_updates        | 12109    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | -250     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2540     |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 48781    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.13     |\n",
      "|    n_updates        | 12170    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | -252     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2550     |\n",
      "|    fps              | 434      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 48917    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.9      |\n",
      "|    n_updates        | 12204    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.4     |\n",
      "|    ep_rew_mean      | -246     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2560     |\n",
      "|    fps              | 434      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 49069    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 12242    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | -239     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2570     |\n",
      "|    fps              | 435      |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 49207    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.76     |\n",
      "|    n_updates        | 12276    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.4     |\n",
      "|    ep_rew_mean      | -245     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2580     |\n",
      "|    fps              | 436      |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 49471    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.58     |\n",
      "|    n_updates        | 12342    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | -246     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2590     |\n",
      "|    fps              | 436      |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 49646    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.7      |\n",
      "|    n_updates        | 12386    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | -249     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 437      |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 49834    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.95     |\n",
      "|    n_updates        | 12433    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | -241     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2610     |\n",
      "|    fps              | 437      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 49959    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.16     |\n",
      "|    n_updates        | 12464    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = \"adv_dqn_1\"\n",
    "adv_dqn.train(model_name, total_timesteps=50000, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e0448-fef5-455c-bbd5-4e96a44bbd69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b6f2091e-cc57-4fee-a0b8-48386f11e07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode 1/1000\n",
      "  Step 1, Current reward: 0.038722\n",
      "  Step 2, Current reward: 0.038722\n",
      "  Step 3, Current reward: 0.038722\n",
      "  Step 4, Current reward: 0.038722\n",
      "  Step 5, Current reward: 0.038722\n",
      "  Step 6, Current reward: 0.038722\n",
      "  Step 7, Current reward: 0.038722\n",
      "  Step 8, Current reward: 0.038722\n",
      "  Step 9, Current reward: 0.038722\n",
      "  Step 10, Current reward: 0.038722\n",
      "  Step 11, Current reward: 0.038722\n",
      "  Step 12, Current reward: 0.038722\n",
      "Episode 1/1000 complete - Max Reward: 0.038722\n",
      "Starting episode 2/1000\n",
      "  Step 1, Current reward: 0.077097\n",
      "  Step 2, Current reward: 0.077097\n",
      "  Step 3, Current reward: 0.077097\n",
      "  Step 4, Current reward: 0.077097\n",
      "  Step 5, Current reward: 0.077097\n",
      "  Step 6, Current reward: 0.077097\n",
      "  Step 7, Current reward: 0.077097\n",
      "  Step 8, Current reward: 0.077097\n",
      "  Step 9, Current reward: 0.077097\n",
      "  Step 10, Current reward: 0.077097\n",
      "  Step 11, Current reward: 0.077097\n",
      "  Step 12, Current reward: 0.077097\n",
      "Episode 2/1000 complete - Max Reward: 0.077097\n",
      "Starting episode 3/1000\n",
      "  Step 1, Current reward: 0.068016\n",
      "  Step 2, Current reward: 0.068016\n",
      "  Step 3, Current reward: 0.068016\n",
      "  Step 4, Current reward: 0.068016\n",
      "  Step 5, Current reward: 0.068016\n",
      "  Step 6, Current reward: 0.068016\n",
      "  Step 7, Current reward: 0.068016\n",
      "  Step 8, Current reward: 0.068016\n",
      "  Step 9, Current reward: 0.068016\n",
      "  Step 10, Current reward: 0.068016\n",
      "  Step 11, Current reward: 0.068016\n",
      "  Step 12, Current reward: 0.068016\n",
      "Episode 3/1000 complete - Max Reward: 0.068016\n",
      "Starting episode 4/1000\n",
      "  Step 1, Current reward: 0.118337\n",
      "  Step 2, Current reward: 0.118337\n",
      "  Step 3, Current reward: 0.118337\n",
      "  Step 4, Current reward: 0.118337\n",
      "  Step 5, Current reward: 0.118337\n",
      "  Step 6, Current reward: 0.118337\n",
      "  Step 7, Current reward: 0.118337\n",
      "  Step 8, Current reward: 0.118337\n",
      "  Step 9, Current reward: 0.118337\n",
      "  Step 10, Current reward: 0.118337\n",
      "  Step 11, Current reward: 0.118337\n",
      "  Step 12, Current reward: 0.118337\n",
      "Episode 4/1000 complete - Max Reward: 0.118337\n",
      "Starting episode 5/1000\n",
      "  Step 1, Current reward: 0.013601\n",
      "  Step 2, Current reward: 0.013601\n",
      "  Step 3, Current reward: 0.013601\n",
      "  Step 4, Current reward: 0.013601\n",
      "  Step 5, Current reward: 0.013601\n",
      "  Step 6, Current reward: 0.013601\n",
      "  Step 7, Current reward: 0.013601\n",
      "  Step 8, Current reward: 0.013601\n",
      "  Step 9, Current reward: 0.013601\n",
      "  Step 10, Current reward: 0.013601\n",
      "  Step 11, Current reward: 0.013601\n",
      "  Step 12, Current reward: 0.013601\n",
      "Episode 5/1000 complete - Max Reward: 0.013601\n",
      "Starting episode 6/1000\n",
      "  Step 1, Current reward: 0.037906\n",
      "  Step 2, Current reward: 0.037906\n",
      "  Step 3, Current reward: 0.037906\n",
      "  Step 4, Current reward: 0.037906\n",
      "  Step 5, Current reward: 0.037906\n",
      "  Step 6, Current reward: 0.037906\n",
      "  Step 7, Current reward: 0.037906\n",
      "  Step 8, Current reward: 0.037906\n",
      "  Step 9, Current reward: 0.037906\n",
      "  Step 10, Current reward: 0.037906\n",
      "  Step 11, Current reward: 0.037906\n",
      "  Step 12, Current reward: 0.037906\n",
      "Episode 6/1000 complete - Max Reward: 0.037906\n",
      "Starting episode 7/1000\n",
      "  Step 1, Current reward: 0.011969\n",
      "  Step 2, Current reward: 0.011969\n",
      "  Step 3, Current reward: 0.011969\n",
      "  Step 4, Current reward: 0.011969\n",
      "  Step 5, Current reward: 0.011969\n",
      "  Step 6, Current reward: 0.011969\n",
      "  Step 7, Current reward: 0.011969\n",
      "  Step 8, Current reward: 0.011969\n",
      "  Step 9, Current reward: 0.011969\n",
      "  Step 10, Current reward: 0.011969\n",
      "  Step 11, Current reward: 0.011969\n",
      "  Step 12, Current reward: 0.011969\n",
      "Episode 7/1000 complete - Max Reward: 0.011969\n",
      "Starting episode 8/1000\n",
      "  Step 1, Current reward: 0.063917\n",
      "  Step 2, Current reward: 0.063917\n",
      "  Step 3, Current reward: 0.063917\n",
      "  Step 4, Current reward: 0.063917\n",
      "  Step 5, Current reward: 0.063917\n",
      "  Step 6, Current reward: 0.063917\n",
      "  Step 7, Current reward: 0.063917\n",
      "  Step 8, Current reward: 0.063917\n",
      "  Step 9, Current reward: 0.063917\n",
      "  Step 10, Current reward: 0.063917\n",
      "  Step 11, Current reward: 0.063917\n",
      "  Step 12, Current reward: 0.063917\n",
      "Episode 8/1000 complete - Max Reward: 0.063917\n",
      "Starting episode 9/1000\n",
      "  Step 1, Current reward: 0.015919\n",
      "  Step 2, Current reward: 0.015919\n",
      "  Step 3, Current reward: 0.015919\n",
      "  Step 4, Current reward: 0.015919\n",
      "  Step 5, Current reward: 0.015919\n",
      "  Step 6, Current reward: 0.015919\n",
      "  Step 7, Current reward: 0.015919\n",
      "  Step 8, Current reward: 0.015919\n",
      "  Step 9, Current reward: 0.015919\n",
      "  Step 10, Current reward: 0.015919\n",
      "  Step 11, Current reward: 0.015919\n",
      "  Step 12, Current reward: 0.015919\n",
      "Episode 9/1000 complete - Max Reward: 0.015919\n",
      "Starting episode 10/1000\n",
      "  Step 1, Current reward: 0.037581\n",
      "  Step 2, Current reward: 0.037581\n",
      "  Step 3, Current reward: 0.037581\n",
      "  Step 4, Current reward: 0.037581\n",
      "  Step 5, Current reward: 0.037581\n",
      "  Step 6, Current reward: 0.037581\n",
      "  Step 7, Current reward: 0.037581\n",
      "  Step 8, Current reward: 0.037581\n",
      "  Step 9, Current reward: 0.037581\n",
      "  Step 10, Current reward: 0.037581\n",
      "  Step 11, Current reward: 0.037581\n",
      "  Step 12, Current reward: 0.037581\n",
      "Episode 10/1000 complete - Max Reward: 0.037581\n",
      "Starting episode 11/1000\n",
      "  Step 1, Current reward: 0.002670\n",
      "  Step 2, Current reward: 0.002670\n",
      "  Step 3, Current reward: 0.002670\n",
      "  Step 4, Current reward: 0.002670\n",
      "  Step 5, Current reward: 0.002670\n",
      "  Step 6, Current reward: 0.002670\n",
      "  Step 7, Current reward: 0.002670\n",
      "  Step 8, Current reward: 0.002670\n",
      "  Step 9, Current reward: 0.002670\n",
      "  Step 10, Current reward: 0.002670\n",
      "  Step 11, Current reward: 0.002670\n",
      "  Step 12, Current reward: 0.002670\n",
      "Episode 11/1000 complete - Max Reward: 0.002670\n",
      "Starting episode 12/1000\n",
      "  Step 1, Current reward: 0.059964\n",
      "  Step 2, Current reward: 0.059964\n",
      "  Step 3, Current reward: 0.059964\n",
      "  Step 4, Current reward: 0.059964\n",
      "  Step 5, Current reward: 0.059964\n",
      "  Step 6, Current reward: 0.059964\n",
      "  Step 7, Current reward: 0.059964\n",
      "  Step 8, Current reward: 0.059964\n",
      "  Step 9, Current reward: 0.059964\n",
      "  Step 10, Current reward: 0.059964\n",
      "  Step 11, Current reward: 0.059964\n",
      "  Step 12, Current reward: 0.059964\n",
      "Episode 12/1000 complete - Max Reward: 0.059964\n",
      "Starting episode 13/1000\n",
      "  Step 1, Current reward: 0.003603\n",
      "  Step 2, Current reward: 0.003603\n",
      "  Step 3, Current reward: 0.003603\n",
      "  Step 4, Current reward: 0.003603\n",
      "  Step 5, Current reward: 0.003603\n",
      "  Step 6, Current reward: 0.003603\n",
      "  Step 7, Current reward: 0.003603\n",
      "  Step 8, Current reward: 0.003603\n",
      "  Step 9, Current reward: 0.003603\n",
      "  Step 10, Current reward: 0.003603\n",
      "  Step 11, Current reward: 0.003603\n",
      "  Step 12, Current reward: 0.003603\n",
      "Episode 13/1000 complete - Max Reward: 0.003603\n",
      "Starting episode 14/1000\n",
      "  Step 1, Current reward: 0.034064\n",
      "  Step 2, Current reward: 0.034064\n",
      "  Step 3, Current reward: 0.034064\n",
      "  Step 4, Current reward: 0.034064\n",
      "  Step 5, Current reward: 0.034064\n",
      "  Step 6, Current reward: 0.034064\n",
      "  Step 7, Current reward: 0.034064\n",
      "  Step 8, Current reward: 0.034064\n",
      "  Step 9, Current reward: 0.034064\n",
      "  Step 10, Current reward: 0.034064\n",
      "  Step 11, Current reward: 0.034064\n",
      "  Step 12, Current reward: 0.034064\n",
      "Episode 14/1000 complete - Max Reward: 0.034064\n",
      "Starting episode 15/1000\n",
      "  Step 1, Current reward: 0.015832\n",
      "  Step 2, Current reward: 0.015832\n",
      "  Step 3, Current reward: 0.015832\n",
      "  Step 4, Current reward: 0.015832\n",
      "  Step 5, Current reward: 0.015832\n",
      "  Step 6, Current reward: 0.015832\n",
      "  Step 7, Current reward: 0.015832\n",
      "  Step 8, Current reward: 0.015832\n",
      "  Step 9, Current reward: 0.015832\n",
      "  Step 10, Current reward: 0.015832\n",
      "  Step 11, Current reward: 0.015832\n",
      "  Step 12, Current reward: 0.015832\n",
      "Episode 15/1000 complete - Max Reward: 0.015832\n",
      "Starting episode 16/1000\n",
      "  Step 1, Current reward: 0.003603\n",
      "  Step 2, Current reward: 0.003603\n",
      "  Step 3, Current reward: 0.003603\n",
      "  Step 4, Current reward: 0.003603\n",
      "  Step 5, Current reward: 0.003603\n",
      "  Step 6, Current reward: 0.003603\n",
      "  Step 7, Current reward: 0.003603\n",
      "  Step 8, Current reward: 0.003603\n",
      "  Step 9, Current reward: 0.003603\n",
      "  Step 10, Current reward: 0.003603\n",
      "  Step 11, Current reward: 0.003603\n",
      "  Step 12, Current reward: 0.003603\n",
      "Episode 16/1000 complete - Max Reward: 0.003603\n",
      "Starting episode 17/1000\n",
      "  Step 1, Current reward: 0.007303\n",
      "  Step 2, Current reward: 0.007303\n",
      "  Step 3, Current reward: 0.007303\n",
      "  Step 4, Current reward: 0.007303\n",
      "  Step 5, Current reward: 0.007303\n",
      "  Step 6, Current reward: 0.007303\n",
      "  Step 7, Current reward: 0.007303\n",
      "  Step 8, Current reward: 0.007303\n",
      "  Step 9, Current reward: 0.007303\n",
      "  Step 10, Current reward: 0.007303\n",
      "  Step 11, Current reward: 0.007303\n",
      "  Step 12, Current reward: 0.007303\n",
      "Episode 17/1000 complete - Max Reward: 0.007303\n",
      "Starting episode 18/1000\n",
      "  Step 1, Current reward: 0.028199\n",
      "  Step 2, Current reward: 0.028199\n",
      "  Step 3, Current reward: 0.028199\n",
      "  Step 4, Current reward: 0.028199\n",
      "  Step 5, Current reward: 0.028199\n",
      "  Step 6, Current reward: 0.028199\n",
      "  Step 7, Current reward: 0.028199\n",
      "  Step 8, Current reward: 0.028199\n",
      "  Step 9, Current reward: 0.028199\n",
      "  Step 10, Current reward: 0.028199\n",
      "  Step 11, Current reward: 0.028199\n",
      "  Step 12, Current reward: 0.028199\n",
      "Episode 18/1000 complete - Max Reward: 0.028199\n",
      "Starting episode 19/1000\n",
      "  Step 1, Current reward: 0.182350\n",
      "  Step 2, Current reward: 0.182350\n",
      "  Step 3, Current reward: 0.182350\n",
      "  Step 4, Current reward: 0.182350\n",
      "  Step 5, Current reward: 0.182350\n",
      "  Step 6, Current reward: 0.182350\n",
      "  Step 7, Current reward: 0.182350\n",
      "  Step 8, Current reward: 0.182350\n",
      "  Step 9, Current reward: 0.182350\n",
      "  Step 10, Current reward: 0.182350\n",
      "  Step 11, Current reward: 0.182350\n",
      "  Step 12, Current reward: 0.182350\n",
      "Episode 19/1000 complete - Max Reward: 0.182350\n",
      "Starting episode 20/1000\n",
      "  Step 1, Current reward: 0.008724\n",
      "  Step 2, Current reward: 0.008724\n",
      "  Step 3, Current reward: 0.008724\n",
      "  Step 4, Current reward: 0.008724\n",
      "  Step 5, Current reward: 0.008724\n",
      "  Step 6, Current reward: 0.008724\n",
      "  Step 7, Current reward: 0.008724\n",
      "  Step 8, Current reward: 0.008724\n",
      "  Step 9, Current reward: 0.008724\n",
      "  Step 10, Current reward: 0.008724\n",
      "  Step 11, Current reward: 0.008724\n",
      "  Step 12, Current reward: 0.008724\n",
      "Episode 20/1000 complete - Max Reward: 0.008724\n",
      "Starting episode 21/1000\n",
      "  Step 1, Current reward: 0.020757\n",
      "  Step 2, Current reward: 0.020757\n",
      "  Step 3, Current reward: 0.020757\n",
      "  Step 4, Current reward: 0.020757\n",
      "  Step 5, Current reward: 0.020757\n",
      "  Step 6, Current reward: 0.020757\n",
      "  Step 7, Current reward: 0.020757\n",
      "  Step 8, Current reward: 0.020757\n",
      "  Step 9, Current reward: 0.020757\n",
      "  Step 10, Current reward: 0.020757\n",
      "  Step 11, Current reward: 0.020757\n",
      "  Step 12, Current reward: 0.020757\n",
      "Episode 21/1000 complete - Max Reward: 0.020757\n",
      "Starting episode 22/1000\n",
      "  Step 1, Current reward: 0.005127\n",
      "  Step 2, Current reward: 0.005127\n",
      "  Step 3, Current reward: 0.005127\n",
      "  Step 4, Current reward: 0.005127\n",
      "  Step 5, Current reward: 0.005127\n",
      "  Step 6, Current reward: 0.005127\n",
      "  Step 7, Current reward: 0.005127\n",
      "  Step 8, Current reward: 0.005127\n",
      "  Step 9, Current reward: 0.005127\n",
      "  Step 10, Current reward: 0.005127\n",
      "  Step 11, Current reward: 0.005127\n",
      "  Step 12, Current reward: 0.005127\n",
      "Episode 22/1000 complete - Max Reward: 0.005127\n",
      "Starting episode 23/1000\n",
      "  Step 1, Current reward: 0.040828\n",
      "  Step 2, Current reward: 0.040828\n",
      "  Step 3, Current reward: 0.040828\n",
      "  Step 4, Current reward: 0.040828\n",
      "  Step 5, Current reward: 0.040828\n",
      "  Step 6, Current reward: 0.040828\n",
      "  Step 7, Current reward: 0.040828\n",
      "  Step 8, Current reward: 0.040828\n",
      "  Step 9, Current reward: 0.040828\n",
      "  Step 10, Current reward: 0.040828\n",
      "  Step 11, Current reward: 0.040828\n",
      "  Step 12, Current reward: 0.040828\n",
      "Episode 23/1000 complete - Max Reward: 0.040828\n",
      "Starting episode 24/1000\n",
      "  Step 1, Current reward: 0.009159\n",
      "  Step 2, Current reward: 0.009159\n",
      "  Step 3, Current reward: 0.009159\n",
      "  Step 4, Current reward: 0.009159\n",
      "  Step 5, Current reward: 0.009159\n",
      "  Step 6, Current reward: 0.009159\n",
      "  Step 7, Current reward: 0.009159\n",
      "  Step 8, Current reward: 0.009159\n",
      "  Step 9, Current reward: 0.009159\n",
      "  Step 10, Current reward: 0.009159\n",
      "  Step 11, Current reward: 0.009159\n",
      "  Step 12, Current reward: 0.009159\n",
      "Episode 24/1000 complete - Max Reward: 0.009159\n",
      "Starting episode 25/1000\n",
      "  Step 1, Current reward: 0.088026\n",
      "  Step 2, Current reward: 0.088026\n",
      "  Step 3, Current reward: 0.088026\n",
      "  Step 4, Current reward: 0.088026\n",
      "  Step 5, Current reward: 0.088026\n",
      "  Step 6, Current reward: 0.088026\n",
      "  Step 7, Current reward: 0.088026\n",
      "  Step 8, Current reward: 0.088026\n",
      "  Step 9, Current reward: 0.088026\n",
      "  Step 10, Current reward: 0.088026\n",
      "  Step 11, Current reward: 0.088026\n",
      "  Step 12, Current reward: 0.088026\n",
      "Episode 25/1000 complete - Max Reward: 0.088026\n",
      "Starting episode 26/1000\n",
      "  Step 1, Current reward: 0.047346\n",
      "  Step 2, Current reward: 0.047346\n",
      "  Step 3, Current reward: 0.047346\n",
      "  Step 4, Current reward: 0.047346\n",
      "  Step 5, Current reward: 0.047346\n",
      "  Step 6, Current reward: 0.047346\n",
      "  Step 7, Current reward: 0.047346\n",
      "  Step 8, Current reward: 0.047346\n",
      "  Step 9, Current reward: 0.047346\n",
      "  Step 10, Current reward: 0.047346\n",
      "  Step 11, Current reward: 0.047346\n",
      "  Step 12, Current reward: 0.047346\n",
      "Episode 26/1000 complete - Max Reward: 0.047346\n",
      "Starting episode 27/1000\n",
      "  Step 1, Current reward: 0.001498\n",
      "  Step 2, Current reward: 0.001498\n",
      "  Step 3, Current reward: 0.001498\n",
      "  Step 4, Current reward: 0.001498\n",
      "  Step 5, Current reward: 0.001498\n",
      "  Step 6, Current reward: 0.001498\n",
      "  Step 7, Current reward: 0.001498\n",
      "  Step 8, Current reward: 0.001498\n",
      "  Step 9, Current reward: 0.001498\n",
      "  Step 10, Current reward: 0.001498\n",
      "  Step 11, Current reward: 0.001498\n",
      "  Step 12, Current reward: 0.001498\n",
      "Episode 27/1000 complete - Max Reward: 0.001498\n",
      "Starting episode 28/1000\n",
      "  Step 1, Current reward: 0.004561\n",
      "  Step 2, Current reward: 0.004561\n",
      "  Step 3, Current reward: 0.004561\n",
      "  Step 4, Current reward: 0.004561\n",
      "  Step 5, Current reward: 0.004561\n",
      "  Step 6, Current reward: 0.004561\n",
      "  Step 7, Current reward: 0.004561\n",
      "  Step 8, Current reward: 0.004561\n",
      "  Step 9, Current reward: 0.004561\n",
      "  Step 10, Current reward: 0.004561\n",
      "  Step 11, Current reward: 0.004561\n",
      "  Step 12, Current reward: 0.004561\n",
      "Episode 28/1000 complete - Max Reward: 0.004561\n",
      "Starting episode 29/1000\n",
      "  Step 1, Current reward: 0.059876\n",
      "  Step 2, Current reward: 0.059876\n",
      "  Step 3, Current reward: 0.059876\n",
      "  Step 4, Current reward: 0.059876\n",
      "  Step 5, Current reward: 0.059876\n",
      "  Step 6, Current reward: 0.059876\n",
      "  Step 7, Current reward: 0.059876\n",
      "  Step 8, Current reward: 0.059876\n",
      "  Step 9, Current reward: 0.059876\n",
      "  Step 10, Current reward: 0.059876\n",
      "  Step 11, Current reward: 0.059876\n",
      "  Step 12, Current reward: 0.059876\n",
      "Episode 29/1000 complete - Max Reward: 0.059876\n",
      "Starting episode 30/1000\n",
      "  Step 1, Current reward: 0.031221\n",
      "  Step 2, Current reward: 0.031221\n",
      "  Step 3, Current reward: 0.031221\n",
      "  Step 4, Current reward: 0.031221\n",
      "  Step 5, Current reward: 0.031221\n",
      "  Step 6, Current reward: 0.031221\n",
      "  Step 7, Current reward: 0.031221\n",
      "  Step 8, Current reward: 0.031221\n",
      "  Step 9, Current reward: 0.031221\n",
      "  Step 10, Current reward: 0.031221\n",
      "  Step 11, Current reward: 0.031221\n",
      "  Step 12, Current reward: 0.031221\n",
      "Episode 30/1000 complete - Max Reward: 0.031221\n",
      "Starting episode 31/1000\n",
      "  Step 1, Current reward: 0.000729\n",
      "  Step 2, Current reward: 0.000729\n",
      "  Step 3, Current reward: 0.000729\n",
      "  Step 4, Current reward: 0.000729\n",
      "  Step 5, Current reward: 0.000729\n",
      "  Step 6, Current reward: 0.000729\n",
      "  Step 7, Current reward: 0.000729\n",
      "  Step 8, Current reward: 0.000729\n",
      "  Step 9, Current reward: 0.000729\n",
      "  Step 10, Current reward: 0.000729\n",
      "  Step 11, Current reward: 0.000729\n",
      "  Step 12, Current reward: 0.000729\n",
      "Episode 31/1000 complete - Max Reward: 0.000729\n",
      "Starting episode 32/1000\n",
      "  Step 1, Current reward: 0.157545\n",
      "  Step 2, Current reward: 0.157545\n",
      "  Step 3, Current reward: 0.157545\n",
      "  Step 4, Current reward: 0.157545\n",
      "  Step 5, Current reward: 0.157545\n",
      "  Step 6, Current reward: 0.157545\n",
      "  Step 7, Current reward: 0.157545\n",
      "  Step 8, Current reward: 0.157545\n",
      "  Step 9, Current reward: 0.157545\n",
      "  Step 10, Current reward: 0.157545\n",
      "  Step 11, Current reward: 0.157545\n",
      "  Step 12, Current reward: 0.157545\n",
      "Episode 32/1000 complete - Max Reward: 0.157545\n",
      "Starting episode 33/1000\n",
      "  Step 1, Current reward: 0.021702\n",
      "  Step 2, Current reward: 0.021702\n",
      "  Step 3, Current reward: 0.021702\n",
      "  Step 4, Current reward: 0.021702\n",
      "  Step 5, Current reward: 0.021702\n",
      "  Step 6, Current reward: 0.021702\n",
      "  Step 7, Current reward: 0.021702\n",
      "  Step 8, Current reward: 0.021702\n",
      "  Step 9, Current reward: 0.021702\n",
      "  Step 10, Current reward: 0.021702\n",
      "  Step 11, Current reward: 0.021702\n",
      "  Step 12, Current reward: 0.021702\n",
      "Episode 33/1000 complete - Max Reward: 0.021702\n",
      "Starting episode 34/1000\n",
      "  Step 1, Current reward: 0.001645\n",
      "  Step 2, Current reward: 0.001645\n",
      "  Step 3, Current reward: 0.001645\n",
      "  Step 4, Current reward: 0.001645\n",
      "  Step 5, Current reward: 0.001645\n",
      "  Step 6, Current reward: 0.001645\n",
      "  Step 7, Current reward: 0.001645\n",
      "  Step 8, Current reward: 0.001645\n",
      "  Step 9, Current reward: 0.001645\n",
      "  Step 10, Current reward: 0.001645\n",
      "  Step 11, Current reward: 0.001645\n",
      "  Step 12, Current reward: 0.001645\n",
      "Episode 34/1000 complete - Max Reward: 0.001645\n",
      "Starting episode 35/1000\n",
      "  Step 1, Current reward: 0.002358\n",
      "  Step 2, Current reward: 0.002358\n",
      "  Step 3, Current reward: 0.002358\n",
      "  Step 4, Current reward: 0.002358\n",
      "  Step 5, Current reward: 0.002358\n",
      "  Step 6, Current reward: 0.002358\n",
      "  Step 7, Current reward: 0.002358\n",
      "  Step 8, Current reward: 0.002358\n",
      "  Step 9, Current reward: 0.002358\n",
      "  Step 10, Current reward: 0.002358\n",
      "  Step 11, Current reward: 0.002358\n",
      "  Step 12, Current reward: 0.002358\n",
      "Episode 35/1000 complete - Max Reward: 0.002358\n",
      "Starting episode 36/1000\n",
      "  Step 1, Current reward: 0.098352\n",
      "  Step 2, Current reward: 0.098352\n",
      "  Step 3, Current reward: 0.098352\n",
      "  Step 4, Current reward: 0.098352\n",
      "  Step 5, Current reward: 0.098352\n",
      "  Step 6, Current reward: 0.098352\n",
      "  Step 7, Current reward: 0.098352\n",
      "  Step 8, Current reward: 0.098352\n",
      "  Step 9, Current reward: 0.098352\n",
      "  Step 10, Current reward: 0.098352\n",
      "  Step 11, Current reward: 0.098352\n",
      "  Step 12, Current reward: 0.098352\n",
      "Episode 36/1000 complete - Max Reward: 0.098352\n",
      "Starting episode 37/1000\n",
      "  Step 1, Current reward: 0.028001\n",
      "  Step 2, Current reward: 0.028001\n",
      "  Step 3, Current reward: 0.028001\n",
      "  Step 4, Current reward: 0.028001\n",
      "  Step 5, Current reward: 0.028001\n",
      "  Step 6, Current reward: 0.028001\n",
      "  Step 7, Current reward: 0.028001\n",
      "  Step 8, Current reward: 0.028001\n",
      "  Step 9, Current reward: 0.028001\n",
      "  Step 10, Current reward: 0.028001\n",
      "  Step 11, Current reward: 0.028001\n",
      "  Step 12, Current reward: 0.028001\n",
      "Episode 37/1000 complete - Max Reward: 0.028001\n",
      "Starting episode 38/1000\n",
      "  Step 1, Current reward: 0.175019\n",
      "  Step 2, Current reward: 0.175019\n",
      "  Step 3, Current reward: 0.175019\n",
      "  Step 4, Current reward: 0.175019\n",
      "  Step 5, Current reward: 0.175019\n",
      "  Step 6, Current reward: 0.175019\n",
      "  Step 7, Current reward: 0.175019\n",
      "  Step 8, Current reward: 0.175019\n",
      "  Step 9, Current reward: 0.175019\n",
      "  Step 10, Current reward: 0.175019\n",
      "  Step 11, Current reward: 0.175019\n",
      "  Step 12, Current reward: 0.175019\n",
      "Episode 38/1000 complete - Max Reward: 0.175019\n",
      "Starting episode 39/1000\n",
      "  Step 1, Current reward: 0.011938\n",
      "  Step 2, Current reward: 0.011938\n",
      "  Step 3, Current reward: 0.011938\n",
      "  Step 4, Current reward: 0.011938\n",
      "  Step 5, Current reward: 0.011938\n",
      "  Step 6, Current reward: 0.011938\n",
      "  Step 7, Current reward: 0.011938\n",
      "  Step 8, Current reward: 0.011938\n",
      "  Step 9, Current reward: 0.011938\n",
      "  Step 10, Current reward: 0.011938\n",
      "  Step 11, Current reward: 0.011938\n",
      "  Step 12, Current reward: 0.011938\n",
      "Episode 39/1000 complete - Max Reward: 0.011938\n",
      "Starting episode 40/1000\n",
      "  Step 1, Current reward: 0.007779\n",
      "  Step 2, Current reward: 0.007779\n",
      "  Step 3, Current reward: 0.007779\n",
      "  Step 4, Current reward: 0.007779\n",
      "  Step 5, Current reward: 0.007779\n",
      "  Step 6, Current reward: 0.007779\n",
      "  Step 7, Current reward: 0.007779\n",
      "  Step 8, Current reward: 0.007779\n",
      "  Step 9, Current reward: 0.007779\n",
      "  Step 10, Current reward: 0.007779\n",
      "  Step 11, Current reward: 0.007779\n",
      "  Step 12, Current reward: 0.007779\n",
      "Episode 40/1000 complete - Max Reward: 0.007779\n",
      "Starting episode 41/1000\n",
      "  Step 1, Current reward: 0.011006\n",
      "  Step 2, Current reward: 0.011006\n",
      "  Step 3, Current reward: 0.011006\n",
      "  Step 4, Current reward: 0.011006\n",
      "  Step 5, Current reward: 0.011006\n",
      "  Step 6, Current reward: 0.011006\n",
      "  Step 7, Current reward: 0.011006\n",
      "  Step 8, Current reward: 0.011006\n",
      "  Step 9, Current reward: 0.011006\n",
      "  Step 10, Current reward: 0.011006\n",
      "  Step 11, Current reward: 0.011006\n",
      "  Step 12, Current reward: 0.011006\n",
      "Episode 41/1000 complete - Max Reward: 0.011006\n",
      "Starting episode 42/1000\n",
      "  Step 1, Current reward: 0.054323\n",
      "  Step 2, Current reward: 0.057436\n",
      "  Step 3, Current reward: 0.060718\n",
      "  Step 4, Current reward: 0.064047\n",
      "  Step 5, Current reward: 0.064047\n",
      "  Step 6, Current reward: 0.064047\n",
      "  Step 7, Current reward: 0.064047\n",
      "  Step 8, Current reward: 0.064047\n",
      "  Step 9, Current reward: 0.064047\n",
      "  Step 10, Current reward: 0.064047\n",
      "  Step 11, Current reward: 0.064047\n",
      "  Step 12, Current reward: 0.064047\n",
      "  Step 13, Current reward: 0.064047\n",
      "  Step 14, Current reward: 0.064047\n",
      "  Step 15, Current reward: 0.064047\n",
      "Episode 42/1000 complete - Max Reward: 0.064047\n",
      "Starting episode 43/1000\n",
      "  Step 1, Current reward: 0.090891\n",
      "  Step 2, Current reward: 0.090891\n",
      "  Step 3, Current reward: 0.090891\n",
      "  Step 4, Current reward: 0.090891\n",
      "  Step 5, Current reward: 0.090891\n",
      "  Step 6, Current reward: 0.090891\n",
      "  Step 7, Current reward: 0.090891\n",
      "  Step 8, Current reward: 0.090891\n",
      "  Step 9, Current reward: 0.090891\n",
      "  Step 10, Current reward: 0.090891\n",
      "  Step 11, Current reward: 0.090891\n",
      "  Step 12, Current reward: 0.090891\n",
      "Episode 43/1000 complete - Max Reward: 0.090891\n",
      "Starting episode 44/1000\n",
      "  Step 1, Current reward: 0.022797\n",
      "  Step 2, Current reward: 0.022797\n",
      "  Step 3, Current reward: 0.022797\n",
      "  Step 4, Current reward: 0.022797\n",
      "  Step 5, Current reward: 0.022797\n",
      "  Step 6, Current reward: 0.022797\n",
      "  Step 7, Current reward: 0.022797\n",
      "  Step 8, Current reward: 0.022797\n",
      "  Step 9, Current reward: 0.022797\n",
      "  Step 10, Current reward: 0.022797\n",
      "  Step 11, Current reward: 0.022797\n",
      "  Step 12, Current reward: 0.022797\n",
      "Episode 44/1000 complete - Max Reward: 0.022797\n",
      "Starting episode 45/1000\n",
      "  Step 1, Current reward: 0.004678\n",
      "  Step 2, Current reward: 0.004678\n",
      "  Step 3, Current reward: 0.004678\n",
      "  Step 4, Current reward: 0.004678\n",
      "  Step 5, Current reward: 0.004678\n",
      "  Step 6, Current reward: 0.004678\n",
      "  Step 7, Current reward: 0.004678\n",
      "  Step 8, Current reward: 0.004678\n",
      "  Step 9, Current reward: 0.004678\n",
      "  Step 10, Current reward: 0.004678\n",
      "  Step 11, Current reward: 0.004678\n",
      "  Step 12, Current reward: 0.004678\n",
      "Episode 45/1000 complete - Max Reward: 0.004678\n",
      "Starting episode 46/1000\n",
      "  Step 1, Current reward: 0.008613\n",
      "  Step 2, Current reward: 0.008613\n",
      "  Step 3, Current reward: 0.008613\n",
      "  Step 4, Current reward: 0.008613\n",
      "  Step 5, Current reward: 0.008613\n",
      "  Step 6, Current reward: 0.008613\n",
      "  Step 7, Current reward: 0.008613\n",
      "  Step 8, Current reward: 0.008613\n",
      "  Step 9, Current reward: 0.008613\n",
      "  Step 10, Current reward: 0.008613\n",
      "  Step 11, Current reward: 0.008613\n",
      "  Step 12, Current reward: 0.008613\n",
      "Episode 46/1000 complete - Max Reward: 0.008613\n",
      "Starting episode 47/1000\n",
      "  Step 1, Current reward: 0.001380\n",
      "  Step 2, Current reward: 0.001380\n",
      "  Step 3, Current reward: 0.001380\n",
      "  Step 4, Current reward: 0.001380\n",
      "  Step 5, Current reward: 0.001380\n",
      "  Step 6, Current reward: 0.001380\n",
      "  Step 7, Current reward: 0.001380\n",
      "  Step 8, Current reward: 0.001380\n",
      "  Step 9, Current reward: 0.001380\n",
      "  Step 10, Current reward: 0.001380\n",
      "  Step 11, Current reward: 0.001380\n",
      "  Step 12, Current reward: 0.001380\n",
      "Episode 47/1000 complete - Max Reward: 0.001380\n",
      "Starting episode 48/1000\n",
      "  Step 1, Current reward: 0.035385\n",
      "  Step 2, Current reward: 0.035385\n",
      "  Step 3, Current reward: 0.035385\n",
      "  Step 4, Current reward: 0.035385\n",
      "  Step 5, Current reward: 0.035385\n",
      "  Step 6, Current reward: 0.035385\n",
      "  Step 7, Current reward: 0.035385\n",
      "  Step 8, Current reward: 0.035385\n",
      "  Step 9, Current reward: 0.035385\n",
      "  Step 10, Current reward: 0.035385\n",
      "  Step 11, Current reward: 0.035385\n",
      "  Step 12, Current reward: 0.035385\n",
      "Episode 48/1000 complete - Max Reward: 0.035385\n",
      "Starting episode 49/1000\n",
      "  Step 1, Current reward: 0.059763\n",
      "  Step 2, Current reward: 0.059763\n",
      "  Step 3, Current reward: 0.059763\n",
      "  Step 4, Current reward: 0.059763\n",
      "  Step 5, Current reward: 0.059763\n",
      "  Step 6, Current reward: 0.059763\n",
      "  Step 7, Current reward: 0.059763\n",
      "  Step 8, Current reward: 0.059763\n",
      "  Step 9, Current reward: 0.059763\n",
      "  Step 10, Current reward: 0.059763\n",
      "  Step 11, Current reward: 0.059763\n",
      "  Step 12, Current reward: 0.059763\n",
      "Episode 49/1000 complete - Max Reward: 0.059763\n",
      "Starting episode 50/1000\n",
      "  Step 1, Current reward: 0.038313\n",
      "  Step 2, Current reward: 0.038313\n",
      "  Step 3, Current reward: 0.038313\n",
      "  Step 4, Current reward: 0.038313\n",
      "  Step 5, Current reward: 0.038313\n",
      "  Step 6, Current reward: 0.038313\n",
      "  Step 7, Current reward: 0.038313\n",
      "  Step 8, Current reward: 0.038313\n",
      "  Step 9, Current reward: 0.038313\n",
      "  Step 10, Current reward: 0.038313\n",
      "  Step 11, Current reward: 0.038313\n",
      "  Step 12, Current reward: 0.038313\n",
      "Episode 50/1000 complete - Max Reward: 0.038313\n",
      "Starting episode 51/1000\n",
      "  Step 1, Current reward: 0.026605\n",
      "  Step 2, Current reward: 0.026605\n",
      "  Step 3, Current reward: 0.026605\n",
      "  Step 4, Current reward: 0.026605\n",
      "  Step 5, Current reward: 0.026605\n",
      "  Step 6, Current reward: 0.026605\n",
      "  Step 7, Current reward: 0.026605\n",
      "  Step 8, Current reward: 0.026605\n",
      "  Step 9, Current reward: 0.026605\n",
      "  Step 10, Current reward: 0.026605\n",
      "  Step 11, Current reward: 0.026605\n",
      "  Step 12, Current reward: 0.026605\n",
      "Episode 51/1000 complete - Max Reward: 0.026605\n",
      "Starting episode 52/1000\n",
      "  Step 1, Current reward: 0.013021\n",
      "  Step 2, Current reward: 0.014198\n",
      "  Step 3, Current reward: 0.015411\n",
      "  Step 4, Current reward: 0.015411\n",
      "  Step 5, Current reward: 0.015411\n",
      "  Step 6, Current reward: 0.015411\n",
      "  Step 7, Current reward: 0.015411\n",
      "  Step 8, Current reward: 0.015411\n",
      "  Step 9, Current reward: 0.015411\n",
      "  Step 10, Current reward: 0.015411\n",
      "  Step 11, Current reward: 0.015411\n",
      "  Step 12, Current reward: 0.015411\n",
      "  Step 13, Current reward: 0.015411\n",
      "  Step 14, Current reward: 0.015411\n",
      "Episode 52/1000 complete - Max Reward: 0.015411\n",
      "Starting episode 53/1000\n",
      "  Step 1, Current reward: 0.010312\n",
      "  Step 2, Current reward: 0.010312\n",
      "  Step 3, Current reward: 0.010312\n",
      "  Step 4, Current reward: 0.010312\n",
      "  Step 5, Current reward: 0.010312\n",
      "  Step 6, Current reward: 0.010312\n",
      "  Step 7, Current reward: 0.010312\n",
      "  Step 8, Current reward: 0.010312\n",
      "  Step 9, Current reward: 0.010312\n",
      "  Step 10, Current reward: 0.010312\n",
      "  Step 11, Current reward: 0.010312\n",
      "  Step 12, Current reward: 0.010312\n",
      "Episode 53/1000 complete - Max Reward: 0.010312\n",
      "Starting episode 54/1000\n",
      "  Step 1, Current reward: 0.067306\n",
      "  Step 2, Current reward: 0.067306\n",
      "  Step 3, Current reward: 0.067306\n",
      "  Step 4, Current reward: 0.067306\n",
      "  Step 5, Current reward: 0.067306\n",
      "  Step 6, Current reward: 0.067306\n",
      "  Step 7, Current reward: 0.067306\n",
      "  Step 8, Current reward: 0.067306\n",
      "  Step 9, Current reward: 0.067306\n",
      "  Step 10, Current reward: 0.067306\n",
      "  Step 11, Current reward: 0.067306\n",
      "  Step 12, Current reward: 0.067306\n",
      "Episode 54/1000 complete - Max Reward: 0.067306\n",
      "Starting episode 55/1000\n",
      "  Step 1, Current reward: 0.019078\n",
      "  Step 2, Current reward: 0.019078\n",
      "  Step 3, Current reward: 0.019078\n",
      "  Step 4, Current reward: 0.019078\n",
      "  Step 5, Current reward: 0.019078\n",
      "  Step 6, Current reward: 0.019078\n",
      "  Step 7, Current reward: 0.019078\n",
      "  Step 8, Current reward: 0.019078\n",
      "  Step 9, Current reward: 0.019078\n",
      "  Step 10, Current reward: 0.019078\n",
      "  Step 11, Current reward: 0.019078\n",
      "  Step 12, Current reward: 0.019078\n",
      "Episode 55/1000 complete - Max Reward: 0.019078\n",
      "Starting episode 56/1000\n",
      "  Step 1, Current reward: 0.027186\n",
      "  Step 2, Current reward: 0.027186\n",
      "  Step 3, Current reward: 0.027186\n",
      "  Step 4, Current reward: 0.027186\n",
      "  Step 5, Current reward: 0.027186\n",
      "  Step 6, Current reward: 0.027186\n",
      "  Step 7, Current reward: 0.027186\n",
      "  Step 8, Current reward: 0.027186\n",
      "  Step 9, Current reward: 0.027186\n",
      "  Step 10, Current reward: 0.027186\n",
      "  Step 11, Current reward: 0.027186\n",
      "  Step 12, Current reward: 0.027186\n",
      "Episode 56/1000 complete - Max Reward: 0.027186\n",
      "Starting episode 57/1000\n",
      "  Step 1, Current reward: 0.001064\n",
      "  Step 2, Current reward: 0.001064\n",
      "  Step 3, Current reward: 0.001064\n",
      "  Step 4, Current reward: 0.001064\n",
      "  Step 5, Current reward: 0.001064\n",
      "  Step 6, Current reward: 0.001064\n",
      "  Step 7, Current reward: 0.001064\n",
      "  Step 8, Current reward: 0.001064\n",
      "  Step 9, Current reward: 0.001064\n",
      "  Step 10, Current reward: 0.001064\n",
      "  Step 11, Current reward: 0.001064\n",
      "  Step 12, Current reward: 0.001064\n",
      "Episode 57/1000 complete - Max Reward: 0.001064\n",
      "Starting episode 58/1000\n",
      "  Step 1, Current reward: 0.011349\n",
      "  Step 2, Current reward: 0.011349\n",
      "  Step 3, Current reward: 0.011349\n",
      "  Step 4, Current reward: 0.011349\n",
      "  Step 5, Current reward: 0.011349\n",
      "  Step 6, Current reward: 0.011349\n",
      "  Step 7, Current reward: 0.011349\n",
      "  Step 8, Current reward: 0.011349\n",
      "  Step 9, Current reward: 0.011349\n",
      "  Step 10, Current reward: 0.011349\n",
      "  Step 11, Current reward: 0.011349\n",
      "  Step 12, Current reward: 0.011349\n",
      "Episode 58/1000 complete - Max Reward: 0.011349\n",
      "Starting episode 59/1000\n",
      "  Step 1, Current reward: 0.081302\n",
      "  Step 2, Current reward: 0.081302\n",
      "  Step 3, Current reward: 0.081302\n",
      "  Step 4, Current reward: 0.081302\n",
      "  Step 5, Current reward: 0.081302\n",
      "  Step 6, Current reward: 0.081302\n",
      "  Step 7, Current reward: 0.081302\n",
      "  Step 8, Current reward: 0.081302\n",
      "  Step 9, Current reward: 0.081302\n",
      "  Step 10, Current reward: 0.081302\n",
      "  Step 11, Current reward: 0.081302\n",
      "  Step 12, Current reward: 0.081302\n",
      "Episode 59/1000 complete - Max Reward: 0.081302\n",
      "Starting episode 60/1000\n",
      "  Step 1, Current reward: 0.000782\n",
      "  Step 2, Current reward: 0.000782\n",
      "  Step 3, Current reward: 0.000782\n",
      "  Step 4, Current reward: 0.000782\n",
      "  Step 5, Current reward: 0.000782\n",
      "  Step 6, Current reward: 0.000782\n",
      "  Step 7, Current reward: 0.000782\n",
      "  Step 8, Current reward: 0.000782\n",
      "  Step 9, Current reward: 0.000782\n",
      "  Step 10, Current reward: 0.000782\n",
      "  Step 11, Current reward: 0.000782\n",
      "  Step 12, Current reward: 0.000782\n",
      "Episode 60/1000 complete - Max Reward: 0.000782\n",
      "Starting episode 61/1000\n",
      "  Step 1, Current reward: 0.007660\n",
      "  Step 2, Current reward: 0.007660\n",
      "  Step 3, Current reward: 0.007660\n",
      "  Step 4, Current reward: 0.007660\n",
      "  Step 5, Current reward: 0.007660\n",
      "  Step 6, Current reward: 0.007660\n",
      "  Step 7, Current reward: 0.007660\n",
      "  Step 8, Current reward: 0.007660\n",
      "  Step 9, Current reward: 0.007660\n",
      "  Step 10, Current reward: 0.007660\n",
      "  Step 11, Current reward: 0.007660\n",
      "  Step 12, Current reward: 0.007660\n",
      "Episode 61/1000 complete - Max Reward: 0.007660\n",
      "Starting episode 62/1000\n",
      "  Step 1, Current reward: 0.085949\n",
      "  Step 2, Current reward: 0.085949\n",
      "  Step 3, Current reward: 0.085949\n",
      "  Step 4, Current reward: 0.085949\n",
      "  Step 5, Current reward: 0.085949\n",
      "  Step 6, Current reward: 0.085949\n",
      "  Step 7, Current reward: 0.085949\n",
      "  Step 8, Current reward: 0.085949\n",
      "  Step 9, Current reward: 0.085949\n",
      "  Step 10, Current reward: 0.085949\n",
      "  Step 11, Current reward: 0.085949\n",
      "  Step 12, Current reward: 0.085949\n",
      "Episode 62/1000 complete - Max Reward: 0.085949\n",
      "Starting episode 63/1000\n",
      "  Step 1, Current reward: 0.007458\n",
      "  Step 2, Current reward: 0.007458\n",
      "  Step 3, Current reward: 0.007458\n",
      "  Step 4, Current reward: 0.007458\n",
      "  Step 5, Current reward: 0.007458\n",
      "  Step 6, Current reward: 0.007458\n",
      "  Step 7, Current reward: 0.007458\n",
      "  Step 8, Current reward: 0.007458\n",
      "  Step 9, Current reward: 0.007458\n",
      "  Step 10, Current reward: 0.007458\n",
      "  Step 11, Current reward: 0.007458\n",
      "  Step 12, Current reward: 0.007458\n",
      "Episode 63/1000 complete - Max Reward: 0.007458\n",
      "Starting episode 64/1000\n",
      "  Step 1, Current reward: 0.050529\n",
      "  Step 2, Current reward: 0.050529\n",
      "  Step 3, Current reward: 0.050529\n",
      "  Step 4, Current reward: 0.050529\n",
      "  Step 5, Current reward: 0.050529\n",
      "  Step 6, Current reward: 0.050529\n",
      "  Step 7, Current reward: 0.050529\n",
      "  Step 8, Current reward: 0.050529\n",
      "  Step 9, Current reward: 0.050529\n",
      "  Step 10, Current reward: 0.050529\n",
      "  Step 11, Current reward: 0.050529\n",
      "  Step 12, Current reward: 0.050529\n",
      "Episode 64/1000 complete - Max Reward: 0.050529\n",
      "Starting episode 65/1000\n",
      "  Step 1, Current reward: 0.003510\n",
      "  Step 2, Current reward: 0.003510\n",
      "  Step 3, Current reward: 0.003510\n",
      "  Step 4, Current reward: 0.003510\n",
      "  Step 5, Current reward: 0.003510\n",
      "  Step 6, Current reward: 0.003510\n",
      "  Step 7, Current reward: 0.003510\n",
      "  Step 8, Current reward: 0.003510\n",
      "  Step 9, Current reward: 0.003510\n",
      "  Step 10, Current reward: 0.003510\n",
      "  Step 11, Current reward: 0.003510\n",
      "  Step 12, Current reward: 0.003510\n",
      "Episode 65/1000 complete - Max Reward: 0.003510\n",
      "Starting episode 66/1000\n",
      "  Step 1, Current reward: 0.021224\n",
      "  Step 2, Current reward: 0.022220\n",
      "  Step 3, Current reward: 0.023135\n",
      "  Step 4, Current reward: 0.023943\n",
      "  Step 5, Current reward: 0.024584\n",
      "  Step 6, Current reward: 0.024956\n",
      "  Step 7, Current reward: 0.024939\n",
      "  Step 8, Current reward: 0.024532\n",
      "  Step 9, Current reward: 0.024532\n",
      "  Step 10, Current reward: 0.024532\n",
      "  Step 11, Current reward: 0.024532\n",
      "  Step 12, Current reward: 0.024532\n",
      "  Step 13, Current reward: 0.024532\n",
      "  Step 14, Current reward: 0.024532\n",
      "  Step 15, Current reward: 0.024532\n",
      "  Step 16, Current reward: 0.024532\n",
      "  Step 17, Current reward: 0.024532\n",
      "Episode 66/1000 complete - Max Reward: 0.024956\n",
      "Starting episode 67/1000\n",
      "  Step 1, Current reward: 0.078667\n",
      "  Step 2, Current reward: 0.078667\n",
      "  Step 3, Current reward: 0.078667\n",
      "  Step 4, Current reward: 0.078667\n",
      "  Step 5, Current reward: 0.078667\n",
      "  Step 6, Current reward: 0.078667\n",
      "  Step 7, Current reward: 0.078667\n",
      "  Step 8, Current reward: 0.078667\n",
      "  Step 9, Current reward: 0.078667\n",
      "  Step 10, Current reward: 0.078667\n",
      "  Step 11, Current reward: 0.078667\n",
      "  Step 12, Current reward: 0.078667\n",
      "Episode 67/1000 complete - Max Reward: 0.078667\n",
      "Starting episode 68/1000\n",
      "  Step 1, Current reward: 0.004322\n",
      "  Step 2, Current reward: 0.004322\n",
      "  Step 3, Current reward: 0.004322\n",
      "  Step 4, Current reward: 0.004322\n",
      "  Step 5, Current reward: 0.004322\n",
      "  Step 6, Current reward: 0.004322\n",
      "  Step 7, Current reward: 0.004322\n",
      "  Step 8, Current reward: 0.004322\n",
      "  Step 9, Current reward: 0.004322\n",
      "  Step 10, Current reward: 0.004322\n",
      "  Step 11, Current reward: 0.004322\n",
      "  Step 12, Current reward: 0.004322\n",
      "Episode 68/1000 complete - Max Reward: 0.004322\n",
      "Starting episode 69/1000\n",
      "  Step 1, Current reward: 0.025904\n",
      "  Step 2, Current reward: 0.025904\n",
      "  Step 3, Current reward: 0.025904\n",
      "  Step 4, Current reward: 0.025904\n",
      "  Step 5, Current reward: 0.025904\n",
      "  Step 6, Current reward: 0.025904\n",
      "  Step 7, Current reward: 0.025904\n",
      "  Step 8, Current reward: 0.025904\n",
      "  Step 9, Current reward: 0.025904\n",
      "  Step 10, Current reward: 0.025904\n",
      "  Step 11, Current reward: 0.025904\n",
      "  Step 12, Current reward: 0.025904\n",
      "Episode 69/1000 complete - Max Reward: 0.025904\n",
      "Starting episode 70/1000\n",
      "  Step 1, Current reward: 0.000755\n",
      "  Step 2, Current reward: 0.000755\n",
      "  Step 3, Current reward: 0.000755\n",
      "  Step 4, Current reward: 0.000755\n",
      "  Step 5, Current reward: 0.000755\n",
      "  Step 6, Current reward: 0.000755\n",
      "  Step 7, Current reward: 0.000755\n",
      "  Step 8, Current reward: 0.000755\n",
      "  Step 9, Current reward: 0.000755\n",
      "  Step 10, Current reward: 0.000755\n",
      "  Step 11, Current reward: 0.000755\n",
      "  Step 12, Current reward: 0.000755\n",
      "Episode 70/1000 complete - Max Reward: 0.000755\n",
      "Starting episode 71/1000\n",
      "  Step 1, Current reward: 0.029275\n",
      "  Step 2, Current reward: 0.029275\n",
      "  Step 3, Current reward: 0.029275\n",
      "  Step 4, Current reward: 0.029275\n",
      "  Step 5, Current reward: 0.029275\n",
      "  Step 6, Current reward: 0.029275\n",
      "  Step 7, Current reward: 0.029275\n",
      "  Step 8, Current reward: 0.029275\n",
      "  Step 9, Current reward: 0.029275\n",
      "  Step 10, Current reward: 0.029275\n",
      "  Step 11, Current reward: 0.029275\n",
      "  Step 12, Current reward: 0.029275\n",
      "Episode 71/1000 complete - Max Reward: 0.029275\n",
      "Starting episode 72/1000\n",
      "  Step 1, Current reward: 0.064545\n",
      "  Step 2, Current reward: 0.064545\n",
      "  Step 3, Current reward: 0.064545\n",
      "  Step 4, Current reward: 0.064545\n",
      "  Step 5, Current reward: 0.064545\n",
      "  Step 6, Current reward: 0.064545\n",
      "  Step 7, Current reward: 0.064545\n",
      "  Step 8, Current reward: 0.064545\n",
      "  Step 9, Current reward: 0.064545\n",
      "  Step 10, Current reward: 0.064545\n",
      "  Step 11, Current reward: 0.064545\n",
      "  Step 12, Current reward: 0.064545\n",
      "Episode 72/1000 complete - Max Reward: 0.064545\n",
      "Starting episode 73/1000\n",
      "  Step 1, Current reward: 0.052951\n",
      "  Step 2, Current reward: 0.052951\n",
      "  Step 3, Current reward: 0.052951\n",
      "  Step 4, Current reward: 0.052951\n",
      "  Step 5, Current reward: 0.052951\n",
      "  Step 6, Current reward: 0.052951\n",
      "  Step 7, Current reward: 0.052951\n",
      "  Step 8, Current reward: 0.052951\n",
      "  Step 9, Current reward: 0.052951\n",
      "  Step 10, Current reward: 0.052951\n",
      "  Step 11, Current reward: 0.052951\n",
      "  Step 12, Current reward: 0.052951\n",
      "Episode 73/1000 complete - Max Reward: 0.052951\n",
      "Starting episode 74/1000\n",
      "  Step 1, Current reward: 0.010899\n",
      "  Step 2, Current reward: 0.010899\n",
      "  Step 3, Current reward: 0.010899\n",
      "  Step 4, Current reward: 0.010899\n",
      "  Step 5, Current reward: 0.010899\n",
      "  Step 6, Current reward: 0.010899\n",
      "  Step 7, Current reward: 0.010899\n",
      "  Step 8, Current reward: 0.010899\n",
      "  Step 9, Current reward: 0.010899\n",
      "  Step 10, Current reward: 0.010899\n",
      "  Step 11, Current reward: 0.010899\n",
      "  Step 12, Current reward: 0.010899\n",
      "Episode 74/1000 complete - Max Reward: 0.010899\n",
      "Starting episode 75/1000\n",
      "  Step 1, Current reward: 0.041259\n",
      "  Step 2, Current reward: 0.041259\n",
      "  Step 3, Current reward: 0.041259\n",
      "  Step 4, Current reward: 0.041259\n",
      "  Step 5, Current reward: 0.041259\n",
      "  Step 6, Current reward: 0.041259\n",
      "  Step 7, Current reward: 0.041259\n",
      "  Step 8, Current reward: 0.041259\n",
      "  Step 9, Current reward: 0.041259\n",
      "  Step 10, Current reward: 0.041259\n",
      "  Step 11, Current reward: 0.041259\n",
      "  Step 12, Current reward: 0.041259\n",
      "Episode 75/1000 complete - Max Reward: 0.041259\n",
      "Starting episode 76/1000\n",
      "  Step 1, Current reward: 0.012980\n",
      "  Step 2, Current reward: 0.012980\n",
      "  Step 3, Current reward: 0.012980\n",
      "  Step 4, Current reward: 0.012980\n",
      "  Step 5, Current reward: 0.012980\n",
      "  Step 6, Current reward: 0.012980\n",
      "  Step 7, Current reward: 0.012980\n",
      "  Step 8, Current reward: 0.012980\n",
      "  Step 9, Current reward: 0.012980\n",
      "  Step 10, Current reward: 0.012980\n",
      "  Step 11, Current reward: 0.012980\n",
      "  Step 12, Current reward: 0.012980\n",
      "Episode 76/1000 complete - Max Reward: 0.012980\n",
      "Starting episode 77/1000\n",
      "  Step 1, Current reward: 0.181065\n",
      "  Step 2, Current reward: 0.181065\n",
      "  Step 3, Current reward: 0.181065\n",
      "  Step 4, Current reward: 0.181065\n",
      "  Step 5, Current reward: 0.181065\n",
      "  Step 6, Current reward: 0.181065\n",
      "  Step 7, Current reward: 0.181065\n",
      "  Step 8, Current reward: 0.181065\n",
      "  Step 9, Current reward: 0.181065\n",
      "  Step 10, Current reward: 0.181065\n",
      "  Step 11, Current reward: 0.181065\n",
      "  Step 12, Current reward: 0.181065\n",
      "Episode 77/1000 complete - Max Reward: 0.181065\n",
      "Starting episode 78/1000\n",
      "  Step 1, Current reward: 0.003371\n",
      "  Step 2, Current reward: 0.003371\n",
      "  Step 3, Current reward: 0.003371\n",
      "  Step 4, Current reward: 0.003371\n",
      "  Step 5, Current reward: 0.003371\n",
      "  Step 6, Current reward: 0.003371\n",
      "  Step 7, Current reward: 0.003371\n",
      "  Step 8, Current reward: 0.003371\n",
      "  Step 9, Current reward: 0.003371\n",
      "  Step 10, Current reward: 0.003371\n",
      "  Step 11, Current reward: 0.003371\n",
      "  Step 12, Current reward: 0.003371\n",
      "Episode 78/1000 complete - Max Reward: 0.003371\n",
      "Starting episode 79/1000\n",
      "  Step 1, Current reward: 0.028215\n",
      "  Step 2, Current reward: 0.028215\n",
      "  Step 3, Current reward: 0.028215\n",
      "  Step 4, Current reward: 0.028215\n",
      "  Step 5, Current reward: 0.028215\n",
      "  Step 6, Current reward: 0.028215\n",
      "  Step 7, Current reward: 0.028215\n",
      "  Step 8, Current reward: 0.028215\n",
      "  Step 9, Current reward: 0.028215\n",
      "  Step 10, Current reward: 0.028215\n",
      "  Step 11, Current reward: 0.028215\n",
      "  Step 12, Current reward: 0.028215\n",
      "Episode 79/1000 complete - Max Reward: 0.028215\n",
      "Starting episode 80/1000\n",
      "  Step 1, Current reward: 0.018824\n",
      "  Step 2, Current reward: 0.018824\n",
      "  Step 3, Current reward: 0.018824\n",
      "  Step 4, Current reward: 0.018824\n",
      "  Step 5, Current reward: 0.018824\n",
      "  Step 6, Current reward: 0.018824\n",
      "  Step 7, Current reward: 0.018824\n",
      "  Step 8, Current reward: 0.018824\n",
      "  Step 9, Current reward: 0.018824\n",
      "  Step 10, Current reward: 0.018824\n",
      "  Step 11, Current reward: 0.018824\n",
      "  Step 12, Current reward: 0.018824\n",
      "Episode 80/1000 complete - Max Reward: 0.018824\n",
      "Starting episode 81/1000\n",
      "  Step 1, Current reward: 0.021136\n",
      "  Step 2, Current reward: 0.021136\n",
      "  Step 3, Current reward: 0.021136\n",
      "  Step 4, Current reward: 0.021136\n",
      "  Step 5, Current reward: 0.021136\n",
      "  Step 6, Current reward: 0.021136\n",
      "  Step 7, Current reward: 0.021136\n",
      "  Step 8, Current reward: 0.021136\n",
      "  Step 9, Current reward: 0.021136\n",
      "  Step 10, Current reward: 0.021136\n",
      "  Step 11, Current reward: 0.021136\n",
      "  Step 12, Current reward: 0.021136\n",
      "Episode 81/1000 complete - Max Reward: 0.021136\n",
      "Starting episode 82/1000\n",
      "  Step 1, Current reward: 0.001725\n",
      "  Step 2, Current reward: 0.001725\n",
      "  Step 3, Current reward: 0.001725\n",
      "  Step 4, Current reward: 0.001725\n",
      "  Step 5, Current reward: 0.001725\n",
      "  Step 6, Current reward: 0.001725\n",
      "  Step 7, Current reward: 0.001725\n",
      "  Step 8, Current reward: 0.001725\n",
      "  Step 9, Current reward: 0.001725\n",
      "  Step 10, Current reward: 0.001725\n",
      "  Step 11, Current reward: 0.001725\n",
      "  Step 12, Current reward: 0.001725\n",
      "Episode 82/1000 complete - Max Reward: 0.001725\n",
      "Starting episode 83/1000\n",
      "  Step 1, Current reward: 0.001914\n",
      "  Step 2, Current reward: 0.001835\n",
      "  Step 3, Current reward: 0.001742\n",
      "  Step 4, Current reward: 0.001742\n",
      "  Step 5, Current reward: 0.001742\n",
      "  Step 6, Current reward: 0.001742\n",
      "  Step 7, Current reward: 0.001742\n",
      "  Step 8, Current reward: 0.001742\n",
      "  Step 9, Current reward: 0.001742\n",
      "  Step 10, Current reward: 0.001742\n",
      "  Step 11, Current reward: 0.001742\n",
      "  Step 12, Current reward: 0.001742\n",
      "Episode 83/1000 complete - Max Reward: 0.001914\n",
      "Starting episode 84/1000\n",
      "  Step 1, Current reward: 0.008639\n",
      "  Step 2, Current reward: 0.008639\n",
      "  Step 3, Current reward: 0.008639\n",
      "  Step 4, Current reward: 0.008639\n",
      "  Step 5, Current reward: 0.008639\n",
      "  Step 6, Current reward: 0.008639\n",
      "  Step 7, Current reward: 0.008639\n",
      "  Step 8, Current reward: 0.008639\n",
      "  Step 9, Current reward: 0.008639\n",
      "  Step 10, Current reward: 0.008639\n",
      "  Step 11, Current reward: 0.008639\n",
      "  Step 12, Current reward: 0.008639\n",
      "Episode 84/1000 complete - Max Reward: 0.008639\n",
      "Starting episode 85/1000\n",
      "  Step 1, Current reward: 0.008141\n",
      "  Step 2, Current reward: 0.008141\n",
      "  Step 3, Current reward: 0.008141\n",
      "  Step 4, Current reward: 0.008141\n",
      "  Step 5, Current reward: 0.008141\n",
      "  Step 6, Current reward: 0.008141\n",
      "  Step 7, Current reward: 0.008141\n",
      "  Step 8, Current reward: 0.008141\n",
      "  Step 9, Current reward: 0.008141\n",
      "  Step 10, Current reward: 0.008141\n",
      "  Step 11, Current reward: 0.008141\n",
      "  Step 12, Current reward: 0.008141\n",
      "Episode 85/1000 complete - Max Reward: 0.008141\n",
      "Starting episode 86/1000\n",
      "  Step 1, Current reward: 0.021770\n",
      "  Step 2, Current reward: 0.021770\n",
      "  Step 3, Current reward: 0.021770\n",
      "  Step 4, Current reward: 0.021770\n",
      "  Step 5, Current reward: 0.021770\n",
      "  Step 6, Current reward: 0.021770\n",
      "  Step 7, Current reward: 0.021770\n",
      "  Step 8, Current reward: 0.021770\n",
      "  Step 9, Current reward: 0.021770\n",
      "  Step 10, Current reward: 0.021770\n",
      "  Step 11, Current reward: 0.021770\n",
      "  Step 12, Current reward: 0.021770\n",
      "Episode 86/1000 complete - Max Reward: 0.021770\n",
      "Starting episode 87/1000\n",
      "  Step 1, Current reward: 0.001925\n",
      "  Step 2, Current reward: 0.001925\n",
      "  Step 3, Current reward: 0.001925\n",
      "  Step 4, Current reward: 0.001925\n",
      "  Step 5, Current reward: 0.001925\n",
      "  Step 6, Current reward: 0.001925\n",
      "  Step 7, Current reward: 0.001925\n",
      "  Step 8, Current reward: 0.001925\n",
      "  Step 9, Current reward: 0.001925\n",
      "  Step 10, Current reward: 0.001925\n",
      "  Step 11, Current reward: 0.001925\n",
      "  Step 12, Current reward: 0.001925\n",
      "Episode 87/1000 complete - Max Reward: 0.001925\n",
      "Starting episode 88/1000\n",
      "  Step 1, Current reward: 0.024081\n",
      "  Step 2, Current reward: 0.024081\n",
      "  Step 3, Current reward: 0.024081\n",
      "  Step 4, Current reward: 0.024081\n",
      "  Step 5, Current reward: 0.024081\n",
      "  Step 6, Current reward: 0.024081\n",
      "  Step 7, Current reward: 0.024081\n",
      "  Step 8, Current reward: 0.024081\n",
      "  Step 9, Current reward: 0.024081\n",
      "  Step 10, Current reward: 0.024081\n",
      "  Step 11, Current reward: 0.024081\n",
      "  Step 12, Current reward: 0.024081\n",
      "Episode 88/1000 complete - Max Reward: 0.024081\n",
      "Starting episode 89/1000\n",
      "  Step 1, Current reward: 0.072300\n",
      "  Step 2, Current reward: 0.072300\n",
      "  Step 3, Current reward: 0.072300\n",
      "  Step 4, Current reward: 0.072300\n",
      "  Step 5, Current reward: 0.072300\n",
      "  Step 6, Current reward: 0.072300\n",
      "  Step 7, Current reward: 0.072300\n",
      "  Step 8, Current reward: 0.072300\n",
      "  Step 9, Current reward: 0.072300\n",
      "  Step 10, Current reward: 0.072300\n",
      "  Step 11, Current reward: 0.072300\n",
      "  Step 12, Current reward: 0.072300\n",
      "Episode 89/1000 complete - Max Reward: 0.072300\n",
      "Starting episode 90/1000\n",
      "  Step 1, Current reward: 0.002327\n",
      "  Step 2, Current reward: 0.002781\n",
      "  Step 3, Current reward: 0.002781\n",
      "  Step 4, Current reward: 0.002781\n",
      "  Step 5, Current reward: 0.002781\n",
      "  Step 6, Current reward: 0.002781\n",
      "  Step 7, Current reward: 0.002781\n",
      "  Step 8, Current reward: 0.002781\n",
      "  Step 9, Current reward: 0.002781\n",
      "  Step 10, Current reward: 0.002781\n",
      "  Step 11, Current reward: 0.002781\n",
      "  Step 12, Current reward: 0.002781\n",
      "  Step 13, Current reward: 0.002781\n",
      "Episode 90/1000 complete - Max Reward: 0.002781\n",
      "Starting episode 91/1000\n",
      "  Step 1, Current reward: 0.005003\n",
      "  Step 2, Current reward: 0.005003\n",
      "  Step 3, Current reward: 0.005003\n",
      "  Step 4, Current reward: 0.005003\n",
      "  Step 5, Current reward: 0.005003\n",
      "  Step 6, Current reward: 0.005003\n",
      "  Step 7, Current reward: 0.005003\n",
      "  Step 8, Current reward: 0.005003\n",
      "  Step 9, Current reward: 0.005003\n",
      "  Step 10, Current reward: 0.005003\n",
      "  Step 11, Current reward: 0.005003\n",
      "  Step 12, Current reward: 0.005003\n",
      "Episode 91/1000 complete - Max Reward: 0.005003\n",
      "Starting episode 92/1000\n",
      "  Step 1, Current reward: 0.014381\n",
      "  Step 2, Current reward: 0.014381\n",
      "  Step 3, Current reward: 0.014381\n",
      "  Step 4, Current reward: 0.014381\n",
      "  Step 5, Current reward: 0.014381\n",
      "  Step 6, Current reward: 0.014381\n",
      "  Step 7, Current reward: 0.014381\n",
      "  Step 8, Current reward: 0.014381\n",
      "  Step 9, Current reward: 0.014381\n",
      "  Step 10, Current reward: 0.014381\n",
      "  Step 11, Current reward: 0.014381\n",
      "  Step 12, Current reward: 0.014381\n",
      "Episode 92/1000 complete - Max Reward: 0.014381\n",
      "Starting episode 93/1000\n",
      "  Step 1, Current reward: 0.016400\n",
      "  Step 2, Current reward: 0.016400\n",
      "  Step 3, Current reward: 0.016400\n",
      "  Step 4, Current reward: 0.016400\n",
      "  Step 5, Current reward: 0.016400\n",
      "  Step 6, Current reward: 0.016400\n",
      "  Step 7, Current reward: 0.016400\n",
      "  Step 8, Current reward: 0.016400\n",
      "  Step 9, Current reward: 0.016400\n",
      "  Step 10, Current reward: 0.016400\n",
      "  Step 11, Current reward: 0.016400\n",
      "  Step 12, Current reward: 0.016400\n",
      "Episode 93/1000 complete - Max Reward: 0.016400\n",
      "Starting episode 94/1000\n",
      "  Step 1, Current reward: 0.025394\n",
      "  Step 2, Current reward: 0.025394\n",
      "  Step 3, Current reward: 0.025394\n",
      "  Step 4, Current reward: 0.025394\n",
      "  Step 5, Current reward: 0.025394\n",
      "  Step 6, Current reward: 0.025394\n",
      "  Step 7, Current reward: 0.025394\n",
      "  Step 8, Current reward: 0.025394\n",
      "  Step 9, Current reward: 0.025394\n",
      "  Step 10, Current reward: 0.025394\n",
      "  Step 11, Current reward: 0.025394\n",
      "  Step 12, Current reward: 0.025394\n",
      "Episode 94/1000 complete - Max Reward: 0.025394\n",
      "Starting episode 95/1000\n",
      "  Step 1, Current reward: 0.000140\n",
      "  Step 2, Current reward: 0.000140\n",
      "  Step 3, Current reward: 0.000140\n",
      "  Step 4, Current reward: 0.000140\n",
      "  Step 5, Current reward: 0.000140\n",
      "  Step 6, Current reward: 0.000140\n",
      "  Step 7, Current reward: 0.000140\n",
      "  Step 8, Current reward: 0.000140\n",
      "  Step 9, Current reward: 0.000140\n",
      "  Step 10, Current reward: 0.000140\n",
      "  Step 11, Current reward: 0.000140\n",
      "  Step 12, Current reward: 0.000140\n",
      "Episode 95/1000 complete - Max Reward: 0.000140\n",
      "Starting episode 96/1000\n",
      "  Step 1, Current reward: 0.019712\n",
      "  Step 2, Current reward: 0.019712\n",
      "  Step 3, Current reward: 0.019712\n",
      "  Step 4, Current reward: 0.019712\n",
      "  Step 5, Current reward: 0.019712\n",
      "  Step 6, Current reward: 0.019712\n",
      "  Step 7, Current reward: 0.019712\n",
      "  Step 8, Current reward: 0.019712\n",
      "  Step 9, Current reward: 0.019712\n",
      "  Step 10, Current reward: 0.019712\n",
      "  Step 11, Current reward: 0.019712\n",
      "  Step 12, Current reward: 0.019712\n",
      "Episode 96/1000 complete - Max Reward: 0.019712\n",
      "Starting episode 97/1000\n",
      "  Step 1, Current reward: 0.027395\n",
      "  Step 2, Current reward: 0.027395\n",
      "  Step 3, Current reward: 0.027395\n",
      "  Step 4, Current reward: 0.027395\n",
      "  Step 5, Current reward: 0.027395\n",
      "  Step 6, Current reward: 0.027395\n",
      "  Step 7, Current reward: 0.027395\n",
      "  Step 8, Current reward: 0.027395\n",
      "  Step 9, Current reward: 0.027395\n",
      "  Step 10, Current reward: 0.027395\n",
      "  Step 11, Current reward: 0.027395\n",
      "  Step 12, Current reward: 0.027395\n",
      "Episode 97/1000 complete - Max Reward: 0.027395\n",
      "Starting episode 98/1000\n",
      "  Step 1, Current reward: 0.037248\n",
      "  Step 2, Current reward: 0.037248\n",
      "  Step 3, Current reward: 0.037248\n",
      "  Step 4, Current reward: 0.037248\n",
      "  Step 5, Current reward: 0.037248\n",
      "  Step 6, Current reward: 0.037248\n",
      "  Step 7, Current reward: 0.037248\n",
      "  Step 8, Current reward: 0.037248\n",
      "  Step 9, Current reward: 0.037248\n",
      "  Step 10, Current reward: 0.037248\n",
      "  Step 11, Current reward: 0.037248\n",
      "  Step 12, Current reward: 0.037248\n",
      "Episode 98/1000 complete - Max Reward: 0.037248\n",
      "Starting episode 99/1000\n",
      "  Step 1, Current reward: 0.001518\n",
      "  Step 2, Current reward: 0.001518\n",
      "  Step 3, Current reward: 0.001518\n",
      "  Step 4, Current reward: 0.001518\n",
      "  Step 5, Current reward: 0.001518\n",
      "  Step 6, Current reward: 0.001518\n",
      "  Step 7, Current reward: 0.001518\n",
      "  Step 8, Current reward: 0.001518\n",
      "  Step 9, Current reward: 0.001518\n",
      "  Step 10, Current reward: 0.001518\n",
      "  Step 11, Current reward: 0.001518\n",
      "  Step 12, Current reward: 0.001518\n",
      "Episode 99/1000 complete - Max Reward: 0.001518\n",
      "Starting episode 100/1000\n",
      "  Step 1, Current reward: 0.015091\n",
      "  Step 2, Current reward: 0.015091\n",
      "  Step 3, Current reward: 0.015091\n",
      "  Step 4, Current reward: 0.015091\n",
      "  Step 5, Current reward: 0.015091\n",
      "  Step 6, Current reward: 0.015091\n",
      "  Step 7, Current reward: 0.015091\n",
      "  Step 8, Current reward: 0.015091\n",
      "  Step 9, Current reward: 0.015091\n",
      "  Step 10, Current reward: 0.015091\n",
      "  Step 11, Current reward: 0.015091\n",
      "  Step 12, Current reward: 0.015091\n",
      "Episode 100/1000 complete - Max Reward: 0.015091\n",
      "Starting episode 101/1000\n",
      "  Step 1, Current reward: 0.002573\n",
      "  Step 2, Current reward: 0.002573\n",
      "  Step 3, Current reward: 0.002573\n",
      "  Step 4, Current reward: 0.002573\n",
      "  Step 5, Current reward: 0.002573\n",
      "  Step 6, Current reward: 0.002573\n",
      "  Step 7, Current reward: 0.002573\n",
      "  Step 8, Current reward: 0.002573\n",
      "  Step 9, Current reward: 0.002573\n",
      "  Step 10, Current reward: 0.002573\n",
      "  Step 11, Current reward: 0.002573\n",
      "  Step 12, Current reward: 0.002573\n",
      "Episode 101/1000 complete - Max Reward: 0.002573\n",
      "Starting episode 102/1000\n",
      "  Step 1, Current reward: 0.018701\n",
      "  Step 2, Current reward: 0.018701\n",
      "  Step 3, Current reward: 0.018701\n",
      "  Step 4, Current reward: 0.018701\n",
      "  Step 5, Current reward: 0.018701\n",
      "  Step 6, Current reward: 0.018701\n",
      "  Step 7, Current reward: 0.018701\n",
      "  Step 8, Current reward: 0.018701\n",
      "  Step 9, Current reward: 0.018701\n",
      "  Step 10, Current reward: 0.018701\n",
      "  Step 11, Current reward: 0.018701\n",
      "  Step 12, Current reward: 0.018701\n",
      "Episode 102/1000 complete - Max Reward: 0.018701\n",
      "Starting episode 103/1000\n",
      "  Step 1, Current reward: 0.073481\n",
      "  Step 2, Current reward: 0.073481\n",
      "  Step 3, Current reward: 0.073481\n",
      "  Step 4, Current reward: 0.073481\n",
      "  Step 5, Current reward: 0.073481\n",
      "  Step 6, Current reward: 0.073481\n",
      "  Step 7, Current reward: 0.073481\n",
      "  Step 8, Current reward: 0.073481\n",
      "  Step 9, Current reward: 0.073481\n",
      "  Step 10, Current reward: 0.073481\n",
      "  Step 11, Current reward: 0.073481\n",
      "  Step 12, Current reward: 0.073481\n",
      "Episode 103/1000 complete - Max Reward: 0.073481\n",
      "Starting episode 104/1000\n",
      "  Step 1, Current reward: 0.010525\n",
      "  Step 2, Current reward: 0.010525\n",
      "  Step 3, Current reward: 0.010525\n",
      "  Step 4, Current reward: 0.010525\n",
      "  Step 5, Current reward: 0.010525\n",
      "  Step 6, Current reward: 0.010525\n",
      "  Step 7, Current reward: 0.010525\n",
      "  Step 8, Current reward: 0.010525\n",
      "  Step 9, Current reward: 0.010525\n",
      "  Step 10, Current reward: 0.010525\n",
      "  Step 11, Current reward: 0.010525\n",
      "  Step 12, Current reward: 0.010525\n",
      "Episode 104/1000 complete - Max Reward: 0.010525\n",
      "Starting episode 105/1000\n",
      "  Step 1, Current reward: 0.017444\n",
      "  Step 2, Current reward: 0.017444\n",
      "  Step 3, Current reward: 0.017444\n",
      "  Step 4, Current reward: 0.017444\n",
      "  Step 5, Current reward: 0.017444\n",
      "  Step 6, Current reward: 0.017444\n",
      "  Step 7, Current reward: 0.017444\n",
      "  Step 8, Current reward: 0.017444\n",
      "  Step 9, Current reward: 0.017444\n",
      "  Step 10, Current reward: 0.017444\n",
      "  Step 11, Current reward: 0.017444\n",
      "  Step 12, Current reward: 0.017444\n",
      "Episode 105/1000 complete - Max Reward: 0.017444\n",
      "Starting episode 106/1000\n",
      "  Step 1, Current reward: 0.011706\n",
      "  Step 2, Current reward: 0.011706\n",
      "  Step 3, Current reward: 0.011706\n",
      "  Step 4, Current reward: 0.011706\n",
      "  Step 5, Current reward: 0.011706\n",
      "  Step 6, Current reward: 0.011706\n",
      "  Step 7, Current reward: 0.011706\n",
      "  Step 8, Current reward: 0.011706\n",
      "  Step 9, Current reward: 0.011706\n",
      "  Step 10, Current reward: 0.011706\n",
      "  Step 11, Current reward: 0.011706\n",
      "  Step 12, Current reward: 0.011706\n",
      "Episode 106/1000 complete - Max Reward: 0.011706\n",
      "Starting episode 107/1000\n",
      "  Step 1, Current reward: 0.007106\n",
      "  Step 2, Current reward: 0.007106\n",
      "  Step 3, Current reward: 0.007106\n",
      "  Step 4, Current reward: 0.007106\n",
      "  Step 5, Current reward: 0.007106\n",
      "  Step 6, Current reward: 0.007106\n",
      "  Step 7, Current reward: 0.007106\n",
      "  Step 8, Current reward: 0.007106\n",
      "  Step 9, Current reward: 0.007106\n",
      "  Step 10, Current reward: 0.007106\n",
      "  Step 11, Current reward: 0.007106\n",
      "  Step 12, Current reward: 0.007106\n",
      "Episode 107/1000 complete - Max Reward: 0.007106\n",
      "Starting episode 108/1000\n",
      "  Step 1, Current reward: 0.003064\n",
      "  Step 2, Current reward: 0.003064\n",
      "  Step 3, Current reward: 0.003064\n",
      "  Step 4, Current reward: 0.003064\n",
      "  Step 5, Current reward: 0.003064\n",
      "  Step 6, Current reward: 0.003064\n",
      "  Step 7, Current reward: 0.003064\n",
      "  Step 8, Current reward: 0.003064\n",
      "  Step 9, Current reward: 0.003064\n",
      "  Step 10, Current reward: 0.003064\n",
      "  Step 11, Current reward: 0.003064\n",
      "  Step 12, Current reward: 0.003064\n",
      "Episode 108/1000 complete - Max Reward: 0.003064\n",
      "Starting episode 109/1000\n",
      "  Step 1, Current reward: 0.016397\n",
      "  Step 2, Current reward: 0.016397\n",
      "  Step 3, Current reward: 0.016397\n",
      "  Step 4, Current reward: 0.016397\n",
      "  Step 5, Current reward: 0.016397\n",
      "  Step 6, Current reward: 0.016397\n",
      "  Step 7, Current reward: 0.016397\n",
      "  Step 8, Current reward: 0.016397\n",
      "  Step 9, Current reward: 0.016397\n",
      "  Step 10, Current reward: 0.016397\n",
      "  Step 11, Current reward: 0.016397\n",
      "  Step 12, Current reward: 0.016397\n",
      "Episode 109/1000 complete - Max Reward: 0.016397\n",
      "Starting episode 110/1000\n",
      "  Step 1, Current reward: 0.000984\n",
      "  Step 2, Current reward: 0.000984\n",
      "  Step 3, Current reward: 0.000984\n",
      "  Step 4, Current reward: 0.000984\n",
      "  Step 5, Current reward: 0.000984\n",
      "  Step 6, Current reward: 0.000984\n",
      "  Step 7, Current reward: 0.000984\n",
      "  Step 8, Current reward: 0.000984\n",
      "  Step 9, Current reward: 0.000984\n",
      "  Step 10, Current reward: 0.000984\n",
      "  Step 11, Current reward: 0.000984\n",
      "  Step 12, Current reward: 0.000984\n",
      "Episode 110/1000 complete - Max Reward: 0.000984\n",
      "Starting episode 111/1000\n",
      "  Step 1, Current reward: 0.011051\n",
      "  Step 2, Current reward: 0.011400\n",
      "  Step 3, Current reward: 0.011754\n",
      "  Step 4, Current reward: 0.012094\n",
      "  Step 5, Current reward: 0.012416\n",
      "  Step 6, Current reward: 0.012712\n",
      "  Step 7, Current reward: 0.012974\n",
      "  Step 8, Current reward: 0.012974\n",
      "  Step 9, Current reward: 0.012974\n",
      "  Step 10, Current reward: 0.012974\n",
      "  Step 11, Current reward: 0.012974\n",
      "  Step 12, Current reward: 0.012974\n",
      "  Step 13, Current reward: 0.012974\n",
      "  Step 14, Current reward: 0.012974\n",
      "  Step 15, Current reward: 0.012974\n",
      "  Step 16, Current reward: 0.012974\n",
      "  Step 17, Current reward: 0.012974\n",
      "  Step 18, Current reward: 0.012974\n",
      "Episode 111/1000 complete - Max Reward: 0.012974\n",
      "Starting episode 112/1000\n",
      "  Step 1, Current reward: 0.055867\n",
      "  Step 2, Current reward: 0.055867\n",
      "  Step 3, Current reward: 0.055867\n",
      "  Step 4, Current reward: 0.055867\n",
      "  Step 5, Current reward: 0.055867\n",
      "  Step 6, Current reward: 0.055867\n",
      "  Step 7, Current reward: 0.055867\n",
      "  Step 8, Current reward: 0.055867\n",
      "  Step 9, Current reward: 0.055867\n",
      "  Step 10, Current reward: 0.055867\n",
      "  Step 11, Current reward: 0.055867\n",
      "  Step 12, Current reward: 0.055867\n",
      "Episode 112/1000 complete - Max Reward: 0.055867\n",
      "Starting episode 113/1000\n",
      "  Step 1, Current reward: 0.007348\n",
      "  Step 2, Current reward: 0.007348\n",
      "  Step 3, Current reward: 0.007348\n",
      "  Step 4, Current reward: 0.007348\n",
      "  Step 5, Current reward: 0.007348\n",
      "  Step 6, Current reward: 0.007348\n",
      "  Step 7, Current reward: 0.007348\n",
      "  Step 8, Current reward: 0.007348\n",
      "  Step 9, Current reward: 0.007348\n",
      "  Step 10, Current reward: 0.007348\n",
      "  Step 11, Current reward: 0.007348\n",
      "  Step 12, Current reward: 0.007348\n",
      "Episode 113/1000 complete - Max Reward: 0.007348\n",
      "Starting episode 114/1000\n",
      "  Step 1, Current reward: 0.014448\n",
      "  Step 2, Current reward: 0.014448\n",
      "  Step 3, Current reward: 0.014448\n",
      "  Step 4, Current reward: 0.014448\n",
      "  Step 5, Current reward: 0.014448\n",
      "  Step 6, Current reward: 0.014448\n",
      "  Step 7, Current reward: 0.014448\n",
      "  Step 8, Current reward: 0.014448\n",
      "  Step 9, Current reward: 0.014448\n",
      "  Step 10, Current reward: 0.014448\n",
      "  Step 11, Current reward: 0.014448\n",
      "  Step 12, Current reward: 0.014448\n",
      "Episode 114/1000 complete - Max Reward: 0.014448\n",
      "Starting episode 115/1000\n",
      "  Step 1, Current reward: 0.003763\n",
      "  Step 2, Current reward: 0.003763\n",
      "  Step 3, Current reward: 0.003763\n",
      "  Step 4, Current reward: 0.003763\n",
      "  Step 5, Current reward: 0.003763\n",
      "  Step 6, Current reward: 0.003763\n",
      "  Step 7, Current reward: 0.003763\n",
      "  Step 8, Current reward: 0.003763\n",
      "  Step 9, Current reward: 0.003763\n",
      "  Step 10, Current reward: 0.003763\n",
      "  Step 11, Current reward: 0.003763\n",
      "  Step 12, Current reward: 0.003763\n",
      "Episode 115/1000 complete - Max Reward: 0.003763\n",
      "Starting episode 116/1000\n",
      "  Step 1, Current reward: 0.016628\n",
      "  Step 2, Current reward: 0.016628\n",
      "  Step 3, Current reward: 0.016628\n",
      "  Step 4, Current reward: 0.016628\n",
      "  Step 5, Current reward: 0.016628\n",
      "  Step 6, Current reward: 0.016628\n",
      "  Step 7, Current reward: 0.016628\n",
      "  Step 8, Current reward: 0.016628\n",
      "  Step 9, Current reward: 0.016628\n",
      "  Step 10, Current reward: 0.016628\n",
      "  Step 11, Current reward: 0.016628\n",
      "  Step 12, Current reward: 0.016628\n",
      "Episode 116/1000 complete - Max Reward: 0.016628\n",
      "Starting episode 117/1000\n",
      "  Step 1, Current reward: 0.001096\n",
      "  Step 2, Current reward: 0.001096\n",
      "  Step 3, Current reward: 0.001096\n",
      "  Step 4, Current reward: 0.001096\n",
      "  Step 5, Current reward: 0.001096\n",
      "  Step 6, Current reward: 0.001096\n",
      "  Step 7, Current reward: 0.001096\n",
      "  Step 8, Current reward: 0.001096\n",
      "  Step 9, Current reward: 0.001096\n",
      "  Step 10, Current reward: 0.001096\n",
      "  Step 11, Current reward: 0.001096\n",
      "  Step 12, Current reward: 0.001096\n",
      "Episode 117/1000 complete - Max Reward: 0.001096\n",
      "Starting episode 118/1000\n",
      "  Step 1, Current reward: 0.005989\n",
      "  Step 2, Current reward: 0.005989\n",
      "  Step 3, Current reward: 0.005989\n",
      "  Step 4, Current reward: 0.005989\n",
      "  Step 5, Current reward: 0.005989\n",
      "  Step 6, Current reward: 0.005989\n",
      "  Step 7, Current reward: 0.005989\n",
      "  Step 8, Current reward: 0.005989\n",
      "  Step 9, Current reward: 0.005989\n",
      "  Step 10, Current reward: 0.005989\n",
      "  Step 11, Current reward: 0.005989\n",
      "  Step 12, Current reward: 0.005989\n",
      "Episode 118/1000 complete - Max Reward: 0.005989\n",
      "Starting episode 119/1000\n",
      "  Step 1, Current reward: 0.000219\n",
      "  Step 2, Current reward: 0.000219\n",
      "  Step 3, Current reward: 0.000219\n",
      "  Step 4, Current reward: 0.000219\n",
      "  Step 5, Current reward: 0.000219\n",
      "  Step 6, Current reward: 0.000219\n",
      "  Step 7, Current reward: 0.000219\n",
      "  Step 8, Current reward: 0.000219\n",
      "  Step 9, Current reward: 0.000219\n",
      "  Step 10, Current reward: 0.000219\n",
      "  Step 11, Current reward: 0.000219\n",
      "  Step 12, Current reward: 0.000219\n",
      "Episode 119/1000 complete - Max Reward: 0.000219\n",
      "Starting episode 120/1000\n",
      "  Step 1, Current reward: 0.028274\n",
      "  Step 2, Current reward: 0.028274\n",
      "  Step 3, Current reward: 0.028274\n",
      "  Step 4, Current reward: 0.028274\n",
      "  Step 5, Current reward: 0.028274\n",
      "  Step 6, Current reward: 0.028274\n",
      "  Step 7, Current reward: 0.028274\n",
      "  Step 8, Current reward: 0.028274\n",
      "  Step 9, Current reward: 0.028274\n",
      "  Step 10, Current reward: 0.028274\n",
      "  Step 11, Current reward: 0.028274\n",
      "  Step 12, Current reward: 0.028274\n",
      "Episode 120/1000 complete - Max Reward: 0.028274\n",
      "Starting episode 121/1000\n",
      "  Step 1, Current reward: 0.000913\n",
      "  Step 2, Current reward: 0.000913\n",
      "  Step 3, Current reward: 0.000913\n",
      "  Step 4, Current reward: 0.000913\n",
      "  Step 5, Current reward: 0.000913\n",
      "  Step 6, Current reward: 0.000913\n",
      "  Step 7, Current reward: 0.000913\n",
      "  Step 8, Current reward: 0.000913\n",
      "  Step 9, Current reward: 0.000913\n",
      "  Step 10, Current reward: 0.000913\n",
      "  Step 11, Current reward: 0.000913\n",
      "  Step 12, Current reward: 0.000913\n",
      "Episode 121/1000 complete - Max Reward: 0.000913\n",
      "Starting episode 122/1000\n",
      "  Step 1, Current reward: 0.000571\n",
      "  Step 2, Current reward: 0.000571\n",
      "  Step 3, Current reward: 0.000571\n",
      "  Step 4, Current reward: 0.000571\n",
      "  Step 5, Current reward: 0.000571\n",
      "  Step 6, Current reward: 0.000571\n",
      "  Step 7, Current reward: 0.000571\n",
      "  Step 8, Current reward: 0.000571\n",
      "  Step 9, Current reward: 0.000571\n",
      "  Step 10, Current reward: 0.000571\n",
      "  Step 11, Current reward: 0.000571\n",
      "  Step 12, Current reward: 0.000571\n",
      "Episode 122/1000 complete - Max Reward: 0.000571\n",
      "Starting episode 123/1000\n",
      "  Step 1, Current reward: 0.004575\n",
      "  Step 2, Current reward: 0.004575\n",
      "  Step 3, Current reward: 0.004575\n",
      "  Step 4, Current reward: 0.004575\n",
      "  Step 5, Current reward: 0.004575\n",
      "  Step 6, Current reward: 0.004575\n",
      "  Step 7, Current reward: 0.004575\n",
      "  Step 8, Current reward: 0.004575\n",
      "  Step 9, Current reward: 0.004575\n",
      "  Step 10, Current reward: 0.004575\n",
      "  Step 11, Current reward: 0.004575\n",
      "  Step 12, Current reward: 0.004575\n",
      "Episode 123/1000 complete - Max Reward: 0.004575\n",
      "Starting episode 124/1000\n",
      "  Step 1, Current reward: 0.003028\n",
      "  Step 2, Current reward: 0.003028\n",
      "  Step 3, Current reward: 0.003028\n",
      "  Step 4, Current reward: 0.003028\n",
      "  Step 5, Current reward: 0.003028\n",
      "  Step 6, Current reward: 0.003028\n",
      "  Step 7, Current reward: 0.003028\n",
      "  Step 8, Current reward: 0.003028\n",
      "  Step 9, Current reward: 0.003028\n",
      "  Step 10, Current reward: 0.003028\n",
      "  Step 11, Current reward: 0.003028\n",
      "  Step 12, Current reward: 0.003028\n",
      "Episode 124/1000 complete - Max Reward: 0.003028\n",
      "Starting episode 125/1000\n",
      "  Step 1, Current reward: 0.008091\n",
      "  Step 2, Current reward: 0.008091\n",
      "  Step 3, Current reward: 0.008091\n",
      "  Step 4, Current reward: 0.008091\n",
      "  Step 5, Current reward: 0.008091\n",
      "  Step 6, Current reward: 0.008091\n",
      "  Step 7, Current reward: 0.008091\n",
      "  Step 8, Current reward: 0.008091\n",
      "  Step 9, Current reward: 0.008091\n",
      "  Step 10, Current reward: 0.008091\n",
      "  Step 11, Current reward: 0.008091\n",
      "  Step 12, Current reward: 0.008091\n",
      "Episode 125/1000 complete - Max Reward: 0.008091\n",
      "Starting episode 126/1000\n",
      "  Step 1, Current reward: 0.024460\n",
      "  Step 2, Current reward: 0.024460\n",
      "  Step 3, Current reward: 0.024460\n",
      "  Step 4, Current reward: 0.024460\n",
      "  Step 5, Current reward: 0.024460\n",
      "  Step 6, Current reward: 0.024460\n",
      "  Step 7, Current reward: 0.024460\n",
      "  Step 8, Current reward: 0.024460\n",
      "  Step 9, Current reward: 0.024460\n",
      "  Step 10, Current reward: 0.024460\n",
      "  Step 11, Current reward: 0.024460\n",
      "  Step 12, Current reward: 0.024460\n",
      "Episode 126/1000 complete - Max Reward: 0.024460\n",
      "Starting episode 127/1000\n",
      "  Step 1, Current reward: 0.052657\n",
      "  Step 2, Current reward: 0.052657\n",
      "  Step 3, Current reward: 0.052657\n",
      "  Step 4, Current reward: 0.052657\n",
      "  Step 5, Current reward: 0.052657\n",
      "  Step 6, Current reward: 0.052657\n",
      "  Step 7, Current reward: 0.052657\n",
      "  Step 8, Current reward: 0.052657\n",
      "  Step 9, Current reward: 0.052657\n",
      "  Step 10, Current reward: 0.052657\n",
      "  Step 11, Current reward: 0.052657\n",
      "  Step 12, Current reward: 0.052657\n",
      "Episode 127/1000 complete - Max Reward: 0.052657\n",
      "Starting episode 128/1000\n",
      "  Step 1, Current reward: 0.005485\n",
      "  Step 2, Current reward: 0.005485\n",
      "  Step 3, Current reward: 0.005485\n",
      "  Step 4, Current reward: 0.005485\n",
      "  Step 5, Current reward: 0.005485\n",
      "  Step 6, Current reward: 0.005485\n",
      "  Step 7, Current reward: 0.005485\n",
      "  Step 8, Current reward: 0.005485\n",
      "  Step 9, Current reward: 0.005485\n",
      "  Step 10, Current reward: 0.005485\n",
      "  Step 11, Current reward: 0.005485\n",
      "  Step 12, Current reward: 0.005485\n",
      "Episode 128/1000 complete - Max Reward: 0.005485\n",
      "Starting episode 129/1000\n",
      "  Step 1, Current reward: 0.003653\n",
      "  Step 2, Current reward: 0.003653\n",
      "  Step 3, Current reward: 0.003653\n",
      "  Step 4, Current reward: 0.003653\n",
      "  Step 5, Current reward: 0.003653\n",
      "  Step 6, Current reward: 0.003653\n",
      "  Step 7, Current reward: 0.003653\n",
      "  Step 8, Current reward: 0.003653\n",
      "  Step 9, Current reward: 0.003653\n",
      "  Step 10, Current reward: 0.003653\n",
      "  Step 11, Current reward: 0.003653\n",
      "  Step 12, Current reward: 0.003653\n",
      "Episode 129/1000 complete - Max Reward: 0.003653\n",
      "Starting episode 130/1000\n",
      "  Step 1, Current reward: 0.000358\n",
      "  Step 2, Current reward: 0.000358\n",
      "  Step 3, Current reward: 0.000358\n",
      "  Step 4, Current reward: 0.000358\n",
      "  Step 5, Current reward: 0.000358\n",
      "  Step 6, Current reward: 0.000358\n",
      "  Step 7, Current reward: 0.000358\n",
      "  Step 8, Current reward: 0.000358\n",
      "  Step 9, Current reward: 0.000358\n",
      "  Step 10, Current reward: 0.000358\n",
      "  Step 11, Current reward: 0.000358\n",
      "  Step 12, Current reward: 0.000358\n",
      "Episode 130/1000 complete - Max Reward: 0.000358\n",
      "Starting episode 131/1000\n",
      "  Step 1, Current reward: 0.002656\n",
      "  Step 2, Current reward: 0.002656\n",
      "  Step 3, Current reward: 0.002656\n",
      "  Step 4, Current reward: 0.002656\n",
      "  Step 5, Current reward: 0.002656\n",
      "  Step 6, Current reward: 0.002656\n",
      "  Step 7, Current reward: 0.002656\n",
      "  Step 8, Current reward: 0.002656\n",
      "  Step 9, Current reward: 0.002656\n",
      "  Step 10, Current reward: 0.002656\n",
      "  Step 11, Current reward: 0.002656\n",
      "  Step 12, Current reward: 0.002656\n",
      "Episode 131/1000 complete - Max Reward: 0.002656\n",
      "Starting episode 132/1000\n",
      "  Step 1, Current reward: 0.006506\n",
      "  Step 2, Current reward: 0.006506\n",
      "  Step 3, Current reward: 0.006506\n",
      "  Step 4, Current reward: 0.006506\n",
      "  Step 5, Current reward: 0.006506\n",
      "  Step 6, Current reward: 0.006506\n",
      "  Step 7, Current reward: 0.006506\n",
      "  Step 8, Current reward: 0.006506\n",
      "  Step 9, Current reward: 0.006506\n",
      "  Step 10, Current reward: 0.006506\n",
      "  Step 11, Current reward: 0.006506\n",
      "  Step 12, Current reward: 0.006506\n",
      "Episode 132/1000 complete - Max Reward: 0.006506\n",
      "Starting episode 133/1000\n",
      "  Step 1, Current reward: 0.003859\n",
      "  Step 2, Current reward: 0.003859\n",
      "  Step 3, Current reward: 0.003859\n",
      "  Step 4, Current reward: 0.003859\n",
      "  Step 5, Current reward: 0.003859\n",
      "  Step 6, Current reward: 0.003859\n",
      "  Step 7, Current reward: 0.003859\n",
      "  Step 8, Current reward: 0.003859\n",
      "  Step 9, Current reward: 0.003859\n",
      "  Step 10, Current reward: 0.003859\n",
      "  Step 11, Current reward: 0.003859\n",
      "  Step 12, Current reward: 0.003859\n",
      "Episode 133/1000 complete - Max Reward: 0.003859\n",
      "Starting episode 134/1000\n",
      "  Step 1, Current reward: 0.006508\n",
      "  Step 2, Current reward: 0.006508\n",
      "  Step 3, Current reward: 0.006508\n",
      "  Step 4, Current reward: 0.006508\n",
      "  Step 5, Current reward: 0.006508\n",
      "  Step 6, Current reward: 0.006508\n",
      "  Step 7, Current reward: 0.006508\n",
      "  Step 8, Current reward: 0.006508\n",
      "  Step 9, Current reward: 0.006508\n",
      "  Step 10, Current reward: 0.006508\n",
      "  Step 11, Current reward: 0.006508\n",
      "  Step 12, Current reward: 0.006508\n",
      "Episode 134/1000 complete - Max Reward: 0.006508\n",
      "Starting episode 135/1000\n",
      "  Step 1, Current reward: 0.128520\n",
      "  Step 2, Current reward: 0.128520\n",
      "  Step 3, Current reward: 0.128520\n",
      "  Step 4, Current reward: 0.128520\n",
      "  Step 5, Current reward: 0.128520\n",
      "  Step 6, Current reward: 0.128520\n",
      "  Step 7, Current reward: 0.128520\n",
      "  Step 8, Current reward: 0.128520\n",
      "  Step 9, Current reward: 0.128520\n",
      "  Step 10, Current reward: 0.128520\n",
      "  Step 11, Current reward: 0.128520\n",
      "  Step 12, Current reward: 0.128520\n",
      "Episode 135/1000 complete - Max Reward: 0.128520\n",
      "Starting episode 136/1000\n",
      "  Step 1, Current reward: 0.004999\n",
      "  Step 2, Current reward: 0.004999\n",
      "  Step 3, Current reward: 0.004999\n",
      "  Step 4, Current reward: 0.004999\n",
      "  Step 5, Current reward: 0.004999\n",
      "  Step 6, Current reward: 0.004999\n",
      "  Step 7, Current reward: 0.004999\n",
      "  Step 8, Current reward: 0.004999\n",
      "  Step 9, Current reward: 0.004999\n",
      "  Step 10, Current reward: 0.004999\n",
      "  Step 11, Current reward: 0.004999\n",
      "  Step 12, Current reward: 0.004999\n",
      "Episode 136/1000 complete - Max Reward: 0.004999\n",
      "Starting episode 137/1000\n",
      "  Step 1, Current reward: 0.001846\n",
      "  Step 2, Current reward: 0.001846\n",
      "  Step 3, Current reward: 0.001846\n",
      "  Step 4, Current reward: 0.001846\n",
      "  Step 5, Current reward: 0.001846\n",
      "  Step 6, Current reward: 0.001846\n",
      "  Step 7, Current reward: 0.001846\n",
      "  Step 8, Current reward: 0.001846\n",
      "  Step 9, Current reward: 0.001846\n",
      "  Step 10, Current reward: 0.001846\n",
      "  Step 11, Current reward: 0.001846\n",
      "  Step 12, Current reward: 0.001846\n",
      "Episode 137/1000 complete - Max Reward: 0.001846\n",
      "Starting episode 138/1000\n",
      "  Step 1, Current reward: 0.001014\n",
      "  Step 2, Current reward: 0.001014\n",
      "  Step 3, Current reward: 0.001014\n",
      "  Step 4, Current reward: 0.001014\n",
      "  Step 5, Current reward: 0.001014\n",
      "  Step 6, Current reward: 0.001014\n",
      "  Step 7, Current reward: 0.001014\n",
      "  Step 8, Current reward: 0.001014\n",
      "  Step 9, Current reward: 0.001014\n",
      "  Step 10, Current reward: 0.001014\n",
      "  Step 11, Current reward: 0.001014\n",
      "  Step 12, Current reward: 0.001014\n",
      "Episode 138/1000 complete - Max Reward: 0.001014\n",
      "Starting episode 139/1000\n",
      "  Step 1, Current reward: 0.062582\n",
      "  Step 2, Current reward: 0.062582\n",
      "  Step 3, Current reward: 0.062582\n",
      "  Step 4, Current reward: 0.062582\n",
      "  Step 5, Current reward: 0.062582\n",
      "  Step 6, Current reward: 0.062582\n",
      "  Step 7, Current reward: 0.062582\n",
      "  Step 8, Current reward: 0.062582\n",
      "  Step 9, Current reward: 0.062582\n",
      "  Step 10, Current reward: 0.062582\n",
      "  Step 11, Current reward: 0.062582\n",
      "  Step 12, Current reward: 0.062582\n",
      "Episode 139/1000 complete - Max Reward: 0.062582\n",
      "Starting episode 140/1000\n",
      "  Step 1, Current reward: 0.028482\n",
      "  Step 2, Current reward: 0.028482\n",
      "  Step 3, Current reward: 0.028482\n",
      "  Step 4, Current reward: 0.028482\n",
      "  Step 5, Current reward: 0.028482\n",
      "  Step 6, Current reward: 0.028482\n",
      "  Step 7, Current reward: 0.028482\n",
      "  Step 8, Current reward: 0.028482\n",
      "  Step 9, Current reward: 0.028482\n",
      "  Step 10, Current reward: 0.028482\n",
      "  Step 11, Current reward: 0.028482\n",
      "  Step 12, Current reward: 0.028482\n",
      "Episode 140/1000 complete - Max Reward: 0.028482\n",
      "Starting episode 141/1000\n",
      "  Step 1, Current reward: 0.025801\n",
      "  Step 2, Current reward: 0.025801\n",
      "  Step 3, Current reward: 0.025801\n",
      "  Step 4, Current reward: 0.025801\n",
      "  Step 5, Current reward: 0.025801\n",
      "  Step 6, Current reward: 0.025801\n",
      "  Step 7, Current reward: 0.025801\n",
      "  Step 8, Current reward: 0.025801\n",
      "  Step 9, Current reward: 0.025801\n",
      "  Step 10, Current reward: 0.025801\n",
      "  Step 11, Current reward: 0.025801\n",
      "  Step 12, Current reward: 0.025801\n",
      "Episode 141/1000 complete - Max Reward: 0.025801\n",
      "Starting episode 142/1000\n",
      "  Step 1, Current reward: 0.030789\n",
      "  Step 2, Current reward: 0.030789\n",
      "  Step 3, Current reward: 0.030789\n",
      "  Step 4, Current reward: 0.030789\n",
      "  Step 5, Current reward: 0.030789\n",
      "  Step 6, Current reward: 0.030789\n",
      "  Step 7, Current reward: 0.030789\n",
      "  Step 8, Current reward: 0.030789\n",
      "  Step 9, Current reward: 0.030789\n",
      "  Step 10, Current reward: 0.030789\n",
      "  Step 11, Current reward: 0.030789\n",
      "  Step 12, Current reward: 0.030789\n",
      "Episode 142/1000 complete - Max Reward: 0.030789\n",
      "Starting episode 143/1000\n",
      "  Step 1, Current reward: 0.010615\n",
      "  Step 2, Current reward: 0.010615\n",
      "  Step 3, Current reward: 0.010615\n",
      "  Step 4, Current reward: 0.010615\n",
      "  Step 5, Current reward: 0.010615\n",
      "  Step 6, Current reward: 0.010615\n",
      "  Step 7, Current reward: 0.010615\n",
      "  Step 8, Current reward: 0.010615\n",
      "  Step 9, Current reward: 0.010615\n",
      "  Step 10, Current reward: 0.010615\n",
      "  Step 11, Current reward: 0.010615\n",
      "  Step 12, Current reward: 0.010615\n",
      "Episode 143/1000 complete - Max Reward: 0.010615\n",
      "Starting episode 144/1000\n",
      "  Step 1, Current reward: 0.060518\n",
      "  Step 2, Current reward: 0.060518\n",
      "  Step 3, Current reward: 0.060518\n",
      "  Step 4, Current reward: 0.060518\n",
      "  Step 5, Current reward: 0.060518\n",
      "  Step 6, Current reward: 0.060518\n",
      "  Step 7, Current reward: 0.060518\n",
      "  Step 8, Current reward: 0.060518\n",
      "  Step 9, Current reward: 0.060518\n",
      "  Step 10, Current reward: 0.060518\n",
      "  Step 11, Current reward: 0.060518\n",
      "  Step 12, Current reward: 0.060518\n",
      "Episode 144/1000 complete - Max Reward: 0.060518\n",
      "Starting episode 145/1000\n",
      "  Step 1, Current reward: 0.011153\n",
      "  Step 2, Current reward: 0.011153\n",
      "  Step 3, Current reward: 0.011153\n",
      "  Step 4, Current reward: 0.011153\n",
      "  Step 5, Current reward: 0.011153\n",
      "  Step 6, Current reward: 0.011153\n",
      "  Step 7, Current reward: 0.011153\n",
      "  Step 8, Current reward: 0.011153\n",
      "  Step 9, Current reward: 0.011153\n",
      "  Step 10, Current reward: 0.011153\n",
      "  Step 11, Current reward: 0.011153\n",
      "  Step 12, Current reward: 0.011153\n",
      "Episode 145/1000 complete - Max Reward: 0.011153\n",
      "Starting episode 146/1000\n",
      "  Step 1, Current reward: 0.014977\n",
      "  Step 2, Current reward: 0.014977\n",
      "  Step 3, Current reward: 0.014977\n",
      "  Step 4, Current reward: 0.014977\n",
      "  Step 5, Current reward: 0.014977\n",
      "  Step 6, Current reward: 0.014977\n",
      "  Step 7, Current reward: 0.014977\n",
      "  Step 8, Current reward: 0.014977\n",
      "  Step 9, Current reward: 0.014977\n",
      "  Step 10, Current reward: 0.014977\n",
      "  Step 11, Current reward: 0.014977\n",
      "  Step 12, Current reward: 0.014977\n",
      "Episode 146/1000 complete - Max Reward: 0.014977\n",
      "Starting episode 147/1000\n",
      "  Step 1, Current reward: 0.011420\n",
      "  Step 2, Current reward: 0.011420\n",
      "  Step 3, Current reward: 0.011420\n",
      "  Step 4, Current reward: 0.011420\n",
      "  Step 5, Current reward: 0.011420\n",
      "  Step 6, Current reward: 0.011420\n",
      "  Step 7, Current reward: 0.011420\n",
      "  Step 8, Current reward: 0.011420\n",
      "  Step 9, Current reward: 0.011420\n",
      "  Step 10, Current reward: 0.011420\n",
      "  Step 11, Current reward: 0.011420\n",
      "  Step 12, Current reward: 0.011420\n",
      "Episode 147/1000 complete - Max Reward: 0.011420\n",
      "Starting episode 148/1000\n",
      "  Step 1, Current reward: 0.017616\n",
      "  Step 2, Current reward: 0.017616\n",
      "  Step 3, Current reward: 0.017616\n",
      "  Step 4, Current reward: 0.017616\n",
      "  Step 5, Current reward: 0.017616\n",
      "  Step 6, Current reward: 0.017616\n",
      "  Step 7, Current reward: 0.017616\n",
      "  Step 8, Current reward: 0.017616\n",
      "  Step 9, Current reward: 0.017616\n",
      "  Step 10, Current reward: 0.017616\n",
      "  Step 11, Current reward: 0.017616\n",
      "  Step 12, Current reward: 0.017616\n",
      "Episode 148/1000 complete - Max Reward: 0.017616\n",
      "Starting episode 149/1000\n",
      "  Step 1, Current reward: 0.041845\n",
      "  Step 2, Current reward: 0.041845\n",
      "  Step 3, Current reward: 0.041845\n",
      "  Step 4, Current reward: 0.041845\n",
      "  Step 5, Current reward: 0.041845\n",
      "  Step 6, Current reward: 0.041845\n",
      "  Step 7, Current reward: 0.041845\n",
      "  Step 8, Current reward: 0.041845\n",
      "  Step 9, Current reward: 0.041845\n",
      "  Step 10, Current reward: 0.041845\n",
      "  Step 11, Current reward: 0.041845\n",
      "  Step 12, Current reward: 0.041845\n",
      "Episode 149/1000 complete - Max Reward: 0.041845\n",
      "Starting episode 150/1000\n",
      "  Step 1, Current reward: 0.006897\n",
      "  Step 2, Current reward: 0.006897\n",
      "  Step 3, Current reward: 0.006897\n",
      "  Step 4, Current reward: 0.006897\n",
      "  Step 5, Current reward: 0.006897\n",
      "  Step 6, Current reward: 0.006897\n",
      "  Step 7, Current reward: 0.006897\n",
      "  Step 8, Current reward: 0.006897\n",
      "  Step 9, Current reward: 0.006897\n",
      "  Step 10, Current reward: 0.006897\n",
      "  Step 11, Current reward: 0.006897\n",
      "  Step 12, Current reward: 0.006897\n",
      "Episode 150/1000 complete - Max Reward: 0.006897\n",
      "Starting episode 151/1000\n",
      "  Step 1, Current reward: 0.058358\n",
      "  Step 2, Current reward: 0.058358\n",
      "  Step 3, Current reward: 0.058358\n",
      "  Step 4, Current reward: 0.058358\n",
      "  Step 5, Current reward: 0.058358\n",
      "  Step 6, Current reward: 0.058358\n",
      "  Step 7, Current reward: 0.058358\n",
      "  Step 8, Current reward: 0.058358\n",
      "  Step 9, Current reward: 0.058358\n",
      "  Step 10, Current reward: 0.058358\n",
      "  Step 11, Current reward: 0.058358\n",
      "  Step 12, Current reward: 0.058358\n",
      "Episode 151/1000 complete - Max Reward: 0.058358\n",
      "Starting episode 152/1000\n",
      "  Step 1, Current reward: 0.011030\n",
      "  Step 2, Current reward: 0.011030\n",
      "  Step 3, Current reward: 0.011030\n",
      "  Step 4, Current reward: 0.011030\n",
      "  Step 5, Current reward: 0.011030\n",
      "  Step 6, Current reward: 0.011030\n",
      "  Step 7, Current reward: 0.011030\n",
      "  Step 8, Current reward: 0.011030\n",
      "  Step 9, Current reward: 0.011030\n",
      "  Step 10, Current reward: 0.011030\n",
      "  Step 11, Current reward: 0.011030\n",
      "  Step 12, Current reward: 0.011030\n",
      "Episode 152/1000 complete - Max Reward: 0.011030\n",
      "Starting episode 153/1000\n",
      "  Step 1, Current reward: 0.041356\n",
      "  Step 2, Current reward: 0.041356\n",
      "  Step 3, Current reward: 0.041356\n",
      "  Step 4, Current reward: 0.041356\n",
      "  Step 5, Current reward: 0.041356\n",
      "  Step 6, Current reward: 0.041356\n",
      "  Step 7, Current reward: 0.041356\n",
      "  Step 8, Current reward: 0.041356\n",
      "  Step 9, Current reward: 0.041356\n",
      "  Step 10, Current reward: 0.041356\n",
      "  Step 11, Current reward: 0.041356\n",
      "  Step 12, Current reward: 0.041356\n",
      "Episode 153/1000 complete - Max Reward: 0.041356\n",
      "Starting episode 154/1000\n",
      "  Step 1, Current reward: 0.005194\n",
      "  Step 2, Current reward: 0.005194\n",
      "  Step 3, Current reward: 0.005194\n",
      "  Step 4, Current reward: 0.005194\n",
      "  Step 5, Current reward: 0.005194\n",
      "  Step 6, Current reward: 0.005194\n",
      "  Step 7, Current reward: 0.005194\n",
      "  Step 8, Current reward: 0.005194\n",
      "  Step 9, Current reward: 0.005194\n",
      "  Step 10, Current reward: 0.005194\n",
      "  Step 11, Current reward: 0.005194\n",
      "  Step 12, Current reward: 0.005194\n",
      "Episode 154/1000 complete - Max Reward: 0.005194\n",
      "Starting episode 155/1000\n",
      "  Step 1, Current reward: 0.049079\n",
      "  Step 2, Current reward: 0.049079\n",
      "  Step 3, Current reward: 0.049079\n",
      "  Step 4, Current reward: 0.049079\n",
      "  Step 5, Current reward: 0.049079\n",
      "  Step 6, Current reward: 0.049079\n",
      "  Step 7, Current reward: 0.049079\n",
      "  Step 8, Current reward: 0.049079\n",
      "  Step 9, Current reward: 0.049079\n",
      "  Step 10, Current reward: 0.049079\n",
      "  Step 11, Current reward: 0.049079\n",
      "  Step 12, Current reward: 0.049079\n",
      "Episode 155/1000 complete - Max Reward: 0.049079\n",
      "Starting episode 156/1000\n",
      "  Step 1, Current reward: 0.038756\n",
      "  Step 2, Current reward: 0.038756\n",
      "  Step 3, Current reward: 0.038756\n",
      "  Step 4, Current reward: 0.038756\n",
      "  Step 5, Current reward: 0.038756\n",
      "  Step 6, Current reward: 0.038756\n",
      "  Step 7, Current reward: 0.038756\n",
      "  Step 8, Current reward: 0.038756\n",
      "  Step 9, Current reward: 0.038756\n",
      "  Step 10, Current reward: 0.038756\n",
      "  Step 11, Current reward: 0.038756\n",
      "  Step 12, Current reward: 0.038756\n",
      "Episode 156/1000 complete - Max Reward: 0.038756\n",
      "Starting episode 157/1000\n",
      "  Step 1, Current reward: 0.002405\n",
      "  Step 2, Current reward: 0.002405\n",
      "  Step 3, Current reward: 0.002405\n",
      "  Step 4, Current reward: 0.002405\n",
      "  Step 5, Current reward: 0.002405\n",
      "  Step 6, Current reward: 0.002405\n",
      "  Step 7, Current reward: 0.002405\n",
      "  Step 8, Current reward: 0.002405\n",
      "  Step 9, Current reward: 0.002405\n",
      "  Step 10, Current reward: 0.002405\n",
      "  Step 11, Current reward: 0.002405\n",
      "  Step 12, Current reward: 0.002405\n",
      "Episode 157/1000 complete - Max Reward: 0.002405\n",
      "Starting episode 158/1000\n",
      "  Step 1, Current reward: 0.018066\n",
      "  Step 2, Current reward: 0.018066\n",
      "  Step 3, Current reward: 0.018066\n",
      "  Step 4, Current reward: 0.018066\n",
      "  Step 5, Current reward: 0.018066\n",
      "  Step 6, Current reward: 0.018066\n",
      "  Step 7, Current reward: 0.018066\n",
      "  Step 8, Current reward: 0.018066\n",
      "  Step 9, Current reward: 0.018066\n",
      "  Step 10, Current reward: 0.018066\n",
      "  Step 11, Current reward: 0.018066\n",
      "  Step 12, Current reward: 0.018066\n",
      "Episode 158/1000 complete - Max Reward: 0.018066\n",
      "Starting episode 159/1000\n",
      "  Step 1, Current reward: 0.066297\n",
      "  Step 2, Current reward: 0.066297\n",
      "  Step 3, Current reward: 0.066297\n",
      "  Step 4, Current reward: 0.066297\n",
      "  Step 5, Current reward: 0.066297\n",
      "  Step 6, Current reward: 0.066297\n",
      "  Step 7, Current reward: 0.066297\n",
      "  Step 8, Current reward: 0.066297\n",
      "  Step 9, Current reward: 0.066297\n",
      "  Step 10, Current reward: 0.066297\n",
      "  Step 11, Current reward: 0.066297\n",
      "  Step 12, Current reward: 0.066297\n",
      "Episode 159/1000 complete - Max Reward: 0.066297\n",
      "Starting episode 160/1000\n",
      "  Step 1, Current reward: 0.067823\n",
      "  Step 2, Current reward: 0.067823\n",
      "  Step 3, Current reward: 0.067823\n",
      "  Step 4, Current reward: 0.067823\n",
      "  Step 5, Current reward: 0.067823\n",
      "  Step 6, Current reward: 0.067823\n",
      "  Step 7, Current reward: 0.067823\n",
      "  Step 8, Current reward: 0.067823\n",
      "  Step 9, Current reward: 0.067823\n",
      "  Step 10, Current reward: 0.067823\n",
      "  Step 11, Current reward: 0.067823\n",
      "  Step 12, Current reward: 0.067823\n",
      "Episode 160/1000 complete - Max Reward: 0.067823\n",
      "Starting episode 161/1000\n",
      "  Step 1, Current reward: 0.016420\n",
      "  Step 2, Current reward: 0.016420\n",
      "  Step 3, Current reward: 0.016420\n",
      "  Step 4, Current reward: 0.016420\n",
      "  Step 5, Current reward: 0.016420\n",
      "  Step 6, Current reward: 0.016420\n",
      "  Step 7, Current reward: 0.016420\n",
      "  Step 8, Current reward: 0.016420\n",
      "  Step 9, Current reward: 0.016420\n",
      "  Step 10, Current reward: 0.016420\n",
      "  Step 11, Current reward: 0.016420\n",
      "  Step 12, Current reward: 0.016420\n",
      "Episode 161/1000 complete - Max Reward: 0.016420\n",
      "Starting episode 162/1000\n",
      "  Step 1, Current reward: 0.003424\n",
      "  Step 2, Current reward: 0.003424\n",
      "  Step 3, Current reward: 0.003424\n",
      "  Step 4, Current reward: 0.003424\n",
      "  Step 5, Current reward: 0.003424\n",
      "  Step 6, Current reward: 0.003424\n",
      "  Step 7, Current reward: 0.003424\n",
      "  Step 8, Current reward: 0.003424\n",
      "  Step 9, Current reward: 0.003424\n",
      "  Step 10, Current reward: 0.003424\n",
      "  Step 11, Current reward: 0.003424\n",
      "  Step 12, Current reward: 0.003424\n",
      "Episode 162/1000 complete - Max Reward: 0.003424\n",
      "Starting episode 163/1000\n",
      "  Step 1, Current reward: 0.023947\n",
      "  Step 2, Current reward: 0.023947\n",
      "  Step 3, Current reward: 0.023947\n",
      "  Step 4, Current reward: 0.023947\n",
      "  Step 5, Current reward: 0.023947\n",
      "  Step 6, Current reward: 0.023947\n",
      "  Step 7, Current reward: 0.023947\n",
      "  Step 8, Current reward: 0.023947\n",
      "  Step 9, Current reward: 0.023947\n",
      "  Step 10, Current reward: 0.023947\n",
      "  Step 11, Current reward: 0.023947\n",
      "  Step 12, Current reward: 0.023947\n",
      "Episode 163/1000 complete - Max Reward: 0.023947\n",
      "Starting episode 164/1000\n",
      "  Step 1, Current reward: 0.003827\n",
      "  Step 2, Current reward: 0.003827\n",
      "  Step 3, Current reward: 0.003827\n",
      "  Step 4, Current reward: 0.003827\n",
      "  Step 5, Current reward: 0.003827\n",
      "  Step 6, Current reward: 0.003827\n",
      "  Step 7, Current reward: 0.003827\n",
      "  Step 8, Current reward: 0.003827\n",
      "  Step 9, Current reward: 0.003827\n",
      "  Step 10, Current reward: 0.003827\n",
      "  Step 11, Current reward: 0.003827\n",
      "  Step 12, Current reward: 0.003827\n",
      "Episode 164/1000 complete - Max Reward: 0.003827\n",
      "Starting episode 165/1000\n",
      "  Step 1, Current reward: 0.114340\n",
      "  Step 2, Current reward: 0.114340\n",
      "  Step 3, Current reward: 0.114340\n",
      "  Step 4, Current reward: 0.114340\n",
      "  Step 5, Current reward: 0.114340\n",
      "  Step 6, Current reward: 0.114340\n",
      "  Step 7, Current reward: 0.114340\n",
      "  Step 8, Current reward: 0.114340\n",
      "  Step 9, Current reward: 0.114340\n",
      "  Step 10, Current reward: 0.114340\n",
      "  Step 11, Current reward: 0.114340\n",
      "  Step 12, Current reward: 0.114340\n",
      "Episode 165/1000 complete - Max Reward: 0.114340\n",
      "Starting episode 166/1000\n",
      "  Step 1, Current reward: 0.008573\n",
      "  Step 2, Current reward: 0.008573\n",
      "  Step 3, Current reward: 0.008573\n",
      "  Step 4, Current reward: 0.008573\n",
      "  Step 5, Current reward: 0.008573\n",
      "  Step 6, Current reward: 0.008573\n",
      "  Step 7, Current reward: 0.008573\n",
      "  Step 8, Current reward: 0.008573\n",
      "  Step 9, Current reward: 0.008573\n",
      "  Step 10, Current reward: 0.008573\n",
      "  Step 11, Current reward: 0.008573\n",
      "  Step 12, Current reward: 0.008573\n",
      "Episode 166/1000 complete - Max Reward: 0.008573\n",
      "Starting episode 167/1000\n",
      "  Step 1, Current reward: 0.135036\n",
      "  Step 2, Current reward: 0.135036\n",
      "  Step 3, Current reward: 0.135036\n",
      "  Step 4, Current reward: 0.135036\n",
      "  Step 5, Current reward: 0.135036\n",
      "  Step 6, Current reward: 0.135036\n",
      "  Step 7, Current reward: 0.135036\n",
      "  Step 8, Current reward: 0.135036\n",
      "  Step 9, Current reward: 0.135036\n",
      "  Step 10, Current reward: 0.135036\n",
      "  Step 11, Current reward: 0.135036\n",
      "  Step 12, Current reward: 0.135036\n",
      "Episode 167/1000 complete - Max Reward: 0.135036\n",
      "Starting episode 168/1000\n",
      "  Step 1, Current reward: 0.015212\n",
      "  Step 2, Current reward: 0.015212\n",
      "  Step 3, Current reward: 0.015212\n",
      "  Step 4, Current reward: 0.015212\n",
      "  Step 5, Current reward: 0.015212\n",
      "  Step 6, Current reward: 0.015212\n",
      "  Step 7, Current reward: 0.015212\n",
      "  Step 8, Current reward: 0.015212\n",
      "  Step 9, Current reward: 0.015212\n",
      "  Step 10, Current reward: 0.015212\n",
      "  Step 11, Current reward: 0.015212\n",
      "  Step 12, Current reward: 0.015212\n",
      "Episode 168/1000 complete - Max Reward: 0.015212\n",
      "Starting episode 169/1000\n",
      "  Step 1, Current reward: 0.001800\n",
      "  Step 2, Current reward: 0.001800\n",
      "  Step 3, Current reward: 0.001800\n",
      "  Step 4, Current reward: 0.001800\n",
      "  Step 5, Current reward: 0.001800\n",
      "  Step 6, Current reward: 0.001800\n",
      "  Step 7, Current reward: 0.001800\n",
      "  Step 8, Current reward: 0.001800\n",
      "  Step 9, Current reward: 0.001800\n",
      "  Step 10, Current reward: 0.001800\n",
      "  Step 11, Current reward: 0.001800\n",
      "  Step 12, Current reward: 0.001800\n",
      "Episode 169/1000 complete - Max Reward: 0.001800\n",
      "Starting episode 170/1000\n",
      "  Step 1, Current reward: 0.007699\n",
      "  Step 2, Current reward: 0.007699\n",
      "  Step 3, Current reward: 0.007699\n",
      "  Step 4, Current reward: 0.007699\n",
      "  Step 5, Current reward: 0.007699\n",
      "  Step 6, Current reward: 0.007699\n",
      "  Step 7, Current reward: 0.007699\n",
      "  Step 8, Current reward: 0.007699\n",
      "  Step 9, Current reward: 0.007699\n",
      "  Step 10, Current reward: 0.007699\n",
      "  Step 11, Current reward: 0.007699\n",
      "  Step 12, Current reward: 0.007699\n",
      "Episode 170/1000 complete - Max Reward: 0.007699\n",
      "Starting episode 171/1000\n",
      "  Step 1, Current reward: 0.002866\n",
      "  Step 2, Current reward: 0.002866\n",
      "  Step 3, Current reward: 0.002866\n",
      "  Step 4, Current reward: 0.002866\n",
      "  Step 5, Current reward: 0.002866\n",
      "  Step 6, Current reward: 0.002866\n",
      "  Step 7, Current reward: 0.002866\n",
      "  Step 8, Current reward: 0.002866\n",
      "  Step 9, Current reward: 0.002866\n",
      "  Step 10, Current reward: 0.002866\n",
      "  Step 11, Current reward: 0.002866\n",
      "  Step 12, Current reward: 0.002866\n",
      "Episode 171/1000 complete - Max Reward: 0.002866\n",
      "Starting episode 172/1000\n",
      "  Step 1, Current reward: 0.006312\n",
      "  Step 2, Current reward: 0.006312\n",
      "  Step 3, Current reward: 0.006312\n",
      "  Step 4, Current reward: 0.006312\n",
      "  Step 5, Current reward: 0.006312\n",
      "  Step 6, Current reward: 0.006312\n",
      "  Step 7, Current reward: 0.006312\n",
      "  Step 8, Current reward: 0.006312\n",
      "  Step 9, Current reward: 0.006312\n",
      "  Step 10, Current reward: 0.006312\n",
      "  Step 11, Current reward: 0.006312\n",
      "  Step 12, Current reward: 0.006312\n",
      "Episode 172/1000 complete - Max Reward: 0.006312\n",
      "Starting episode 173/1000\n",
      "  Step 1, Current reward: 0.007643\n",
      "  Step 2, Current reward: 0.007643\n",
      "  Step 3, Current reward: 0.007643\n",
      "  Step 4, Current reward: 0.007643\n",
      "  Step 5, Current reward: 0.007643\n",
      "  Step 6, Current reward: 0.007643\n",
      "  Step 7, Current reward: 0.007643\n",
      "  Step 8, Current reward: 0.007643\n",
      "  Step 9, Current reward: 0.007643\n",
      "  Step 10, Current reward: 0.007643\n",
      "  Step 11, Current reward: 0.007643\n",
      "  Step 12, Current reward: 0.007643\n",
      "Episode 173/1000 complete - Max Reward: 0.007643\n",
      "Starting episode 174/1000\n",
      "  Step 1, Current reward: 0.003614\n",
      "  Step 2, Current reward: 0.003614\n",
      "  Step 3, Current reward: 0.003614\n",
      "  Step 4, Current reward: 0.003614\n",
      "  Step 5, Current reward: 0.003614\n",
      "  Step 6, Current reward: 0.003614\n",
      "  Step 7, Current reward: 0.003614\n",
      "  Step 8, Current reward: 0.003614\n",
      "  Step 9, Current reward: 0.003614\n",
      "  Step 10, Current reward: 0.003614\n",
      "  Step 11, Current reward: 0.003614\n",
      "  Step 12, Current reward: 0.003614\n",
      "Episode 174/1000 complete - Max Reward: 0.003614\n",
      "Starting episode 175/1000\n",
      "  Step 1, Current reward: 0.177339\n",
      "  Step 2, Current reward: 0.179818\n",
      "  Step 3, Current reward: 0.194850\n",
      "  Step 4, Current reward: 0.207255\n",
      "  Step 5, Current reward: 0.214233\n",
      "  Step 6, Current reward: 0.212781\n",
      "  Step 7, Current reward: 0.202280\n",
      "  Step 8, Current reward: 0.186909\n",
      "  Step 9, Current reward: 0.171838\n",
      "  Step 10, Current reward: 0.159079\n",
      "  Step 11, Current reward: 0.159079\n",
      "  Step 12, Current reward: 0.159079\n",
      "  Step 13, Current reward: 0.159079\n",
      "  Step 14, Current reward: 0.159079\n",
      "  Step 15, Current reward: 0.159079\n",
      "  Step 16, Current reward: 0.159079\n",
      "Episode 175/1000 complete - Max Reward: 0.214233\n",
      "Starting episode 176/1000\n",
      "  Step 1, Current reward: 0.043578\n",
      "  Step 2, Current reward: 0.043578\n",
      "  Step 3, Current reward: 0.043578\n",
      "  Step 4, Current reward: 0.043578\n",
      "  Step 5, Current reward: 0.043578\n",
      "  Step 6, Current reward: 0.043578\n",
      "  Step 7, Current reward: 0.043578\n",
      "  Step 8, Current reward: 0.043578\n",
      "  Step 9, Current reward: 0.043578\n",
      "  Step 10, Current reward: 0.043578\n",
      "  Step 11, Current reward: 0.043578\n",
      "  Step 12, Current reward: 0.043578\n",
      "Episode 176/1000 complete - Max Reward: 0.043578\n",
      "Starting episode 177/1000\n",
      "  Step 1, Current reward: 0.003857\n",
      "  Step 2, Current reward: 0.003857\n",
      "  Step 3, Current reward: 0.003857\n",
      "  Step 4, Current reward: 0.003857\n",
      "  Step 5, Current reward: 0.003857\n",
      "  Step 6, Current reward: 0.003857\n",
      "  Step 7, Current reward: 0.003857\n",
      "  Step 8, Current reward: 0.003857\n",
      "  Step 9, Current reward: 0.003857\n",
      "  Step 10, Current reward: 0.003857\n",
      "  Step 11, Current reward: 0.003857\n",
      "  Step 12, Current reward: 0.003857\n",
      "Episode 177/1000 complete - Max Reward: 0.003857\n",
      "Starting episode 178/1000\n",
      "  Step 1, Current reward: 0.012035\n",
      "  Step 2, Current reward: 0.012035\n",
      "  Step 3, Current reward: 0.012035\n",
      "  Step 4, Current reward: 0.012035\n",
      "  Step 5, Current reward: 0.012035\n",
      "  Step 6, Current reward: 0.012035\n",
      "  Step 7, Current reward: 0.012035\n",
      "  Step 8, Current reward: 0.012035\n",
      "  Step 9, Current reward: 0.012035\n",
      "  Step 10, Current reward: 0.012035\n",
      "  Step 11, Current reward: 0.012035\n",
      "  Step 12, Current reward: 0.012035\n",
      "Episode 178/1000 complete - Max Reward: 0.012035\n",
      "Starting episode 179/1000\n",
      "  Step 1, Current reward: 0.023167\n",
      "  Step 2, Current reward: 0.023167\n",
      "  Step 3, Current reward: 0.023167\n",
      "  Step 4, Current reward: 0.023167\n",
      "  Step 5, Current reward: 0.023167\n",
      "  Step 6, Current reward: 0.023167\n",
      "  Step 7, Current reward: 0.023167\n",
      "  Step 8, Current reward: 0.023167\n",
      "  Step 9, Current reward: 0.023167\n",
      "  Step 10, Current reward: 0.023167\n",
      "  Step 11, Current reward: 0.023167\n",
      "  Step 12, Current reward: 0.023167\n",
      "Episode 179/1000 complete - Max Reward: 0.023167\n",
      "Starting episode 180/1000\n",
      "  Step 1, Current reward: 0.022999\n",
      "  Step 2, Current reward: 0.022999\n",
      "  Step 3, Current reward: 0.022999\n",
      "  Step 4, Current reward: 0.022999\n",
      "  Step 5, Current reward: 0.022999\n",
      "  Step 6, Current reward: 0.022999\n",
      "  Step 7, Current reward: 0.022999\n",
      "  Step 8, Current reward: 0.022999\n",
      "  Step 9, Current reward: 0.022999\n",
      "  Step 10, Current reward: 0.022999\n",
      "  Step 11, Current reward: 0.022999\n",
      "  Step 12, Current reward: 0.022999\n",
      "Episode 180/1000 complete - Max Reward: 0.022999\n",
      "Starting episode 181/1000\n",
      "  Step 1, Current reward: 0.176255\n",
      "  Step 2, Current reward: 0.176255\n",
      "  Step 3, Current reward: 0.176255\n",
      "  Step 4, Current reward: 0.176255\n",
      "  Step 5, Current reward: 0.176255\n",
      "  Step 6, Current reward: 0.176255\n",
      "  Step 7, Current reward: 0.176255\n",
      "  Step 8, Current reward: 0.176255\n",
      "  Step 9, Current reward: 0.176255\n",
      "  Step 10, Current reward: 0.176255\n",
      "  Step 11, Current reward: 0.176255\n",
      "  Step 12, Current reward: 0.176255\n",
      "Episode 181/1000 complete - Max Reward: 0.176255\n",
      "Starting episode 182/1000\n",
      "  Step 1, Current reward: 0.004960\n",
      "  Step 2, Current reward: 0.004960\n",
      "  Step 3, Current reward: 0.004960\n",
      "  Step 4, Current reward: 0.004960\n",
      "  Step 5, Current reward: 0.004960\n",
      "  Step 6, Current reward: 0.004960\n",
      "  Step 7, Current reward: 0.004960\n",
      "  Step 8, Current reward: 0.004960\n",
      "  Step 9, Current reward: 0.004960\n",
      "  Step 10, Current reward: 0.004960\n",
      "  Step 11, Current reward: 0.004960\n",
      "  Step 12, Current reward: 0.004960\n",
      "Episode 182/1000 complete - Max Reward: 0.004960\n",
      "Starting episode 183/1000\n",
      "  Step 1, Current reward: 0.006055\n",
      "  Step 2, Current reward: 0.006055\n",
      "  Step 3, Current reward: 0.006055\n",
      "  Step 4, Current reward: 0.006055\n",
      "  Step 5, Current reward: 0.006055\n",
      "  Step 6, Current reward: 0.006055\n",
      "  Step 7, Current reward: 0.006055\n",
      "  Step 8, Current reward: 0.006055\n",
      "  Step 9, Current reward: 0.006055\n",
      "  Step 10, Current reward: 0.006055\n",
      "  Step 11, Current reward: 0.006055\n",
      "  Step 12, Current reward: 0.006055\n",
      "Episode 183/1000 complete - Max Reward: 0.006055\n",
      "Starting episode 184/1000\n",
      "  Step 1, Current reward: 0.007371\n",
      "  Step 2, Current reward: 0.007371\n",
      "  Step 3, Current reward: 0.007371\n",
      "  Step 4, Current reward: 0.007371\n",
      "  Step 5, Current reward: 0.007371\n",
      "  Step 6, Current reward: 0.007371\n",
      "  Step 7, Current reward: 0.007371\n",
      "  Step 8, Current reward: 0.007371\n",
      "  Step 9, Current reward: 0.007371\n",
      "  Step 10, Current reward: 0.007371\n",
      "  Step 11, Current reward: 0.007371\n",
      "  Step 12, Current reward: 0.007371\n",
      "Episode 184/1000 complete - Max Reward: 0.007371\n",
      "Starting episode 185/1000\n",
      "  Step 1, Current reward: 0.000376\n",
      "  Step 2, Current reward: 0.000376\n",
      "  Step 3, Current reward: 0.000376\n",
      "  Step 4, Current reward: 0.000376\n",
      "  Step 5, Current reward: 0.000376\n",
      "  Step 6, Current reward: 0.000376\n",
      "  Step 7, Current reward: 0.000376\n",
      "  Step 8, Current reward: 0.000376\n",
      "  Step 9, Current reward: 0.000376\n",
      "  Step 10, Current reward: 0.000376\n",
      "  Step 11, Current reward: 0.000376\n",
      "  Step 12, Current reward: 0.000376\n",
      "Episode 185/1000 complete - Max Reward: 0.000376\n",
      "Starting episode 186/1000\n",
      "  Step 1, Current reward: 0.016891\n",
      "  Step 2, Current reward: 0.017440\n",
      "  Step 3, Current reward: 0.017739\n",
      "  Step 4, Current reward: 0.017753\n",
      "  Step 5, Current reward: 0.017492\n",
      "  Step 6, Current reward: 0.017024\n",
      "  Step 7, Current reward: 0.016361\n",
      "  Step 8, Current reward: 0.015550\n",
      "  Step 9, Current reward: 0.014630\n",
      "  Step 10, Current reward: 0.013639\n",
      "  Step 11, Current reward: 0.012609\n",
      "  Step 12, Current reward: 0.011568\n",
      "  Step 13, Current reward: 0.010543\n",
      "  Step 14, Current reward: 0.009558\n",
      "  Step 15, Current reward: 0.008631\n",
      "Episode 186/1000 complete - Max Reward: 0.017753\n",
      "Starting episode 187/1000\n",
      "  Step 1, Current reward: 0.002838\n",
      "  Step 2, Current reward: 0.002838\n",
      "  Step 3, Current reward: 0.002838\n",
      "  Step 4, Current reward: 0.002838\n",
      "  Step 5, Current reward: 0.002838\n",
      "  Step 6, Current reward: 0.002838\n",
      "  Step 7, Current reward: 0.002838\n",
      "  Step 8, Current reward: 0.002838\n",
      "  Step 9, Current reward: 0.002838\n",
      "  Step 10, Current reward: 0.002838\n",
      "  Step 11, Current reward: 0.002838\n",
      "  Step 12, Current reward: 0.002838\n",
      "Episode 187/1000 complete - Max Reward: 0.002838\n",
      "Starting episode 188/1000\n",
      "  Step 1, Current reward: 0.045928\n",
      "  Step 2, Current reward: 0.045928\n",
      "  Step 3, Current reward: 0.045928\n",
      "  Step 4, Current reward: 0.045928\n",
      "  Step 5, Current reward: 0.045928\n",
      "  Step 6, Current reward: 0.045928\n",
      "  Step 7, Current reward: 0.045928\n",
      "  Step 8, Current reward: 0.045928\n",
      "  Step 9, Current reward: 0.045928\n",
      "  Step 10, Current reward: 0.045928\n",
      "  Step 11, Current reward: 0.045928\n",
      "  Step 12, Current reward: 0.045928\n",
      "Episode 188/1000 complete - Max Reward: 0.045928\n",
      "Starting episode 189/1000\n",
      "  Step 1, Current reward: 0.007540\n",
      "  Step 2, Current reward: 0.007540\n",
      "  Step 3, Current reward: 0.007540\n",
      "  Step 4, Current reward: 0.007540\n",
      "  Step 5, Current reward: 0.007540\n",
      "  Step 6, Current reward: 0.007540\n",
      "  Step 7, Current reward: 0.007540\n",
      "  Step 8, Current reward: 0.007540\n",
      "  Step 9, Current reward: 0.007540\n",
      "  Step 10, Current reward: 0.007540\n",
      "  Step 11, Current reward: 0.007540\n",
      "  Step 12, Current reward: 0.007540\n",
      "Episode 189/1000 complete - Max Reward: 0.007540\n",
      "Starting episode 190/1000\n",
      "  Step 1, Current reward: 0.036435\n",
      "  Step 2, Current reward: 0.036435\n",
      "  Step 3, Current reward: 0.036435\n",
      "  Step 4, Current reward: 0.036435\n",
      "  Step 5, Current reward: 0.036435\n",
      "  Step 6, Current reward: 0.036435\n",
      "  Step 7, Current reward: 0.036435\n",
      "  Step 8, Current reward: 0.036435\n",
      "  Step 9, Current reward: 0.036435\n",
      "  Step 10, Current reward: 0.036435\n",
      "  Step 11, Current reward: 0.036435\n",
      "  Step 12, Current reward: 0.036435\n",
      "Episode 190/1000 complete - Max Reward: 0.036435\n",
      "Starting episode 191/1000\n",
      "  Step 1, Current reward: 0.016842\n",
      "  Step 2, Current reward: 0.016842\n",
      "  Step 3, Current reward: 0.016842\n",
      "  Step 4, Current reward: 0.016842\n",
      "  Step 5, Current reward: 0.016842\n",
      "  Step 6, Current reward: 0.016842\n",
      "  Step 7, Current reward: 0.016842\n",
      "  Step 8, Current reward: 0.016842\n",
      "  Step 9, Current reward: 0.016842\n",
      "  Step 10, Current reward: 0.016842\n",
      "  Step 11, Current reward: 0.016842\n",
      "  Step 12, Current reward: 0.016842\n",
      "Episode 191/1000 complete - Max Reward: 0.016842\n",
      "Starting episode 192/1000\n",
      "  Step 1, Current reward: 0.019579\n",
      "  Step 2, Current reward: 0.019579\n",
      "  Step 3, Current reward: 0.019579\n",
      "  Step 4, Current reward: 0.019579\n",
      "  Step 5, Current reward: 0.019579\n",
      "  Step 6, Current reward: 0.019579\n",
      "  Step 7, Current reward: 0.019579\n",
      "  Step 8, Current reward: 0.019579\n",
      "  Step 9, Current reward: 0.019579\n",
      "  Step 10, Current reward: 0.019579\n",
      "  Step 11, Current reward: 0.019579\n",
      "  Step 12, Current reward: 0.019579\n",
      "Episode 192/1000 complete - Max Reward: 0.019579\n",
      "Starting episode 193/1000\n",
      "  Step 1, Current reward: 0.029957\n",
      "  Step 2, Current reward: 0.029957\n",
      "  Step 3, Current reward: 0.029957\n",
      "  Step 4, Current reward: 0.029957\n",
      "  Step 5, Current reward: 0.029957\n",
      "  Step 6, Current reward: 0.029957\n",
      "  Step 7, Current reward: 0.029957\n",
      "  Step 8, Current reward: 0.029957\n",
      "  Step 9, Current reward: 0.029957\n",
      "  Step 10, Current reward: 0.029957\n",
      "  Step 11, Current reward: 0.029957\n",
      "  Step 12, Current reward: 0.029957\n",
      "Episode 193/1000 complete - Max Reward: 0.029957\n",
      "Starting episode 194/1000\n",
      "  Step 1, Current reward: 0.027853\n",
      "  Step 2, Current reward: 0.027853\n",
      "  Step 3, Current reward: 0.027853\n",
      "  Step 4, Current reward: 0.027853\n",
      "  Step 5, Current reward: 0.027853\n",
      "  Step 6, Current reward: 0.027853\n",
      "  Step 7, Current reward: 0.027853\n",
      "  Step 8, Current reward: 0.027853\n",
      "  Step 9, Current reward: 0.027853\n",
      "  Step 10, Current reward: 0.027853\n",
      "  Step 11, Current reward: 0.027853\n",
      "  Step 12, Current reward: 0.027853\n",
      "Episode 194/1000 complete - Max Reward: 0.027853\n",
      "Starting episode 195/1000\n",
      "  Step 1, Current reward: 0.018942\n",
      "  Step 2, Current reward: 0.018942\n",
      "  Step 3, Current reward: 0.018942\n",
      "  Step 4, Current reward: 0.018942\n",
      "  Step 5, Current reward: 0.018942\n",
      "  Step 6, Current reward: 0.018942\n",
      "  Step 7, Current reward: 0.018942\n",
      "  Step 8, Current reward: 0.018942\n",
      "  Step 9, Current reward: 0.018942\n",
      "  Step 10, Current reward: 0.018942\n",
      "  Step 11, Current reward: 0.018942\n",
      "  Step 12, Current reward: 0.018942\n",
      "Episode 195/1000 complete - Max Reward: 0.018942\n",
      "Starting episode 196/1000\n",
      "  Step 1, Current reward: 0.020694\n",
      "  Step 2, Current reward: 0.020694\n",
      "  Step 3, Current reward: 0.020694\n",
      "  Step 4, Current reward: 0.020694\n",
      "  Step 5, Current reward: 0.020694\n",
      "  Step 6, Current reward: 0.020694\n",
      "  Step 7, Current reward: 0.020694\n",
      "  Step 8, Current reward: 0.020694\n",
      "  Step 9, Current reward: 0.020694\n",
      "  Step 10, Current reward: 0.020694\n",
      "  Step 11, Current reward: 0.020694\n",
      "  Step 12, Current reward: 0.020694\n",
      "Episode 196/1000 complete - Max Reward: 0.020694\n",
      "Starting episode 197/1000\n",
      "  Step 1, Current reward: 0.001997\n",
      "  Step 2, Current reward: 0.001997\n",
      "  Step 3, Current reward: 0.001997\n",
      "  Step 4, Current reward: 0.001997\n",
      "  Step 5, Current reward: 0.001997\n",
      "  Step 6, Current reward: 0.001997\n",
      "  Step 7, Current reward: 0.001997\n",
      "  Step 8, Current reward: 0.001997\n",
      "  Step 9, Current reward: 0.001997\n",
      "  Step 10, Current reward: 0.001997\n",
      "  Step 11, Current reward: 0.001997\n",
      "  Step 12, Current reward: 0.001997\n",
      "Episode 197/1000 complete - Max Reward: 0.001997\n",
      "Starting episode 198/1000\n",
      "  Step 1, Current reward: 0.032702\n",
      "  Step 2, Current reward: 0.032702\n",
      "  Step 3, Current reward: 0.032702\n",
      "  Step 4, Current reward: 0.032702\n",
      "  Step 5, Current reward: 0.032702\n",
      "  Step 6, Current reward: 0.032702\n",
      "  Step 7, Current reward: 0.032702\n",
      "  Step 8, Current reward: 0.032702\n",
      "  Step 9, Current reward: 0.032702\n",
      "  Step 10, Current reward: 0.032702\n",
      "  Step 11, Current reward: 0.032702\n",
      "  Step 12, Current reward: 0.032702\n",
      "Episode 198/1000 complete - Max Reward: 0.032702\n",
      "Starting episode 199/1000\n",
      "  Step 1, Current reward: 0.018844\n",
      "  Step 2, Current reward: 0.018844\n",
      "  Step 3, Current reward: 0.018844\n",
      "  Step 4, Current reward: 0.018844\n",
      "  Step 5, Current reward: 0.018844\n",
      "  Step 6, Current reward: 0.018844\n",
      "  Step 7, Current reward: 0.018844\n",
      "  Step 8, Current reward: 0.018844\n",
      "  Step 9, Current reward: 0.018844\n",
      "  Step 10, Current reward: 0.018844\n",
      "  Step 11, Current reward: 0.018844\n",
      "  Step 12, Current reward: 0.018844\n",
      "Episode 199/1000 complete - Max Reward: 0.018844\n",
      "Starting episode 200/1000\n",
      "  Step 1, Current reward: 0.032481\n",
      "  Step 2, Current reward: 0.032481\n",
      "  Step 3, Current reward: 0.032481\n",
      "  Step 4, Current reward: 0.032481\n",
      "  Step 5, Current reward: 0.032481\n",
      "  Step 6, Current reward: 0.032481\n",
      "  Step 7, Current reward: 0.032481\n",
      "  Step 8, Current reward: 0.032481\n",
      "  Step 9, Current reward: 0.032481\n",
      "  Step 10, Current reward: 0.032481\n",
      "  Step 11, Current reward: 0.032481\n",
      "  Step 12, Current reward: 0.032481\n",
      "Episode 200/1000 complete - Max Reward: 0.032481\n",
      "Starting episode 201/1000\n",
      "  Step 1, Current reward: 0.028691\n",
      "  Step 2, Current reward: 0.028691\n",
      "  Step 3, Current reward: 0.028691\n",
      "  Step 4, Current reward: 0.028691\n",
      "  Step 5, Current reward: 0.028691\n",
      "  Step 6, Current reward: 0.028691\n",
      "  Step 7, Current reward: 0.028691\n",
      "  Step 8, Current reward: 0.028691\n",
      "  Step 9, Current reward: 0.028691\n",
      "  Step 10, Current reward: 0.028691\n",
      "  Step 11, Current reward: 0.028691\n",
      "  Step 12, Current reward: 0.028691\n",
      "Episode 201/1000 complete - Max Reward: 0.028691\n",
      "Starting episode 202/1000\n",
      "  Step 1, Current reward: 0.024379\n",
      "  Step 2, Current reward: 0.024379\n",
      "  Step 3, Current reward: 0.024379\n",
      "  Step 4, Current reward: 0.024379\n",
      "  Step 5, Current reward: 0.024379\n",
      "  Step 6, Current reward: 0.024379\n",
      "  Step 7, Current reward: 0.024379\n",
      "  Step 8, Current reward: 0.024379\n",
      "  Step 9, Current reward: 0.024379\n",
      "  Step 10, Current reward: 0.024379\n",
      "  Step 11, Current reward: 0.024379\n",
      "  Step 12, Current reward: 0.024379\n",
      "Episode 202/1000 complete - Max Reward: 0.024379\n",
      "Starting episode 203/1000\n",
      "  Step 1, Current reward: 0.079504\n",
      "  Step 2, Current reward: 0.079504\n",
      "  Step 3, Current reward: 0.079504\n",
      "  Step 4, Current reward: 0.079504\n",
      "  Step 5, Current reward: 0.079504\n",
      "  Step 6, Current reward: 0.079504\n",
      "  Step 7, Current reward: 0.079504\n",
      "  Step 8, Current reward: 0.079504\n",
      "  Step 9, Current reward: 0.079504\n",
      "  Step 10, Current reward: 0.079504\n",
      "  Step 11, Current reward: 0.079504\n",
      "  Step 12, Current reward: 0.079504\n",
      "Episode 203/1000 complete - Max Reward: 0.079504\n",
      "Starting episode 204/1000\n",
      "  Step 1, Current reward: 0.015970\n",
      "  Step 2, Current reward: 0.015970\n",
      "  Step 3, Current reward: 0.015970\n",
      "  Step 4, Current reward: 0.015970\n",
      "  Step 5, Current reward: 0.015970\n",
      "  Step 6, Current reward: 0.015970\n",
      "  Step 7, Current reward: 0.015970\n",
      "  Step 8, Current reward: 0.015970\n",
      "  Step 9, Current reward: 0.015970\n",
      "  Step 10, Current reward: 0.015970\n",
      "  Step 11, Current reward: 0.015970\n",
      "  Step 12, Current reward: 0.015970\n",
      "Episode 204/1000 complete - Max Reward: 0.015970\n",
      "Starting episode 205/1000\n",
      "  Step 1, Current reward: 0.000386\n",
      "  Step 2, Current reward: 0.000386\n",
      "  Step 3, Current reward: 0.000386\n",
      "  Step 4, Current reward: 0.000386\n",
      "  Step 5, Current reward: 0.000386\n",
      "  Step 6, Current reward: 0.000386\n",
      "  Step 7, Current reward: 0.000386\n",
      "  Step 8, Current reward: 0.000386\n",
      "  Step 9, Current reward: 0.000386\n",
      "  Step 10, Current reward: 0.000386\n",
      "  Step 11, Current reward: 0.000386\n",
      "  Step 12, Current reward: 0.000386\n",
      "Episode 205/1000 complete - Max Reward: 0.000386\n",
      "Starting episode 206/1000\n",
      "  Step 1, Current reward: 0.008954\n",
      "  Step 2, Current reward: 0.008954\n",
      "  Step 3, Current reward: 0.008954\n",
      "  Step 4, Current reward: 0.008954\n",
      "  Step 5, Current reward: 0.008954\n",
      "  Step 6, Current reward: 0.008954\n",
      "  Step 7, Current reward: 0.008954\n",
      "  Step 8, Current reward: 0.008954\n",
      "  Step 9, Current reward: 0.008954\n",
      "  Step 10, Current reward: 0.008954\n",
      "  Step 11, Current reward: 0.008954\n",
      "  Step 12, Current reward: 0.008954\n",
      "Episode 206/1000 complete - Max Reward: 0.008954\n",
      "Starting episode 207/1000\n",
      "  Step 1, Current reward: 0.134798\n",
      "  Step 2, Current reward: 0.134798\n",
      "  Step 3, Current reward: 0.134798\n",
      "  Step 4, Current reward: 0.134798\n",
      "  Step 5, Current reward: 0.134798\n",
      "  Step 6, Current reward: 0.134798\n",
      "  Step 7, Current reward: 0.134798\n",
      "  Step 8, Current reward: 0.134798\n",
      "  Step 9, Current reward: 0.134798\n",
      "  Step 10, Current reward: 0.134798\n",
      "  Step 11, Current reward: 0.134798\n",
      "  Step 12, Current reward: 0.134798\n",
      "Episode 207/1000 complete - Max Reward: 0.134798\n",
      "Starting episode 208/1000\n",
      "  Step 1, Current reward: 0.010339\n",
      "  Step 2, Current reward: 0.010339\n",
      "  Step 3, Current reward: 0.010339\n",
      "  Step 4, Current reward: 0.010339\n",
      "  Step 5, Current reward: 0.010339\n",
      "  Step 6, Current reward: 0.010339\n",
      "  Step 7, Current reward: 0.010339\n",
      "  Step 8, Current reward: 0.010339\n",
      "  Step 9, Current reward: 0.010339\n",
      "  Step 10, Current reward: 0.010339\n",
      "  Step 11, Current reward: 0.010339\n",
      "  Step 12, Current reward: 0.010339\n",
      "Episode 208/1000 complete - Max Reward: 0.010339\n",
      "Starting episode 209/1000\n",
      "  Step 1, Current reward: 0.033423\n",
      "  Step 2, Current reward: 0.033836\n",
      "  Step 3, Current reward: 0.033672\n",
      "  Step 4, Current reward: 0.032860\n",
      "  Step 5, Current reward: 0.031385\n",
      "  Step 6, Current reward: 0.029370\n",
      "  Step 7, Current reward: 0.027053\n",
      "  Step 8, Current reward: 0.024698\n",
      "  Step 9, Current reward: 0.022699\n",
      "  Step 10, Current reward: 0.021510\n",
      "  Step 11, Current reward: 0.020356\n",
      "  Step 12, Current reward: 0.020356\n",
      "  Step 13, Current reward: 0.020356\n",
      "Episode 209/1000 complete - Max Reward: 0.033836\n",
      "Starting episode 210/1000\n",
      "  Step 1, Current reward: 0.050382\n",
      "  Step 2, Current reward: 0.050382\n",
      "  Step 3, Current reward: 0.050382\n",
      "  Step 4, Current reward: 0.050382\n",
      "  Step 5, Current reward: 0.050382\n",
      "  Step 6, Current reward: 0.050382\n",
      "  Step 7, Current reward: 0.050382\n",
      "  Step 8, Current reward: 0.050382\n",
      "  Step 9, Current reward: 0.050382\n",
      "  Step 10, Current reward: 0.050382\n",
      "  Step 11, Current reward: 0.050382\n",
      "  Step 12, Current reward: 0.050382\n",
      "Episode 210/1000 complete - Max Reward: 0.050382\n",
      "Starting episode 211/1000\n",
      "  Step 1, Current reward: 0.007177\n",
      "  Step 2, Current reward: 0.007177\n",
      "  Step 3, Current reward: 0.007177\n",
      "  Step 4, Current reward: 0.007177\n",
      "  Step 5, Current reward: 0.007177\n",
      "  Step 6, Current reward: 0.007177\n",
      "  Step 7, Current reward: 0.007177\n",
      "  Step 8, Current reward: 0.007177\n",
      "  Step 9, Current reward: 0.007177\n",
      "  Step 10, Current reward: 0.007177\n",
      "  Step 11, Current reward: 0.007177\n",
      "  Step 12, Current reward: 0.007177\n",
      "Episode 211/1000 complete - Max Reward: 0.007177\n",
      "Starting episode 212/1000\n",
      "  Step 1, Current reward: 0.012883\n",
      "  Step 2, Current reward: 0.012883\n",
      "  Step 3, Current reward: 0.012883\n",
      "  Step 4, Current reward: 0.012883\n",
      "  Step 5, Current reward: 0.012883\n",
      "  Step 6, Current reward: 0.012883\n",
      "  Step 7, Current reward: 0.012883\n",
      "  Step 8, Current reward: 0.012883\n",
      "  Step 9, Current reward: 0.012883\n",
      "  Step 10, Current reward: 0.012883\n",
      "  Step 11, Current reward: 0.012883\n",
      "  Step 12, Current reward: 0.012883\n",
      "Episode 212/1000 complete - Max Reward: 0.012883\n",
      "Starting episode 213/1000\n",
      "  Step 1, Current reward: 0.078650\n",
      "  Step 2, Current reward: 0.078650\n",
      "  Step 3, Current reward: 0.078650\n",
      "  Step 4, Current reward: 0.078650\n",
      "  Step 5, Current reward: 0.078650\n",
      "  Step 6, Current reward: 0.078650\n",
      "  Step 7, Current reward: 0.078650\n",
      "  Step 8, Current reward: 0.078650\n",
      "  Step 9, Current reward: 0.078650\n",
      "  Step 10, Current reward: 0.078650\n",
      "  Step 11, Current reward: 0.078650\n",
      "  Step 12, Current reward: 0.078650\n",
      "Episode 213/1000 complete - Max Reward: 0.078650\n",
      "Starting episode 214/1000\n",
      "  Step 1, Current reward: 0.011719\n",
      "  Step 2, Current reward: 0.011719\n",
      "  Step 3, Current reward: 0.011719\n",
      "  Step 4, Current reward: 0.011719\n",
      "  Step 5, Current reward: 0.011719\n",
      "  Step 6, Current reward: 0.011719\n",
      "  Step 7, Current reward: 0.011719\n",
      "  Step 8, Current reward: 0.011719\n",
      "  Step 9, Current reward: 0.011719\n",
      "  Step 10, Current reward: 0.011719\n",
      "  Step 11, Current reward: 0.011719\n",
      "  Step 12, Current reward: 0.011719\n",
      "Episode 214/1000 complete - Max Reward: 0.011719\n",
      "Starting episode 215/1000\n",
      "  Step 1, Current reward: 0.011748\n",
      "  Step 2, Current reward: 0.011748\n",
      "  Step 3, Current reward: 0.011748\n",
      "  Step 4, Current reward: 0.011748\n",
      "  Step 5, Current reward: 0.011748\n",
      "  Step 6, Current reward: 0.011748\n",
      "  Step 7, Current reward: 0.011748\n",
      "  Step 8, Current reward: 0.011748\n",
      "  Step 9, Current reward: 0.011748\n",
      "  Step 10, Current reward: 0.011748\n",
      "  Step 11, Current reward: 0.011748\n",
      "  Step 12, Current reward: 0.011748\n",
      "Episode 215/1000 complete - Max Reward: 0.011748\n",
      "Starting episode 216/1000\n",
      "  Step 1, Current reward: 0.065873\n",
      "  Step 2, Current reward: 0.065873\n",
      "  Step 3, Current reward: 0.065873\n",
      "  Step 4, Current reward: 0.065873\n",
      "  Step 5, Current reward: 0.065873\n",
      "  Step 6, Current reward: 0.065873\n",
      "  Step 7, Current reward: 0.065873\n",
      "  Step 8, Current reward: 0.065873\n",
      "  Step 9, Current reward: 0.065873\n",
      "  Step 10, Current reward: 0.065873\n",
      "  Step 11, Current reward: 0.065873\n",
      "  Step 12, Current reward: 0.065873\n",
      "Episode 216/1000 complete - Max Reward: 0.065873\n",
      "Starting episode 217/1000\n",
      "  Step 1, Current reward: 0.016043\n",
      "  Step 2, Current reward: 0.016043\n",
      "  Step 3, Current reward: 0.016043\n",
      "  Step 4, Current reward: 0.016043\n",
      "  Step 5, Current reward: 0.016043\n",
      "  Step 6, Current reward: 0.016043\n",
      "  Step 7, Current reward: 0.016043\n",
      "  Step 8, Current reward: 0.016043\n",
      "  Step 9, Current reward: 0.016043\n",
      "  Step 10, Current reward: 0.016043\n",
      "  Step 11, Current reward: 0.016043\n",
      "  Step 12, Current reward: 0.016043\n",
      "Episode 217/1000 complete - Max Reward: 0.016043\n",
      "Starting episode 218/1000\n",
      "  Step 1, Current reward: 0.131822\n",
      "  Step 2, Current reward: 0.131822\n",
      "  Step 3, Current reward: 0.131822\n",
      "  Step 4, Current reward: 0.131822\n",
      "  Step 5, Current reward: 0.131822\n",
      "  Step 6, Current reward: 0.131822\n",
      "  Step 7, Current reward: 0.131822\n",
      "  Step 8, Current reward: 0.131822\n",
      "  Step 9, Current reward: 0.131822\n",
      "  Step 10, Current reward: 0.131822\n",
      "  Step 11, Current reward: 0.131822\n",
      "  Step 12, Current reward: 0.131822\n",
      "Episode 218/1000 complete - Max Reward: 0.131822\n",
      "Starting episode 219/1000\n",
      "  Step 1, Current reward: 0.008291\n",
      "  Step 2, Current reward: 0.008291\n",
      "  Step 3, Current reward: 0.008291\n",
      "  Step 4, Current reward: 0.008291\n",
      "  Step 5, Current reward: 0.008291\n",
      "  Step 6, Current reward: 0.008291\n",
      "  Step 7, Current reward: 0.008291\n",
      "  Step 8, Current reward: 0.008291\n",
      "  Step 9, Current reward: 0.008291\n",
      "  Step 10, Current reward: 0.008291\n",
      "  Step 11, Current reward: 0.008291\n",
      "  Step 12, Current reward: 0.008291\n",
      "Episode 219/1000 complete - Max Reward: 0.008291\n",
      "Starting episode 220/1000\n",
      "  Step 1, Current reward: 0.003781\n",
      "  Step 2, Current reward: 0.003781\n",
      "  Step 3, Current reward: 0.003781\n",
      "  Step 4, Current reward: 0.003781\n",
      "  Step 5, Current reward: 0.003781\n",
      "  Step 6, Current reward: 0.003781\n",
      "  Step 7, Current reward: 0.003781\n",
      "  Step 8, Current reward: 0.003781\n",
      "  Step 9, Current reward: 0.003781\n",
      "  Step 10, Current reward: 0.003781\n",
      "  Step 11, Current reward: 0.003781\n",
      "  Step 12, Current reward: 0.003781\n",
      "Episode 220/1000 complete - Max Reward: 0.003781\n",
      "Starting episode 221/1000\n",
      "  Step 1, Current reward: 0.186270\n",
      "  Step 2, Current reward: 0.186270\n",
      "  Step 3, Current reward: 0.186270\n",
      "  Step 4, Current reward: 0.186270\n",
      "  Step 5, Current reward: 0.186270\n",
      "  Step 6, Current reward: 0.186270\n",
      "  Step 7, Current reward: 0.186270\n",
      "  Step 8, Current reward: 0.186270\n",
      "  Step 9, Current reward: 0.186270\n",
      "  Step 10, Current reward: 0.186270\n",
      "  Step 11, Current reward: 0.186270\n",
      "  Step 12, Current reward: 0.186270\n",
      "Episode 221/1000 complete - Max Reward: 0.186270\n",
      "Starting episode 222/1000\n",
      "  Step 1, Current reward: 0.019437\n",
      "  Step 2, Current reward: 0.019437\n",
      "  Step 3, Current reward: 0.019437\n",
      "  Step 4, Current reward: 0.019437\n",
      "  Step 5, Current reward: 0.019437\n",
      "  Step 6, Current reward: 0.019437\n",
      "  Step 7, Current reward: 0.019437\n",
      "  Step 8, Current reward: 0.019437\n",
      "  Step 9, Current reward: 0.019437\n",
      "  Step 10, Current reward: 0.019437\n",
      "  Step 11, Current reward: 0.019437\n",
      "  Step 12, Current reward: 0.019437\n",
      "Episode 222/1000 complete - Max Reward: 0.019437\n",
      "Starting episode 223/1000\n",
      "  Step 1, Current reward: 0.091059\n",
      "  Step 2, Current reward: 0.091059\n",
      "  Step 3, Current reward: 0.091059\n",
      "  Step 4, Current reward: 0.091059\n",
      "  Step 5, Current reward: 0.091059\n",
      "  Step 6, Current reward: 0.091059\n",
      "  Step 7, Current reward: 0.091059\n",
      "  Step 8, Current reward: 0.091059\n",
      "  Step 9, Current reward: 0.091059\n",
      "  Step 10, Current reward: 0.091059\n",
      "  Step 11, Current reward: 0.091059\n",
      "  Step 12, Current reward: 0.091059\n",
      "Episode 223/1000 complete - Max Reward: 0.091059\n",
      "Starting episode 224/1000\n",
      "  Step 1, Current reward: 0.102406\n",
      "  Step 2, Current reward: 0.102406\n",
      "  Step 3, Current reward: 0.102406\n",
      "  Step 4, Current reward: 0.102406\n",
      "  Step 5, Current reward: 0.102406\n",
      "  Step 6, Current reward: 0.102406\n",
      "  Step 7, Current reward: 0.102406\n",
      "  Step 8, Current reward: 0.102406\n",
      "  Step 9, Current reward: 0.102406\n",
      "  Step 10, Current reward: 0.102406\n",
      "  Step 11, Current reward: 0.102406\n",
      "  Step 12, Current reward: 0.102406\n",
      "Episode 224/1000 complete - Max Reward: 0.102406\n",
      "Starting episode 225/1000\n",
      "  Step 1, Current reward: 0.201478\n",
      "  Step 2, Current reward: 0.201478\n",
      "  Step 3, Current reward: 0.201478\n",
      "  Step 4, Current reward: 0.201478\n",
      "  Step 5, Current reward: 0.201478\n",
      "  Step 6, Current reward: 0.201478\n",
      "  Step 7, Current reward: 0.201478\n",
      "  Step 8, Current reward: 0.201478\n",
      "  Step 9, Current reward: 0.201478\n",
      "  Step 10, Current reward: 0.201478\n",
      "  Step 11, Current reward: 0.201478\n",
      "  Step 12, Current reward: 0.201478\n",
      "Episode 225/1000 complete - Max Reward: 0.201478\n",
      "Starting episode 226/1000\n",
      "  Step 1, Current reward: 0.045336\n",
      "  Step 2, Current reward: 0.045336\n",
      "  Step 3, Current reward: 0.045336\n",
      "  Step 4, Current reward: 0.045336\n",
      "  Step 5, Current reward: 0.045336\n",
      "  Step 6, Current reward: 0.045336\n",
      "  Step 7, Current reward: 0.045336\n",
      "  Step 8, Current reward: 0.045336\n",
      "  Step 9, Current reward: 0.045336\n",
      "  Step 10, Current reward: 0.045336\n",
      "  Step 11, Current reward: 0.045336\n",
      "  Step 12, Current reward: 0.045336\n",
      "Episode 226/1000 complete - Max Reward: 0.045336\n",
      "Starting episode 227/1000\n",
      "  Step 1, Current reward: 0.014030\n",
      "  Step 2, Current reward: 0.014030\n",
      "  Step 3, Current reward: 0.014030\n",
      "  Step 4, Current reward: 0.014030\n",
      "  Step 5, Current reward: 0.014030\n",
      "  Step 6, Current reward: 0.014030\n",
      "  Step 7, Current reward: 0.014030\n",
      "  Step 8, Current reward: 0.014030\n",
      "  Step 9, Current reward: 0.014030\n",
      "  Step 10, Current reward: 0.014030\n",
      "  Step 11, Current reward: 0.014030\n",
      "  Step 12, Current reward: 0.014030\n",
      "Episode 227/1000 complete - Max Reward: 0.014030\n",
      "Starting episode 228/1000\n",
      "  Step 1, Current reward: 0.022599\n",
      "  Step 2, Current reward: 0.022599\n",
      "  Step 3, Current reward: 0.022599\n",
      "  Step 4, Current reward: 0.022599\n",
      "  Step 5, Current reward: 0.022599\n",
      "  Step 6, Current reward: 0.022599\n",
      "  Step 7, Current reward: 0.022599\n",
      "  Step 8, Current reward: 0.022599\n",
      "  Step 9, Current reward: 0.022599\n",
      "  Step 10, Current reward: 0.022599\n",
      "  Step 11, Current reward: 0.022599\n",
      "  Step 12, Current reward: 0.022599\n",
      "Episode 228/1000 complete - Max Reward: 0.022599\n",
      "Starting episode 229/1000\n",
      "  Step 1, Current reward: 0.008723\n",
      "  Step 2, Current reward: 0.008723\n",
      "  Step 3, Current reward: 0.008723\n",
      "  Step 4, Current reward: 0.008723\n",
      "  Step 5, Current reward: 0.008723\n",
      "  Step 6, Current reward: 0.008723\n",
      "  Step 7, Current reward: 0.008723\n",
      "  Step 8, Current reward: 0.008723\n",
      "  Step 9, Current reward: 0.008723\n",
      "  Step 10, Current reward: 0.008723\n",
      "  Step 11, Current reward: 0.008723\n",
      "  Step 12, Current reward: 0.008723\n",
      "Episode 229/1000 complete - Max Reward: 0.008723\n",
      "Starting episode 230/1000\n",
      "  Step 1, Current reward: 0.054198\n",
      "  Step 2, Current reward: 0.054198\n",
      "  Step 3, Current reward: 0.054198\n",
      "  Step 4, Current reward: 0.054198\n",
      "  Step 5, Current reward: 0.054198\n",
      "  Step 6, Current reward: 0.054198\n",
      "  Step 7, Current reward: 0.054198\n",
      "  Step 8, Current reward: 0.054198\n",
      "  Step 9, Current reward: 0.054198\n",
      "  Step 10, Current reward: 0.054198\n",
      "  Step 11, Current reward: 0.054198\n",
      "  Step 12, Current reward: 0.054198\n",
      "Episode 230/1000 complete - Max Reward: 0.054198\n",
      "Starting episode 231/1000\n",
      "  Step 1, Current reward: 0.011133\n",
      "  Step 2, Current reward: 0.011133\n",
      "  Step 3, Current reward: 0.011133\n",
      "  Step 4, Current reward: 0.011133\n",
      "  Step 5, Current reward: 0.011133\n",
      "  Step 6, Current reward: 0.011133\n",
      "  Step 7, Current reward: 0.011133\n",
      "  Step 8, Current reward: 0.011133\n",
      "  Step 9, Current reward: 0.011133\n",
      "  Step 10, Current reward: 0.011133\n",
      "  Step 11, Current reward: 0.011133\n",
      "  Step 12, Current reward: 0.011133\n",
      "Episode 231/1000 complete - Max Reward: 0.011133\n",
      "Starting episode 232/1000\n",
      "  Step 1, Current reward: 0.177099\n",
      "  Step 2, Current reward: 0.177099\n",
      "  Step 3, Current reward: 0.177099\n",
      "  Step 4, Current reward: 0.177099\n",
      "  Step 5, Current reward: 0.177099\n",
      "  Step 6, Current reward: 0.177099\n",
      "  Step 7, Current reward: 0.177099\n",
      "  Step 8, Current reward: 0.177099\n",
      "  Step 9, Current reward: 0.177099\n",
      "  Step 10, Current reward: 0.177099\n",
      "  Step 11, Current reward: 0.177099\n",
      "  Step 12, Current reward: 0.177099\n",
      "Episode 232/1000 complete - Max Reward: 0.177099\n",
      "Starting episode 233/1000\n",
      "  Step 1, Current reward: 0.065519\n",
      "  Step 2, Current reward: 0.065519\n",
      "  Step 3, Current reward: 0.065519\n",
      "  Step 4, Current reward: 0.065519\n",
      "  Step 5, Current reward: 0.065519\n",
      "  Step 6, Current reward: 0.065519\n",
      "  Step 7, Current reward: 0.065519\n",
      "  Step 8, Current reward: 0.065519\n",
      "  Step 9, Current reward: 0.065519\n",
      "  Step 10, Current reward: 0.065519\n",
      "  Step 11, Current reward: 0.065519\n",
      "  Step 12, Current reward: 0.065519\n",
      "Episode 233/1000 complete - Max Reward: 0.065519\n",
      "Starting episode 234/1000\n",
      "  Step 1, Current reward: 0.006165\n",
      "  Step 2, Current reward: 0.006165\n",
      "  Step 3, Current reward: 0.006165\n",
      "  Step 4, Current reward: 0.006165\n",
      "  Step 5, Current reward: 0.006165\n",
      "  Step 6, Current reward: 0.006165\n",
      "  Step 7, Current reward: 0.006165\n",
      "  Step 8, Current reward: 0.006165\n",
      "  Step 9, Current reward: 0.006165\n",
      "  Step 10, Current reward: 0.006165\n",
      "  Step 11, Current reward: 0.006165\n",
      "  Step 12, Current reward: 0.006165\n",
      "Episode 234/1000 complete - Max Reward: 0.006165\n",
      "Starting episode 235/1000\n",
      "  Step 1, Current reward: 0.003844\n",
      "  Step 2, Current reward: 0.003844\n",
      "  Step 3, Current reward: 0.003844\n",
      "  Step 4, Current reward: 0.003844\n",
      "  Step 5, Current reward: 0.003844\n",
      "  Step 6, Current reward: 0.003844\n",
      "  Step 7, Current reward: 0.003844\n",
      "  Step 8, Current reward: 0.003844\n",
      "  Step 9, Current reward: 0.003844\n",
      "  Step 10, Current reward: 0.003844\n",
      "  Step 11, Current reward: 0.003844\n",
      "  Step 12, Current reward: 0.003844\n",
      "Episode 235/1000 complete - Max Reward: 0.003844\n",
      "Starting episode 236/1000\n",
      "  Step 1, Current reward: 0.173452\n",
      "  Step 2, Current reward: 0.173452\n",
      "  Step 3, Current reward: 0.173452\n",
      "  Step 4, Current reward: 0.173452\n",
      "  Step 5, Current reward: 0.173452\n",
      "  Step 6, Current reward: 0.173452\n",
      "  Step 7, Current reward: 0.173452\n",
      "  Step 8, Current reward: 0.173452\n",
      "  Step 9, Current reward: 0.173452\n",
      "  Step 10, Current reward: 0.173452\n",
      "  Step 11, Current reward: 0.173452\n",
      "  Step 12, Current reward: 0.173452\n",
      "Episode 236/1000 complete - Max Reward: 0.173452\n",
      "Starting episode 237/1000\n",
      "  Step 1, Current reward: 0.013299\n",
      "  Step 2, Current reward: 0.013299\n",
      "  Step 3, Current reward: 0.013299\n",
      "  Step 4, Current reward: 0.013299\n",
      "  Step 5, Current reward: 0.013299\n",
      "  Step 6, Current reward: 0.013299\n",
      "  Step 7, Current reward: 0.013299\n",
      "  Step 8, Current reward: 0.013299\n",
      "  Step 9, Current reward: 0.013299\n",
      "  Step 10, Current reward: 0.013299\n",
      "  Step 11, Current reward: 0.013299\n",
      "  Step 12, Current reward: 0.013299\n",
      "Episode 237/1000 complete - Max Reward: 0.013299\n",
      "Starting episode 238/1000\n",
      "  Step 1, Current reward: 0.115532\n",
      "  Step 2, Current reward: 0.115532\n",
      "  Step 3, Current reward: 0.115532\n",
      "  Step 4, Current reward: 0.115532\n",
      "  Step 5, Current reward: 0.115532\n",
      "  Step 6, Current reward: 0.115532\n",
      "  Step 7, Current reward: 0.115532\n",
      "  Step 8, Current reward: 0.115532\n",
      "  Step 9, Current reward: 0.115532\n",
      "  Step 10, Current reward: 0.115532\n",
      "  Step 11, Current reward: 0.115532\n",
      "  Step 12, Current reward: 0.115532\n",
      "Episode 238/1000 complete - Max Reward: 0.115532\n",
      "Starting episode 239/1000\n",
      "  Step 1, Current reward: 0.003034\n",
      "  Step 2, Current reward: 0.003034\n",
      "  Step 3, Current reward: 0.003034\n",
      "  Step 4, Current reward: 0.003034\n",
      "  Step 5, Current reward: 0.003034\n",
      "  Step 6, Current reward: 0.003034\n",
      "  Step 7, Current reward: 0.003034\n",
      "  Step 8, Current reward: 0.003034\n",
      "  Step 9, Current reward: 0.003034\n",
      "  Step 10, Current reward: 0.003034\n",
      "  Step 11, Current reward: 0.003034\n",
      "  Step 12, Current reward: 0.003034\n",
      "Episode 239/1000 complete - Max Reward: 0.003034\n",
      "Starting episode 240/1000\n",
      "  Step 1, Current reward: 0.039895\n",
      "  Step 2, Current reward: 0.039895\n",
      "  Step 3, Current reward: 0.039895\n",
      "  Step 4, Current reward: 0.039895\n",
      "  Step 5, Current reward: 0.039895\n",
      "  Step 6, Current reward: 0.039895\n",
      "  Step 7, Current reward: 0.039895\n",
      "  Step 8, Current reward: 0.039895\n",
      "  Step 9, Current reward: 0.039895\n",
      "  Step 10, Current reward: 0.039895\n",
      "  Step 11, Current reward: 0.039895\n",
      "  Step 12, Current reward: 0.039895\n",
      "Episode 240/1000 complete - Max Reward: 0.039895\n",
      "Starting episode 241/1000\n",
      "  Step 1, Current reward: 0.010207\n",
      "  Step 2, Current reward: 0.010207\n",
      "  Step 3, Current reward: 0.010207\n",
      "  Step 4, Current reward: 0.010207\n",
      "  Step 5, Current reward: 0.010207\n",
      "  Step 6, Current reward: 0.010207\n",
      "  Step 7, Current reward: 0.010207\n",
      "  Step 8, Current reward: 0.010207\n",
      "  Step 9, Current reward: 0.010207\n",
      "  Step 10, Current reward: 0.010207\n",
      "  Step 11, Current reward: 0.010207\n",
      "  Step 12, Current reward: 0.010207\n",
      "Episode 241/1000 complete - Max Reward: 0.010207\n",
      "Starting episode 242/1000\n",
      "  Step 1, Current reward: 0.020775\n",
      "  Step 2, Current reward: 0.020775\n",
      "  Step 3, Current reward: 0.020775\n",
      "  Step 4, Current reward: 0.020775\n",
      "  Step 5, Current reward: 0.020775\n",
      "  Step 6, Current reward: 0.020775\n",
      "  Step 7, Current reward: 0.020775\n",
      "  Step 8, Current reward: 0.020775\n",
      "  Step 9, Current reward: 0.020775\n",
      "  Step 10, Current reward: 0.020775\n",
      "  Step 11, Current reward: 0.020775\n",
      "  Step 12, Current reward: 0.020775\n",
      "Episode 242/1000 complete - Max Reward: 0.020775\n",
      "Starting episode 243/1000\n",
      "  Step 1, Current reward: 0.011744\n",
      "  Step 2, Current reward: 0.011744\n",
      "  Step 3, Current reward: 0.011744\n",
      "  Step 4, Current reward: 0.011744\n",
      "  Step 5, Current reward: 0.011744\n",
      "  Step 6, Current reward: 0.011744\n",
      "  Step 7, Current reward: 0.011744\n",
      "  Step 8, Current reward: 0.011744\n",
      "  Step 9, Current reward: 0.011744\n",
      "  Step 10, Current reward: 0.011744\n",
      "  Step 11, Current reward: 0.011744\n",
      "  Step 12, Current reward: 0.011744\n",
      "Episode 243/1000 complete - Max Reward: 0.011744\n",
      "Starting episode 244/1000\n",
      "  Step 1, Current reward: 0.000557\n",
      "  Step 2, Current reward: 0.000557\n",
      "  Step 3, Current reward: 0.000557\n",
      "  Step 4, Current reward: 0.000557\n",
      "  Step 5, Current reward: 0.000557\n",
      "  Step 6, Current reward: 0.000557\n",
      "  Step 7, Current reward: 0.000557\n",
      "  Step 8, Current reward: 0.000557\n",
      "  Step 9, Current reward: 0.000557\n",
      "  Step 10, Current reward: 0.000557\n",
      "  Step 11, Current reward: 0.000557\n",
      "  Step 12, Current reward: 0.000557\n",
      "Episode 244/1000 complete - Max Reward: 0.000557\n",
      "Starting episode 245/1000\n",
      "  Step 1, Current reward: 0.006074\n",
      "  Step 2, Current reward: 0.006074\n",
      "  Step 3, Current reward: 0.006074\n",
      "  Step 4, Current reward: 0.006074\n",
      "  Step 5, Current reward: 0.006074\n",
      "  Step 6, Current reward: 0.006074\n",
      "  Step 7, Current reward: 0.006074\n",
      "  Step 8, Current reward: 0.006074\n",
      "  Step 9, Current reward: 0.006074\n",
      "  Step 10, Current reward: 0.006074\n",
      "  Step 11, Current reward: 0.006074\n",
      "  Step 12, Current reward: 0.006074\n",
      "Episode 245/1000 complete - Max Reward: 0.006074\n",
      "Starting episode 246/1000\n",
      "  Step 1, Current reward: 0.000729\n",
      "  Step 2, Current reward: 0.000729\n",
      "  Step 3, Current reward: 0.000729\n",
      "  Step 4, Current reward: 0.000729\n",
      "  Step 5, Current reward: 0.000729\n",
      "  Step 6, Current reward: 0.000729\n",
      "  Step 7, Current reward: 0.000729\n",
      "  Step 8, Current reward: 0.000729\n",
      "  Step 9, Current reward: 0.000729\n",
      "  Step 10, Current reward: 0.000729\n",
      "  Step 11, Current reward: 0.000729\n",
      "  Step 12, Current reward: 0.000729\n",
      "Episode 246/1000 complete - Max Reward: 0.000729\n",
      "Starting episode 247/1000\n",
      "  Step 1, Current reward: 0.035747\n",
      "  Step 2, Current reward: 0.035747\n",
      "  Step 3, Current reward: 0.035747\n",
      "  Step 4, Current reward: 0.035747\n",
      "  Step 5, Current reward: 0.035747\n",
      "  Step 6, Current reward: 0.035747\n",
      "  Step 7, Current reward: 0.035747\n",
      "  Step 8, Current reward: 0.035747\n",
      "  Step 9, Current reward: 0.035747\n",
      "  Step 10, Current reward: 0.035747\n",
      "  Step 11, Current reward: 0.035747\n",
      "  Step 12, Current reward: 0.035747\n",
      "Episode 247/1000 complete - Max Reward: 0.035747\n",
      "Starting episode 248/1000\n",
      "  Step 1, Current reward: 0.009986\n",
      "  Step 2, Current reward: 0.009986\n",
      "  Step 3, Current reward: 0.009986\n",
      "  Step 4, Current reward: 0.009986\n",
      "  Step 5, Current reward: 0.009986\n",
      "  Step 6, Current reward: 0.009986\n",
      "  Step 7, Current reward: 0.009986\n",
      "  Step 8, Current reward: 0.009986\n",
      "  Step 9, Current reward: 0.009986\n",
      "  Step 10, Current reward: 0.009986\n",
      "  Step 11, Current reward: 0.009986\n",
      "  Step 12, Current reward: 0.009986\n",
      "Episode 248/1000 complete - Max Reward: 0.009986\n",
      "Starting episode 249/1000\n",
      "  Step 1, Current reward: 0.017859\n",
      "  Step 2, Current reward: 0.017859\n",
      "  Step 3, Current reward: 0.017859\n",
      "  Step 4, Current reward: 0.017859\n",
      "  Step 5, Current reward: 0.017859\n",
      "  Step 6, Current reward: 0.017859\n",
      "  Step 7, Current reward: 0.017859\n",
      "  Step 8, Current reward: 0.017859\n",
      "  Step 9, Current reward: 0.017859\n",
      "  Step 10, Current reward: 0.017859\n",
      "  Step 11, Current reward: 0.017859\n",
      "  Step 12, Current reward: 0.017859\n",
      "Episode 249/1000 complete - Max Reward: 0.017859\n",
      "Starting episode 250/1000\n",
      "  Step 1, Current reward: 0.035951\n",
      "  Step 2, Current reward: 0.035951\n",
      "  Step 3, Current reward: 0.035951\n",
      "  Step 4, Current reward: 0.035951\n",
      "  Step 5, Current reward: 0.035951\n",
      "  Step 6, Current reward: 0.035951\n",
      "  Step 7, Current reward: 0.035951\n",
      "  Step 8, Current reward: 0.035951\n",
      "  Step 9, Current reward: 0.035951\n",
      "  Step 10, Current reward: 0.035951\n",
      "  Step 11, Current reward: 0.035951\n",
      "  Step 12, Current reward: 0.035951\n",
      "Episode 250/1000 complete - Max Reward: 0.035951\n",
      "Starting episode 251/1000\n",
      "  Step 1, Current reward: 0.010836\n",
      "  Step 2, Current reward: 0.010836\n",
      "  Step 3, Current reward: 0.010836\n",
      "  Step 4, Current reward: 0.010836\n",
      "  Step 5, Current reward: 0.010836\n",
      "  Step 6, Current reward: 0.010836\n",
      "  Step 7, Current reward: 0.010836\n",
      "  Step 8, Current reward: 0.010836\n",
      "  Step 9, Current reward: 0.010836\n",
      "  Step 10, Current reward: 0.010836\n",
      "  Step 11, Current reward: 0.010836\n",
      "  Step 12, Current reward: 0.010836\n",
      "Episode 251/1000 complete - Max Reward: 0.010836\n",
      "Starting episode 252/1000\n",
      "  Step 1, Current reward: 0.009917\n",
      "  Step 2, Current reward: 0.009917\n",
      "  Step 3, Current reward: 0.009917\n",
      "  Step 4, Current reward: 0.009917\n",
      "  Step 5, Current reward: 0.009917\n",
      "  Step 6, Current reward: 0.009917\n",
      "  Step 7, Current reward: 0.009917\n",
      "  Step 8, Current reward: 0.009917\n",
      "  Step 9, Current reward: 0.009917\n",
      "  Step 10, Current reward: 0.009917\n",
      "  Step 11, Current reward: 0.009917\n",
      "  Step 12, Current reward: 0.009917\n",
      "Episode 252/1000 complete - Max Reward: 0.009917\n",
      "Starting episode 253/1000\n",
      "  Step 1, Current reward: 0.027540\n",
      "  Step 2, Current reward: 0.027540\n",
      "  Step 3, Current reward: 0.027540\n",
      "  Step 4, Current reward: 0.027540\n",
      "  Step 5, Current reward: 0.027540\n",
      "  Step 6, Current reward: 0.027540\n",
      "  Step 7, Current reward: 0.027540\n",
      "  Step 8, Current reward: 0.027540\n",
      "  Step 9, Current reward: 0.027540\n",
      "  Step 10, Current reward: 0.027540\n",
      "  Step 11, Current reward: 0.027540\n",
      "  Step 12, Current reward: 0.027540\n",
      "Episode 253/1000 complete - Max Reward: 0.027540\n",
      "Starting episode 254/1000\n",
      "  Step 1, Current reward: 0.058729\n",
      "  Step 2, Current reward: 0.058729\n",
      "  Step 3, Current reward: 0.058729\n",
      "  Step 4, Current reward: 0.058729\n",
      "  Step 5, Current reward: 0.058729\n",
      "  Step 6, Current reward: 0.058729\n",
      "  Step 7, Current reward: 0.058729\n",
      "  Step 8, Current reward: 0.058729\n",
      "  Step 9, Current reward: 0.058729\n",
      "  Step 10, Current reward: 0.058729\n",
      "  Step 11, Current reward: 0.058729\n",
      "  Step 12, Current reward: 0.058729\n",
      "Episode 254/1000 complete - Max Reward: 0.058729\n",
      "Starting episode 255/1000\n",
      "  Step 1, Current reward: 0.001152\n",
      "  Step 2, Current reward: 0.001152\n",
      "  Step 3, Current reward: 0.001152\n",
      "  Step 4, Current reward: 0.001152\n",
      "  Step 5, Current reward: 0.001152\n",
      "  Step 6, Current reward: 0.001152\n",
      "  Step 7, Current reward: 0.001152\n",
      "  Step 8, Current reward: 0.001152\n",
      "  Step 9, Current reward: 0.001152\n",
      "  Step 10, Current reward: 0.001152\n",
      "  Step 11, Current reward: 0.001152\n",
      "  Step 12, Current reward: 0.001152\n",
      "Episode 255/1000 complete - Max Reward: 0.001152\n",
      "Starting episode 256/1000\n",
      "  Step 1, Current reward: 0.006476\n",
      "  Step 2, Current reward: 0.006476\n",
      "  Step 3, Current reward: 0.006476\n",
      "  Step 4, Current reward: 0.006476\n",
      "  Step 5, Current reward: 0.006476\n",
      "  Step 6, Current reward: 0.006476\n",
      "  Step 7, Current reward: 0.006476\n",
      "  Step 8, Current reward: 0.006476\n",
      "  Step 9, Current reward: 0.006476\n",
      "  Step 10, Current reward: 0.006476\n",
      "  Step 11, Current reward: 0.006476\n",
      "  Step 12, Current reward: 0.006476\n",
      "Episode 256/1000 complete - Max Reward: 0.006476\n",
      "Starting episode 257/1000\n",
      "  Step 1, Current reward: 0.050878\n",
      "  Step 2, Current reward: 0.050878\n",
      "  Step 3, Current reward: 0.050878\n",
      "  Step 4, Current reward: 0.050878\n",
      "  Step 5, Current reward: 0.050878\n",
      "  Step 6, Current reward: 0.050878\n",
      "  Step 7, Current reward: 0.050878\n",
      "  Step 8, Current reward: 0.050878\n",
      "  Step 9, Current reward: 0.050878\n",
      "  Step 10, Current reward: 0.050878\n",
      "  Step 11, Current reward: 0.050878\n",
      "  Step 12, Current reward: 0.050878\n",
      "Episode 257/1000 complete - Max Reward: 0.050878\n",
      "Starting episode 258/1000\n",
      "  Step 1, Current reward: 0.019930\n",
      "  Step 2, Current reward: 0.019930\n",
      "  Step 3, Current reward: 0.019930\n",
      "  Step 4, Current reward: 0.019930\n",
      "  Step 5, Current reward: 0.019930\n",
      "  Step 6, Current reward: 0.019930\n",
      "  Step 7, Current reward: 0.019930\n",
      "  Step 8, Current reward: 0.019930\n",
      "  Step 9, Current reward: 0.019930\n",
      "  Step 10, Current reward: 0.019930\n",
      "  Step 11, Current reward: 0.019930\n",
      "  Step 12, Current reward: 0.019930\n",
      "Episode 258/1000 complete - Max Reward: 0.019930\n",
      "Starting episode 259/1000\n",
      "  Step 1, Current reward: 0.017575\n",
      "  Step 2, Current reward: 0.017575\n",
      "  Step 3, Current reward: 0.017575\n",
      "  Step 4, Current reward: 0.017575\n",
      "  Step 5, Current reward: 0.017575\n",
      "  Step 6, Current reward: 0.017575\n",
      "  Step 7, Current reward: 0.017575\n",
      "  Step 8, Current reward: 0.017575\n",
      "  Step 9, Current reward: 0.017575\n",
      "  Step 10, Current reward: 0.017575\n",
      "  Step 11, Current reward: 0.017575\n",
      "  Step 12, Current reward: 0.017575\n",
      "Episode 259/1000 complete - Max Reward: 0.017575\n",
      "Starting episode 260/1000\n",
      "  Step 1, Current reward: 0.013350\n",
      "  Step 2, Current reward: 0.013350\n",
      "  Step 3, Current reward: 0.013350\n",
      "  Step 4, Current reward: 0.013350\n",
      "  Step 5, Current reward: 0.013350\n",
      "  Step 6, Current reward: 0.013350\n",
      "  Step 7, Current reward: 0.013350\n",
      "  Step 8, Current reward: 0.013350\n",
      "  Step 9, Current reward: 0.013350\n",
      "  Step 10, Current reward: 0.013350\n",
      "  Step 11, Current reward: 0.013350\n",
      "  Step 12, Current reward: 0.013350\n",
      "Episode 260/1000 complete - Max Reward: 0.013350\n",
      "Starting episode 261/1000\n",
      "  Step 1, Current reward: 0.004474\n",
      "  Step 2, Current reward: 0.004474\n",
      "  Step 3, Current reward: 0.004474\n",
      "  Step 4, Current reward: 0.004474\n",
      "  Step 5, Current reward: 0.004474\n",
      "  Step 6, Current reward: 0.004474\n",
      "  Step 7, Current reward: 0.004474\n",
      "  Step 8, Current reward: 0.004474\n",
      "  Step 9, Current reward: 0.004474\n",
      "  Step 10, Current reward: 0.004474\n",
      "  Step 11, Current reward: 0.004474\n",
      "  Step 12, Current reward: 0.004474\n",
      "Episode 261/1000 complete - Max Reward: 0.004474\n",
      "Starting episode 262/1000\n",
      "  Step 1, Current reward: 0.016743\n",
      "  Step 2, Current reward: 0.016743\n",
      "  Step 3, Current reward: 0.016743\n",
      "  Step 4, Current reward: 0.016743\n",
      "  Step 5, Current reward: 0.016743\n",
      "  Step 6, Current reward: 0.016743\n",
      "  Step 7, Current reward: 0.016743\n",
      "  Step 8, Current reward: 0.016743\n",
      "  Step 9, Current reward: 0.016743\n",
      "  Step 10, Current reward: 0.016743\n",
      "  Step 11, Current reward: 0.016743\n",
      "  Step 12, Current reward: 0.016743\n",
      "Episode 262/1000 complete - Max Reward: 0.016743\n",
      "Starting episode 263/1000\n",
      "  Step 1, Current reward: 0.048688\n",
      "  Step 2, Current reward: 0.048688\n",
      "  Step 3, Current reward: 0.048688\n",
      "  Step 4, Current reward: 0.048688\n",
      "  Step 5, Current reward: 0.048688\n",
      "  Step 6, Current reward: 0.048688\n",
      "  Step 7, Current reward: 0.048688\n",
      "  Step 8, Current reward: 0.048688\n",
      "  Step 9, Current reward: 0.048688\n",
      "  Step 10, Current reward: 0.048688\n",
      "  Step 11, Current reward: 0.048688\n",
      "  Step 12, Current reward: 0.048688\n",
      "Episode 263/1000 complete - Max Reward: 0.048688\n",
      "Starting episode 264/1000\n",
      "  Step 1, Current reward: 0.025932\n",
      "  Step 2, Current reward: 0.025932\n",
      "  Step 3, Current reward: 0.025932\n",
      "  Step 4, Current reward: 0.025932\n",
      "  Step 5, Current reward: 0.025932\n",
      "  Step 6, Current reward: 0.025932\n",
      "  Step 7, Current reward: 0.025932\n",
      "  Step 8, Current reward: 0.025932\n",
      "  Step 9, Current reward: 0.025932\n",
      "  Step 10, Current reward: 0.025932\n",
      "  Step 11, Current reward: 0.025932\n",
      "  Step 12, Current reward: 0.025932\n",
      "Episode 264/1000 complete - Max Reward: 0.025932\n",
      "Starting episode 265/1000\n",
      "  Step 1, Current reward: 0.057569\n",
      "  Step 2, Current reward: 0.057569\n",
      "  Step 3, Current reward: 0.057569\n",
      "  Step 4, Current reward: 0.057569\n",
      "  Step 5, Current reward: 0.057569\n",
      "  Step 6, Current reward: 0.057569\n",
      "  Step 7, Current reward: 0.057569\n",
      "  Step 8, Current reward: 0.057569\n",
      "  Step 9, Current reward: 0.057569\n",
      "  Step 10, Current reward: 0.057569\n",
      "  Step 11, Current reward: 0.057569\n",
      "  Step 12, Current reward: 0.057569\n",
      "Episode 265/1000 complete - Max Reward: 0.057569\n",
      "Starting episode 266/1000\n",
      "  Step 1, Current reward: 0.022661\n",
      "  Step 2, Current reward: 0.022661\n",
      "  Step 3, Current reward: 0.022661\n",
      "  Step 4, Current reward: 0.022661\n",
      "  Step 5, Current reward: 0.022661\n",
      "  Step 6, Current reward: 0.022661\n",
      "  Step 7, Current reward: 0.022661\n",
      "  Step 8, Current reward: 0.022661\n",
      "  Step 9, Current reward: 0.022661\n",
      "  Step 10, Current reward: 0.022661\n",
      "  Step 11, Current reward: 0.022661\n",
      "  Step 12, Current reward: 0.022661\n",
      "Episode 266/1000 complete - Max Reward: 0.022661\n",
      "Starting episode 267/1000\n",
      "  Step 1, Current reward: 0.024067\n",
      "  Step 2, Current reward: 0.024067\n",
      "  Step 3, Current reward: 0.024067\n",
      "  Step 4, Current reward: 0.024067\n",
      "  Step 5, Current reward: 0.024067\n",
      "  Step 6, Current reward: 0.024067\n",
      "  Step 7, Current reward: 0.024067\n",
      "  Step 8, Current reward: 0.024067\n",
      "  Step 9, Current reward: 0.024067\n",
      "  Step 10, Current reward: 0.024067\n",
      "  Step 11, Current reward: 0.024067\n",
      "  Step 12, Current reward: 0.024067\n",
      "Episode 267/1000 complete - Max Reward: 0.024067\n",
      "Starting episode 268/1000\n",
      "  Step 1, Current reward: 0.000934\n",
      "  Step 2, Current reward: 0.000934\n",
      "  Step 3, Current reward: 0.000934\n",
      "  Step 4, Current reward: 0.000934\n",
      "  Step 5, Current reward: 0.000934\n",
      "  Step 6, Current reward: 0.000934\n",
      "  Step 7, Current reward: 0.000934\n",
      "  Step 8, Current reward: 0.000934\n",
      "  Step 9, Current reward: 0.000934\n",
      "  Step 10, Current reward: 0.000934\n",
      "  Step 11, Current reward: 0.000934\n",
      "  Step 12, Current reward: 0.000934\n",
      "Episode 268/1000 complete - Max Reward: 0.000934\n",
      "Starting episode 269/1000\n",
      "  Step 1, Current reward: 0.081860\n",
      "  Step 2, Current reward: 0.081860\n",
      "  Step 3, Current reward: 0.081860\n",
      "  Step 4, Current reward: 0.081860\n",
      "  Step 5, Current reward: 0.081860\n",
      "  Step 6, Current reward: 0.081860\n",
      "  Step 7, Current reward: 0.081860\n",
      "  Step 8, Current reward: 0.081860\n",
      "  Step 9, Current reward: 0.081860\n",
      "  Step 10, Current reward: 0.081860\n",
      "  Step 11, Current reward: 0.081860\n",
      "  Step 12, Current reward: 0.081860\n",
      "Episode 269/1000 complete - Max Reward: 0.081860\n",
      "Starting episode 270/1000\n",
      "  Step 1, Current reward: 0.009650\n",
      "  Step 2, Current reward: 0.009650\n",
      "  Step 3, Current reward: 0.009650\n",
      "  Step 4, Current reward: 0.009650\n",
      "  Step 5, Current reward: 0.009650\n",
      "  Step 6, Current reward: 0.009650\n",
      "  Step 7, Current reward: 0.009650\n",
      "  Step 8, Current reward: 0.009650\n",
      "  Step 9, Current reward: 0.009650\n",
      "  Step 10, Current reward: 0.009650\n",
      "  Step 11, Current reward: 0.009650\n",
      "  Step 12, Current reward: 0.009650\n",
      "Episode 270/1000 complete - Max Reward: 0.009650\n",
      "Starting episode 271/1000\n",
      "  Step 1, Current reward: 0.061898\n",
      "  Step 2, Current reward: 0.061898\n",
      "  Step 3, Current reward: 0.061898\n",
      "  Step 4, Current reward: 0.061898\n",
      "  Step 5, Current reward: 0.061898\n",
      "  Step 6, Current reward: 0.061898\n",
      "  Step 7, Current reward: 0.061898\n",
      "  Step 8, Current reward: 0.061898\n",
      "  Step 9, Current reward: 0.061898\n",
      "  Step 10, Current reward: 0.061898\n",
      "  Step 11, Current reward: 0.061898\n",
      "  Step 12, Current reward: 0.061898\n",
      "Episode 271/1000 complete - Max Reward: 0.061898\n",
      "Starting episode 272/1000\n",
      "  Step 1, Current reward: 0.001322\n",
      "  Step 2, Current reward: 0.001198\n",
      "  Step 3, Current reward: 0.001084\n",
      "  Step 4, Current reward: 0.000995\n",
      "  Step 5, Current reward: 0.000943\n",
      "  Step 6, Current reward: 0.000894\n",
      "  Step 7, Current reward: 0.000894\n",
      "  Step 8, Current reward: 0.000894\n",
      "  Step 9, Current reward: 0.000894\n",
      "  Step 10, Current reward: 0.000894\n",
      "  Step 11, Current reward: 0.000894\n",
      "  Step 12, Current reward: 0.000894\n",
      "Episode 272/1000 complete - Max Reward: 0.001322\n",
      "Starting episode 273/1000\n",
      "  Step 1, Current reward: 0.031917\n",
      "  Step 2, Current reward: 0.031917\n",
      "  Step 3, Current reward: 0.031917\n",
      "  Step 4, Current reward: 0.031917\n",
      "  Step 5, Current reward: 0.031917\n",
      "  Step 6, Current reward: 0.031917\n",
      "  Step 7, Current reward: 0.031917\n",
      "  Step 8, Current reward: 0.031917\n",
      "  Step 9, Current reward: 0.031917\n",
      "  Step 10, Current reward: 0.031917\n",
      "  Step 11, Current reward: 0.031917\n",
      "  Step 12, Current reward: 0.031917\n",
      "Episode 273/1000 complete - Max Reward: 0.031917\n",
      "Starting episode 274/1000\n",
      "  Step 1, Current reward: 0.016770\n",
      "  Step 2, Current reward: 0.016770\n",
      "  Step 3, Current reward: 0.016770\n",
      "  Step 4, Current reward: 0.016770\n",
      "  Step 5, Current reward: 0.016770\n",
      "  Step 6, Current reward: 0.016770\n",
      "  Step 7, Current reward: 0.016770\n",
      "  Step 8, Current reward: 0.016770\n",
      "  Step 9, Current reward: 0.016770\n",
      "  Step 10, Current reward: 0.016770\n",
      "  Step 11, Current reward: 0.016770\n",
      "  Step 12, Current reward: 0.016770\n",
      "Episode 274/1000 complete - Max Reward: 0.016770\n",
      "Starting episode 275/1000\n",
      "  Step 1, Current reward: 0.014968\n",
      "  Step 2, Current reward: 0.014968\n",
      "  Step 3, Current reward: 0.014968\n",
      "  Step 4, Current reward: 0.014968\n",
      "  Step 5, Current reward: 0.014968\n",
      "  Step 6, Current reward: 0.014968\n",
      "  Step 7, Current reward: 0.014968\n",
      "  Step 8, Current reward: 0.014968\n",
      "  Step 9, Current reward: 0.014968\n",
      "  Step 10, Current reward: 0.014968\n",
      "  Step 11, Current reward: 0.014968\n",
      "  Step 12, Current reward: 0.014968\n",
      "Episode 275/1000 complete - Max Reward: 0.014968\n",
      "Starting episode 276/1000\n",
      "  Step 1, Current reward: 0.034417\n",
      "  Step 2, Current reward: 0.034417\n",
      "  Step 3, Current reward: 0.034417\n",
      "  Step 4, Current reward: 0.034417\n",
      "  Step 5, Current reward: 0.034417\n",
      "  Step 6, Current reward: 0.034417\n",
      "  Step 7, Current reward: 0.034417\n",
      "  Step 8, Current reward: 0.034417\n",
      "  Step 9, Current reward: 0.034417\n",
      "  Step 10, Current reward: 0.034417\n",
      "  Step 11, Current reward: 0.034417\n",
      "  Step 12, Current reward: 0.034417\n",
      "Episode 276/1000 complete - Max Reward: 0.034417\n",
      "Starting episode 277/1000\n",
      "  Step 1, Current reward: 0.001002\n",
      "  Step 2, Current reward: 0.001002\n",
      "  Step 3, Current reward: 0.001002\n",
      "  Step 4, Current reward: 0.001002\n",
      "  Step 5, Current reward: 0.001002\n",
      "  Step 6, Current reward: 0.001002\n",
      "  Step 7, Current reward: 0.001002\n",
      "  Step 8, Current reward: 0.001002\n",
      "  Step 9, Current reward: 0.001002\n",
      "  Step 10, Current reward: 0.001002\n",
      "  Step 11, Current reward: 0.001002\n",
      "  Step 12, Current reward: 0.001002\n",
      "Episode 277/1000 complete - Max Reward: 0.001002\n",
      "Starting episode 278/1000\n",
      "  Step 1, Current reward: 0.000316\n",
      "  Step 2, Current reward: 0.000302\n",
      "  Step 3, Current reward: 0.000302\n",
      "  Step 4, Current reward: 0.000302\n",
      "  Step 5, Current reward: 0.000302\n",
      "  Step 6, Current reward: 0.000302\n",
      "  Step 7, Current reward: 0.000302\n",
      "  Step 8, Current reward: 0.000302\n",
      "  Step 9, Current reward: 0.000302\n",
      "  Step 10, Current reward: 0.000302\n",
      "  Step 11, Current reward: 0.000302\n",
      "  Step 12, Current reward: 0.000302\n",
      "Episode 278/1000 complete - Max Reward: 0.000316\n",
      "Starting episode 279/1000\n",
      "  Step 1, Current reward: 0.036671\n",
      "  Step 2, Current reward: 0.036671\n",
      "  Step 3, Current reward: 0.036671\n",
      "  Step 4, Current reward: 0.036671\n",
      "  Step 5, Current reward: 0.036671\n",
      "  Step 6, Current reward: 0.036671\n",
      "  Step 7, Current reward: 0.036671\n",
      "  Step 8, Current reward: 0.036671\n",
      "  Step 9, Current reward: 0.036671\n",
      "  Step 10, Current reward: 0.036671\n",
      "  Step 11, Current reward: 0.036671\n",
      "  Step 12, Current reward: 0.036671\n",
      "Episode 279/1000 complete - Max Reward: 0.036671\n",
      "Starting episode 280/1000\n",
      "  Step 1, Current reward: 0.002408\n",
      "  Step 2, Current reward: 0.002408\n",
      "  Step 3, Current reward: 0.002408\n",
      "  Step 4, Current reward: 0.002408\n",
      "  Step 5, Current reward: 0.002408\n",
      "  Step 6, Current reward: 0.002408\n",
      "  Step 7, Current reward: 0.002408\n",
      "  Step 8, Current reward: 0.002408\n",
      "  Step 9, Current reward: 0.002408\n",
      "  Step 10, Current reward: 0.002408\n",
      "  Step 11, Current reward: 0.002408\n",
      "  Step 12, Current reward: 0.002408\n",
      "Episode 280/1000 complete - Max Reward: 0.002408\n",
      "Starting episode 281/1000\n",
      "  Step 1, Current reward: 0.002901\n",
      "  Step 2, Current reward: 0.002901\n",
      "  Step 3, Current reward: 0.002901\n",
      "  Step 4, Current reward: 0.002901\n",
      "  Step 5, Current reward: 0.002901\n",
      "  Step 6, Current reward: 0.002901\n",
      "  Step 7, Current reward: 0.002901\n",
      "  Step 8, Current reward: 0.002901\n",
      "  Step 9, Current reward: 0.002901\n",
      "  Step 10, Current reward: 0.002901\n",
      "  Step 11, Current reward: 0.002901\n",
      "  Step 12, Current reward: 0.002901\n",
      "Episode 281/1000 complete - Max Reward: 0.002901\n",
      "Starting episode 282/1000\n",
      "  Step 1, Current reward: 0.011958\n",
      "  Step 2, Current reward: 0.011958\n",
      "  Step 3, Current reward: 0.011958\n",
      "  Step 4, Current reward: 0.011958\n",
      "  Step 5, Current reward: 0.011958\n",
      "  Step 6, Current reward: 0.011958\n",
      "  Step 7, Current reward: 0.011958\n",
      "  Step 8, Current reward: 0.011958\n",
      "  Step 9, Current reward: 0.011958\n",
      "  Step 10, Current reward: 0.011958\n",
      "  Step 11, Current reward: 0.011958\n",
      "  Step 12, Current reward: 0.011958\n",
      "Episode 282/1000 complete - Max Reward: 0.011958\n",
      "Starting episode 283/1000\n",
      "  Step 1, Current reward: 0.002644\n",
      "  Step 2, Current reward: 0.002644\n",
      "  Step 3, Current reward: 0.002644\n",
      "  Step 4, Current reward: 0.002644\n",
      "  Step 5, Current reward: 0.002644\n",
      "  Step 6, Current reward: 0.002644\n",
      "  Step 7, Current reward: 0.002644\n",
      "  Step 8, Current reward: 0.002644\n",
      "  Step 9, Current reward: 0.002644\n",
      "  Step 10, Current reward: 0.002644\n",
      "  Step 11, Current reward: 0.002644\n",
      "  Step 12, Current reward: 0.002644\n",
      "Episode 283/1000 complete - Max Reward: 0.002644\n",
      "Starting episode 284/1000\n",
      "  Step 1, Current reward: 0.010026\n",
      "  Step 2, Current reward: 0.010026\n",
      "  Step 3, Current reward: 0.010026\n",
      "  Step 4, Current reward: 0.010026\n",
      "  Step 5, Current reward: 0.010026\n",
      "  Step 6, Current reward: 0.010026\n",
      "  Step 7, Current reward: 0.010026\n",
      "  Step 8, Current reward: 0.010026\n",
      "  Step 9, Current reward: 0.010026\n",
      "  Step 10, Current reward: 0.010026\n",
      "  Step 11, Current reward: 0.010026\n",
      "  Step 12, Current reward: 0.010026\n",
      "Episode 284/1000 complete - Max Reward: 0.010026\n",
      "Starting episode 285/1000\n",
      "  Step 1, Current reward: 0.016593\n",
      "  Step 2, Current reward: 0.016593\n",
      "  Step 3, Current reward: 0.016593\n",
      "  Step 4, Current reward: 0.016593\n",
      "  Step 5, Current reward: 0.016593\n",
      "  Step 6, Current reward: 0.016593\n",
      "  Step 7, Current reward: 0.016593\n",
      "  Step 8, Current reward: 0.016593\n",
      "  Step 9, Current reward: 0.016593\n",
      "  Step 10, Current reward: 0.016593\n",
      "  Step 11, Current reward: 0.016593\n",
      "  Step 12, Current reward: 0.016593\n",
      "Episode 285/1000 complete - Max Reward: 0.016593\n",
      "Starting episode 286/1000\n",
      "  Step 1, Current reward: 0.009718\n",
      "  Step 2, Current reward: 0.009718\n",
      "  Step 3, Current reward: 0.009718\n",
      "  Step 4, Current reward: 0.009718\n",
      "  Step 5, Current reward: 0.009718\n",
      "  Step 6, Current reward: 0.009718\n",
      "  Step 7, Current reward: 0.009718\n",
      "  Step 8, Current reward: 0.009718\n",
      "  Step 9, Current reward: 0.009718\n",
      "  Step 10, Current reward: 0.009718\n",
      "  Step 11, Current reward: 0.009718\n",
      "  Step 12, Current reward: 0.009718\n",
      "Episode 286/1000 complete - Max Reward: 0.009718\n",
      "Starting episode 287/1000\n",
      "  Step 1, Current reward: 0.004170\n",
      "  Step 2, Current reward: 0.004170\n",
      "  Step 3, Current reward: 0.004170\n",
      "  Step 4, Current reward: 0.004170\n",
      "  Step 5, Current reward: 0.004170\n",
      "  Step 6, Current reward: 0.004170\n",
      "  Step 7, Current reward: 0.004170\n",
      "  Step 8, Current reward: 0.004170\n",
      "  Step 9, Current reward: 0.004170\n",
      "  Step 10, Current reward: 0.004170\n",
      "  Step 11, Current reward: 0.004170\n",
      "  Step 12, Current reward: 0.004170\n",
      "Episode 287/1000 complete - Max Reward: 0.004170\n",
      "Starting episode 288/1000\n",
      "  Step 1, Current reward: 0.020851\n",
      "  Step 2, Current reward: 0.020851\n",
      "  Step 3, Current reward: 0.020851\n",
      "  Step 4, Current reward: 0.020851\n",
      "  Step 5, Current reward: 0.020851\n",
      "  Step 6, Current reward: 0.020851\n",
      "  Step 7, Current reward: 0.020851\n",
      "  Step 8, Current reward: 0.020851\n",
      "  Step 9, Current reward: 0.020851\n",
      "  Step 10, Current reward: 0.020851\n",
      "  Step 11, Current reward: 0.020851\n",
      "  Step 12, Current reward: 0.020851\n",
      "Episode 288/1000 complete - Max Reward: 0.020851\n",
      "Starting episode 289/1000\n",
      "  Step 1, Current reward: 0.031682\n",
      "  Step 2, Current reward: 0.031682\n",
      "  Step 3, Current reward: 0.031682\n",
      "  Step 4, Current reward: 0.031682\n",
      "  Step 5, Current reward: 0.031682\n",
      "  Step 6, Current reward: 0.031682\n",
      "  Step 7, Current reward: 0.031682\n",
      "  Step 8, Current reward: 0.031682\n",
      "  Step 9, Current reward: 0.031682\n",
      "  Step 10, Current reward: 0.031682\n",
      "  Step 11, Current reward: 0.031682\n",
      "  Step 12, Current reward: 0.031682\n",
      "Episode 289/1000 complete - Max Reward: 0.031682\n",
      "Starting episode 290/1000\n",
      "  Step 1, Current reward: 0.040757\n",
      "  Step 2, Current reward: 0.040757\n",
      "  Step 3, Current reward: 0.040757\n",
      "  Step 4, Current reward: 0.040757\n",
      "  Step 5, Current reward: 0.040757\n",
      "  Step 6, Current reward: 0.040757\n",
      "  Step 7, Current reward: 0.040757\n",
      "  Step 8, Current reward: 0.040757\n",
      "  Step 9, Current reward: 0.040757\n",
      "  Step 10, Current reward: 0.040757\n",
      "  Step 11, Current reward: 0.040757\n",
      "  Step 12, Current reward: 0.040757\n",
      "Episode 290/1000 complete - Max Reward: 0.040757\n",
      "Starting episode 291/1000\n",
      "  Step 1, Current reward: 0.011636\n",
      "  Step 2, Current reward: 0.011636\n",
      "  Step 3, Current reward: 0.011636\n",
      "  Step 4, Current reward: 0.011636\n",
      "  Step 5, Current reward: 0.011636\n",
      "  Step 6, Current reward: 0.011636\n",
      "  Step 7, Current reward: 0.011636\n",
      "  Step 8, Current reward: 0.011636\n",
      "  Step 9, Current reward: 0.011636\n",
      "  Step 10, Current reward: 0.011636\n",
      "  Step 11, Current reward: 0.011636\n",
      "  Step 12, Current reward: 0.011636\n",
      "Episode 291/1000 complete - Max Reward: 0.011636\n",
      "Starting episode 292/1000\n",
      "  Step 1, Current reward: 0.014794\n",
      "  Step 2, Current reward: 0.014794\n",
      "  Step 3, Current reward: 0.014794\n",
      "  Step 4, Current reward: 0.014794\n",
      "  Step 5, Current reward: 0.014794\n",
      "  Step 6, Current reward: 0.014794\n",
      "  Step 7, Current reward: 0.014794\n",
      "  Step 8, Current reward: 0.014794\n",
      "  Step 9, Current reward: 0.014794\n",
      "  Step 10, Current reward: 0.014794\n",
      "  Step 11, Current reward: 0.014794\n",
      "  Step 12, Current reward: 0.014794\n",
      "Episode 292/1000 complete - Max Reward: 0.014794\n",
      "Starting episode 293/1000\n",
      "  Step 1, Current reward: 0.167858\n",
      "  Step 2, Current reward: 0.167858\n",
      "  Step 3, Current reward: 0.167858\n",
      "  Step 4, Current reward: 0.167858\n",
      "  Step 5, Current reward: 0.167858\n",
      "  Step 6, Current reward: 0.167858\n",
      "  Step 7, Current reward: 0.167858\n",
      "  Step 8, Current reward: 0.167858\n",
      "  Step 9, Current reward: 0.167858\n",
      "  Step 10, Current reward: 0.167858\n",
      "  Step 11, Current reward: 0.167858\n",
      "  Step 12, Current reward: 0.167858\n",
      "Episode 293/1000 complete - Max Reward: 0.167858\n",
      "Starting episode 294/1000\n",
      "  Step 1, Current reward: 0.005787\n",
      "  Step 2, Current reward: 0.005787\n",
      "  Step 3, Current reward: 0.005787\n",
      "  Step 4, Current reward: 0.005787\n",
      "  Step 5, Current reward: 0.005787\n",
      "  Step 6, Current reward: 0.005787\n",
      "  Step 7, Current reward: 0.005787\n",
      "  Step 8, Current reward: 0.005787\n",
      "  Step 9, Current reward: 0.005787\n",
      "  Step 10, Current reward: 0.005787\n",
      "  Step 11, Current reward: 0.005787\n",
      "  Step 12, Current reward: 0.005787\n",
      "Episode 294/1000 complete - Max Reward: 0.005787\n",
      "Starting episode 295/1000\n",
      "  Step 1, Current reward: 0.005878\n",
      "  Step 2, Current reward: 0.005878\n",
      "  Step 3, Current reward: 0.005878\n",
      "  Step 4, Current reward: 0.005878\n",
      "  Step 5, Current reward: 0.005878\n",
      "  Step 6, Current reward: 0.005878\n",
      "  Step 7, Current reward: 0.005878\n",
      "  Step 8, Current reward: 0.005878\n",
      "  Step 9, Current reward: 0.005878\n",
      "  Step 10, Current reward: 0.005878\n",
      "  Step 11, Current reward: 0.005878\n",
      "  Step 12, Current reward: 0.005878\n",
      "Episode 295/1000 complete - Max Reward: 0.005878\n",
      "Starting episode 296/1000\n",
      "  Step 1, Current reward: 0.000937\n",
      "  Step 2, Current reward: 0.000937\n",
      "  Step 3, Current reward: 0.000937\n",
      "  Step 4, Current reward: 0.000937\n",
      "  Step 5, Current reward: 0.000937\n",
      "  Step 6, Current reward: 0.000937\n",
      "  Step 7, Current reward: 0.000937\n",
      "  Step 8, Current reward: 0.000937\n",
      "  Step 9, Current reward: 0.000937\n",
      "  Step 10, Current reward: 0.000937\n",
      "  Step 11, Current reward: 0.000937\n",
      "  Step 12, Current reward: 0.000937\n",
      "Episode 296/1000 complete - Max Reward: 0.000937\n",
      "Starting episode 297/1000\n",
      "  Step 1, Current reward: 0.016358\n",
      "  Step 2, Current reward: 0.016358\n",
      "  Step 3, Current reward: 0.016358\n",
      "  Step 4, Current reward: 0.016358\n",
      "  Step 5, Current reward: 0.016358\n",
      "  Step 6, Current reward: 0.016358\n",
      "  Step 7, Current reward: 0.016358\n",
      "  Step 8, Current reward: 0.016358\n",
      "  Step 9, Current reward: 0.016358\n",
      "  Step 10, Current reward: 0.016358\n",
      "  Step 11, Current reward: 0.016358\n",
      "  Step 12, Current reward: 0.016358\n",
      "Episode 297/1000 complete - Max Reward: 0.016358\n",
      "Starting episode 298/1000\n",
      "  Step 1, Current reward: 0.008181\n",
      "  Step 2, Current reward: 0.008181\n",
      "  Step 3, Current reward: 0.008181\n",
      "  Step 4, Current reward: 0.008181\n",
      "  Step 5, Current reward: 0.008181\n",
      "  Step 6, Current reward: 0.008181\n",
      "  Step 7, Current reward: 0.008181\n",
      "  Step 8, Current reward: 0.008181\n",
      "  Step 9, Current reward: 0.008181\n",
      "  Step 10, Current reward: 0.008181\n",
      "  Step 11, Current reward: 0.008181\n",
      "  Step 12, Current reward: 0.008181\n",
      "Episode 298/1000 complete - Max Reward: 0.008181\n",
      "Starting episode 299/1000\n",
      "  Step 1, Current reward: 0.034026\n",
      "  Step 2, Current reward: 0.034026\n",
      "  Step 3, Current reward: 0.034026\n",
      "  Step 4, Current reward: 0.034026\n",
      "  Step 5, Current reward: 0.034026\n",
      "  Step 6, Current reward: 0.034026\n",
      "  Step 7, Current reward: 0.034026\n",
      "  Step 8, Current reward: 0.034026\n",
      "  Step 9, Current reward: 0.034026\n",
      "  Step 10, Current reward: 0.034026\n",
      "  Step 11, Current reward: 0.034026\n",
      "  Step 12, Current reward: 0.034026\n",
      "Episode 299/1000 complete - Max Reward: 0.034026\n",
      "Starting episode 300/1000\n",
      "  Step 1, Current reward: 0.000103\n",
      "  Step 2, Current reward: 0.000103\n",
      "  Step 3, Current reward: 0.000103\n",
      "  Step 4, Current reward: 0.000103\n",
      "  Step 5, Current reward: 0.000103\n",
      "  Step 6, Current reward: 0.000103\n",
      "  Step 7, Current reward: 0.000103\n",
      "  Step 8, Current reward: 0.000103\n",
      "  Step 9, Current reward: 0.000103\n",
      "  Step 10, Current reward: 0.000103\n",
      "  Step 11, Current reward: 0.000103\n",
      "  Step 12, Current reward: 0.000103\n",
      "Episode 300/1000 complete - Max Reward: 0.000103\n",
      "Starting episode 301/1000\n",
      "  Step 1, Current reward: 0.016450\n",
      "  Step 2, Current reward: 0.016450\n",
      "  Step 3, Current reward: 0.016450\n",
      "  Step 4, Current reward: 0.016450\n",
      "  Step 5, Current reward: 0.016450\n",
      "  Step 6, Current reward: 0.016450\n",
      "  Step 7, Current reward: 0.016450\n",
      "  Step 8, Current reward: 0.016450\n",
      "  Step 9, Current reward: 0.016450\n",
      "  Step 10, Current reward: 0.016450\n",
      "  Step 11, Current reward: 0.016450\n",
      "  Step 12, Current reward: 0.016450\n",
      "Episode 301/1000 complete - Max Reward: 0.016450\n",
      "Starting episode 302/1000\n",
      "  Step 1, Current reward: 0.006111\n",
      "  Step 2, Current reward: 0.006111\n",
      "  Step 3, Current reward: 0.006111\n",
      "  Step 4, Current reward: 0.006111\n",
      "  Step 5, Current reward: 0.006111\n",
      "  Step 6, Current reward: 0.006111\n",
      "  Step 7, Current reward: 0.006111\n",
      "  Step 8, Current reward: 0.006111\n",
      "  Step 9, Current reward: 0.006111\n",
      "  Step 10, Current reward: 0.006111\n",
      "  Step 11, Current reward: 0.006111\n",
      "  Step 12, Current reward: 0.006111\n",
      "Episode 302/1000 complete - Max Reward: 0.006111\n",
      "Starting episode 303/1000\n",
      "  Step 1, Current reward: 0.035849\n",
      "  Step 2, Current reward: 0.035849\n",
      "  Step 3, Current reward: 0.035849\n",
      "  Step 4, Current reward: 0.035849\n",
      "  Step 5, Current reward: 0.035849\n",
      "  Step 6, Current reward: 0.035849\n",
      "  Step 7, Current reward: 0.035849\n",
      "  Step 8, Current reward: 0.035849\n",
      "  Step 9, Current reward: 0.035849\n",
      "  Step 10, Current reward: 0.035849\n",
      "  Step 11, Current reward: 0.035849\n",
      "  Step 12, Current reward: 0.035849\n",
      "Episode 303/1000 complete - Max Reward: 0.035849\n",
      "Starting episode 304/1000\n",
      "  Step 1, Current reward: 0.002939\n",
      "  Step 2, Current reward: 0.002939\n",
      "  Step 3, Current reward: 0.002939\n",
      "  Step 4, Current reward: 0.002939\n",
      "  Step 5, Current reward: 0.002939\n",
      "  Step 6, Current reward: 0.002939\n",
      "  Step 7, Current reward: 0.002939\n",
      "  Step 8, Current reward: 0.002939\n",
      "  Step 9, Current reward: 0.002939\n",
      "  Step 10, Current reward: 0.002939\n",
      "  Step 11, Current reward: 0.002939\n",
      "  Step 12, Current reward: 0.002939\n",
      "Episode 304/1000 complete - Max Reward: 0.002939\n",
      "Starting episode 305/1000\n",
      "  Step 1, Current reward: 0.043073\n",
      "  Step 2, Current reward: 0.043073\n",
      "  Step 3, Current reward: 0.043073\n",
      "  Step 4, Current reward: 0.043073\n",
      "  Step 5, Current reward: 0.043073\n",
      "  Step 6, Current reward: 0.043073\n",
      "  Step 7, Current reward: 0.043073\n",
      "  Step 8, Current reward: 0.043073\n",
      "  Step 9, Current reward: 0.043073\n",
      "  Step 10, Current reward: 0.043073\n",
      "  Step 11, Current reward: 0.043073\n",
      "  Step 12, Current reward: 0.043073\n",
      "Episode 305/1000 complete - Max Reward: 0.043073\n",
      "Starting episode 306/1000\n",
      "  Step 1, Current reward: 0.063572\n",
      "  Step 2, Current reward: 0.063572\n",
      "  Step 3, Current reward: 0.063572\n",
      "  Step 4, Current reward: 0.063572\n",
      "  Step 5, Current reward: 0.063572\n",
      "  Step 6, Current reward: 0.063572\n",
      "  Step 7, Current reward: 0.063572\n",
      "  Step 8, Current reward: 0.063572\n",
      "  Step 9, Current reward: 0.063572\n",
      "  Step 10, Current reward: 0.063572\n",
      "  Step 11, Current reward: 0.063572\n",
      "  Step 12, Current reward: 0.063572\n",
      "Episode 306/1000 complete - Max Reward: 0.063572\n",
      "Starting episode 307/1000\n",
      "  Step 1, Current reward: 0.006744\n",
      "  Step 2, Current reward: 0.006744\n",
      "  Step 3, Current reward: 0.006744\n",
      "  Step 4, Current reward: 0.006744\n",
      "  Step 5, Current reward: 0.006744\n",
      "  Step 6, Current reward: 0.006744\n",
      "  Step 7, Current reward: 0.006744\n",
      "  Step 8, Current reward: 0.006744\n",
      "  Step 9, Current reward: 0.006744\n",
      "  Step 10, Current reward: 0.006744\n",
      "  Step 11, Current reward: 0.006744\n",
      "  Step 12, Current reward: 0.006744\n",
      "Episode 307/1000 complete - Max Reward: 0.006744\n",
      "Starting episode 308/1000\n",
      "  Step 1, Current reward: 0.002221\n",
      "  Step 2, Current reward: 0.002221\n",
      "  Step 3, Current reward: 0.002221\n",
      "  Step 4, Current reward: 0.002221\n",
      "  Step 5, Current reward: 0.002221\n",
      "  Step 6, Current reward: 0.002221\n",
      "  Step 7, Current reward: 0.002221\n",
      "  Step 8, Current reward: 0.002221\n",
      "  Step 9, Current reward: 0.002221\n",
      "  Step 10, Current reward: 0.002221\n",
      "  Step 11, Current reward: 0.002221\n",
      "  Step 12, Current reward: 0.002221\n",
      "Episode 308/1000 complete - Max Reward: 0.002221\n",
      "Starting episode 309/1000\n",
      "  Step 1, Current reward: 0.000973\n",
      "  Step 2, Current reward: 0.000973\n",
      "  Step 3, Current reward: 0.000973\n",
      "  Step 4, Current reward: 0.000973\n",
      "  Step 5, Current reward: 0.000973\n",
      "  Step 6, Current reward: 0.000973\n",
      "  Step 7, Current reward: 0.000973\n",
      "  Step 8, Current reward: 0.000973\n",
      "  Step 9, Current reward: 0.000973\n",
      "  Step 10, Current reward: 0.000973\n",
      "  Step 11, Current reward: 0.000973\n",
      "  Step 12, Current reward: 0.000973\n",
      "Episode 309/1000 complete - Max Reward: 0.000973\n",
      "Starting episode 310/1000\n",
      "  Step 1, Current reward: 0.212016\n",
      "  Step 2, Current reward: 0.212016\n",
      "  Step 3, Current reward: 0.212016\n",
      "  Step 4, Current reward: 0.212016\n",
      "  Step 5, Current reward: 0.212016\n",
      "  Step 6, Current reward: 0.212016\n",
      "  Step 7, Current reward: 0.212016\n",
      "  Step 8, Current reward: 0.212016\n",
      "  Step 9, Current reward: 0.212016\n",
      "  Step 10, Current reward: 0.212016\n",
      "  Step 11, Current reward: 0.212016\n",
      "  Step 12, Current reward: 0.212016\n",
      "Episode 310/1000 complete - Max Reward: 0.212016\n",
      "Starting episode 311/1000\n",
      "  Step 1, Current reward: 0.085987\n",
      "  Step 2, Current reward: 0.085987\n",
      "  Step 3, Current reward: 0.085987\n",
      "  Step 4, Current reward: 0.085987\n",
      "  Step 5, Current reward: 0.085987\n",
      "  Step 6, Current reward: 0.085987\n",
      "  Step 7, Current reward: 0.085987\n",
      "  Step 8, Current reward: 0.085987\n",
      "  Step 9, Current reward: 0.085987\n",
      "  Step 10, Current reward: 0.085987\n",
      "  Step 11, Current reward: 0.085987\n",
      "  Step 12, Current reward: 0.085987\n",
      "Episode 311/1000 complete - Max Reward: 0.085987\n",
      "Starting episode 312/1000\n",
      "  Step 1, Current reward: 0.001945\n",
      "  Step 2, Current reward: 0.001945\n",
      "  Step 3, Current reward: 0.001945\n",
      "  Step 4, Current reward: 0.001945\n",
      "  Step 5, Current reward: 0.001945\n",
      "  Step 6, Current reward: 0.001945\n",
      "  Step 7, Current reward: 0.001945\n",
      "  Step 8, Current reward: 0.001945\n",
      "  Step 9, Current reward: 0.001945\n",
      "  Step 10, Current reward: 0.001945\n",
      "  Step 11, Current reward: 0.001945\n",
      "  Step 12, Current reward: 0.001945\n",
      "Episode 312/1000 complete - Max Reward: 0.001945\n",
      "Starting episode 313/1000\n",
      "  Step 1, Current reward: 0.026146\n",
      "  Step 2, Current reward: 0.026146\n",
      "  Step 3, Current reward: 0.026146\n",
      "  Step 4, Current reward: 0.026146\n",
      "  Step 5, Current reward: 0.026146\n",
      "  Step 6, Current reward: 0.026146\n",
      "  Step 7, Current reward: 0.026146\n",
      "  Step 8, Current reward: 0.026146\n",
      "  Step 9, Current reward: 0.026146\n",
      "  Step 10, Current reward: 0.026146\n",
      "  Step 11, Current reward: 0.026146\n",
      "  Step 12, Current reward: 0.026146\n",
      "Episode 313/1000 complete - Max Reward: 0.026146\n",
      "Starting episode 314/1000\n",
      "  Step 1, Current reward: 0.006355\n",
      "  Step 2, Current reward: 0.006959\n",
      "  Step 3, Current reward: 0.007669\n",
      "  Step 4, Current reward: 0.008495\n",
      "  Step 5, Current reward: 0.008495\n",
      "  Step 6, Current reward: 0.008495\n",
      "  Step 7, Current reward: 0.008495\n",
      "  Step 8, Current reward: 0.008495\n",
      "  Step 9, Current reward: 0.008495\n",
      "  Step 10, Current reward: 0.008495\n",
      "  Step 11, Current reward: 0.008495\n",
      "  Step 12, Current reward: 0.008495\n",
      "  Step 13, Current reward: 0.008495\n",
      "  Step 14, Current reward: 0.008495\n",
      "  Step 15, Current reward: 0.008495\n",
      "Episode 314/1000 complete - Max Reward: 0.008495\n",
      "Starting episode 315/1000\n",
      "  Step 1, Current reward: 0.166462\n",
      "  Step 2, Current reward: 0.166462\n",
      "  Step 3, Current reward: 0.166462\n",
      "  Step 4, Current reward: 0.166462\n",
      "  Step 5, Current reward: 0.166462\n",
      "  Step 6, Current reward: 0.166462\n",
      "  Step 7, Current reward: 0.166462\n",
      "  Step 8, Current reward: 0.166462\n",
      "  Step 9, Current reward: 0.166462\n",
      "  Step 10, Current reward: 0.166462\n",
      "  Step 11, Current reward: 0.166462\n",
      "  Step 12, Current reward: 0.166462\n",
      "Episode 315/1000 complete - Max Reward: 0.166462\n",
      "Starting episode 316/1000\n",
      "  Step 1, Current reward: 0.041793\n",
      "  Step 2, Current reward: 0.041793\n",
      "  Step 3, Current reward: 0.041793\n",
      "  Step 4, Current reward: 0.041793\n",
      "  Step 5, Current reward: 0.041793\n",
      "  Step 6, Current reward: 0.041793\n",
      "  Step 7, Current reward: 0.041793\n",
      "  Step 8, Current reward: 0.041793\n",
      "  Step 9, Current reward: 0.041793\n",
      "  Step 10, Current reward: 0.041793\n",
      "  Step 11, Current reward: 0.041793\n",
      "  Step 12, Current reward: 0.041793\n",
      "Episode 316/1000 complete - Max Reward: 0.041793\n",
      "Starting episode 317/1000\n",
      "  Step 1, Current reward: 0.042835\n",
      "  Step 2, Current reward: 0.042835\n",
      "  Step 3, Current reward: 0.042835\n",
      "  Step 4, Current reward: 0.042835\n",
      "  Step 5, Current reward: 0.042835\n",
      "  Step 6, Current reward: 0.042835\n",
      "  Step 7, Current reward: 0.042835\n",
      "  Step 8, Current reward: 0.042835\n",
      "  Step 9, Current reward: 0.042835\n",
      "  Step 10, Current reward: 0.042835\n",
      "  Step 11, Current reward: 0.042835\n",
      "  Step 12, Current reward: 0.042835\n",
      "Episode 317/1000 complete - Max Reward: 0.042835\n",
      "Starting episode 318/1000\n",
      "  Step 1, Current reward: 0.031874\n",
      "  Step 2, Current reward: 0.031874\n",
      "  Step 3, Current reward: 0.031874\n",
      "  Step 4, Current reward: 0.031874\n",
      "  Step 5, Current reward: 0.031874\n",
      "  Step 6, Current reward: 0.031874\n",
      "  Step 7, Current reward: 0.031874\n",
      "  Step 8, Current reward: 0.031874\n",
      "  Step 9, Current reward: 0.031874\n",
      "  Step 10, Current reward: 0.031874\n",
      "  Step 11, Current reward: 0.031874\n",
      "  Step 12, Current reward: 0.031874\n",
      "Episode 318/1000 complete - Max Reward: 0.031874\n",
      "Starting episode 319/1000\n",
      "  Step 1, Current reward: 0.016152\n",
      "  Step 2, Current reward: 0.016152\n",
      "  Step 3, Current reward: 0.016152\n",
      "  Step 4, Current reward: 0.016152\n",
      "  Step 5, Current reward: 0.016152\n",
      "  Step 6, Current reward: 0.016152\n",
      "  Step 7, Current reward: 0.016152\n",
      "  Step 8, Current reward: 0.016152\n",
      "  Step 9, Current reward: 0.016152\n",
      "  Step 10, Current reward: 0.016152\n",
      "  Step 11, Current reward: 0.016152\n",
      "  Step 12, Current reward: 0.016152\n",
      "Episode 319/1000 complete - Max Reward: 0.016152\n",
      "Starting episode 320/1000\n",
      "  Step 1, Current reward: 0.043248\n",
      "  Step 2, Current reward: 0.043248\n",
      "  Step 3, Current reward: 0.043248\n",
      "  Step 4, Current reward: 0.043248\n",
      "  Step 5, Current reward: 0.043248\n",
      "  Step 6, Current reward: 0.043248\n",
      "  Step 7, Current reward: 0.043248\n",
      "  Step 8, Current reward: 0.043248\n",
      "  Step 9, Current reward: 0.043248\n",
      "  Step 10, Current reward: 0.043248\n",
      "  Step 11, Current reward: 0.043248\n",
      "  Step 12, Current reward: 0.043248\n",
      "Episode 320/1000 complete - Max Reward: 0.043248\n",
      "Starting episode 321/1000\n",
      "  Step 1, Current reward: 0.023261\n",
      "  Step 2, Current reward: 0.023261\n",
      "  Step 3, Current reward: 0.023261\n",
      "  Step 4, Current reward: 0.023261\n",
      "  Step 5, Current reward: 0.023261\n",
      "  Step 6, Current reward: 0.023261\n",
      "  Step 7, Current reward: 0.023261\n",
      "  Step 8, Current reward: 0.023261\n",
      "  Step 9, Current reward: 0.023261\n",
      "  Step 10, Current reward: 0.023261\n",
      "  Step 11, Current reward: 0.023261\n",
      "  Step 12, Current reward: 0.023261\n",
      "Episode 321/1000 complete - Max Reward: 0.023261\n",
      "Starting episode 322/1000\n",
      "  Step 1, Current reward: 0.160864\n",
      "  Step 2, Current reward: 0.160864\n",
      "  Step 3, Current reward: 0.160864\n",
      "  Step 4, Current reward: 0.160864\n",
      "  Step 5, Current reward: 0.160864\n",
      "  Step 6, Current reward: 0.160864\n",
      "  Step 7, Current reward: 0.160864\n",
      "  Step 8, Current reward: 0.160864\n",
      "  Step 9, Current reward: 0.160864\n",
      "  Step 10, Current reward: 0.160864\n",
      "  Step 11, Current reward: 0.160864\n",
      "  Step 12, Current reward: 0.160864\n",
      "Episode 322/1000 complete - Max Reward: 0.160864\n",
      "Starting episode 323/1000\n",
      "  Step 1, Current reward: 0.039727\n",
      "  Step 2, Current reward: 0.039727\n",
      "  Step 3, Current reward: 0.039727\n",
      "  Step 4, Current reward: 0.039727\n",
      "  Step 5, Current reward: 0.039727\n",
      "  Step 6, Current reward: 0.039727\n",
      "  Step 7, Current reward: 0.039727\n",
      "  Step 8, Current reward: 0.039727\n",
      "  Step 9, Current reward: 0.039727\n",
      "  Step 10, Current reward: 0.039727\n",
      "  Step 11, Current reward: 0.039727\n",
      "  Step 12, Current reward: 0.039727\n",
      "Episode 323/1000 complete - Max Reward: 0.039727\n",
      "Starting episode 324/1000\n",
      "  Step 1, Current reward: 0.009169\n",
      "  Step 2, Current reward: 0.009169\n",
      "  Step 3, Current reward: 0.009169\n",
      "  Step 4, Current reward: 0.009169\n",
      "  Step 5, Current reward: 0.009169\n",
      "  Step 6, Current reward: 0.009169\n",
      "  Step 7, Current reward: 0.009169\n",
      "  Step 8, Current reward: 0.009169\n",
      "  Step 9, Current reward: 0.009169\n",
      "  Step 10, Current reward: 0.009169\n",
      "  Step 11, Current reward: 0.009169\n",
      "  Step 12, Current reward: 0.009169\n",
      "Episode 324/1000 complete - Max Reward: 0.009169\n",
      "Starting episode 325/1000\n",
      "  Step 1, Current reward: 0.004102\n",
      "  Step 2, Current reward: 0.004102\n",
      "  Step 3, Current reward: 0.004102\n",
      "  Step 4, Current reward: 0.004102\n",
      "  Step 5, Current reward: 0.004102\n",
      "  Step 6, Current reward: 0.004102\n",
      "  Step 7, Current reward: 0.004102\n",
      "  Step 8, Current reward: 0.004102\n",
      "  Step 9, Current reward: 0.004102\n",
      "  Step 10, Current reward: 0.004102\n",
      "  Step 11, Current reward: 0.004102\n",
      "  Step 12, Current reward: 0.004102\n",
      "Episode 325/1000 complete - Max Reward: 0.004102\n",
      "Starting episode 326/1000\n",
      "  Step 1, Current reward: 0.004423\n",
      "  Step 2, Current reward: 0.004423\n",
      "  Step 3, Current reward: 0.004423\n",
      "  Step 4, Current reward: 0.004423\n",
      "  Step 5, Current reward: 0.004423\n",
      "  Step 6, Current reward: 0.004423\n",
      "  Step 7, Current reward: 0.004423\n",
      "  Step 8, Current reward: 0.004423\n",
      "  Step 9, Current reward: 0.004423\n",
      "  Step 10, Current reward: 0.004423\n",
      "  Step 11, Current reward: 0.004423\n",
      "  Step 12, Current reward: 0.004423\n",
      "Episode 326/1000 complete - Max Reward: 0.004423\n",
      "Starting episode 327/1000\n",
      "  Step 1, Current reward: 0.062681\n",
      "  Step 2, Current reward: 0.062681\n",
      "  Step 3, Current reward: 0.062681\n",
      "  Step 4, Current reward: 0.062681\n",
      "  Step 5, Current reward: 0.062681\n",
      "  Step 6, Current reward: 0.062681\n",
      "  Step 7, Current reward: 0.062681\n",
      "  Step 8, Current reward: 0.062681\n",
      "  Step 9, Current reward: 0.062681\n",
      "  Step 10, Current reward: 0.062681\n",
      "  Step 11, Current reward: 0.062681\n",
      "  Step 12, Current reward: 0.062681\n",
      "Episode 327/1000 complete - Max Reward: 0.062681\n",
      "Starting episode 328/1000\n",
      "  Step 1, Current reward: 0.054068\n",
      "  Step 2, Current reward: 0.054068\n",
      "  Step 3, Current reward: 0.054068\n",
      "  Step 4, Current reward: 0.054068\n",
      "  Step 5, Current reward: 0.054068\n",
      "  Step 6, Current reward: 0.054068\n",
      "  Step 7, Current reward: 0.054068\n",
      "  Step 8, Current reward: 0.054068\n",
      "  Step 9, Current reward: 0.054068\n",
      "  Step 10, Current reward: 0.054068\n",
      "  Step 11, Current reward: 0.054068\n",
      "  Step 12, Current reward: 0.054068\n",
      "Episode 328/1000 complete - Max Reward: 0.054068\n",
      "Starting episode 329/1000\n",
      "  Step 1, Current reward: 0.090988\n",
      "  Step 2, Current reward: 0.090988\n",
      "  Step 3, Current reward: 0.090988\n",
      "  Step 4, Current reward: 0.090988\n",
      "  Step 5, Current reward: 0.090988\n",
      "  Step 6, Current reward: 0.090988\n",
      "  Step 7, Current reward: 0.090988\n",
      "  Step 8, Current reward: 0.090988\n",
      "  Step 9, Current reward: 0.090988\n",
      "  Step 10, Current reward: 0.090988\n",
      "  Step 11, Current reward: 0.090988\n",
      "  Step 12, Current reward: 0.090988\n",
      "Episode 329/1000 complete - Max Reward: 0.090988\n",
      "Starting episode 330/1000\n",
      "  Step 1, Current reward: 0.154121\n",
      "  Step 2, Current reward: 0.154121\n",
      "  Step 3, Current reward: 0.154121\n",
      "  Step 4, Current reward: 0.154121\n",
      "  Step 5, Current reward: 0.154121\n",
      "  Step 6, Current reward: 0.154121\n",
      "  Step 7, Current reward: 0.154121\n",
      "  Step 8, Current reward: 0.154121\n",
      "  Step 9, Current reward: 0.154121\n",
      "  Step 10, Current reward: 0.154121\n",
      "  Step 11, Current reward: 0.154121\n",
      "  Step 12, Current reward: 0.154121\n",
      "Episode 330/1000 complete - Max Reward: 0.154121\n",
      "Starting episode 331/1000\n",
      "  Step 1, Current reward: 0.058276\n",
      "  Step 2, Current reward: 0.058276\n",
      "  Step 3, Current reward: 0.058276\n",
      "  Step 4, Current reward: 0.058276\n",
      "  Step 5, Current reward: 0.058276\n",
      "  Step 6, Current reward: 0.058276\n",
      "  Step 7, Current reward: 0.058276\n",
      "  Step 8, Current reward: 0.058276\n",
      "  Step 9, Current reward: 0.058276\n",
      "  Step 10, Current reward: 0.058276\n",
      "  Step 11, Current reward: 0.058276\n",
      "  Step 12, Current reward: 0.058276\n",
      "Episode 331/1000 complete - Max Reward: 0.058276\n",
      "Starting episode 332/1000\n",
      "  Step 1, Current reward: 0.000549\n",
      "  Step 2, Current reward: 0.000549\n",
      "  Step 3, Current reward: 0.000549\n",
      "  Step 4, Current reward: 0.000549\n",
      "  Step 5, Current reward: 0.000549\n",
      "  Step 6, Current reward: 0.000549\n",
      "  Step 7, Current reward: 0.000549\n",
      "  Step 8, Current reward: 0.000549\n",
      "  Step 9, Current reward: 0.000549\n",
      "  Step 10, Current reward: 0.000549\n",
      "  Step 11, Current reward: 0.000549\n",
      "  Step 12, Current reward: 0.000549\n",
      "Episode 332/1000 complete - Max Reward: 0.000549\n",
      "Starting episode 333/1000\n",
      "  Step 1, Current reward: 0.015912\n",
      "  Step 2, Current reward: 0.015912\n",
      "  Step 3, Current reward: 0.015912\n",
      "  Step 4, Current reward: 0.015912\n",
      "  Step 5, Current reward: 0.015912\n",
      "  Step 6, Current reward: 0.015912\n",
      "  Step 7, Current reward: 0.015912\n",
      "  Step 8, Current reward: 0.015912\n",
      "  Step 9, Current reward: 0.015912\n",
      "  Step 10, Current reward: 0.015912\n",
      "  Step 11, Current reward: 0.015912\n",
      "  Step 12, Current reward: 0.015912\n",
      "Episode 333/1000 complete - Max Reward: 0.015912\n",
      "Starting episode 334/1000\n",
      "  Step 1, Current reward: 0.001629\n",
      "  Step 2, Current reward: 0.001629\n",
      "  Step 3, Current reward: 0.001629\n",
      "  Step 4, Current reward: 0.001629\n",
      "  Step 5, Current reward: 0.001629\n",
      "  Step 6, Current reward: 0.001629\n",
      "  Step 7, Current reward: 0.001629\n",
      "  Step 8, Current reward: 0.001629\n",
      "  Step 9, Current reward: 0.001629\n",
      "  Step 10, Current reward: 0.001629\n",
      "  Step 11, Current reward: 0.001629\n",
      "  Step 12, Current reward: 0.001629\n",
      "Episode 334/1000 complete - Max Reward: 0.001629\n",
      "Starting episode 335/1000\n",
      "  Step 1, Current reward: 0.036824\n",
      "  Step 2, Current reward: 0.036824\n",
      "  Step 3, Current reward: 0.036824\n",
      "  Step 4, Current reward: 0.036824\n",
      "  Step 5, Current reward: 0.036824\n",
      "  Step 6, Current reward: 0.036824\n",
      "  Step 7, Current reward: 0.036824\n",
      "  Step 8, Current reward: 0.036824\n",
      "  Step 9, Current reward: 0.036824\n",
      "  Step 10, Current reward: 0.036824\n",
      "  Step 11, Current reward: 0.036824\n",
      "  Step 12, Current reward: 0.036824\n",
      "Episode 335/1000 complete - Max Reward: 0.036824\n",
      "Starting episode 336/1000\n",
      "  Step 1, Current reward: 0.028753\n",
      "  Step 2, Current reward: 0.028753\n",
      "  Step 3, Current reward: 0.028753\n",
      "  Step 4, Current reward: 0.028753\n",
      "  Step 5, Current reward: 0.028753\n",
      "  Step 6, Current reward: 0.028753\n",
      "  Step 7, Current reward: 0.028753\n",
      "  Step 8, Current reward: 0.028753\n",
      "  Step 9, Current reward: 0.028753\n",
      "  Step 10, Current reward: 0.028753\n",
      "  Step 11, Current reward: 0.028753\n",
      "  Step 12, Current reward: 0.028753\n",
      "Episode 336/1000 complete - Max Reward: 0.028753\n",
      "Starting episode 337/1000\n",
      "  Step 1, Current reward: 0.089483\n",
      "  Step 2, Current reward: 0.089483\n",
      "  Step 3, Current reward: 0.089483\n",
      "  Step 4, Current reward: 0.089483\n",
      "  Step 5, Current reward: 0.089483\n",
      "  Step 6, Current reward: 0.089483\n",
      "  Step 7, Current reward: 0.089483\n",
      "  Step 8, Current reward: 0.089483\n",
      "  Step 9, Current reward: 0.089483\n",
      "  Step 10, Current reward: 0.089483\n",
      "  Step 11, Current reward: 0.089483\n",
      "  Step 12, Current reward: 0.089483\n",
      "Episode 337/1000 complete - Max Reward: 0.089483\n",
      "Starting episode 338/1000\n",
      "  Step 1, Current reward: 0.040421\n",
      "  Step 2, Current reward: 0.040421\n",
      "  Step 3, Current reward: 0.040421\n",
      "  Step 4, Current reward: 0.040421\n",
      "  Step 5, Current reward: 0.040421\n",
      "  Step 6, Current reward: 0.040421\n",
      "  Step 7, Current reward: 0.040421\n",
      "  Step 8, Current reward: 0.040421\n",
      "  Step 9, Current reward: 0.040421\n",
      "  Step 10, Current reward: 0.040421\n",
      "  Step 11, Current reward: 0.040421\n",
      "  Step 12, Current reward: 0.040421\n",
      "Episode 338/1000 complete - Max Reward: 0.040421\n",
      "Starting episode 339/1000\n",
      "  Step 1, Current reward: 0.001769\n",
      "  Step 2, Current reward: 0.001769\n",
      "  Step 3, Current reward: 0.001769\n",
      "  Step 4, Current reward: 0.001769\n",
      "  Step 5, Current reward: 0.001769\n",
      "  Step 6, Current reward: 0.001769\n",
      "  Step 7, Current reward: 0.001769\n",
      "  Step 8, Current reward: 0.001769\n",
      "  Step 9, Current reward: 0.001769\n",
      "  Step 10, Current reward: 0.001769\n",
      "  Step 11, Current reward: 0.001769\n",
      "  Step 12, Current reward: 0.001769\n",
      "Episode 339/1000 complete - Max Reward: 0.001769\n",
      "Starting episode 340/1000\n",
      "  Step 1, Current reward: 0.013848\n",
      "  Step 2, Current reward: 0.013848\n",
      "  Step 3, Current reward: 0.013848\n",
      "  Step 4, Current reward: 0.013848\n",
      "  Step 5, Current reward: 0.013848\n",
      "  Step 6, Current reward: 0.013848\n",
      "  Step 7, Current reward: 0.013848\n",
      "  Step 8, Current reward: 0.013848\n",
      "  Step 9, Current reward: 0.013848\n",
      "  Step 10, Current reward: 0.013848\n",
      "  Step 11, Current reward: 0.013848\n",
      "  Step 12, Current reward: 0.013848\n",
      "Episode 340/1000 complete - Max Reward: 0.013848\n",
      "Starting episode 341/1000\n",
      "  Step 1, Current reward: 0.008085\n",
      "  Step 2, Current reward: 0.008085\n",
      "  Step 3, Current reward: 0.008085\n",
      "  Step 4, Current reward: 0.008085\n",
      "  Step 5, Current reward: 0.008085\n",
      "  Step 6, Current reward: 0.008085\n",
      "  Step 7, Current reward: 0.008085\n",
      "  Step 8, Current reward: 0.008085\n",
      "  Step 9, Current reward: 0.008085\n",
      "  Step 10, Current reward: 0.008085\n",
      "  Step 11, Current reward: 0.008085\n",
      "  Step 12, Current reward: 0.008085\n",
      "Episode 341/1000 complete - Max Reward: 0.008085\n",
      "Starting episode 342/1000\n",
      "  Step 1, Current reward: 0.022024\n",
      "  Step 2, Current reward: 0.022024\n",
      "  Step 3, Current reward: 0.022024\n",
      "  Step 4, Current reward: 0.022024\n",
      "  Step 5, Current reward: 0.022024\n",
      "  Step 6, Current reward: 0.022024\n",
      "  Step 7, Current reward: 0.022024\n",
      "  Step 8, Current reward: 0.022024\n",
      "  Step 9, Current reward: 0.022024\n",
      "  Step 10, Current reward: 0.022024\n",
      "  Step 11, Current reward: 0.022024\n",
      "  Step 12, Current reward: 0.022024\n",
      "Episode 342/1000 complete - Max Reward: 0.022024\n",
      "Starting episode 343/1000\n",
      "  Step 1, Current reward: 0.026893\n",
      "  Step 2, Current reward: 0.026893\n",
      "  Step 3, Current reward: 0.026893\n",
      "  Step 4, Current reward: 0.026893\n",
      "  Step 5, Current reward: 0.026893\n",
      "  Step 6, Current reward: 0.026893\n",
      "  Step 7, Current reward: 0.026893\n",
      "  Step 8, Current reward: 0.026893\n",
      "  Step 9, Current reward: 0.026893\n",
      "  Step 10, Current reward: 0.026893\n",
      "  Step 11, Current reward: 0.026893\n",
      "  Step 12, Current reward: 0.026893\n",
      "Episode 343/1000 complete - Max Reward: 0.026893\n",
      "Starting episode 344/1000\n",
      "  Step 1, Current reward: 0.004880\n",
      "  Step 2, Current reward: 0.004880\n",
      "  Step 3, Current reward: 0.004880\n",
      "  Step 4, Current reward: 0.004880\n",
      "  Step 5, Current reward: 0.004880\n",
      "  Step 6, Current reward: 0.004880\n",
      "  Step 7, Current reward: 0.004880\n",
      "  Step 8, Current reward: 0.004880\n",
      "  Step 9, Current reward: 0.004880\n",
      "  Step 10, Current reward: 0.004880\n",
      "  Step 11, Current reward: 0.004880\n",
      "  Step 12, Current reward: 0.004880\n",
      "Episode 344/1000 complete - Max Reward: 0.004880\n",
      "Starting episode 345/1000\n",
      "  Step 1, Current reward: 0.021299\n",
      "  Step 2, Current reward: 0.021299\n",
      "  Step 3, Current reward: 0.021299\n",
      "  Step 4, Current reward: 0.021299\n",
      "  Step 5, Current reward: 0.021299\n",
      "  Step 6, Current reward: 0.021299\n",
      "  Step 7, Current reward: 0.021299\n",
      "  Step 8, Current reward: 0.021299\n",
      "  Step 9, Current reward: 0.021299\n",
      "  Step 10, Current reward: 0.021299\n",
      "  Step 11, Current reward: 0.021299\n",
      "  Step 12, Current reward: 0.021299\n",
      "Episode 345/1000 complete - Max Reward: 0.021299\n",
      "Starting episode 346/1000\n",
      "  Step 1, Current reward: 0.008280\n",
      "  Step 2, Current reward: 0.008280\n",
      "  Step 3, Current reward: 0.008280\n",
      "  Step 4, Current reward: 0.008280\n",
      "  Step 5, Current reward: 0.008280\n",
      "  Step 6, Current reward: 0.008280\n",
      "  Step 7, Current reward: 0.008280\n",
      "  Step 8, Current reward: 0.008280\n",
      "  Step 9, Current reward: 0.008280\n",
      "  Step 10, Current reward: 0.008280\n",
      "  Step 11, Current reward: 0.008280\n",
      "  Step 12, Current reward: 0.008280\n",
      "Episode 346/1000 complete - Max Reward: 0.008280\n",
      "Starting episode 347/1000\n",
      "  Step 1, Current reward: 0.059280\n",
      "  Step 2, Current reward: 0.059280\n",
      "  Step 3, Current reward: 0.059280\n",
      "  Step 4, Current reward: 0.059280\n",
      "  Step 5, Current reward: 0.059280\n",
      "  Step 6, Current reward: 0.059280\n",
      "  Step 7, Current reward: 0.059280\n",
      "  Step 8, Current reward: 0.059280\n",
      "  Step 9, Current reward: 0.059280\n",
      "  Step 10, Current reward: 0.059280\n",
      "  Step 11, Current reward: 0.059280\n",
      "  Step 12, Current reward: 0.059280\n",
      "Episode 347/1000 complete - Max Reward: 0.059280\n",
      "Starting episode 348/1000\n",
      "  Step 1, Current reward: 0.026169\n",
      "  Step 2, Current reward: 0.026169\n",
      "  Step 3, Current reward: 0.026169\n",
      "  Step 4, Current reward: 0.026169\n",
      "  Step 5, Current reward: 0.026169\n",
      "  Step 6, Current reward: 0.026169\n",
      "  Step 7, Current reward: 0.026169\n",
      "  Step 8, Current reward: 0.026169\n",
      "  Step 9, Current reward: 0.026169\n",
      "  Step 10, Current reward: 0.026169\n",
      "  Step 11, Current reward: 0.026169\n",
      "  Step 12, Current reward: 0.026169\n",
      "Episode 348/1000 complete - Max Reward: 0.026169\n",
      "Starting episode 349/1000\n",
      "  Step 1, Current reward: 0.008292\n",
      "  Step 2, Current reward: 0.008292\n",
      "  Step 3, Current reward: 0.008292\n",
      "  Step 4, Current reward: 0.008292\n",
      "  Step 5, Current reward: 0.008292\n",
      "  Step 6, Current reward: 0.008292\n",
      "  Step 7, Current reward: 0.008292\n",
      "  Step 8, Current reward: 0.008292\n",
      "  Step 9, Current reward: 0.008292\n",
      "  Step 10, Current reward: 0.008292\n",
      "  Step 11, Current reward: 0.008292\n",
      "  Step 12, Current reward: 0.008292\n",
      "Episode 349/1000 complete - Max Reward: 0.008292\n",
      "Starting episode 350/1000\n",
      "  Step 1, Current reward: 0.012127\n",
      "  Step 2, Current reward: 0.012127\n",
      "  Step 3, Current reward: 0.012127\n",
      "  Step 4, Current reward: 0.012127\n",
      "  Step 5, Current reward: 0.012127\n",
      "  Step 6, Current reward: 0.012127\n",
      "  Step 7, Current reward: 0.012127\n",
      "  Step 8, Current reward: 0.012127\n",
      "  Step 9, Current reward: 0.012127\n",
      "  Step 10, Current reward: 0.012127\n",
      "  Step 11, Current reward: 0.012127\n",
      "  Step 12, Current reward: 0.012127\n",
      "Episode 350/1000 complete - Max Reward: 0.012127\n",
      "Starting episode 351/1000\n",
      "  Step 1, Current reward: 0.017283\n",
      "  Step 2, Current reward: 0.017283\n",
      "  Step 3, Current reward: 0.017283\n",
      "  Step 4, Current reward: 0.017283\n",
      "  Step 5, Current reward: 0.017283\n",
      "  Step 6, Current reward: 0.017283\n",
      "  Step 7, Current reward: 0.017283\n",
      "  Step 8, Current reward: 0.017283\n",
      "  Step 9, Current reward: 0.017283\n",
      "  Step 10, Current reward: 0.017283\n",
      "  Step 11, Current reward: 0.017283\n",
      "  Step 12, Current reward: 0.017283\n",
      "Episode 351/1000 complete - Max Reward: 0.017283\n",
      "Starting episode 352/1000\n",
      "  Step 1, Current reward: 0.046136\n",
      "  Step 2, Current reward: 0.046136\n",
      "  Step 3, Current reward: 0.046136\n",
      "  Step 4, Current reward: 0.046136\n",
      "  Step 5, Current reward: 0.046136\n",
      "  Step 6, Current reward: 0.046136\n",
      "  Step 7, Current reward: 0.046136\n",
      "  Step 8, Current reward: 0.046136\n",
      "  Step 9, Current reward: 0.046136\n",
      "  Step 10, Current reward: 0.046136\n",
      "  Step 11, Current reward: 0.046136\n",
      "  Step 12, Current reward: 0.046136\n",
      "Episode 352/1000 complete - Max Reward: 0.046136\n",
      "Starting episode 353/1000\n",
      "  Step 1, Current reward: 0.000634\n",
      "  Step 2, Current reward: 0.000634\n",
      "  Step 3, Current reward: 0.000634\n",
      "  Step 4, Current reward: 0.000634\n",
      "  Step 5, Current reward: 0.000634\n",
      "  Step 6, Current reward: 0.000634\n",
      "  Step 7, Current reward: 0.000634\n",
      "  Step 8, Current reward: 0.000634\n",
      "  Step 9, Current reward: 0.000634\n",
      "  Step 10, Current reward: 0.000634\n",
      "  Step 11, Current reward: 0.000634\n",
      "  Step 12, Current reward: 0.000634\n",
      "Episode 353/1000 complete - Max Reward: 0.000634\n",
      "Starting episode 354/1000\n",
      "  Step 1, Current reward: 0.002172\n",
      "  Step 2, Current reward: 0.002461\n",
      "  Step 3, Current reward: 0.002461\n",
      "  Step 4, Current reward: 0.002461\n",
      "  Step 5, Current reward: 0.002461\n",
      "  Step 6, Current reward: 0.002461\n",
      "  Step 7, Current reward: 0.002461\n",
      "  Step 8, Current reward: 0.002461\n",
      "  Step 9, Current reward: 0.002461\n",
      "  Step 10, Current reward: 0.002461\n",
      "  Step 11, Current reward: 0.002461\n",
      "  Step 12, Current reward: 0.002461\n",
      "  Step 13, Current reward: 0.002461\n",
      "Episode 354/1000 complete - Max Reward: 0.002461\n",
      "Starting episode 355/1000\n",
      "  Step 1, Current reward: 0.012468\n",
      "  Step 2, Current reward: 0.012468\n",
      "  Step 3, Current reward: 0.012468\n",
      "  Step 4, Current reward: 0.012468\n",
      "  Step 5, Current reward: 0.012468\n",
      "  Step 6, Current reward: 0.012468\n",
      "  Step 7, Current reward: 0.012468\n",
      "  Step 8, Current reward: 0.012468\n",
      "  Step 9, Current reward: 0.012468\n",
      "  Step 10, Current reward: 0.012468\n",
      "  Step 11, Current reward: 0.012468\n",
      "  Step 12, Current reward: 0.012468\n",
      "Episode 355/1000 complete - Max Reward: 0.012468\n",
      "Starting episode 356/1000\n",
      "  Step 1, Current reward: 0.065383\n",
      "  Step 2, Current reward: 0.065383\n",
      "  Step 3, Current reward: 0.065383\n",
      "  Step 4, Current reward: 0.065383\n",
      "  Step 5, Current reward: 0.065383\n",
      "  Step 6, Current reward: 0.065383\n",
      "  Step 7, Current reward: 0.065383\n",
      "  Step 8, Current reward: 0.065383\n",
      "  Step 9, Current reward: 0.065383\n",
      "  Step 10, Current reward: 0.065383\n",
      "  Step 11, Current reward: 0.065383\n",
      "  Step 12, Current reward: 0.065383\n",
      "Episode 356/1000 complete - Max Reward: 0.065383\n",
      "Starting episode 357/1000\n",
      "  Step 1, Current reward: 0.038629\n",
      "  Step 2, Current reward: 0.038629\n",
      "  Step 3, Current reward: 0.038629\n",
      "  Step 4, Current reward: 0.038629\n",
      "  Step 5, Current reward: 0.038629\n",
      "  Step 6, Current reward: 0.038629\n",
      "  Step 7, Current reward: 0.038629\n",
      "  Step 8, Current reward: 0.038629\n",
      "  Step 9, Current reward: 0.038629\n",
      "  Step 10, Current reward: 0.038629\n",
      "  Step 11, Current reward: 0.038629\n",
      "  Step 12, Current reward: 0.038629\n",
      "Episode 357/1000 complete - Max Reward: 0.038629\n",
      "Starting episode 358/1000\n",
      "  Step 1, Current reward: 0.013199\n",
      "  Step 2, Current reward: 0.013199\n",
      "  Step 3, Current reward: 0.013199\n",
      "  Step 4, Current reward: 0.013199\n",
      "  Step 5, Current reward: 0.013199\n",
      "  Step 6, Current reward: 0.013199\n",
      "  Step 7, Current reward: 0.013199\n",
      "  Step 8, Current reward: 0.013199\n",
      "  Step 9, Current reward: 0.013199\n",
      "  Step 10, Current reward: 0.013199\n",
      "  Step 11, Current reward: 0.013199\n",
      "  Step 12, Current reward: 0.013199\n",
      "Episode 358/1000 complete - Max Reward: 0.013199\n",
      "Starting episode 359/1000\n",
      "  Step 1, Current reward: 0.027613\n",
      "  Step 2, Current reward: 0.027613\n",
      "  Step 3, Current reward: 0.027613\n",
      "  Step 4, Current reward: 0.027613\n",
      "  Step 5, Current reward: 0.027613\n",
      "  Step 6, Current reward: 0.027613\n",
      "  Step 7, Current reward: 0.027613\n",
      "  Step 8, Current reward: 0.027613\n",
      "  Step 9, Current reward: 0.027613\n",
      "  Step 10, Current reward: 0.027613\n",
      "  Step 11, Current reward: 0.027613\n",
      "  Step 12, Current reward: 0.027613\n",
      "Episode 359/1000 complete - Max Reward: 0.027613\n",
      "Starting episode 360/1000\n",
      "  Step 1, Current reward: 0.000337\n",
      "  Step 2, Current reward: 0.000337\n",
      "  Step 3, Current reward: 0.000337\n",
      "  Step 4, Current reward: 0.000337\n",
      "  Step 5, Current reward: 0.000337\n",
      "  Step 6, Current reward: 0.000337\n",
      "  Step 7, Current reward: 0.000337\n",
      "  Step 8, Current reward: 0.000337\n",
      "  Step 9, Current reward: 0.000337\n",
      "  Step 10, Current reward: 0.000337\n",
      "  Step 11, Current reward: 0.000337\n",
      "  Step 12, Current reward: 0.000337\n",
      "Episode 360/1000 complete - Max Reward: 0.000337\n",
      "Starting episode 361/1000\n",
      "  Step 1, Current reward: 0.001967\n",
      "  Step 2, Current reward: 0.001967\n",
      "  Step 3, Current reward: 0.001967\n",
      "  Step 4, Current reward: 0.001967\n",
      "  Step 5, Current reward: 0.001967\n",
      "  Step 6, Current reward: 0.001967\n",
      "  Step 7, Current reward: 0.001967\n",
      "  Step 8, Current reward: 0.001967\n",
      "  Step 9, Current reward: 0.001967\n",
      "  Step 10, Current reward: 0.001967\n",
      "  Step 11, Current reward: 0.001967\n",
      "  Step 12, Current reward: 0.001967\n",
      "Episode 361/1000 complete - Max Reward: 0.001967\n",
      "Starting episode 362/1000\n",
      "  Step 1, Current reward: 0.058281\n",
      "  Step 2, Current reward: 0.058281\n",
      "  Step 3, Current reward: 0.058281\n",
      "  Step 4, Current reward: 0.058281\n",
      "  Step 5, Current reward: 0.058281\n",
      "  Step 6, Current reward: 0.058281\n",
      "  Step 7, Current reward: 0.058281\n",
      "  Step 8, Current reward: 0.058281\n",
      "  Step 9, Current reward: 0.058281\n",
      "  Step 10, Current reward: 0.058281\n",
      "  Step 11, Current reward: 0.058281\n",
      "  Step 12, Current reward: 0.058281\n",
      "Episode 362/1000 complete - Max Reward: 0.058281\n",
      "Starting episode 363/1000\n",
      "  Step 1, Current reward: 0.004303\n",
      "  Step 2, Current reward: 0.004303\n",
      "  Step 3, Current reward: 0.004303\n",
      "  Step 4, Current reward: 0.004303\n",
      "  Step 5, Current reward: 0.004303\n",
      "  Step 6, Current reward: 0.004303\n",
      "  Step 7, Current reward: 0.004303\n",
      "  Step 8, Current reward: 0.004303\n",
      "  Step 9, Current reward: 0.004303\n",
      "  Step 10, Current reward: 0.004303\n",
      "  Step 11, Current reward: 0.004303\n",
      "  Step 12, Current reward: 0.004303\n",
      "Episode 363/1000 complete - Max Reward: 0.004303\n",
      "Starting episode 364/1000\n",
      "  Step 1, Current reward: 0.000317\n",
      "  Step 2, Current reward: 0.000321\n",
      "  Step 3, Current reward: 0.000324\n",
      "  Step 4, Current reward: 0.000326\n",
      "  Step 5, Current reward: 0.000327\n",
      "  Step 6, Current reward: 0.000327\n",
      "  Step 7, Current reward: 0.000327\n",
      "  Step 8, Current reward: 0.000327\n",
      "  Step 9, Current reward: 0.000327\n",
      "  Step 10, Current reward: 0.000327\n",
      "  Step 11, Current reward: 0.000327\n",
      "  Step 12, Current reward: 0.000327\n",
      "  Step 13, Current reward: 0.000327\n",
      "  Step 14, Current reward: 0.000327\n",
      "  Step 15, Current reward: 0.000327\n",
      "  Step 16, Current reward: 0.000327\n",
      "Episode 364/1000 complete - Max Reward: 0.000327\n",
      "Starting episode 365/1000\n",
      "  Step 1, Current reward: 0.001602\n",
      "  Step 2, Current reward: 0.001602\n",
      "  Step 3, Current reward: 0.001602\n",
      "  Step 4, Current reward: 0.001602\n",
      "  Step 5, Current reward: 0.001602\n",
      "  Step 6, Current reward: 0.001602\n",
      "  Step 7, Current reward: 0.001602\n",
      "  Step 8, Current reward: 0.001602\n",
      "  Step 9, Current reward: 0.001602\n",
      "  Step 10, Current reward: 0.001602\n",
      "  Step 11, Current reward: 0.001602\n",
      "  Step 12, Current reward: 0.001602\n",
      "Episode 365/1000 complete - Max Reward: 0.001602\n",
      "Starting episode 366/1000\n",
      "  Step 1, Current reward: 0.089426\n",
      "  Step 2, Current reward: 0.089426\n",
      "  Step 3, Current reward: 0.089426\n",
      "  Step 4, Current reward: 0.089426\n",
      "  Step 5, Current reward: 0.089426\n",
      "  Step 6, Current reward: 0.089426\n",
      "  Step 7, Current reward: 0.089426\n",
      "  Step 8, Current reward: 0.089426\n",
      "  Step 9, Current reward: 0.089426\n",
      "  Step 10, Current reward: 0.089426\n",
      "  Step 11, Current reward: 0.089426\n",
      "  Step 12, Current reward: 0.089426\n",
      "Episode 366/1000 complete - Max Reward: 0.089426\n",
      "Starting episode 367/1000\n",
      "  Step 1, Current reward: 0.005084\n",
      "  Step 2, Current reward: 0.005084\n",
      "  Step 3, Current reward: 0.005084\n",
      "  Step 4, Current reward: 0.005084\n",
      "  Step 5, Current reward: 0.005084\n",
      "  Step 6, Current reward: 0.005084\n",
      "  Step 7, Current reward: 0.005084\n",
      "  Step 8, Current reward: 0.005084\n",
      "  Step 9, Current reward: 0.005084\n",
      "  Step 10, Current reward: 0.005084\n",
      "  Step 11, Current reward: 0.005084\n",
      "  Step 12, Current reward: 0.005084\n",
      "Episode 367/1000 complete - Max Reward: 0.005084\n",
      "Starting episode 368/1000\n",
      "  Step 1, Current reward: 0.044365\n",
      "  Step 2, Current reward: 0.044365\n",
      "  Step 3, Current reward: 0.044365\n",
      "  Step 4, Current reward: 0.044365\n",
      "  Step 5, Current reward: 0.044365\n",
      "  Step 6, Current reward: 0.044365\n",
      "  Step 7, Current reward: 0.044365\n",
      "  Step 8, Current reward: 0.044365\n",
      "  Step 9, Current reward: 0.044365\n",
      "  Step 10, Current reward: 0.044365\n",
      "  Step 11, Current reward: 0.044365\n",
      "  Step 12, Current reward: 0.044365\n",
      "Episode 368/1000 complete - Max Reward: 0.044365\n",
      "Starting episode 369/1000\n",
      "  Step 1, Current reward: 0.007434\n",
      "  Step 2, Current reward: 0.007323\n",
      "  Step 3, Current reward: 0.007335\n",
      "  Step 4, Current reward: 0.007335\n",
      "  Step 5, Current reward: 0.007335\n",
      "  Step 6, Current reward: 0.007335\n",
      "  Step 7, Current reward: 0.007335\n",
      "  Step 8, Current reward: 0.007335\n",
      "  Step 9, Current reward: 0.007335\n",
      "  Step 10, Current reward: 0.007335\n",
      "  Step 11, Current reward: 0.007335\n",
      "  Step 12, Current reward: 0.007335\n",
      "Episode 369/1000 complete - Max Reward: 0.007434\n",
      "Starting episode 370/1000\n",
      "  Step 1, Current reward: 0.036871\n",
      "  Step 2, Current reward: 0.036871\n",
      "  Step 3, Current reward: 0.036871\n",
      "  Step 4, Current reward: 0.036871\n",
      "  Step 5, Current reward: 0.036871\n",
      "  Step 6, Current reward: 0.036871\n",
      "  Step 7, Current reward: 0.036871\n",
      "  Step 8, Current reward: 0.036871\n",
      "  Step 9, Current reward: 0.036871\n",
      "  Step 10, Current reward: 0.036871\n",
      "  Step 11, Current reward: 0.036871\n",
      "  Step 12, Current reward: 0.036871\n",
      "Episode 370/1000 complete - Max Reward: 0.036871\n",
      "Starting episode 371/1000\n",
      "  Step 1, Current reward: 0.141866\n",
      "  Step 2, Current reward: 0.141866\n",
      "  Step 3, Current reward: 0.141866\n",
      "  Step 4, Current reward: 0.141866\n",
      "  Step 5, Current reward: 0.141866\n",
      "  Step 6, Current reward: 0.141866\n",
      "  Step 7, Current reward: 0.141866\n",
      "  Step 8, Current reward: 0.141866\n",
      "  Step 9, Current reward: 0.141866\n",
      "  Step 10, Current reward: 0.141866\n",
      "  Step 11, Current reward: 0.141866\n",
      "  Step 12, Current reward: 0.141866\n",
      "Episode 371/1000 complete - Max Reward: 0.141866\n",
      "Starting episode 372/1000\n",
      "  Step 1, Current reward: 0.037314\n",
      "  Step 2, Current reward: 0.037314\n",
      "  Step 3, Current reward: 0.037314\n",
      "  Step 4, Current reward: 0.037314\n",
      "  Step 5, Current reward: 0.037314\n",
      "  Step 6, Current reward: 0.037314\n",
      "  Step 7, Current reward: 0.037314\n",
      "  Step 8, Current reward: 0.037314\n",
      "  Step 9, Current reward: 0.037314\n",
      "  Step 10, Current reward: 0.037314\n",
      "  Step 11, Current reward: 0.037314\n",
      "  Step 12, Current reward: 0.037314\n",
      "Episode 372/1000 complete - Max Reward: 0.037314\n",
      "Starting episode 373/1000\n",
      "  Step 1, Current reward: 0.001876\n",
      "  Step 2, Current reward: 0.001876\n",
      "  Step 3, Current reward: 0.001876\n",
      "  Step 4, Current reward: 0.001876\n",
      "  Step 5, Current reward: 0.001876\n",
      "  Step 6, Current reward: 0.001876\n",
      "  Step 7, Current reward: 0.001876\n",
      "  Step 8, Current reward: 0.001876\n",
      "  Step 9, Current reward: 0.001876\n",
      "  Step 10, Current reward: 0.001876\n",
      "  Step 11, Current reward: 0.001876\n",
      "  Step 12, Current reward: 0.001876\n",
      "Episode 373/1000 complete - Max Reward: 0.001876\n",
      "Starting episode 374/1000\n",
      "  Step 1, Current reward: 0.026482\n",
      "  Step 2, Current reward: 0.026482\n",
      "  Step 3, Current reward: 0.026482\n",
      "  Step 4, Current reward: 0.026482\n",
      "  Step 5, Current reward: 0.026482\n",
      "  Step 6, Current reward: 0.026482\n",
      "  Step 7, Current reward: 0.026482\n",
      "  Step 8, Current reward: 0.026482\n",
      "  Step 9, Current reward: 0.026482\n",
      "  Step 10, Current reward: 0.026482\n",
      "  Step 11, Current reward: 0.026482\n",
      "  Step 12, Current reward: 0.026482\n",
      "Episode 374/1000 complete - Max Reward: 0.026482\n",
      "Starting episode 375/1000\n",
      "  Step 1, Current reward: 0.011063\n",
      "  Step 2, Current reward: 0.011063\n",
      "  Step 3, Current reward: 0.011063\n",
      "  Step 4, Current reward: 0.011063\n",
      "  Step 5, Current reward: 0.011063\n",
      "  Step 6, Current reward: 0.011063\n",
      "  Step 7, Current reward: 0.011063\n",
      "  Step 8, Current reward: 0.011063\n",
      "  Step 9, Current reward: 0.011063\n",
      "  Step 10, Current reward: 0.011063\n",
      "  Step 11, Current reward: 0.011063\n",
      "  Step 12, Current reward: 0.011063\n",
      "Episode 375/1000 complete - Max Reward: 0.011063\n",
      "Starting episode 376/1000\n",
      "  Step 1, Current reward: 0.000996\n",
      "  Step 2, Current reward: 0.000996\n",
      "  Step 3, Current reward: 0.000996\n",
      "  Step 4, Current reward: 0.000996\n",
      "  Step 5, Current reward: 0.000996\n",
      "  Step 6, Current reward: 0.000996\n",
      "  Step 7, Current reward: 0.000996\n",
      "  Step 8, Current reward: 0.000996\n",
      "  Step 9, Current reward: 0.000996\n",
      "  Step 10, Current reward: 0.000996\n",
      "  Step 11, Current reward: 0.000996\n",
      "  Step 12, Current reward: 0.000996\n",
      "Episode 376/1000 complete - Max Reward: 0.000996\n",
      "Starting episode 377/1000\n",
      "  Step 1, Current reward: 0.040009\n",
      "  Step 2, Current reward: 0.040009\n",
      "  Step 3, Current reward: 0.040009\n",
      "  Step 4, Current reward: 0.040009\n",
      "  Step 5, Current reward: 0.040009\n",
      "  Step 6, Current reward: 0.040009\n",
      "  Step 7, Current reward: 0.040009\n",
      "  Step 8, Current reward: 0.040009\n",
      "  Step 9, Current reward: 0.040009\n",
      "  Step 10, Current reward: 0.040009\n",
      "  Step 11, Current reward: 0.040009\n",
      "  Step 12, Current reward: 0.040009\n",
      "Episode 377/1000 complete - Max Reward: 0.040009\n",
      "Starting episode 378/1000\n",
      "  Step 1, Current reward: 0.074558\n",
      "  Step 2, Current reward: 0.074558\n",
      "  Step 3, Current reward: 0.074558\n",
      "  Step 4, Current reward: 0.074558\n",
      "  Step 5, Current reward: 0.074558\n",
      "  Step 6, Current reward: 0.074558\n",
      "  Step 7, Current reward: 0.074558\n",
      "  Step 8, Current reward: 0.074558\n",
      "  Step 9, Current reward: 0.074558\n",
      "  Step 10, Current reward: 0.074558\n",
      "  Step 11, Current reward: 0.074558\n",
      "  Step 12, Current reward: 0.074558\n",
      "Episode 378/1000 complete - Max Reward: 0.074558\n",
      "Starting episode 379/1000\n",
      "  Step 1, Current reward: 0.012984\n",
      "  Step 2, Current reward: 0.012984\n",
      "  Step 3, Current reward: 0.012984\n",
      "  Step 4, Current reward: 0.012984\n",
      "  Step 5, Current reward: 0.012984\n",
      "  Step 6, Current reward: 0.012984\n",
      "  Step 7, Current reward: 0.012984\n",
      "  Step 8, Current reward: 0.012984\n",
      "  Step 9, Current reward: 0.012984\n",
      "  Step 10, Current reward: 0.012984\n",
      "  Step 11, Current reward: 0.012984\n",
      "  Step 12, Current reward: 0.012984\n",
      "Episode 379/1000 complete - Max Reward: 0.012984\n",
      "Starting episode 380/1000\n",
      "  Step 1, Current reward: 0.054565\n",
      "  Step 2, Current reward: 0.054565\n",
      "  Step 3, Current reward: 0.054565\n",
      "  Step 4, Current reward: 0.054565\n",
      "  Step 5, Current reward: 0.054565\n",
      "  Step 6, Current reward: 0.054565\n",
      "  Step 7, Current reward: 0.054565\n",
      "  Step 8, Current reward: 0.054565\n",
      "  Step 9, Current reward: 0.054565\n",
      "  Step 10, Current reward: 0.054565\n",
      "  Step 11, Current reward: 0.054565\n",
      "  Step 12, Current reward: 0.054565\n",
      "Episode 380/1000 complete - Max Reward: 0.054565\n",
      "Starting episode 381/1000\n",
      "  Step 1, Current reward: 0.054009\n",
      "  Step 2, Current reward: 0.054009\n",
      "  Step 3, Current reward: 0.054009\n",
      "  Step 4, Current reward: 0.054009\n",
      "  Step 5, Current reward: 0.054009\n",
      "  Step 6, Current reward: 0.054009\n",
      "  Step 7, Current reward: 0.054009\n",
      "  Step 8, Current reward: 0.054009\n",
      "  Step 9, Current reward: 0.054009\n",
      "  Step 10, Current reward: 0.054009\n",
      "  Step 11, Current reward: 0.054009\n",
      "  Step 12, Current reward: 0.054009\n",
      "Episode 381/1000 complete - Max Reward: 0.054009\n",
      "Starting episode 382/1000\n",
      "  Step 1, Current reward: 0.014704\n",
      "  Step 2, Current reward: 0.014704\n",
      "  Step 3, Current reward: 0.014704\n",
      "  Step 4, Current reward: 0.014704\n",
      "  Step 5, Current reward: 0.014704\n",
      "  Step 6, Current reward: 0.014704\n",
      "  Step 7, Current reward: 0.014704\n",
      "  Step 8, Current reward: 0.014704\n",
      "  Step 9, Current reward: 0.014704\n",
      "  Step 10, Current reward: 0.014704\n",
      "  Step 11, Current reward: 0.014704\n",
      "  Step 12, Current reward: 0.014704\n",
      "Episode 382/1000 complete - Max Reward: 0.014704\n",
      "Starting episode 383/1000\n",
      "  Step 1, Current reward: 0.007020\n",
      "  Step 2, Current reward: 0.007020\n",
      "  Step 3, Current reward: 0.007020\n",
      "  Step 4, Current reward: 0.007020\n",
      "  Step 5, Current reward: 0.007020\n",
      "  Step 6, Current reward: 0.007020\n",
      "  Step 7, Current reward: 0.007020\n",
      "  Step 8, Current reward: 0.007020\n",
      "  Step 9, Current reward: 0.007020\n",
      "  Step 10, Current reward: 0.007020\n",
      "  Step 11, Current reward: 0.007020\n",
      "  Step 12, Current reward: 0.007020\n",
      "Episode 383/1000 complete - Max Reward: 0.007020\n",
      "Starting episode 384/1000\n",
      "  Step 1, Current reward: 0.046493\n",
      "  Step 2, Current reward: 0.046493\n",
      "  Step 3, Current reward: 0.046493\n",
      "  Step 4, Current reward: 0.046493\n",
      "  Step 5, Current reward: 0.046493\n",
      "  Step 6, Current reward: 0.046493\n",
      "  Step 7, Current reward: 0.046493\n",
      "  Step 8, Current reward: 0.046493\n",
      "  Step 9, Current reward: 0.046493\n",
      "  Step 10, Current reward: 0.046493\n",
      "  Step 11, Current reward: 0.046493\n",
      "  Step 12, Current reward: 0.046493\n",
      "Episode 384/1000 complete - Max Reward: 0.046493\n",
      "Starting episode 385/1000\n",
      "  Step 1, Current reward: 0.020547\n",
      "  Step 2, Current reward: 0.020547\n",
      "  Step 3, Current reward: 0.020547\n",
      "  Step 4, Current reward: 0.020547\n",
      "  Step 5, Current reward: 0.020547\n",
      "  Step 6, Current reward: 0.020547\n",
      "  Step 7, Current reward: 0.020547\n",
      "  Step 8, Current reward: 0.020547\n",
      "  Step 9, Current reward: 0.020547\n",
      "  Step 10, Current reward: 0.020547\n",
      "  Step 11, Current reward: 0.020547\n",
      "  Step 12, Current reward: 0.020547\n",
      "Episode 385/1000 complete - Max Reward: 0.020547\n",
      "Starting episode 386/1000\n",
      "  Step 1, Current reward: 0.001480\n",
      "  Step 2, Current reward: 0.001480\n",
      "  Step 3, Current reward: 0.001480\n",
      "  Step 4, Current reward: 0.001480\n",
      "  Step 5, Current reward: 0.001480\n",
      "  Step 6, Current reward: 0.001480\n",
      "  Step 7, Current reward: 0.001480\n",
      "  Step 8, Current reward: 0.001480\n",
      "  Step 9, Current reward: 0.001480\n",
      "  Step 10, Current reward: 0.001480\n",
      "  Step 11, Current reward: 0.001480\n",
      "  Step 12, Current reward: 0.001480\n",
      "Episode 386/1000 complete - Max Reward: 0.001480\n",
      "Starting episode 387/1000\n",
      "  Step 1, Current reward: 0.029226\n",
      "  Step 2, Current reward: 0.029226\n",
      "  Step 3, Current reward: 0.029226\n",
      "  Step 4, Current reward: 0.029226\n",
      "  Step 5, Current reward: 0.029226\n",
      "  Step 6, Current reward: 0.029226\n",
      "  Step 7, Current reward: 0.029226\n",
      "  Step 8, Current reward: 0.029226\n",
      "  Step 9, Current reward: 0.029226\n",
      "  Step 10, Current reward: 0.029226\n",
      "  Step 11, Current reward: 0.029226\n",
      "  Step 12, Current reward: 0.029226\n",
      "Episode 387/1000 complete - Max Reward: 0.029226\n",
      "Starting episode 388/1000\n",
      "  Step 1, Current reward: 0.023227\n",
      "  Step 2, Current reward: 0.023227\n",
      "  Step 3, Current reward: 0.023227\n",
      "  Step 4, Current reward: 0.023227\n",
      "  Step 5, Current reward: 0.023227\n",
      "  Step 6, Current reward: 0.023227\n",
      "  Step 7, Current reward: 0.023227\n",
      "  Step 8, Current reward: 0.023227\n",
      "  Step 9, Current reward: 0.023227\n",
      "  Step 10, Current reward: 0.023227\n",
      "  Step 11, Current reward: 0.023227\n",
      "  Step 12, Current reward: 0.023227\n",
      "Episode 388/1000 complete - Max Reward: 0.023227\n",
      "Starting episode 389/1000\n",
      "  Step 1, Current reward: 0.019008\n",
      "  Step 2, Current reward: 0.019008\n",
      "  Step 3, Current reward: 0.019008\n",
      "  Step 4, Current reward: 0.019008\n",
      "  Step 5, Current reward: 0.019008\n",
      "  Step 6, Current reward: 0.019008\n",
      "  Step 7, Current reward: 0.019008\n",
      "  Step 8, Current reward: 0.019008\n",
      "  Step 9, Current reward: 0.019008\n",
      "  Step 10, Current reward: 0.019008\n",
      "  Step 11, Current reward: 0.019008\n",
      "  Step 12, Current reward: 0.019008\n",
      "Episode 389/1000 complete - Max Reward: 0.019008\n",
      "Starting episode 390/1000\n",
      "  Step 1, Current reward: 0.001451\n",
      "  Step 2, Current reward: 0.001451\n",
      "  Step 3, Current reward: 0.001451\n",
      "  Step 4, Current reward: 0.001451\n",
      "  Step 5, Current reward: 0.001451\n",
      "  Step 6, Current reward: 0.001451\n",
      "  Step 7, Current reward: 0.001451\n",
      "  Step 8, Current reward: 0.001451\n",
      "  Step 9, Current reward: 0.001451\n",
      "  Step 10, Current reward: 0.001451\n",
      "  Step 11, Current reward: 0.001451\n",
      "  Step 12, Current reward: 0.001451\n",
      "Episode 390/1000 complete - Max Reward: 0.001451\n",
      "Starting episode 391/1000\n",
      "  Step 1, Current reward: 0.028762\n",
      "  Step 2, Current reward: 0.028762\n",
      "  Step 3, Current reward: 0.028762\n",
      "  Step 4, Current reward: 0.028762\n",
      "  Step 5, Current reward: 0.028762\n",
      "  Step 6, Current reward: 0.028762\n",
      "  Step 7, Current reward: 0.028762\n",
      "  Step 8, Current reward: 0.028762\n",
      "  Step 9, Current reward: 0.028762\n",
      "  Step 10, Current reward: 0.028762\n",
      "  Step 11, Current reward: 0.028762\n",
      "  Step 12, Current reward: 0.028762\n",
      "Episode 391/1000 complete - Max Reward: 0.028762\n",
      "Starting episode 392/1000\n",
      "  Step 1, Current reward: 0.054029\n",
      "  Step 2, Current reward: 0.054029\n",
      "  Step 3, Current reward: 0.054029\n",
      "  Step 4, Current reward: 0.054029\n",
      "  Step 5, Current reward: 0.054029\n",
      "  Step 6, Current reward: 0.054029\n",
      "  Step 7, Current reward: 0.054029\n",
      "  Step 8, Current reward: 0.054029\n",
      "  Step 9, Current reward: 0.054029\n",
      "  Step 10, Current reward: 0.054029\n",
      "  Step 11, Current reward: 0.054029\n",
      "  Step 12, Current reward: 0.054029\n",
      "Episode 392/1000 complete - Max Reward: 0.054029\n",
      "Starting episode 393/1000\n",
      "  Step 1, Current reward: 0.002036\n",
      "  Step 2, Current reward: 0.002036\n",
      "  Step 3, Current reward: 0.002036\n",
      "  Step 4, Current reward: 0.002036\n",
      "  Step 5, Current reward: 0.002036\n",
      "  Step 6, Current reward: 0.002036\n",
      "  Step 7, Current reward: 0.002036\n",
      "  Step 8, Current reward: 0.002036\n",
      "  Step 9, Current reward: 0.002036\n",
      "  Step 10, Current reward: 0.002036\n",
      "  Step 11, Current reward: 0.002036\n",
      "  Step 12, Current reward: 0.002036\n",
      "Episode 393/1000 complete - Max Reward: 0.002036\n",
      "Starting episode 394/1000\n",
      "  Step 1, Current reward: 0.047612\n",
      "  Step 2, Current reward: 0.047612\n",
      "  Step 3, Current reward: 0.047612\n",
      "  Step 4, Current reward: 0.047612\n",
      "  Step 5, Current reward: 0.047612\n",
      "  Step 6, Current reward: 0.047612\n",
      "  Step 7, Current reward: 0.047612\n",
      "  Step 8, Current reward: 0.047612\n",
      "  Step 9, Current reward: 0.047612\n",
      "  Step 10, Current reward: 0.047612\n",
      "  Step 11, Current reward: 0.047612\n",
      "  Step 12, Current reward: 0.047612\n",
      "Episode 394/1000 complete - Max Reward: 0.047612\n",
      "Starting episode 395/1000\n",
      "  Step 1, Current reward: 0.007925\n",
      "  Step 2, Current reward: 0.007925\n",
      "  Step 3, Current reward: 0.007925\n",
      "  Step 4, Current reward: 0.007925\n",
      "  Step 5, Current reward: 0.007925\n",
      "  Step 6, Current reward: 0.007925\n",
      "  Step 7, Current reward: 0.007925\n",
      "  Step 8, Current reward: 0.007925\n",
      "  Step 9, Current reward: 0.007925\n",
      "  Step 10, Current reward: 0.007925\n",
      "  Step 11, Current reward: 0.007925\n",
      "  Step 12, Current reward: 0.007925\n",
      "Episode 395/1000 complete - Max Reward: 0.007925\n",
      "Starting episode 396/1000\n",
      "  Step 1, Current reward: 0.004434\n",
      "  Step 2, Current reward: 0.004434\n",
      "  Step 3, Current reward: 0.004434\n",
      "  Step 4, Current reward: 0.004434\n",
      "  Step 5, Current reward: 0.004434\n",
      "  Step 6, Current reward: 0.004434\n",
      "  Step 7, Current reward: 0.004434\n",
      "  Step 8, Current reward: 0.004434\n",
      "  Step 9, Current reward: 0.004434\n",
      "  Step 10, Current reward: 0.004434\n",
      "  Step 11, Current reward: 0.004434\n",
      "  Step 12, Current reward: 0.004434\n",
      "Episode 396/1000 complete - Max Reward: 0.004434\n",
      "Starting episode 397/1000\n",
      "  Step 1, Current reward: 0.006851\n",
      "  Step 2, Current reward: 0.006851\n",
      "  Step 3, Current reward: 0.006851\n",
      "  Step 4, Current reward: 0.006851\n",
      "  Step 5, Current reward: 0.006851\n",
      "  Step 6, Current reward: 0.006851\n",
      "  Step 7, Current reward: 0.006851\n",
      "  Step 8, Current reward: 0.006851\n",
      "  Step 9, Current reward: 0.006851\n",
      "  Step 10, Current reward: 0.006851\n",
      "  Step 11, Current reward: 0.006851\n",
      "  Step 12, Current reward: 0.006851\n",
      "Episode 397/1000 complete - Max Reward: 0.006851\n",
      "Starting episode 398/1000\n",
      "  Step 1, Current reward: 0.011472\n",
      "  Step 2, Current reward: 0.011472\n",
      "  Step 3, Current reward: 0.011472\n",
      "  Step 4, Current reward: 0.011472\n",
      "  Step 5, Current reward: 0.011472\n",
      "  Step 6, Current reward: 0.011472\n",
      "  Step 7, Current reward: 0.011472\n",
      "  Step 8, Current reward: 0.011472\n",
      "  Step 9, Current reward: 0.011472\n",
      "  Step 10, Current reward: 0.011472\n",
      "  Step 11, Current reward: 0.011472\n",
      "  Step 12, Current reward: 0.011472\n",
      "Episode 398/1000 complete - Max Reward: 0.011472\n",
      "Starting episode 399/1000\n",
      "  Step 1, Current reward: 0.004904\n",
      "  Step 2, Current reward: 0.004904\n",
      "  Step 3, Current reward: 0.004904\n",
      "  Step 4, Current reward: 0.004904\n",
      "  Step 5, Current reward: 0.004904\n",
      "  Step 6, Current reward: 0.004904\n",
      "  Step 7, Current reward: 0.004904\n",
      "  Step 8, Current reward: 0.004904\n",
      "  Step 9, Current reward: 0.004904\n",
      "  Step 10, Current reward: 0.004904\n",
      "  Step 11, Current reward: 0.004904\n",
      "  Step 12, Current reward: 0.004904\n",
      "Episode 399/1000 complete - Max Reward: 0.004904\n",
      "Starting episode 400/1000\n",
      "  Step 1, Current reward: 0.003668\n",
      "  Step 2, Current reward: 0.003668\n",
      "  Step 3, Current reward: 0.003668\n",
      "  Step 4, Current reward: 0.003668\n",
      "  Step 5, Current reward: 0.003668\n",
      "  Step 6, Current reward: 0.003668\n",
      "  Step 7, Current reward: 0.003668\n",
      "  Step 8, Current reward: 0.003668\n",
      "  Step 9, Current reward: 0.003668\n",
      "  Step 10, Current reward: 0.003668\n",
      "  Step 11, Current reward: 0.003668\n",
      "  Step 12, Current reward: 0.003668\n",
      "Episode 400/1000 complete - Max Reward: 0.003668\n",
      "Starting episode 401/1000\n",
      "  Step 1, Current reward: 0.036946\n",
      "  Step 2, Current reward: 0.036946\n",
      "  Step 3, Current reward: 0.036946\n",
      "  Step 4, Current reward: 0.036946\n",
      "  Step 5, Current reward: 0.036946\n",
      "  Step 6, Current reward: 0.036946\n",
      "  Step 7, Current reward: 0.036946\n",
      "  Step 8, Current reward: 0.036946\n",
      "  Step 9, Current reward: 0.036946\n",
      "  Step 10, Current reward: 0.036946\n",
      "  Step 11, Current reward: 0.036946\n",
      "  Step 12, Current reward: 0.036946\n",
      "Episode 401/1000 complete - Max Reward: 0.036946\n",
      "Starting episode 402/1000\n",
      "  Step 1, Current reward: 0.000587\n",
      "  Step 2, Current reward: 0.000587\n",
      "  Step 3, Current reward: 0.000587\n",
      "  Step 4, Current reward: 0.000587\n",
      "  Step 5, Current reward: 0.000587\n",
      "  Step 6, Current reward: 0.000587\n",
      "  Step 7, Current reward: 0.000587\n",
      "  Step 8, Current reward: 0.000587\n",
      "  Step 9, Current reward: 0.000587\n",
      "  Step 10, Current reward: 0.000587\n",
      "  Step 11, Current reward: 0.000587\n",
      "  Step 12, Current reward: 0.000587\n",
      "Episode 402/1000 complete - Max Reward: 0.000587\n",
      "Starting episode 403/1000\n",
      "  Step 1, Current reward: 0.008722\n",
      "  Step 2, Current reward: 0.008722\n",
      "  Step 3, Current reward: 0.008722\n",
      "  Step 4, Current reward: 0.008722\n",
      "  Step 5, Current reward: 0.008722\n",
      "  Step 6, Current reward: 0.008722\n",
      "  Step 7, Current reward: 0.008722\n",
      "  Step 8, Current reward: 0.008722\n",
      "  Step 9, Current reward: 0.008722\n",
      "  Step 10, Current reward: 0.008722\n",
      "  Step 11, Current reward: 0.008722\n",
      "  Step 12, Current reward: 0.008722\n",
      "Episode 403/1000 complete - Max Reward: 0.008722\n",
      "Starting episode 404/1000\n",
      "  Step 1, Current reward: 0.013367\n",
      "  Step 2, Current reward: 0.013367\n",
      "  Step 3, Current reward: 0.013367\n",
      "  Step 4, Current reward: 0.013367\n",
      "  Step 5, Current reward: 0.013367\n",
      "  Step 6, Current reward: 0.013367\n",
      "  Step 7, Current reward: 0.013367\n",
      "  Step 8, Current reward: 0.013367\n",
      "  Step 9, Current reward: 0.013367\n",
      "  Step 10, Current reward: 0.013367\n",
      "  Step 11, Current reward: 0.013367\n",
      "  Step 12, Current reward: 0.013367\n",
      "Episode 404/1000 complete - Max Reward: 0.013367\n",
      "Starting episode 405/1000\n",
      "  Step 1, Current reward: 0.001486\n",
      "  Step 2, Current reward: 0.001486\n",
      "  Step 3, Current reward: 0.001486\n",
      "  Step 4, Current reward: 0.001486\n",
      "  Step 5, Current reward: 0.001486\n",
      "  Step 6, Current reward: 0.001486\n",
      "  Step 7, Current reward: 0.001486\n",
      "  Step 8, Current reward: 0.001486\n",
      "  Step 9, Current reward: 0.001486\n",
      "  Step 10, Current reward: 0.001486\n",
      "  Step 11, Current reward: 0.001486\n",
      "  Step 12, Current reward: 0.001486\n",
      "Episode 405/1000 complete - Max Reward: 0.001486\n",
      "Starting episode 406/1000\n",
      "  Step 1, Current reward: 0.018197\n",
      "  Step 2, Current reward: 0.018197\n",
      "  Step 3, Current reward: 0.018197\n",
      "  Step 4, Current reward: 0.018197\n",
      "  Step 5, Current reward: 0.018197\n",
      "  Step 6, Current reward: 0.018197\n",
      "  Step 7, Current reward: 0.018197\n",
      "  Step 8, Current reward: 0.018197\n",
      "  Step 9, Current reward: 0.018197\n",
      "  Step 10, Current reward: 0.018197\n",
      "  Step 11, Current reward: 0.018197\n",
      "  Step 12, Current reward: 0.018197\n",
      "Episode 406/1000 complete - Max Reward: 0.018197\n",
      "Starting episode 407/1000\n",
      "  Step 1, Current reward: 0.047820\n",
      "  Step 2, Current reward: 0.047820\n",
      "  Step 3, Current reward: 0.047820\n",
      "  Step 4, Current reward: 0.047820\n",
      "  Step 5, Current reward: 0.047820\n",
      "  Step 6, Current reward: 0.047820\n",
      "  Step 7, Current reward: 0.047820\n",
      "  Step 8, Current reward: 0.047820\n",
      "  Step 9, Current reward: 0.047820\n",
      "  Step 10, Current reward: 0.047820\n",
      "  Step 11, Current reward: 0.047820\n",
      "  Step 12, Current reward: 0.047820\n",
      "Episode 407/1000 complete - Max Reward: 0.047820\n",
      "Starting episode 408/1000\n",
      "  Step 1, Current reward: 0.031405\n",
      "  Step 2, Current reward: 0.031405\n",
      "  Step 3, Current reward: 0.031405\n",
      "  Step 4, Current reward: 0.031405\n",
      "  Step 5, Current reward: 0.031405\n",
      "  Step 6, Current reward: 0.031405\n",
      "  Step 7, Current reward: 0.031405\n",
      "  Step 8, Current reward: 0.031405\n",
      "  Step 9, Current reward: 0.031405\n",
      "  Step 10, Current reward: 0.031405\n",
      "  Step 11, Current reward: 0.031405\n",
      "  Step 12, Current reward: 0.031405\n",
      "Episode 408/1000 complete - Max Reward: 0.031405\n",
      "Starting episode 409/1000\n",
      "  Step 1, Current reward: 0.004060\n",
      "  Step 2, Current reward: 0.004060\n",
      "  Step 3, Current reward: 0.004060\n",
      "  Step 4, Current reward: 0.004060\n",
      "  Step 5, Current reward: 0.004060\n",
      "  Step 6, Current reward: 0.004060\n",
      "  Step 7, Current reward: 0.004060\n",
      "  Step 8, Current reward: 0.004060\n",
      "  Step 9, Current reward: 0.004060\n",
      "  Step 10, Current reward: 0.004060\n",
      "  Step 11, Current reward: 0.004060\n",
      "  Step 12, Current reward: 0.004060\n",
      "Episode 409/1000 complete - Max Reward: 0.004060\n",
      "Starting episode 410/1000\n",
      "  Step 1, Current reward: 0.010723\n",
      "  Step 2, Current reward: 0.010723\n",
      "  Step 3, Current reward: 0.010723\n",
      "  Step 4, Current reward: 0.010723\n",
      "  Step 5, Current reward: 0.010723\n",
      "  Step 6, Current reward: 0.010723\n",
      "  Step 7, Current reward: 0.010723\n",
      "  Step 8, Current reward: 0.010723\n",
      "  Step 9, Current reward: 0.010723\n",
      "  Step 10, Current reward: 0.010723\n",
      "  Step 11, Current reward: 0.010723\n",
      "  Step 12, Current reward: 0.010723\n",
      "Episode 410/1000 complete - Max Reward: 0.010723\n",
      "Starting episode 411/1000\n",
      "  Step 1, Current reward: 0.295270\n",
      "  Step 2, Current reward: 0.295270\n",
      "  Step 3, Current reward: 0.295270\n",
      "  Step 4, Current reward: 0.295270\n",
      "  Step 5, Current reward: 0.295270\n",
      "  Step 6, Current reward: 0.295270\n",
      "  Step 7, Current reward: 0.295270\n",
      "  Step 8, Current reward: 0.295270\n",
      "  Step 9, Current reward: 0.295270\n",
      "  Step 10, Current reward: 0.295270\n",
      "  Step 11, Current reward: 0.295270\n",
      "  Step 12, Current reward: 0.295270\n",
      "Episode 411/1000 complete - Max Reward: 0.295270\n",
      "Starting episode 412/1000\n",
      "  Step 1, Current reward: 0.039619\n",
      "  Step 2, Current reward: 0.039619\n",
      "  Step 3, Current reward: 0.039619\n",
      "  Step 4, Current reward: 0.039619\n",
      "  Step 5, Current reward: 0.039619\n",
      "  Step 6, Current reward: 0.039619\n",
      "  Step 7, Current reward: 0.039619\n",
      "  Step 8, Current reward: 0.039619\n",
      "  Step 9, Current reward: 0.039619\n",
      "  Step 10, Current reward: 0.039619\n",
      "  Step 11, Current reward: 0.039619\n",
      "  Step 12, Current reward: 0.039619\n",
      "Episode 412/1000 complete - Max Reward: 0.039619\n",
      "Starting episode 413/1000\n",
      "  Step 1, Current reward: 0.020566\n",
      "  Step 2, Current reward: 0.020566\n",
      "  Step 3, Current reward: 0.020566\n",
      "  Step 4, Current reward: 0.020566\n",
      "  Step 5, Current reward: 0.020566\n",
      "  Step 6, Current reward: 0.020566\n",
      "  Step 7, Current reward: 0.020566\n",
      "  Step 8, Current reward: 0.020566\n",
      "  Step 9, Current reward: 0.020566\n",
      "  Step 10, Current reward: 0.020566\n",
      "  Step 11, Current reward: 0.020566\n",
      "  Step 12, Current reward: 0.020566\n",
      "Episode 413/1000 complete - Max Reward: 0.020566\n",
      "Starting episode 414/1000\n",
      "  Step 1, Current reward: 0.002339\n",
      "  Step 2, Current reward: 0.002339\n",
      "  Step 3, Current reward: 0.002339\n",
      "  Step 4, Current reward: 0.002339\n",
      "  Step 5, Current reward: 0.002339\n",
      "  Step 6, Current reward: 0.002339\n",
      "  Step 7, Current reward: 0.002339\n",
      "  Step 8, Current reward: 0.002339\n",
      "  Step 9, Current reward: 0.002339\n",
      "  Step 10, Current reward: 0.002339\n",
      "  Step 11, Current reward: 0.002339\n",
      "  Step 12, Current reward: 0.002339\n",
      "Episode 414/1000 complete - Max Reward: 0.002339\n",
      "Starting episode 415/1000\n",
      "  Step 1, Current reward: 0.038589\n",
      "  Step 2, Current reward: 0.038589\n",
      "  Step 3, Current reward: 0.038589\n",
      "  Step 4, Current reward: 0.038589\n",
      "  Step 5, Current reward: 0.038589\n",
      "  Step 6, Current reward: 0.038589\n",
      "  Step 7, Current reward: 0.038589\n",
      "  Step 8, Current reward: 0.038589\n",
      "  Step 9, Current reward: 0.038589\n",
      "  Step 10, Current reward: 0.038589\n",
      "  Step 11, Current reward: 0.038589\n",
      "  Step 12, Current reward: 0.038589\n",
      "Episode 415/1000 complete - Max Reward: 0.038589\n",
      "Starting episode 416/1000\n",
      "  Step 1, Current reward: 0.002101\n",
      "  Step 2, Current reward: 0.002101\n",
      "  Step 3, Current reward: 0.002101\n",
      "  Step 4, Current reward: 0.002101\n",
      "  Step 5, Current reward: 0.002101\n",
      "  Step 6, Current reward: 0.002101\n",
      "  Step 7, Current reward: 0.002101\n",
      "  Step 8, Current reward: 0.002101\n",
      "  Step 9, Current reward: 0.002101\n",
      "  Step 10, Current reward: 0.002101\n",
      "  Step 11, Current reward: 0.002101\n",
      "  Step 12, Current reward: 0.002101\n",
      "Episode 416/1000 complete - Max Reward: 0.002101\n",
      "Starting episode 417/1000\n",
      "  Step 1, Current reward: 0.004701\n",
      "  Step 2, Current reward: 0.004701\n",
      "  Step 3, Current reward: 0.004701\n",
      "  Step 4, Current reward: 0.004701\n",
      "  Step 5, Current reward: 0.004701\n",
      "  Step 6, Current reward: 0.004701\n",
      "  Step 7, Current reward: 0.004701\n",
      "  Step 8, Current reward: 0.004701\n",
      "  Step 9, Current reward: 0.004701\n",
      "  Step 10, Current reward: 0.004701\n",
      "  Step 11, Current reward: 0.004701\n",
      "  Step 12, Current reward: 0.004701\n",
      "Episode 417/1000 complete - Max Reward: 0.004701\n",
      "Starting episode 418/1000\n",
      "  Step 1, Current reward: 0.038399\n",
      "  Step 2, Current reward: 0.038399\n",
      "  Step 3, Current reward: 0.038399\n",
      "  Step 4, Current reward: 0.038399\n",
      "  Step 5, Current reward: 0.038399\n",
      "  Step 6, Current reward: 0.038399\n",
      "  Step 7, Current reward: 0.038399\n",
      "  Step 8, Current reward: 0.038399\n",
      "  Step 9, Current reward: 0.038399\n",
      "  Step 10, Current reward: 0.038399\n",
      "  Step 11, Current reward: 0.038399\n",
      "  Step 12, Current reward: 0.038399\n",
      "Episode 418/1000 complete - Max Reward: 0.038399\n",
      "Starting episode 419/1000\n",
      "  Step 1, Current reward: 0.022093\n",
      "  Step 2, Current reward: 0.022093\n",
      "  Step 3, Current reward: 0.022093\n",
      "  Step 4, Current reward: 0.022093\n",
      "  Step 5, Current reward: 0.022093\n",
      "  Step 6, Current reward: 0.022093\n",
      "  Step 7, Current reward: 0.022093\n",
      "  Step 8, Current reward: 0.022093\n",
      "  Step 9, Current reward: 0.022093\n",
      "  Step 10, Current reward: 0.022093\n",
      "  Step 11, Current reward: 0.022093\n",
      "  Step 12, Current reward: 0.022093\n",
      "Episode 419/1000 complete - Max Reward: 0.022093\n",
      "Starting episode 420/1000\n",
      "  Step 1, Current reward: 0.020901\n",
      "  Step 2, Current reward: 0.020901\n",
      "  Step 3, Current reward: 0.020901\n",
      "  Step 4, Current reward: 0.020901\n",
      "  Step 5, Current reward: 0.020901\n",
      "  Step 6, Current reward: 0.020901\n",
      "  Step 7, Current reward: 0.020901\n",
      "  Step 8, Current reward: 0.020901\n",
      "  Step 9, Current reward: 0.020901\n",
      "  Step 10, Current reward: 0.020901\n",
      "  Step 11, Current reward: 0.020901\n",
      "  Step 12, Current reward: 0.020901\n",
      "Episode 420/1000 complete - Max Reward: 0.020901\n",
      "Starting episode 421/1000\n",
      "  Step 1, Current reward: 0.024193\n",
      "  Step 2, Current reward: 0.024193\n",
      "  Step 3, Current reward: 0.024193\n",
      "  Step 4, Current reward: 0.024193\n",
      "  Step 5, Current reward: 0.024193\n",
      "  Step 6, Current reward: 0.024193\n",
      "  Step 7, Current reward: 0.024193\n",
      "  Step 8, Current reward: 0.024193\n",
      "  Step 9, Current reward: 0.024193\n",
      "  Step 10, Current reward: 0.024193\n",
      "  Step 11, Current reward: 0.024193\n",
      "  Step 12, Current reward: 0.024193\n",
      "Episode 421/1000 complete - Max Reward: 0.024193\n",
      "Starting episode 422/1000\n",
      "  Step 1, Current reward: 0.080348\n",
      "  Step 2, Current reward: 0.080348\n",
      "  Step 3, Current reward: 0.080348\n",
      "  Step 4, Current reward: 0.080348\n",
      "  Step 5, Current reward: 0.080348\n",
      "  Step 6, Current reward: 0.080348\n",
      "  Step 7, Current reward: 0.080348\n",
      "  Step 8, Current reward: 0.080348\n",
      "  Step 9, Current reward: 0.080348\n",
      "  Step 10, Current reward: 0.080348\n",
      "  Step 11, Current reward: 0.080348\n",
      "  Step 12, Current reward: 0.080348\n",
      "Episode 422/1000 complete - Max Reward: 0.080348\n",
      "Starting episode 423/1000\n",
      "  Step 1, Current reward: 0.012400\n",
      "  Step 2, Current reward: 0.012400\n",
      "  Step 3, Current reward: 0.012400\n",
      "  Step 4, Current reward: 0.012400\n",
      "  Step 5, Current reward: 0.012400\n",
      "  Step 6, Current reward: 0.012400\n",
      "  Step 7, Current reward: 0.012400\n",
      "  Step 8, Current reward: 0.012400\n",
      "  Step 9, Current reward: 0.012400\n",
      "  Step 10, Current reward: 0.012400\n",
      "  Step 11, Current reward: 0.012400\n",
      "  Step 12, Current reward: 0.012400\n",
      "Episode 423/1000 complete - Max Reward: 0.012400\n",
      "Starting episode 424/1000\n",
      "  Step 1, Current reward: 0.156694\n",
      "  Step 2, Current reward: 0.156694\n",
      "  Step 3, Current reward: 0.156694\n",
      "  Step 4, Current reward: 0.156694\n",
      "  Step 5, Current reward: 0.156694\n",
      "  Step 6, Current reward: 0.156694\n",
      "  Step 7, Current reward: 0.156694\n",
      "  Step 8, Current reward: 0.156694\n",
      "  Step 9, Current reward: 0.156694\n",
      "  Step 10, Current reward: 0.156694\n",
      "  Step 11, Current reward: 0.156694\n",
      "  Step 12, Current reward: 0.156694\n",
      "Episode 424/1000 complete - Max Reward: 0.156694\n",
      "Starting episode 425/1000\n",
      "  Step 1, Current reward: 0.091971\n",
      "  Step 2, Current reward: 0.091971\n",
      "  Step 3, Current reward: 0.091971\n",
      "  Step 4, Current reward: 0.091971\n",
      "  Step 5, Current reward: 0.091971\n",
      "  Step 6, Current reward: 0.091971\n",
      "  Step 7, Current reward: 0.091971\n",
      "  Step 8, Current reward: 0.091971\n",
      "  Step 9, Current reward: 0.091971\n",
      "  Step 10, Current reward: 0.091971\n",
      "  Step 11, Current reward: 0.091971\n",
      "  Step 12, Current reward: 0.091971\n",
      "Episode 425/1000 complete - Max Reward: 0.091971\n",
      "Starting episode 426/1000\n",
      "  Step 1, Current reward: 0.015449\n",
      "  Step 2, Current reward: 0.015449\n",
      "  Step 3, Current reward: 0.015449\n",
      "  Step 4, Current reward: 0.015449\n",
      "  Step 5, Current reward: 0.015449\n",
      "  Step 6, Current reward: 0.015449\n",
      "  Step 7, Current reward: 0.015449\n",
      "  Step 8, Current reward: 0.015449\n",
      "  Step 9, Current reward: 0.015449\n",
      "  Step 10, Current reward: 0.015449\n",
      "  Step 11, Current reward: 0.015449\n",
      "  Step 12, Current reward: 0.015449\n",
      "Episode 426/1000 complete - Max Reward: 0.015449\n",
      "Starting episode 427/1000\n",
      "  Step 1, Current reward: 0.091343\n",
      "  Step 2, Current reward: 0.091343\n",
      "  Step 3, Current reward: 0.091343\n",
      "  Step 4, Current reward: 0.091343\n",
      "  Step 5, Current reward: 0.091343\n",
      "  Step 6, Current reward: 0.091343\n",
      "  Step 7, Current reward: 0.091343\n",
      "  Step 8, Current reward: 0.091343\n",
      "  Step 9, Current reward: 0.091343\n",
      "  Step 10, Current reward: 0.091343\n",
      "  Step 11, Current reward: 0.091343\n",
      "  Step 12, Current reward: 0.091343\n",
      "Episode 427/1000 complete - Max Reward: 0.091343\n",
      "Starting episode 428/1000\n",
      "  Step 1, Current reward: 0.020594\n",
      "  Step 2, Current reward: 0.019525\n",
      "  Step 3, Current reward: 0.019525\n",
      "  Step 4, Current reward: 0.019525\n",
      "  Step 5, Current reward: 0.019525\n",
      "  Step 6, Current reward: 0.019525\n",
      "  Step 7, Current reward: 0.019525\n",
      "  Step 8, Current reward: 0.019525\n",
      "  Step 9, Current reward: 0.019525\n",
      "  Step 10, Current reward: 0.019525\n",
      "  Step 11, Current reward: 0.019525\n",
      "  Step 12, Current reward: 0.019525\n",
      "Episode 428/1000 complete - Max Reward: 0.020594\n",
      "Starting episode 429/1000\n",
      "  Step 1, Current reward: 0.045730\n",
      "  Step 2, Current reward: 0.045730\n",
      "  Step 3, Current reward: 0.045730\n",
      "  Step 4, Current reward: 0.045730\n",
      "  Step 5, Current reward: 0.045730\n",
      "  Step 6, Current reward: 0.045730\n",
      "  Step 7, Current reward: 0.045730\n",
      "  Step 8, Current reward: 0.045730\n",
      "  Step 9, Current reward: 0.045730\n",
      "  Step 10, Current reward: 0.045730\n",
      "  Step 11, Current reward: 0.045730\n",
      "  Step 12, Current reward: 0.045730\n",
      "Episode 429/1000 complete - Max Reward: 0.045730\n",
      "Starting episode 430/1000\n",
      "  Step 1, Current reward: 0.027674\n",
      "  Step 2, Current reward: 0.027674\n",
      "  Step 3, Current reward: 0.027674\n",
      "  Step 4, Current reward: 0.027674\n",
      "  Step 5, Current reward: 0.027674\n",
      "  Step 6, Current reward: 0.027674\n",
      "  Step 7, Current reward: 0.027674\n",
      "  Step 8, Current reward: 0.027674\n",
      "  Step 9, Current reward: 0.027674\n",
      "  Step 10, Current reward: 0.027674\n",
      "  Step 11, Current reward: 0.027674\n",
      "  Step 12, Current reward: 0.027674\n",
      "Episode 430/1000 complete - Max Reward: 0.027674\n",
      "Starting episode 431/1000\n",
      "  Step 1, Current reward: 0.007269\n",
      "  Step 2, Current reward: 0.008200\n",
      "  Step 3, Current reward: 0.009217\n",
      "  Step 4, Current reward: 0.010298\n",
      "  Step 5, Current reward: 0.011403\n",
      "  Step 6, Current reward: 0.012501\n",
      "  Step 7, Current reward: 0.012501\n",
      "  Step 8, Current reward: 0.012501\n",
      "  Step 9, Current reward: 0.012501\n",
      "  Step 10, Current reward: 0.012501\n",
      "  Step 11, Current reward: 0.012501\n",
      "  Step 12, Current reward: 0.012501\n",
      "  Step 13, Current reward: 0.012501\n",
      "  Step 14, Current reward: 0.012501\n",
      "  Step 15, Current reward: 0.012501\n",
      "  Step 16, Current reward: 0.012501\n",
      "  Step 17, Current reward: 0.012501\n",
      "Episode 431/1000 complete - Max Reward: 0.012501\n",
      "Starting episode 432/1000\n",
      "  Step 1, Current reward: 0.073892\n",
      "  Step 2, Current reward: 0.073892\n",
      "  Step 3, Current reward: 0.073892\n",
      "  Step 4, Current reward: 0.073892\n",
      "  Step 5, Current reward: 0.073892\n",
      "  Step 6, Current reward: 0.073892\n",
      "  Step 7, Current reward: 0.073892\n",
      "  Step 8, Current reward: 0.073892\n",
      "  Step 9, Current reward: 0.073892\n",
      "  Step 10, Current reward: 0.073892\n",
      "  Step 11, Current reward: 0.073892\n",
      "  Step 12, Current reward: 0.073892\n",
      "Episode 432/1000 complete - Max Reward: 0.073892\n",
      "Starting episode 433/1000\n",
      "  Step 1, Current reward: 0.013523\n",
      "  Step 2, Current reward: 0.013523\n",
      "  Step 3, Current reward: 0.013523\n",
      "  Step 4, Current reward: 0.013523\n",
      "  Step 5, Current reward: 0.013523\n",
      "  Step 6, Current reward: 0.013523\n",
      "  Step 7, Current reward: 0.013523\n",
      "  Step 8, Current reward: 0.013523\n",
      "  Step 9, Current reward: 0.013523\n",
      "  Step 10, Current reward: 0.013523\n",
      "  Step 11, Current reward: 0.013523\n",
      "  Step 12, Current reward: 0.013523\n",
      "Episode 433/1000 complete - Max Reward: 0.013523\n",
      "Starting episode 434/1000\n",
      "  Step 1, Current reward: 0.001952\n",
      "  Step 2, Current reward: 0.001952\n",
      "  Step 3, Current reward: 0.001952\n",
      "  Step 4, Current reward: 0.001952\n",
      "  Step 5, Current reward: 0.001952\n",
      "  Step 6, Current reward: 0.001952\n",
      "  Step 7, Current reward: 0.001952\n",
      "  Step 8, Current reward: 0.001952\n",
      "  Step 9, Current reward: 0.001952\n",
      "  Step 10, Current reward: 0.001952\n",
      "  Step 11, Current reward: 0.001952\n",
      "  Step 12, Current reward: 0.001952\n",
      "Episode 434/1000 complete - Max Reward: 0.001952\n",
      "Starting episode 435/1000\n",
      "  Step 1, Current reward: 0.004475\n",
      "  Step 2, Current reward: 0.004475\n",
      "  Step 3, Current reward: 0.004475\n",
      "  Step 4, Current reward: 0.004475\n",
      "  Step 5, Current reward: 0.004475\n",
      "  Step 6, Current reward: 0.004475\n",
      "  Step 7, Current reward: 0.004475\n",
      "  Step 8, Current reward: 0.004475\n",
      "  Step 9, Current reward: 0.004475\n",
      "  Step 10, Current reward: 0.004475\n",
      "  Step 11, Current reward: 0.004475\n",
      "  Step 12, Current reward: 0.004475\n",
      "Episode 435/1000 complete - Max Reward: 0.004475\n",
      "Starting episode 436/1000\n",
      "  Step 1, Current reward: 0.031124\n",
      "  Step 2, Current reward: 0.031124\n",
      "  Step 3, Current reward: 0.031124\n",
      "  Step 4, Current reward: 0.031124\n",
      "  Step 5, Current reward: 0.031124\n",
      "  Step 6, Current reward: 0.031124\n",
      "  Step 7, Current reward: 0.031124\n",
      "  Step 8, Current reward: 0.031124\n",
      "  Step 9, Current reward: 0.031124\n",
      "  Step 10, Current reward: 0.031124\n",
      "  Step 11, Current reward: 0.031124\n",
      "  Step 12, Current reward: 0.031124\n",
      "Episode 436/1000 complete - Max Reward: 0.031124\n",
      "Starting episode 437/1000\n",
      "  Step 1, Current reward: 0.083943\n",
      "  Step 2, Current reward: 0.083943\n",
      "  Step 3, Current reward: 0.083943\n",
      "  Step 4, Current reward: 0.083943\n",
      "  Step 5, Current reward: 0.083943\n",
      "  Step 6, Current reward: 0.083943\n",
      "  Step 7, Current reward: 0.083943\n",
      "  Step 8, Current reward: 0.083943\n",
      "  Step 9, Current reward: 0.083943\n",
      "  Step 10, Current reward: 0.083943\n",
      "  Step 11, Current reward: 0.083943\n",
      "  Step 12, Current reward: 0.083943\n",
      "Episode 437/1000 complete - Max Reward: 0.083943\n",
      "Starting episode 438/1000\n",
      "  Step 1, Current reward: 0.134931\n",
      "  Step 2, Current reward: 0.134931\n",
      "  Step 3, Current reward: 0.134931\n",
      "  Step 4, Current reward: 0.134931\n",
      "  Step 5, Current reward: 0.134931\n",
      "  Step 6, Current reward: 0.134931\n",
      "  Step 7, Current reward: 0.134931\n",
      "  Step 8, Current reward: 0.134931\n",
      "  Step 9, Current reward: 0.134931\n",
      "  Step 10, Current reward: 0.134931\n",
      "  Step 11, Current reward: 0.134931\n",
      "  Step 12, Current reward: 0.134931\n",
      "Episode 438/1000 complete - Max Reward: 0.134931\n",
      "Starting episode 439/1000\n",
      "  Step 1, Current reward: 0.006127\n",
      "  Step 2, Current reward: 0.006127\n",
      "  Step 3, Current reward: 0.006127\n",
      "  Step 4, Current reward: 0.006127\n",
      "  Step 5, Current reward: 0.006127\n",
      "  Step 6, Current reward: 0.006127\n",
      "  Step 7, Current reward: 0.006127\n",
      "  Step 8, Current reward: 0.006127\n",
      "  Step 9, Current reward: 0.006127\n",
      "  Step 10, Current reward: 0.006127\n",
      "  Step 11, Current reward: 0.006127\n",
      "  Step 12, Current reward: 0.006127\n",
      "Episode 439/1000 complete - Max Reward: 0.006127\n",
      "Starting episode 440/1000\n",
      "  Step 1, Current reward: 0.046916\n",
      "  Step 2, Current reward: 0.046916\n",
      "  Step 3, Current reward: 0.046916\n",
      "  Step 4, Current reward: 0.046916\n",
      "  Step 5, Current reward: 0.046916\n",
      "  Step 6, Current reward: 0.046916\n",
      "  Step 7, Current reward: 0.046916\n",
      "  Step 8, Current reward: 0.046916\n",
      "  Step 9, Current reward: 0.046916\n",
      "  Step 10, Current reward: 0.046916\n",
      "  Step 11, Current reward: 0.046916\n",
      "  Step 12, Current reward: 0.046916\n",
      "Episode 440/1000 complete - Max Reward: 0.046916\n",
      "Starting episode 441/1000\n",
      "  Step 1, Current reward: 0.071659\n",
      "  Step 2, Current reward: 0.071659\n",
      "  Step 3, Current reward: 0.071659\n",
      "  Step 4, Current reward: 0.071659\n",
      "  Step 5, Current reward: 0.071659\n",
      "  Step 6, Current reward: 0.071659\n",
      "  Step 7, Current reward: 0.071659\n",
      "  Step 8, Current reward: 0.071659\n",
      "  Step 9, Current reward: 0.071659\n",
      "  Step 10, Current reward: 0.071659\n",
      "  Step 11, Current reward: 0.071659\n",
      "  Step 12, Current reward: 0.071659\n",
      "Episode 441/1000 complete - Max Reward: 0.071659\n",
      "Starting episode 442/1000\n",
      "  Step 1, Current reward: 0.094458\n",
      "  Step 2, Current reward: 0.094458\n",
      "  Step 3, Current reward: 0.094458\n",
      "  Step 4, Current reward: 0.094458\n",
      "  Step 5, Current reward: 0.094458\n",
      "  Step 6, Current reward: 0.094458\n",
      "  Step 7, Current reward: 0.094458\n",
      "  Step 8, Current reward: 0.094458\n",
      "  Step 9, Current reward: 0.094458\n",
      "  Step 10, Current reward: 0.094458\n",
      "  Step 11, Current reward: 0.094458\n",
      "  Step 12, Current reward: 0.094458\n",
      "Episode 442/1000 complete - Max Reward: 0.094458\n",
      "Starting episode 443/1000\n",
      "  Step 1, Current reward: 0.027688\n",
      "  Step 2, Current reward: 0.027688\n",
      "  Step 3, Current reward: 0.027688\n",
      "  Step 4, Current reward: 0.027688\n",
      "  Step 5, Current reward: 0.027688\n",
      "  Step 6, Current reward: 0.027688\n",
      "  Step 7, Current reward: 0.027688\n",
      "  Step 8, Current reward: 0.027688\n",
      "  Step 9, Current reward: 0.027688\n",
      "  Step 10, Current reward: 0.027688\n",
      "  Step 11, Current reward: 0.027688\n",
      "  Step 12, Current reward: 0.027688\n",
      "Episode 443/1000 complete - Max Reward: 0.027688\n",
      "Starting episode 444/1000\n",
      "  Step 1, Current reward: 0.000419\n",
      "  Step 2, Current reward: 0.000412\n",
      "  Step 3, Current reward: 0.000402\n",
      "  Step 4, Current reward: 0.000391\n",
      "  Step 5, Current reward: 0.000378\n",
      "  Step 6, Current reward: 0.000362\n",
      "  Step 7, Current reward: 0.000344\n",
      "  Step 8, Current reward: 0.000325\n",
      "  Step 9, Current reward: 0.000308\n",
      "  Step 10, Current reward: 0.000296\n",
      "  Step 11, Current reward: 0.000289\n",
      "  Step 12, Current reward: 0.000280\n",
      "Episode 444/1000 complete - Max Reward: 0.000419\n",
      "Starting episode 445/1000\n",
      "  Step 1, Current reward: 0.048295\n",
      "  Step 2, Current reward: 0.048295\n",
      "  Step 3, Current reward: 0.048295\n",
      "  Step 4, Current reward: 0.048295\n",
      "  Step 5, Current reward: 0.048295\n",
      "  Step 6, Current reward: 0.048295\n",
      "  Step 7, Current reward: 0.048295\n",
      "  Step 8, Current reward: 0.048295\n",
      "  Step 9, Current reward: 0.048295\n",
      "  Step 10, Current reward: 0.048295\n",
      "  Step 11, Current reward: 0.048295\n",
      "  Step 12, Current reward: 0.048295\n",
      "Episode 445/1000 complete - Max Reward: 0.048295\n",
      "Starting episode 446/1000\n",
      "  Step 1, Current reward: 0.067410\n",
      "  Step 2, Current reward: 0.067410\n",
      "  Step 3, Current reward: 0.067410\n",
      "  Step 4, Current reward: 0.067410\n",
      "  Step 5, Current reward: 0.067410\n",
      "  Step 6, Current reward: 0.067410\n",
      "  Step 7, Current reward: 0.067410\n",
      "  Step 8, Current reward: 0.067410\n",
      "  Step 9, Current reward: 0.067410\n",
      "  Step 10, Current reward: 0.067410\n",
      "  Step 11, Current reward: 0.067410\n",
      "  Step 12, Current reward: 0.067410\n",
      "Episode 446/1000 complete - Max Reward: 0.067410\n",
      "Starting episode 447/1000\n",
      "  Step 1, Current reward: 0.033685\n",
      "  Step 2, Current reward: 0.033685\n",
      "  Step 3, Current reward: 0.033685\n",
      "  Step 4, Current reward: 0.033685\n",
      "  Step 5, Current reward: 0.033685\n",
      "  Step 6, Current reward: 0.033685\n",
      "  Step 7, Current reward: 0.033685\n",
      "  Step 8, Current reward: 0.033685\n",
      "  Step 9, Current reward: 0.033685\n",
      "  Step 10, Current reward: 0.033685\n",
      "  Step 11, Current reward: 0.033685\n",
      "  Step 12, Current reward: 0.033685\n",
      "Episode 447/1000 complete - Max Reward: 0.033685\n",
      "Starting episode 448/1000\n",
      "  Step 1, Current reward: 0.000583\n",
      "  Step 2, Current reward: 0.000565\n",
      "  Step 3, Current reward: 0.000565\n",
      "  Step 4, Current reward: 0.000565\n",
      "  Step 5, Current reward: 0.000565\n",
      "  Step 6, Current reward: 0.000565\n",
      "  Step 7, Current reward: 0.000565\n",
      "  Step 8, Current reward: 0.000565\n",
      "  Step 9, Current reward: 0.000565\n",
      "  Step 10, Current reward: 0.000565\n",
      "  Step 11, Current reward: 0.000565\n",
      "  Step 12, Current reward: 0.000565\n",
      "Episode 448/1000 complete - Max Reward: 0.000583\n",
      "Starting episode 449/1000\n",
      "  Step 1, Current reward: 0.024026\n",
      "  Step 2, Current reward: 0.024026\n",
      "  Step 3, Current reward: 0.024026\n",
      "  Step 4, Current reward: 0.024026\n",
      "  Step 5, Current reward: 0.024026\n",
      "  Step 6, Current reward: 0.024026\n",
      "  Step 7, Current reward: 0.024026\n",
      "  Step 8, Current reward: 0.024026\n",
      "  Step 9, Current reward: 0.024026\n",
      "  Step 10, Current reward: 0.024026\n",
      "  Step 11, Current reward: 0.024026\n",
      "  Step 12, Current reward: 0.024026\n",
      "Episode 449/1000 complete - Max Reward: 0.024026\n",
      "Starting episode 450/1000\n",
      "  Step 1, Current reward: 0.039041\n",
      "  Step 2, Current reward: 0.039041\n",
      "  Step 3, Current reward: 0.039041\n",
      "  Step 4, Current reward: 0.039041\n",
      "  Step 5, Current reward: 0.039041\n",
      "  Step 6, Current reward: 0.039041\n",
      "  Step 7, Current reward: 0.039041\n",
      "  Step 8, Current reward: 0.039041\n",
      "  Step 9, Current reward: 0.039041\n",
      "  Step 10, Current reward: 0.039041\n",
      "  Step 11, Current reward: 0.039041\n",
      "  Step 12, Current reward: 0.039041\n",
      "Episode 450/1000 complete - Max Reward: 0.039041\n",
      "Starting episode 451/1000\n",
      "  Step 1, Current reward: 0.006992\n",
      "  Step 2, Current reward: 0.006992\n",
      "  Step 3, Current reward: 0.006992\n",
      "  Step 4, Current reward: 0.006992\n",
      "  Step 5, Current reward: 0.006992\n",
      "  Step 6, Current reward: 0.006992\n",
      "  Step 7, Current reward: 0.006992\n",
      "  Step 8, Current reward: 0.006992\n",
      "  Step 9, Current reward: 0.006992\n",
      "  Step 10, Current reward: 0.006992\n",
      "  Step 11, Current reward: 0.006992\n",
      "  Step 12, Current reward: 0.006992\n",
      "Episode 451/1000 complete - Max Reward: 0.006992\n",
      "Starting episode 452/1000\n",
      "  Step 1, Current reward: 0.040006\n",
      "  Step 2, Current reward: 0.040006\n",
      "  Step 3, Current reward: 0.040006\n",
      "  Step 4, Current reward: 0.040006\n",
      "  Step 5, Current reward: 0.040006\n",
      "  Step 6, Current reward: 0.040006\n",
      "  Step 7, Current reward: 0.040006\n",
      "  Step 8, Current reward: 0.040006\n",
      "  Step 9, Current reward: 0.040006\n",
      "  Step 10, Current reward: 0.040006\n",
      "  Step 11, Current reward: 0.040006\n",
      "  Step 12, Current reward: 0.040006\n",
      "Episode 452/1000 complete - Max Reward: 0.040006\n",
      "Starting episode 453/1000\n",
      "  Step 1, Current reward: 0.021093\n",
      "  Step 2, Current reward: 0.022754\n",
      "  Step 3, Current reward: 0.024573\n",
      "  Step 4, Current reward: 0.026541\n",
      "  Step 5, Current reward: 0.028643\n",
      "  Step 6, Current reward: 0.028643\n",
      "  Step 7, Current reward: 0.028643\n",
      "  Step 8, Current reward: 0.028643\n",
      "  Step 9, Current reward: 0.028643\n",
      "  Step 10, Current reward: 0.028643\n",
      "  Step 11, Current reward: 0.028643\n",
      "  Step 12, Current reward: 0.028643\n",
      "  Step 13, Current reward: 0.028643\n",
      "  Step 14, Current reward: 0.028643\n",
      "  Step 15, Current reward: 0.028643\n",
      "  Step 16, Current reward: 0.028643\n",
      "Episode 453/1000 complete - Max Reward: 0.028643\n",
      "Starting episode 454/1000\n",
      "  Step 1, Current reward: 0.001939\n",
      "  Step 2, Current reward: 0.001223\n",
      "  Step 3, Current reward: 0.000710\n",
      "  Step 4, Current reward: 0.000427\n",
      "  Step 5, Current reward: 0.000312\n",
      "  Step 6, Current reward: 0.000289\n",
      "  Step 7, Current reward: 0.000330\n",
      "  Step 8, Current reward: 0.000330\n",
      "  Step 9, Current reward: 0.000330\n",
      "  Step 10, Current reward: 0.000330\n",
      "  Step 11, Current reward: 0.000330\n",
      "  Step 12, Current reward: 0.000330\n",
      "Episode 454/1000 complete - Max Reward: 0.001939\n",
      "Starting episode 455/1000\n",
      "  Step 1, Current reward: 0.042344\n",
      "  Step 2, Current reward: 0.042344\n",
      "  Step 3, Current reward: 0.042344\n",
      "  Step 4, Current reward: 0.042344\n",
      "  Step 5, Current reward: 0.042344\n",
      "  Step 6, Current reward: 0.042344\n",
      "  Step 7, Current reward: 0.042344\n",
      "  Step 8, Current reward: 0.042344\n",
      "  Step 9, Current reward: 0.042344\n",
      "  Step 10, Current reward: 0.042344\n",
      "  Step 11, Current reward: 0.042344\n",
      "  Step 12, Current reward: 0.042344\n",
      "Episode 455/1000 complete - Max Reward: 0.042344\n",
      "Starting episode 456/1000\n",
      "  Step 1, Current reward: 0.024475\n",
      "  Step 2, Current reward: 0.024475\n",
      "  Step 3, Current reward: 0.024475\n",
      "  Step 4, Current reward: 0.024475\n",
      "  Step 5, Current reward: 0.024475\n",
      "  Step 6, Current reward: 0.024475\n",
      "  Step 7, Current reward: 0.024475\n",
      "  Step 8, Current reward: 0.024475\n",
      "  Step 9, Current reward: 0.024475\n",
      "  Step 10, Current reward: 0.024475\n",
      "  Step 11, Current reward: 0.024475\n",
      "  Step 12, Current reward: 0.024475\n",
      "Episode 456/1000 complete - Max Reward: 0.024475\n",
      "Starting episode 457/1000\n",
      "  Step 1, Current reward: 0.010610\n",
      "  Step 2, Current reward: 0.010610\n",
      "  Step 3, Current reward: 0.010610\n",
      "  Step 4, Current reward: 0.010610\n",
      "  Step 5, Current reward: 0.010610\n",
      "  Step 6, Current reward: 0.010610\n",
      "  Step 7, Current reward: 0.010610\n",
      "  Step 8, Current reward: 0.010610\n",
      "  Step 9, Current reward: 0.010610\n",
      "  Step 10, Current reward: 0.010610\n",
      "  Step 11, Current reward: 0.010610\n",
      "  Step 12, Current reward: 0.010610\n",
      "Episode 457/1000 complete - Max Reward: 0.010610\n",
      "Starting episode 458/1000\n",
      "  Step 1, Current reward: 0.045843\n",
      "  Step 2, Current reward: 0.045843\n",
      "  Step 3, Current reward: 0.045843\n",
      "  Step 4, Current reward: 0.045843\n",
      "  Step 5, Current reward: 0.045843\n",
      "  Step 6, Current reward: 0.045843\n",
      "  Step 7, Current reward: 0.045843\n",
      "  Step 8, Current reward: 0.045843\n",
      "  Step 9, Current reward: 0.045843\n",
      "  Step 10, Current reward: 0.045843\n",
      "  Step 11, Current reward: 0.045843\n",
      "  Step 12, Current reward: 0.045843\n",
      "Episode 458/1000 complete - Max Reward: 0.045843\n",
      "Starting episode 459/1000\n",
      "  Step 1, Current reward: 0.022184\n",
      "  Step 2, Current reward: 0.022184\n",
      "  Step 3, Current reward: 0.022184\n",
      "  Step 4, Current reward: 0.022184\n",
      "  Step 5, Current reward: 0.022184\n",
      "  Step 6, Current reward: 0.022184\n",
      "  Step 7, Current reward: 0.022184\n",
      "  Step 8, Current reward: 0.022184\n",
      "  Step 9, Current reward: 0.022184\n",
      "  Step 10, Current reward: 0.022184\n",
      "  Step 11, Current reward: 0.022184\n",
      "  Step 12, Current reward: 0.022184\n",
      "Episode 459/1000 complete - Max Reward: 0.022184\n",
      "Starting episode 460/1000\n",
      "  Step 1, Current reward: 0.006053\n",
      "  Step 2, Current reward: 0.006476\n",
      "  Step 3, Current reward: 0.006906\n",
      "  Step 4, Current reward: 0.007330\n",
      "  Step 5, Current reward: 0.007734\n",
      "  Step 6, Current reward: 0.008105\n",
      "  Step 7, Current reward: 0.008432\n",
      "  Step 8, Current reward: 0.008710\n",
      "  Step 9, Current reward: 0.008938\n",
      "  Step 10, Current reward: 0.008938\n",
      "  Step 11, Current reward: 0.008938\n",
      "  Step 12, Current reward: 0.008938\n",
      "  Step 13, Current reward: 0.008938\n",
      "  Step 14, Current reward: 0.008938\n",
      "  Step 15, Current reward: 0.008938\n",
      "  Step 16, Current reward: 0.008938\n",
      "  Step 17, Current reward: 0.008938\n",
      "  Step 18, Current reward: 0.008938\n",
      "  Step 19, Current reward: 0.008938\n",
      "  Step 20, Current reward: 0.008938\n",
      "Episode 460/1000 complete - Max Reward: 0.008938\n",
      "Starting episode 461/1000\n",
      "  Step 1, Current reward: 0.013545\n",
      "  Step 2, Current reward: 0.013545\n",
      "  Step 3, Current reward: 0.013545\n",
      "  Step 4, Current reward: 0.013545\n",
      "  Step 5, Current reward: 0.013545\n",
      "  Step 6, Current reward: 0.013545\n",
      "  Step 7, Current reward: 0.013545\n",
      "  Step 8, Current reward: 0.013545\n",
      "  Step 9, Current reward: 0.013545\n",
      "  Step 10, Current reward: 0.013545\n",
      "  Step 11, Current reward: 0.013545\n",
      "  Step 12, Current reward: 0.013545\n",
      "Episode 461/1000 complete - Max Reward: 0.013545\n",
      "Starting episode 462/1000\n",
      "  Step 1, Current reward: 0.204690\n",
      "  Step 2, Current reward: 0.204690\n",
      "  Step 3, Current reward: 0.204690\n",
      "  Step 4, Current reward: 0.204690\n",
      "  Step 5, Current reward: 0.204690\n",
      "  Step 6, Current reward: 0.204690\n",
      "  Step 7, Current reward: 0.204690\n",
      "  Step 8, Current reward: 0.204690\n",
      "  Step 9, Current reward: 0.204690\n",
      "  Step 10, Current reward: 0.204690\n",
      "  Step 11, Current reward: 0.204690\n",
      "  Step 12, Current reward: 0.204690\n",
      "Episode 462/1000 complete - Max Reward: 0.204690\n",
      "Starting episode 463/1000\n",
      "  Step 1, Current reward: 0.077514\n",
      "  Step 2, Current reward: 0.077514\n",
      "  Step 3, Current reward: 0.077514\n",
      "  Step 4, Current reward: 0.077514\n",
      "  Step 5, Current reward: 0.077514\n",
      "  Step 6, Current reward: 0.077514\n",
      "  Step 7, Current reward: 0.077514\n",
      "  Step 8, Current reward: 0.077514\n",
      "  Step 9, Current reward: 0.077514\n",
      "  Step 10, Current reward: 0.077514\n",
      "  Step 11, Current reward: 0.077514\n",
      "  Step 12, Current reward: 0.077514\n",
      "Episode 463/1000 complete - Max Reward: 0.077514\n",
      "Starting episode 464/1000\n",
      "  Step 1, Current reward: 0.021573\n",
      "  Step 2, Current reward: 0.021573\n",
      "  Step 3, Current reward: 0.021573\n",
      "  Step 4, Current reward: 0.021573\n",
      "  Step 5, Current reward: 0.021573\n",
      "  Step 6, Current reward: 0.021573\n",
      "  Step 7, Current reward: 0.021573\n",
      "  Step 8, Current reward: 0.021573\n",
      "  Step 9, Current reward: 0.021573\n",
      "  Step 10, Current reward: 0.021573\n",
      "  Step 11, Current reward: 0.021573\n",
      "  Step 12, Current reward: 0.021573\n",
      "Episode 464/1000 complete - Max Reward: 0.021573\n",
      "Starting episode 465/1000\n",
      "  Step 1, Current reward: 0.023471\n",
      "  Step 2, Current reward: 0.023471\n",
      "  Step 3, Current reward: 0.023471\n",
      "  Step 4, Current reward: 0.023471\n",
      "  Step 5, Current reward: 0.023471\n",
      "  Step 6, Current reward: 0.023471\n",
      "  Step 7, Current reward: 0.023471\n",
      "  Step 8, Current reward: 0.023471\n",
      "  Step 9, Current reward: 0.023471\n",
      "  Step 10, Current reward: 0.023471\n",
      "  Step 11, Current reward: 0.023471\n",
      "  Step 12, Current reward: 0.023471\n",
      "Episode 465/1000 complete - Max Reward: 0.023471\n",
      "Starting episode 466/1000\n",
      "  Step 1, Current reward: 0.007361\n",
      "  Step 2, Current reward: 0.007361\n",
      "  Step 3, Current reward: 0.007361\n",
      "  Step 4, Current reward: 0.007361\n",
      "  Step 5, Current reward: 0.007361\n",
      "  Step 6, Current reward: 0.007361\n",
      "  Step 7, Current reward: 0.007361\n",
      "  Step 8, Current reward: 0.007361\n",
      "  Step 9, Current reward: 0.007361\n",
      "  Step 10, Current reward: 0.007361\n",
      "  Step 11, Current reward: 0.007361\n",
      "  Step 12, Current reward: 0.007361\n",
      "Episode 466/1000 complete - Max Reward: 0.007361\n",
      "Starting episode 467/1000\n",
      "  Step 1, Current reward: 0.000441\n",
      "  Step 2, Current reward: 0.000441\n",
      "  Step 3, Current reward: 0.000441\n",
      "  Step 4, Current reward: 0.000441\n",
      "  Step 5, Current reward: 0.000441\n",
      "  Step 6, Current reward: 0.000441\n",
      "  Step 7, Current reward: 0.000441\n",
      "  Step 8, Current reward: 0.000441\n",
      "  Step 9, Current reward: 0.000441\n",
      "  Step 10, Current reward: 0.000441\n",
      "  Step 11, Current reward: 0.000441\n",
      "  Step 12, Current reward: 0.000441\n",
      "Episode 467/1000 complete - Max Reward: 0.000441\n",
      "Starting episode 468/1000\n",
      "  Step 1, Current reward: 0.012677\n",
      "  Step 2, Current reward: 0.012677\n",
      "  Step 3, Current reward: 0.012677\n",
      "  Step 4, Current reward: 0.012677\n",
      "  Step 5, Current reward: 0.012677\n",
      "  Step 6, Current reward: 0.012677\n",
      "  Step 7, Current reward: 0.012677\n",
      "  Step 8, Current reward: 0.012677\n",
      "  Step 9, Current reward: 0.012677\n",
      "  Step 10, Current reward: 0.012677\n",
      "  Step 11, Current reward: 0.012677\n",
      "  Step 12, Current reward: 0.012677\n",
      "Episode 468/1000 complete - Max Reward: 0.012677\n",
      "Starting episode 469/1000\n",
      "  Step 1, Current reward: 0.023114\n",
      "  Step 2, Current reward: 0.023114\n",
      "  Step 3, Current reward: 0.023114\n",
      "  Step 4, Current reward: 0.023114\n",
      "  Step 5, Current reward: 0.023114\n",
      "  Step 6, Current reward: 0.023114\n",
      "  Step 7, Current reward: 0.023114\n",
      "  Step 8, Current reward: 0.023114\n",
      "  Step 9, Current reward: 0.023114\n",
      "  Step 10, Current reward: 0.023114\n",
      "  Step 11, Current reward: 0.023114\n",
      "  Step 12, Current reward: 0.023114\n",
      "Episode 469/1000 complete - Max Reward: 0.023114\n",
      "Starting episode 470/1000\n",
      "  Step 1, Current reward: 0.021627\n",
      "  Step 2, Current reward: 0.021627\n",
      "  Step 3, Current reward: 0.021627\n",
      "  Step 4, Current reward: 0.021627\n",
      "  Step 5, Current reward: 0.021627\n",
      "  Step 6, Current reward: 0.021627\n",
      "  Step 7, Current reward: 0.021627\n",
      "  Step 8, Current reward: 0.021627\n",
      "  Step 9, Current reward: 0.021627\n",
      "  Step 10, Current reward: 0.021627\n",
      "  Step 11, Current reward: 0.021627\n",
      "  Step 12, Current reward: 0.021627\n",
      "Episode 470/1000 complete - Max Reward: 0.021627\n",
      "Starting episode 471/1000\n",
      "  Step 1, Current reward: 0.020321\n",
      "  Step 2, Current reward: 0.020321\n",
      "  Step 3, Current reward: 0.020321\n",
      "  Step 4, Current reward: 0.020321\n",
      "  Step 5, Current reward: 0.020321\n",
      "  Step 6, Current reward: 0.020321\n",
      "  Step 7, Current reward: 0.020321\n",
      "  Step 8, Current reward: 0.020321\n",
      "  Step 9, Current reward: 0.020321\n",
      "  Step 10, Current reward: 0.020321\n",
      "  Step 11, Current reward: 0.020321\n",
      "  Step 12, Current reward: 0.020321\n",
      "Episode 471/1000 complete - Max Reward: 0.020321\n",
      "Starting episode 472/1000\n",
      "  Step 1, Current reward: 0.103122\n",
      "  Step 2, Current reward: 0.103122\n",
      "  Step 3, Current reward: 0.103122\n",
      "  Step 4, Current reward: 0.103122\n",
      "  Step 5, Current reward: 0.103122\n",
      "  Step 6, Current reward: 0.103122\n",
      "  Step 7, Current reward: 0.103122\n",
      "  Step 8, Current reward: 0.103122\n",
      "  Step 9, Current reward: 0.103122\n",
      "  Step 10, Current reward: 0.103122\n",
      "  Step 11, Current reward: 0.103122\n",
      "  Step 12, Current reward: 0.103122\n",
      "Episode 472/1000 complete - Max Reward: 0.103122\n",
      "Starting episode 473/1000\n",
      "  Step 1, Current reward: 0.003670\n",
      "  Step 2, Current reward: 0.003670\n",
      "  Step 3, Current reward: 0.003670\n",
      "  Step 4, Current reward: 0.003670\n",
      "  Step 5, Current reward: 0.003670\n",
      "  Step 6, Current reward: 0.003670\n",
      "  Step 7, Current reward: 0.003670\n",
      "  Step 8, Current reward: 0.003670\n",
      "  Step 9, Current reward: 0.003670\n",
      "  Step 10, Current reward: 0.003670\n",
      "  Step 11, Current reward: 0.003670\n",
      "  Step 12, Current reward: 0.003670\n",
      "Episode 473/1000 complete - Max Reward: 0.003670\n",
      "Starting episode 474/1000\n",
      "  Step 1, Current reward: 0.013241\n",
      "  Step 2, Current reward: 0.013241\n",
      "  Step 3, Current reward: 0.013241\n",
      "  Step 4, Current reward: 0.013241\n",
      "  Step 5, Current reward: 0.013241\n",
      "  Step 6, Current reward: 0.013241\n",
      "  Step 7, Current reward: 0.013241\n",
      "  Step 8, Current reward: 0.013241\n",
      "  Step 9, Current reward: 0.013241\n",
      "  Step 10, Current reward: 0.013241\n",
      "  Step 11, Current reward: 0.013241\n",
      "  Step 12, Current reward: 0.013241\n",
      "Episode 474/1000 complete - Max Reward: 0.013241\n",
      "Starting episode 475/1000\n",
      "  Step 1, Current reward: 0.013702\n",
      "  Step 2, Current reward: 0.013702\n",
      "  Step 3, Current reward: 0.013702\n",
      "  Step 4, Current reward: 0.013702\n",
      "  Step 5, Current reward: 0.013702\n",
      "  Step 6, Current reward: 0.013702\n",
      "  Step 7, Current reward: 0.013702\n",
      "  Step 8, Current reward: 0.013702\n",
      "  Step 9, Current reward: 0.013702\n",
      "  Step 10, Current reward: 0.013702\n",
      "  Step 11, Current reward: 0.013702\n",
      "  Step 12, Current reward: 0.013702\n",
      "Episode 475/1000 complete - Max Reward: 0.013702\n",
      "Starting episode 476/1000\n",
      "  Step 1, Current reward: 0.025607\n",
      "  Step 2, Current reward: 0.025607\n",
      "  Step 3, Current reward: 0.025607\n",
      "  Step 4, Current reward: 0.025607\n",
      "  Step 5, Current reward: 0.025607\n",
      "  Step 6, Current reward: 0.025607\n",
      "  Step 7, Current reward: 0.025607\n",
      "  Step 8, Current reward: 0.025607\n",
      "  Step 9, Current reward: 0.025607\n",
      "  Step 10, Current reward: 0.025607\n",
      "  Step 11, Current reward: 0.025607\n",
      "  Step 12, Current reward: 0.025607\n",
      "Episode 476/1000 complete - Max Reward: 0.025607\n",
      "Starting episode 477/1000\n",
      "  Step 1, Current reward: 0.144453\n",
      "  Step 2, Current reward: 0.144453\n",
      "  Step 3, Current reward: 0.144453\n",
      "  Step 4, Current reward: 0.144453\n",
      "  Step 5, Current reward: 0.144453\n",
      "  Step 6, Current reward: 0.144453\n",
      "  Step 7, Current reward: 0.144453\n",
      "  Step 8, Current reward: 0.144453\n",
      "  Step 9, Current reward: 0.144453\n",
      "  Step 10, Current reward: 0.144453\n",
      "  Step 11, Current reward: 0.144453\n",
      "  Step 12, Current reward: 0.144453\n",
      "Episode 477/1000 complete - Max Reward: 0.144453\n",
      "Starting episode 478/1000\n",
      "  Step 1, Current reward: 0.028749\n",
      "  Step 2, Current reward: 0.028749\n",
      "  Step 3, Current reward: 0.028749\n",
      "  Step 4, Current reward: 0.028749\n",
      "  Step 5, Current reward: 0.028749\n",
      "  Step 6, Current reward: 0.028749\n",
      "  Step 7, Current reward: 0.028749\n",
      "  Step 8, Current reward: 0.028749\n",
      "  Step 9, Current reward: 0.028749\n",
      "  Step 10, Current reward: 0.028749\n",
      "  Step 11, Current reward: 0.028749\n",
      "  Step 12, Current reward: 0.028749\n",
      "Episode 478/1000 complete - Max Reward: 0.028749\n",
      "Starting episode 479/1000\n",
      "  Step 1, Current reward: 0.017785\n",
      "  Step 2, Current reward: 0.017785\n",
      "  Step 3, Current reward: 0.017785\n",
      "  Step 4, Current reward: 0.017785\n",
      "  Step 5, Current reward: 0.017785\n",
      "  Step 6, Current reward: 0.017785\n",
      "  Step 7, Current reward: 0.017785\n",
      "  Step 8, Current reward: 0.017785\n",
      "  Step 9, Current reward: 0.017785\n",
      "  Step 10, Current reward: 0.017785\n",
      "  Step 11, Current reward: 0.017785\n",
      "  Step 12, Current reward: 0.017785\n",
      "Episode 479/1000 complete - Max Reward: 0.017785\n",
      "Starting episode 480/1000\n",
      "  Step 1, Current reward: 0.035716\n",
      "  Step 2, Current reward: 0.035716\n",
      "  Step 3, Current reward: 0.035716\n",
      "  Step 4, Current reward: 0.035716\n",
      "  Step 5, Current reward: 0.035716\n",
      "  Step 6, Current reward: 0.035716\n",
      "  Step 7, Current reward: 0.035716\n",
      "  Step 8, Current reward: 0.035716\n",
      "  Step 9, Current reward: 0.035716\n",
      "  Step 10, Current reward: 0.035716\n",
      "  Step 11, Current reward: 0.035716\n",
      "  Step 12, Current reward: 0.035716\n",
      "Episode 480/1000 complete - Max Reward: 0.035716\n",
      "Starting episode 481/1000\n",
      "  Step 1, Current reward: 0.006170\n",
      "  Step 2, Current reward: 0.006170\n",
      "  Step 3, Current reward: 0.006170\n",
      "  Step 4, Current reward: 0.006170\n",
      "  Step 5, Current reward: 0.006170\n",
      "  Step 6, Current reward: 0.006170\n",
      "  Step 7, Current reward: 0.006170\n",
      "  Step 8, Current reward: 0.006170\n",
      "  Step 9, Current reward: 0.006170\n",
      "  Step 10, Current reward: 0.006170\n",
      "  Step 11, Current reward: 0.006170\n",
      "  Step 12, Current reward: 0.006170\n",
      "Episode 481/1000 complete - Max Reward: 0.006170\n",
      "Starting episode 482/1000\n",
      "  Step 1, Current reward: 0.050478\n",
      "  Step 2, Current reward: 0.050478\n",
      "  Step 3, Current reward: 0.050478\n",
      "  Step 4, Current reward: 0.050478\n",
      "  Step 5, Current reward: 0.050478\n",
      "  Step 6, Current reward: 0.050478\n",
      "  Step 7, Current reward: 0.050478\n",
      "  Step 8, Current reward: 0.050478\n",
      "  Step 9, Current reward: 0.050478\n",
      "  Step 10, Current reward: 0.050478\n",
      "  Step 11, Current reward: 0.050478\n",
      "  Step 12, Current reward: 0.050478\n",
      "Episode 482/1000 complete - Max Reward: 0.050478\n",
      "Starting episode 483/1000\n",
      "  Step 1, Current reward: 0.000712\n",
      "  Step 2, Current reward: 0.000731\n",
      "  Step 3, Current reward: 0.000750\n",
      "  Step 4, Current reward: 0.000772\n",
      "  Step 5, Current reward: 0.000800\n",
      "  Step 6, Current reward: 0.000834\n",
      "  Step 7, Current reward: 0.000864\n",
      "  Step 8, Current reward: 0.000888\n",
      "  Step 9, Current reward: 0.000909\n",
      "  Step 10, Current reward: 0.000927\n",
      "  Step 11, Current reward: 0.000941\n",
      "  Step 12, Current reward: 0.000953\n",
      "  Step 13, Current reward: 0.000963\n",
      "  Step 14, Current reward: 0.000968\n",
      "  Step 15, Current reward: 0.000964\n",
      "  Step 16, Current reward: 0.000956\n",
      "  Step 17, Current reward: 0.000942\n",
      "  Step 18, Current reward: 0.000923\n",
      "  Step 19, Current reward: 0.000900\n",
      "  Step 20, Current reward: 0.000874\n",
      "  Step 21, Current reward: 0.000845\n",
      "  Step 22, Current reward: 0.000815\n",
      "  Step 23, Current reward: 0.000782\n",
      "  Step 24, Current reward: 0.000748\n",
      "  Step 25, Current reward: 0.000714\n",
      "Episode 483/1000 complete - Max Reward: 0.000968\n",
      "Starting episode 484/1000\n",
      "  Step 1, Current reward: 0.000223\n",
      "  Step 2, Current reward: 0.000223\n",
      "  Step 3, Current reward: 0.000223\n",
      "  Step 4, Current reward: 0.000223\n",
      "  Step 5, Current reward: 0.000223\n",
      "  Step 6, Current reward: 0.000223\n",
      "  Step 7, Current reward: 0.000223\n",
      "  Step 8, Current reward: 0.000223\n",
      "  Step 9, Current reward: 0.000223\n",
      "  Step 10, Current reward: 0.000223\n",
      "  Step 11, Current reward: 0.000223\n",
      "  Step 12, Current reward: 0.000223\n",
      "Episode 484/1000 complete - Max Reward: 0.000223\n",
      "Starting episode 485/1000\n",
      "  Step 1, Current reward: 0.011630\n",
      "  Step 2, Current reward: 0.011630\n",
      "  Step 3, Current reward: 0.011630\n",
      "  Step 4, Current reward: 0.011630\n",
      "  Step 5, Current reward: 0.011630\n",
      "  Step 6, Current reward: 0.011630\n",
      "  Step 7, Current reward: 0.011630\n",
      "  Step 8, Current reward: 0.011630\n",
      "  Step 9, Current reward: 0.011630\n",
      "  Step 10, Current reward: 0.011630\n",
      "  Step 11, Current reward: 0.011630\n",
      "  Step 12, Current reward: 0.011630\n",
      "Episode 485/1000 complete - Max Reward: 0.011630\n",
      "Starting episode 486/1000\n",
      "  Step 1, Current reward: 0.020945\n",
      "  Step 2, Current reward: 0.020945\n",
      "  Step 3, Current reward: 0.020945\n",
      "  Step 4, Current reward: 0.020945\n",
      "  Step 5, Current reward: 0.020945\n",
      "  Step 6, Current reward: 0.020945\n",
      "  Step 7, Current reward: 0.020945\n",
      "  Step 8, Current reward: 0.020945\n",
      "  Step 9, Current reward: 0.020945\n",
      "  Step 10, Current reward: 0.020945\n",
      "  Step 11, Current reward: 0.020945\n",
      "  Step 12, Current reward: 0.020945\n",
      "Episode 486/1000 complete - Max Reward: 0.020945\n",
      "Starting episode 487/1000\n",
      "  Step 1, Current reward: 0.065649\n",
      "  Step 2, Current reward: 0.065649\n",
      "  Step 3, Current reward: 0.065649\n",
      "  Step 4, Current reward: 0.065649\n",
      "  Step 5, Current reward: 0.065649\n",
      "  Step 6, Current reward: 0.065649\n",
      "  Step 7, Current reward: 0.065649\n",
      "  Step 8, Current reward: 0.065649\n",
      "  Step 9, Current reward: 0.065649\n",
      "  Step 10, Current reward: 0.065649\n",
      "  Step 11, Current reward: 0.065649\n",
      "  Step 12, Current reward: 0.065649\n",
      "Episode 487/1000 complete - Max Reward: 0.065649\n",
      "Starting episode 488/1000\n",
      "  Step 1, Current reward: 0.042969\n",
      "  Step 2, Current reward: 0.042969\n",
      "  Step 3, Current reward: 0.042969\n",
      "  Step 4, Current reward: 0.042969\n",
      "  Step 5, Current reward: 0.042969\n",
      "  Step 6, Current reward: 0.042969\n",
      "  Step 7, Current reward: 0.042969\n",
      "  Step 8, Current reward: 0.042969\n",
      "  Step 9, Current reward: 0.042969\n",
      "  Step 10, Current reward: 0.042969\n",
      "  Step 11, Current reward: 0.042969\n",
      "  Step 12, Current reward: 0.042969\n",
      "Episode 488/1000 complete - Max Reward: 0.042969\n",
      "Starting episode 489/1000\n",
      "  Step 1, Current reward: 0.074533\n",
      "  Step 2, Current reward: 0.074533\n",
      "  Step 3, Current reward: 0.074533\n",
      "  Step 4, Current reward: 0.074533\n",
      "  Step 5, Current reward: 0.074533\n",
      "  Step 6, Current reward: 0.074533\n",
      "  Step 7, Current reward: 0.074533\n",
      "  Step 8, Current reward: 0.074533\n",
      "  Step 9, Current reward: 0.074533\n",
      "  Step 10, Current reward: 0.074533\n",
      "  Step 11, Current reward: 0.074533\n",
      "  Step 12, Current reward: 0.074533\n",
      "Episode 489/1000 complete - Max Reward: 0.074533\n",
      "Starting episode 490/1000\n",
      "  Step 1, Current reward: 0.046040\n",
      "  Step 2, Current reward: 0.046040\n",
      "  Step 3, Current reward: 0.046040\n",
      "  Step 4, Current reward: 0.046040\n",
      "  Step 5, Current reward: 0.046040\n",
      "  Step 6, Current reward: 0.046040\n",
      "  Step 7, Current reward: 0.046040\n",
      "  Step 8, Current reward: 0.046040\n",
      "  Step 9, Current reward: 0.046040\n",
      "  Step 10, Current reward: 0.046040\n",
      "  Step 11, Current reward: 0.046040\n",
      "  Step 12, Current reward: 0.046040\n",
      "Episode 490/1000 complete - Max Reward: 0.046040\n",
      "Starting episode 491/1000\n",
      "  Step 1, Current reward: 0.007142\n",
      "  Step 2, Current reward: 0.007142\n",
      "  Step 3, Current reward: 0.007142\n",
      "  Step 4, Current reward: 0.007142\n",
      "  Step 5, Current reward: 0.007142\n",
      "  Step 6, Current reward: 0.007142\n",
      "  Step 7, Current reward: 0.007142\n",
      "  Step 8, Current reward: 0.007142\n",
      "  Step 9, Current reward: 0.007142\n",
      "  Step 10, Current reward: 0.007142\n",
      "  Step 11, Current reward: 0.007142\n",
      "  Step 12, Current reward: 0.007142\n",
      "Episode 491/1000 complete - Max Reward: 0.007142\n",
      "Starting episode 492/1000\n",
      "  Step 1, Current reward: 0.010017\n",
      "  Step 2, Current reward: 0.010017\n",
      "  Step 3, Current reward: 0.010017\n",
      "  Step 4, Current reward: 0.010017\n",
      "  Step 5, Current reward: 0.010017\n",
      "  Step 6, Current reward: 0.010017\n",
      "  Step 7, Current reward: 0.010017\n",
      "  Step 8, Current reward: 0.010017\n",
      "  Step 9, Current reward: 0.010017\n",
      "  Step 10, Current reward: 0.010017\n",
      "  Step 11, Current reward: 0.010017\n",
      "  Step 12, Current reward: 0.010017\n",
      "Episode 492/1000 complete - Max Reward: 0.010017\n",
      "Starting episode 493/1000\n",
      "  Step 1, Current reward: 0.006771\n",
      "  Step 2, Current reward: 0.006771\n",
      "  Step 3, Current reward: 0.006771\n",
      "  Step 4, Current reward: 0.006771\n",
      "  Step 5, Current reward: 0.006771\n",
      "  Step 6, Current reward: 0.006771\n",
      "  Step 7, Current reward: 0.006771\n",
      "  Step 8, Current reward: 0.006771\n",
      "  Step 9, Current reward: 0.006771\n",
      "  Step 10, Current reward: 0.006771\n",
      "  Step 11, Current reward: 0.006771\n",
      "  Step 12, Current reward: 0.006771\n",
      "Episode 493/1000 complete - Max Reward: 0.006771\n",
      "Starting episode 494/1000\n",
      "  Step 1, Current reward: 0.033632\n",
      "  Step 2, Current reward: 0.033632\n",
      "  Step 3, Current reward: 0.033632\n",
      "  Step 4, Current reward: 0.033632\n",
      "  Step 5, Current reward: 0.033632\n",
      "  Step 6, Current reward: 0.033632\n",
      "  Step 7, Current reward: 0.033632\n",
      "  Step 8, Current reward: 0.033632\n",
      "  Step 9, Current reward: 0.033632\n",
      "  Step 10, Current reward: 0.033632\n",
      "  Step 11, Current reward: 0.033632\n",
      "  Step 12, Current reward: 0.033632\n",
      "Episode 494/1000 complete - Max Reward: 0.033632\n",
      "Starting episode 495/1000\n",
      "  Step 1, Current reward: 0.008612\n",
      "  Step 2, Current reward: 0.008612\n",
      "  Step 3, Current reward: 0.008612\n",
      "  Step 4, Current reward: 0.008612\n",
      "  Step 5, Current reward: 0.008612\n",
      "  Step 6, Current reward: 0.008612\n",
      "  Step 7, Current reward: 0.008612\n",
      "  Step 8, Current reward: 0.008612\n",
      "  Step 9, Current reward: 0.008612\n",
      "  Step 10, Current reward: 0.008612\n",
      "  Step 11, Current reward: 0.008612\n",
      "  Step 12, Current reward: 0.008612\n",
      "Episode 495/1000 complete - Max Reward: 0.008612\n",
      "Starting episode 496/1000\n",
      "  Step 1, Current reward: 0.046212\n",
      "  Step 2, Current reward: 0.046212\n",
      "  Step 3, Current reward: 0.046212\n",
      "  Step 4, Current reward: 0.046212\n",
      "  Step 5, Current reward: 0.046212\n",
      "  Step 6, Current reward: 0.046212\n",
      "  Step 7, Current reward: 0.046212\n",
      "  Step 8, Current reward: 0.046212\n",
      "  Step 9, Current reward: 0.046212\n",
      "  Step 10, Current reward: 0.046212\n",
      "  Step 11, Current reward: 0.046212\n",
      "  Step 12, Current reward: 0.046212\n",
      "Episode 496/1000 complete - Max Reward: 0.046212\n",
      "Starting episode 497/1000\n",
      "  Step 1, Current reward: 0.001335\n",
      "  Step 2, Current reward: 0.001335\n",
      "  Step 3, Current reward: 0.001335\n",
      "  Step 4, Current reward: 0.001335\n",
      "  Step 5, Current reward: 0.001335\n",
      "  Step 6, Current reward: 0.001335\n",
      "  Step 7, Current reward: 0.001335\n",
      "  Step 8, Current reward: 0.001335\n",
      "  Step 9, Current reward: 0.001335\n",
      "  Step 10, Current reward: 0.001335\n",
      "  Step 11, Current reward: 0.001335\n",
      "  Step 12, Current reward: 0.001335\n",
      "Episode 497/1000 complete - Max Reward: 0.001335\n",
      "Starting episode 498/1000\n",
      "  Step 1, Current reward: 0.006697\n",
      "  Step 2, Current reward: 0.006697\n",
      "  Step 3, Current reward: 0.006697\n",
      "  Step 4, Current reward: 0.006697\n",
      "  Step 5, Current reward: 0.006697\n",
      "  Step 6, Current reward: 0.006697\n",
      "  Step 7, Current reward: 0.006697\n",
      "  Step 8, Current reward: 0.006697\n",
      "  Step 9, Current reward: 0.006697\n",
      "  Step 10, Current reward: 0.006697\n",
      "  Step 11, Current reward: 0.006697\n",
      "  Step 12, Current reward: 0.006697\n",
      "Episode 498/1000 complete - Max Reward: 0.006697\n",
      "Starting episode 499/1000\n",
      "  Step 1, Current reward: 0.012057\n",
      "  Step 2, Current reward: 0.012057\n",
      "  Step 3, Current reward: 0.012057\n",
      "  Step 4, Current reward: 0.012057\n",
      "  Step 5, Current reward: 0.012057\n",
      "  Step 6, Current reward: 0.012057\n",
      "  Step 7, Current reward: 0.012057\n",
      "  Step 8, Current reward: 0.012057\n",
      "  Step 9, Current reward: 0.012057\n",
      "  Step 10, Current reward: 0.012057\n",
      "  Step 11, Current reward: 0.012057\n",
      "  Step 12, Current reward: 0.012057\n",
      "Episode 499/1000 complete - Max Reward: 0.012057\n",
      "Starting episode 500/1000\n",
      "  Step 1, Current reward: 0.005137\n",
      "  Step 2, Current reward: 0.005137\n",
      "  Step 3, Current reward: 0.005137\n",
      "  Step 4, Current reward: 0.005137\n",
      "  Step 5, Current reward: 0.005137\n",
      "  Step 6, Current reward: 0.005137\n",
      "  Step 7, Current reward: 0.005137\n",
      "  Step 8, Current reward: 0.005137\n",
      "  Step 9, Current reward: 0.005137\n",
      "  Step 10, Current reward: 0.005137\n",
      "  Step 11, Current reward: 0.005137\n",
      "  Step 12, Current reward: 0.005137\n",
      "Episode 500/1000 complete - Max Reward: 0.005137\n",
      "Starting episode 501/1000\n",
      "  Step 1, Current reward: 0.007854\n",
      "  Step 2, Current reward: 0.007854\n",
      "  Step 3, Current reward: 0.007854\n",
      "  Step 4, Current reward: 0.007854\n",
      "  Step 5, Current reward: 0.007854\n",
      "  Step 6, Current reward: 0.007854\n",
      "  Step 7, Current reward: 0.007854\n",
      "  Step 8, Current reward: 0.007854\n",
      "  Step 9, Current reward: 0.007854\n",
      "  Step 10, Current reward: 0.007854\n",
      "  Step 11, Current reward: 0.007854\n",
      "  Step 12, Current reward: 0.007854\n",
      "Episode 501/1000 complete - Max Reward: 0.007854\n",
      "Starting episode 502/1000\n",
      "  Step 1, Current reward: 0.000674\n",
      "  Step 2, Current reward: 0.000674\n",
      "  Step 3, Current reward: 0.000674\n",
      "  Step 4, Current reward: 0.000674\n",
      "  Step 5, Current reward: 0.000674\n",
      "  Step 6, Current reward: 0.000674\n",
      "  Step 7, Current reward: 0.000674\n",
      "  Step 8, Current reward: 0.000674\n",
      "  Step 9, Current reward: 0.000674\n",
      "  Step 10, Current reward: 0.000674\n",
      "  Step 11, Current reward: 0.000674\n",
      "  Step 12, Current reward: 0.000674\n",
      "Episode 502/1000 complete - Max Reward: 0.000674\n",
      "Starting episode 503/1000\n",
      "  Step 1, Current reward: 0.013372\n",
      "  Step 2, Current reward: 0.013372\n",
      "  Step 3, Current reward: 0.013372\n",
      "  Step 4, Current reward: 0.013372\n",
      "  Step 5, Current reward: 0.013372\n",
      "  Step 6, Current reward: 0.013372\n",
      "  Step 7, Current reward: 0.013372\n",
      "  Step 8, Current reward: 0.013372\n",
      "  Step 9, Current reward: 0.013372\n",
      "  Step 10, Current reward: 0.013372\n",
      "  Step 11, Current reward: 0.013372\n",
      "  Step 12, Current reward: 0.013372\n",
      "Episode 503/1000 complete - Max Reward: 0.013372\n",
      "Starting episode 504/1000\n",
      "  Step 1, Current reward: 0.007198\n",
      "  Step 2, Current reward: 0.007198\n",
      "  Step 3, Current reward: 0.007198\n",
      "  Step 4, Current reward: 0.007198\n",
      "  Step 5, Current reward: 0.007198\n",
      "  Step 6, Current reward: 0.007198\n",
      "  Step 7, Current reward: 0.007198\n",
      "  Step 8, Current reward: 0.007198\n",
      "  Step 9, Current reward: 0.007198\n",
      "  Step 10, Current reward: 0.007198\n",
      "  Step 11, Current reward: 0.007198\n",
      "  Step 12, Current reward: 0.007198\n",
      "Episode 504/1000 complete - Max Reward: 0.007198\n",
      "Starting episode 505/1000\n",
      "  Step 1, Current reward: 0.090295\n",
      "  Step 2, Current reward: 0.090295\n",
      "  Step 3, Current reward: 0.090295\n",
      "  Step 4, Current reward: 0.090295\n",
      "  Step 5, Current reward: 0.090295\n",
      "  Step 6, Current reward: 0.090295\n",
      "  Step 7, Current reward: 0.090295\n",
      "  Step 8, Current reward: 0.090295\n",
      "  Step 9, Current reward: 0.090295\n",
      "  Step 10, Current reward: 0.090295\n",
      "  Step 11, Current reward: 0.090295\n",
      "  Step 12, Current reward: 0.090295\n",
      "Episode 505/1000 complete - Max Reward: 0.090295\n",
      "Starting episode 506/1000\n",
      "  Step 1, Current reward: 0.025133\n",
      "  Step 2, Current reward: 0.025133\n",
      "  Step 3, Current reward: 0.025133\n",
      "  Step 4, Current reward: 0.025133\n",
      "  Step 5, Current reward: 0.025133\n",
      "  Step 6, Current reward: 0.025133\n",
      "  Step 7, Current reward: 0.025133\n",
      "  Step 8, Current reward: 0.025133\n",
      "  Step 9, Current reward: 0.025133\n",
      "  Step 10, Current reward: 0.025133\n",
      "  Step 11, Current reward: 0.025133\n",
      "  Step 12, Current reward: 0.025133\n",
      "Episode 506/1000 complete - Max Reward: 0.025133\n",
      "Starting episode 507/1000\n",
      "  Step 1, Current reward: 0.153066\n",
      "  Step 2, Current reward: 0.153066\n",
      "  Step 3, Current reward: 0.153066\n",
      "  Step 4, Current reward: 0.153066\n",
      "  Step 5, Current reward: 0.153066\n",
      "  Step 6, Current reward: 0.153066\n",
      "  Step 7, Current reward: 0.153066\n",
      "  Step 8, Current reward: 0.153066\n",
      "  Step 9, Current reward: 0.153066\n",
      "  Step 10, Current reward: 0.153066\n",
      "  Step 11, Current reward: 0.153066\n",
      "  Step 12, Current reward: 0.153066\n",
      "Episode 507/1000 complete - Max Reward: 0.153066\n",
      "Starting episode 508/1000\n",
      "  Step 1, Current reward: 0.021898\n",
      "  Step 2, Current reward: 0.021898\n",
      "  Step 3, Current reward: 0.021898\n",
      "  Step 4, Current reward: 0.021898\n",
      "  Step 5, Current reward: 0.021898\n",
      "  Step 6, Current reward: 0.021898\n",
      "  Step 7, Current reward: 0.021898\n",
      "  Step 8, Current reward: 0.021898\n",
      "  Step 9, Current reward: 0.021898\n",
      "  Step 10, Current reward: 0.021898\n",
      "  Step 11, Current reward: 0.021898\n",
      "  Step 12, Current reward: 0.021898\n",
      "Episode 508/1000 complete - Max Reward: 0.021898\n",
      "Starting episode 509/1000\n",
      "  Step 1, Current reward: 0.005823\n",
      "  Step 2, Current reward: 0.005823\n",
      "  Step 3, Current reward: 0.005823\n",
      "  Step 4, Current reward: 0.005823\n",
      "  Step 5, Current reward: 0.005823\n",
      "  Step 6, Current reward: 0.005823\n",
      "  Step 7, Current reward: 0.005823\n",
      "  Step 8, Current reward: 0.005823\n",
      "  Step 9, Current reward: 0.005823\n",
      "  Step 10, Current reward: 0.005823\n",
      "  Step 11, Current reward: 0.005823\n",
      "  Step 12, Current reward: 0.005823\n",
      "Episode 509/1000 complete - Max Reward: 0.005823\n",
      "Starting episode 510/1000\n",
      "  Step 1, Current reward: 0.049040\n",
      "  Step 2, Current reward: 0.049040\n",
      "  Step 3, Current reward: 0.049040\n",
      "  Step 4, Current reward: 0.049040\n",
      "  Step 5, Current reward: 0.049040\n",
      "  Step 6, Current reward: 0.049040\n",
      "  Step 7, Current reward: 0.049040\n",
      "  Step 8, Current reward: 0.049040\n",
      "  Step 9, Current reward: 0.049040\n",
      "  Step 10, Current reward: 0.049040\n",
      "  Step 11, Current reward: 0.049040\n",
      "  Step 12, Current reward: 0.049040\n",
      "Episode 510/1000 complete - Max Reward: 0.049040\n",
      "Starting episode 511/1000\n",
      "  Step 1, Current reward: 0.039475\n",
      "  Step 2, Current reward: 0.039475\n",
      "  Step 3, Current reward: 0.039475\n",
      "  Step 4, Current reward: 0.039475\n",
      "  Step 5, Current reward: 0.039475\n",
      "  Step 6, Current reward: 0.039475\n",
      "  Step 7, Current reward: 0.039475\n",
      "  Step 8, Current reward: 0.039475\n",
      "  Step 9, Current reward: 0.039475\n",
      "  Step 10, Current reward: 0.039475\n",
      "  Step 11, Current reward: 0.039475\n",
      "  Step 12, Current reward: 0.039475\n",
      "Episode 511/1000 complete - Max Reward: 0.039475\n",
      "Starting episode 512/1000\n",
      "  Step 1, Current reward: 0.012442\n",
      "  Step 2, Current reward: 0.012442\n",
      "  Step 3, Current reward: 0.012442\n",
      "  Step 4, Current reward: 0.012442\n",
      "  Step 5, Current reward: 0.012442\n",
      "  Step 6, Current reward: 0.012442\n",
      "  Step 7, Current reward: 0.012442\n",
      "  Step 8, Current reward: 0.012442\n",
      "  Step 9, Current reward: 0.012442\n",
      "  Step 10, Current reward: 0.012442\n",
      "  Step 11, Current reward: 0.012442\n",
      "  Step 12, Current reward: 0.012442\n",
      "Episode 512/1000 complete - Max Reward: 0.012442\n",
      "Starting episode 513/1000\n",
      "  Step 1, Current reward: 0.000391\n",
      "  Step 2, Current reward: 0.000391\n",
      "  Step 3, Current reward: 0.000391\n",
      "  Step 4, Current reward: 0.000391\n",
      "  Step 5, Current reward: 0.000391\n",
      "  Step 6, Current reward: 0.000391\n",
      "  Step 7, Current reward: 0.000391\n",
      "  Step 8, Current reward: 0.000391\n",
      "  Step 9, Current reward: 0.000391\n",
      "  Step 10, Current reward: 0.000391\n",
      "  Step 11, Current reward: 0.000391\n",
      "  Step 12, Current reward: 0.000391\n",
      "Episode 513/1000 complete - Max Reward: 0.000391\n",
      "Starting episode 514/1000\n",
      "  Step 1, Current reward: 0.010133\n",
      "  Step 2, Current reward: 0.010133\n",
      "  Step 3, Current reward: 0.010133\n",
      "  Step 4, Current reward: 0.010133\n",
      "  Step 5, Current reward: 0.010133\n",
      "  Step 6, Current reward: 0.010133\n",
      "  Step 7, Current reward: 0.010133\n",
      "  Step 8, Current reward: 0.010133\n",
      "  Step 9, Current reward: 0.010133\n",
      "  Step 10, Current reward: 0.010133\n",
      "  Step 11, Current reward: 0.010133\n",
      "  Step 12, Current reward: 0.010133\n",
      "Episode 514/1000 complete - Max Reward: 0.010133\n",
      "Starting episode 515/1000\n",
      "  Step 1, Current reward: 0.107909\n",
      "  Step 2, Current reward: 0.107909\n",
      "  Step 3, Current reward: 0.107909\n",
      "  Step 4, Current reward: 0.107909\n",
      "  Step 5, Current reward: 0.107909\n",
      "  Step 6, Current reward: 0.107909\n",
      "  Step 7, Current reward: 0.107909\n",
      "  Step 8, Current reward: 0.107909\n",
      "  Step 9, Current reward: 0.107909\n",
      "  Step 10, Current reward: 0.107909\n",
      "  Step 11, Current reward: 0.107909\n",
      "  Step 12, Current reward: 0.107909\n",
      "Episode 515/1000 complete - Max Reward: 0.107909\n",
      "Starting episode 516/1000\n",
      "  Step 1, Current reward: 0.055786\n",
      "  Step 2, Current reward: 0.055786\n",
      "  Step 3, Current reward: 0.055786\n",
      "  Step 4, Current reward: 0.055786\n",
      "  Step 5, Current reward: 0.055786\n",
      "  Step 6, Current reward: 0.055786\n",
      "  Step 7, Current reward: 0.055786\n",
      "  Step 8, Current reward: 0.055786\n",
      "  Step 9, Current reward: 0.055786\n",
      "  Step 10, Current reward: 0.055786\n",
      "  Step 11, Current reward: 0.055786\n",
      "  Step 12, Current reward: 0.055786\n",
      "Episode 516/1000 complete - Max Reward: 0.055786\n",
      "Starting episode 517/1000\n",
      "  Step 1, Current reward: 0.123480\n",
      "  Step 2, Current reward: 0.123480\n",
      "  Step 3, Current reward: 0.123480\n",
      "  Step 4, Current reward: 0.123480\n",
      "  Step 5, Current reward: 0.123480\n",
      "  Step 6, Current reward: 0.123480\n",
      "  Step 7, Current reward: 0.123480\n",
      "  Step 8, Current reward: 0.123480\n",
      "  Step 9, Current reward: 0.123480\n",
      "  Step 10, Current reward: 0.123480\n",
      "  Step 11, Current reward: 0.123480\n",
      "  Step 12, Current reward: 0.123480\n",
      "Episode 517/1000 complete - Max Reward: 0.123480\n",
      "Starting episode 518/1000\n",
      "  Step 1, Current reward: 0.000871\n",
      "  Step 2, Current reward: 0.000883\n",
      "  Step 3, Current reward: 0.000883\n",
      "  Step 4, Current reward: 0.000883\n",
      "  Step 5, Current reward: 0.000883\n",
      "  Step 6, Current reward: 0.000883\n",
      "  Step 7, Current reward: 0.000883\n",
      "  Step 8, Current reward: 0.000883\n",
      "  Step 9, Current reward: 0.000883\n",
      "  Step 10, Current reward: 0.000883\n",
      "  Step 11, Current reward: 0.000883\n",
      "  Step 12, Current reward: 0.000883\n",
      "  Step 13, Current reward: 0.000883\n",
      "Episode 518/1000 complete - Max Reward: 0.000883\n",
      "Starting episode 519/1000\n",
      "  Step 1, Current reward: 0.000326\n",
      "  Step 2, Current reward: 0.000326\n",
      "  Step 3, Current reward: 0.000326\n",
      "  Step 4, Current reward: 0.000326\n",
      "  Step 5, Current reward: 0.000326\n",
      "  Step 6, Current reward: 0.000326\n",
      "  Step 7, Current reward: 0.000326\n",
      "  Step 8, Current reward: 0.000326\n",
      "  Step 9, Current reward: 0.000326\n",
      "  Step 10, Current reward: 0.000326\n",
      "  Step 11, Current reward: 0.000326\n",
      "  Step 12, Current reward: 0.000326\n",
      "Episode 519/1000 complete - Max Reward: 0.000326\n",
      "Starting episode 520/1000\n",
      "  Step 1, Current reward: 0.003485\n",
      "  Step 2, Current reward: 0.003485\n",
      "  Step 3, Current reward: 0.003485\n",
      "  Step 4, Current reward: 0.003485\n",
      "  Step 5, Current reward: 0.003485\n",
      "  Step 6, Current reward: 0.003485\n",
      "  Step 7, Current reward: 0.003485\n",
      "  Step 8, Current reward: 0.003485\n",
      "  Step 9, Current reward: 0.003485\n",
      "  Step 10, Current reward: 0.003485\n",
      "  Step 11, Current reward: 0.003485\n",
      "  Step 12, Current reward: 0.003485\n",
      "Episode 520/1000 complete - Max Reward: 0.003485\n",
      "Starting episode 521/1000\n",
      "  Step 1, Current reward: 0.017632\n",
      "  Step 2, Current reward: 0.017632\n",
      "  Step 3, Current reward: 0.017632\n",
      "  Step 4, Current reward: 0.017632\n",
      "  Step 5, Current reward: 0.017632\n",
      "  Step 6, Current reward: 0.017632\n",
      "  Step 7, Current reward: 0.017632\n",
      "  Step 8, Current reward: 0.017632\n",
      "  Step 9, Current reward: 0.017632\n",
      "  Step 10, Current reward: 0.017632\n",
      "  Step 11, Current reward: 0.017632\n",
      "  Step 12, Current reward: 0.017632\n",
      "Episode 521/1000 complete - Max Reward: 0.017632\n",
      "Starting episode 522/1000\n",
      "  Step 1, Current reward: 0.056914\n",
      "  Step 2, Current reward: 0.056914\n",
      "  Step 3, Current reward: 0.056914\n",
      "  Step 4, Current reward: 0.056914\n",
      "  Step 5, Current reward: 0.056914\n",
      "  Step 6, Current reward: 0.056914\n",
      "  Step 7, Current reward: 0.056914\n",
      "  Step 8, Current reward: 0.056914\n",
      "  Step 9, Current reward: 0.056914\n",
      "  Step 10, Current reward: 0.056914\n",
      "  Step 11, Current reward: 0.056914\n",
      "  Step 12, Current reward: 0.056914\n",
      "Episode 522/1000 complete - Max Reward: 0.056914\n",
      "Starting episode 523/1000\n",
      "  Step 1, Current reward: 0.004884\n",
      "  Step 2, Current reward: 0.004884\n",
      "  Step 3, Current reward: 0.004884\n",
      "  Step 4, Current reward: 0.004884\n",
      "  Step 5, Current reward: 0.004884\n",
      "  Step 6, Current reward: 0.004884\n",
      "  Step 7, Current reward: 0.004884\n",
      "  Step 8, Current reward: 0.004884\n",
      "  Step 9, Current reward: 0.004884\n",
      "  Step 10, Current reward: 0.004884\n",
      "  Step 11, Current reward: 0.004884\n",
      "  Step 12, Current reward: 0.004884\n",
      "Episode 523/1000 complete - Max Reward: 0.004884\n",
      "Starting episode 524/1000\n",
      "  Step 1, Current reward: 0.015605\n",
      "  Step 2, Current reward: 0.015605\n",
      "  Step 3, Current reward: 0.015605\n",
      "  Step 4, Current reward: 0.015605\n",
      "  Step 5, Current reward: 0.015605\n",
      "  Step 6, Current reward: 0.015605\n",
      "  Step 7, Current reward: 0.015605\n",
      "  Step 8, Current reward: 0.015605\n",
      "  Step 9, Current reward: 0.015605\n",
      "  Step 10, Current reward: 0.015605\n",
      "  Step 11, Current reward: 0.015605\n",
      "  Step 12, Current reward: 0.015605\n",
      "Episode 524/1000 complete - Max Reward: 0.015605\n",
      "Starting episode 525/1000\n",
      "  Step 1, Current reward: 0.032085\n",
      "  Step 2, Current reward: 0.032085\n",
      "  Step 3, Current reward: 0.032085\n",
      "  Step 4, Current reward: 0.032085\n",
      "  Step 5, Current reward: 0.032085\n",
      "  Step 6, Current reward: 0.032085\n",
      "  Step 7, Current reward: 0.032085\n",
      "  Step 8, Current reward: 0.032085\n",
      "  Step 9, Current reward: 0.032085\n",
      "  Step 10, Current reward: 0.032085\n",
      "  Step 11, Current reward: 0.032085\n",
      "  Step 12, Current reward: 0.032085\n",
      "Episode 525/1000 complete - Max Reward: 0.032085\n",
      "Starting episode 526/1000\n",
      "  Step 1, Current reward: 0.011405\n",
      "  Step 2, Current reward: 0.011405\n",
      "  Step 3, Current reward: 0.011405\n",
      "  Step 4, Current reward: 0.011405\n",
      "  Step 5, Current reward: 0.011405\n",
      "  Step 6, Current reward: 0.011405\n",
      "  Step 7, Current reward: 0.011405\n",
      "  Step 8, Current reward: 0.011405\n",
      "  Step 9, Current reward: 0.011405\n",
      "  Step 10, Current reward: 0.011405\n",
      "  Step 11, Current reward: 0.011405\n",
      "  Step 12, Current reward: 0.011405\n",
      "Episode 526/1000 complete - Max Reward: 0.011405\n",
      "Starting episode 527/1000\n",
      "  Step 1, Current reward: 0.070543\n",
      "  Step 2, Current reward: 0.070543\n",
      "  Step 3, Current reward: 0.070543\n",
      "  Step 4, Current reward: 0.070543\n",
      "  Step 5, Current reward: 0.070543\n",
      "  Step 6, Current reward: 0.070543\n",
      "  Step 7, Current reward: 0.070543\n",
      "  Step 8, Current reward: 0.070543\n",
      "  Step 9, Current reward: 0.070543\n",
      "  Step 10, Current reward: 0.070543\n",
      "  Step 11, Current reward: 0.070543\n",
      "  Step 12, Current reward: 0.070543\n",
      "Episode 527/1000 complete - Max Reward: 0.070543\n",
      "Starting episode 528/1000\n",
      "  Step 1, Current reward: 0.000466\n",
      "  Step 2, Current reward: 0.000466\n",
      "  Step 3, Current reward: 0.000466\n",
      "  Step 4, Current reward: 0.000466\n",
      "  Step 5, Current reward: 0.000466\n",
      "  Step 6, Current reward: 0.000466\n",
      "  Step 7, Current reward: 0.000466\n",
      "  Step 8, Current reward: 0.000466\n",
      "  Step 9, Current reward: 0.000466\n",
      "  Step 10, Current reward: 0.000466\n",
      "  Step 11, Current reward: 0.000466\n",
      "  Step 12, Current reward: 0.000466\n",
      "Episode 528/1000 complete - Max Reward: 0.000466\n",
      "Starting episode 529/1000\n",
      "  Step 1, Current reward: 0.020890\n",
      "  Step 2, Current reward: 0.020890\n",
      "  Step 3, Current reward: 0.020890\n",
      "  Step 4, Current reward: 0.020890\n",
      "  Step 5, Current reward: 0.020890\n",
      "  Step 6, Current reward: 0.020890\n",
      "  Step 7, Current reward: 0.020890\n",
      "  Step 8, Current reward: 0.020890\n",
      "  Step 9, Current reward: 0.020890\n",
      "  Step 10, Current reward: 0.020890\n",
      "  Step 11, Current reward: 0.020890\n",
      "  Step 12, Current reward: 0.020890\n",
      "Episode 529/1000 complete - Max Reward: 0.020890\n",
      "Starting episode 530/1000\n",
      "  Step 1, Current reward: 0.004933\n",
      "  Step 2, Current reward: 0.004933\n",
      "  Step 3, Current reward: 0.004933\n",
      "  Step 4, Current reward: 0.004933\n",
      "  Step 5, Current reward: 0.004933\n",
      "  Step 6, Current reward: 0.004933\n",
      "  Step 7, Current reward: 0.004933\n",
      "  Step 8, Current reward: 0.004933\n",
      "  Step 9, Current reward: 0.004933\n",
      "  Step 10, Current reward: 0.004933\n",
      "  Step 11, Current reward: 0.004933\n",
      "  Step 12, Current reward: 0.004933\n",
      "Episode 530/1000 complete - Max Reward: 0.004933\n",
      "Starting episode 531/1000\n",
      "  Step 1, Current reward: 0.001341\n",
      "  Step 2, Current reward: 0.001341\n",
      "  Step 3, Current reward: 0.001341\n",
      "  Step 4, Current reward: 0.001341\n",
      "  Step 5, Current reward: 0.001341\n",
      "  Step 6, Current reward: 0.001341\n",
      "  Step 7, Current reward: 0.001341\n",
      "  Step 8, Current reward: 0.001341\n",
      "  Step 9, Current reward: 0.001341\n",
      "  Step 10, Current reward: 0.001341\n",
      "  Step 11, Current reward: 0.001341\n",
      "  Step 12, Current reward: 0.001341\n",
      "Episode 531/1000 complete - Max Reward: 0.001341\n",
      "Starting episode 532/1000\n",
      "  Step 1, Current reward: 0.060902\n",
      "  Step 2, Current reward: 0.060902\n",
      "  Step 3, Current reward: 0.060902\n",
      "  Step 4, Current reward: 0.060902\n",
      "  Step 5, Current reward: 0.060902\n",
      "  Step 6, Current reward: 0.060902\n",
      "  Step 7, Current reward: 0.060902\n",
      "  Step 8, Current reward: 0.060902\n",
      "  Step 9, Current reward: 0.060902\n",
      "  Step 10, Current reward: 0.060902\n",
      "  Step 11, Current reward: 0.060902\n",
      "  Step 12, Current reward: 0.060902\n",
      "Episode 532/1000 complete - Max Reward: 0.060902\n",
      "Starting episode 533/1000\n",
      "  Step 1, Current reward: 0.032496\n",
      "  Step 2, Current reward: 0.032496\n",
      "  Step 3, Current reward: 0.032496\n",
      "  Step 4, Current reward: 0.032496\n",
      "  Step 5, Current reward: 0.032496\n",
      "  Step 6, Current reward: 0.032496\n",
      "  Step 7, Current reward: 0.032496\n",
      "  Step 8, Current reward: 0.032496\n",
      "  Step 9, Current reward: 0.032496\n",
      "  Step 10, Current reward: 0.032496\n",
      "  Step 11, Current reward: 0.032496\n",
      "  Step 12, Current reward: 0.032496\n",
      "Episode 533/1000 complete - Max Reward: 0.032496\n",
      "Starting episode 534/1000\n",
      "  Step 1, Current reward: 0.021599\n",
      "  Step 2, Current reward: 0.021599\n",
      "  Step 3, Current reward: 0.021599\n",
      "  Step 4, Current reward: 0.021599\n",
      "  Step 5, Current reward: 0.021599\n",
      "  Step 6, Current reward: 0.021599\n",
      "  Step 7, Current reward: 0.021599\n",
      "  Step 8, Current reward: 0.021599\n",
      "  Step 9, Current reward: 0.021599\n",
      "  Step 10, Current reward: 0.021599\n",
      "  Step 11, Current reward: 0.021599\n",
      "  Step 12, Current reward: 0.021599\n",
      "Episode 534/1000 complete - Max Reward: 0.021599\n",
      "Starting episode 535/1000\n",
      "  Step 1, Current reward: 0.054992\n",
      "  Step 2, Current reward: 0.054992\n",
      "  Step 3, Current reward: 0.054992\n",
      "  Step 4, Current reward: 0.054992\n",
      "  Step 5, Current reward: 0.054992\n",
      "  Step 6, Current reward: 0.054992\n",
      "  Step 7, Current reward: 0.054992\n",
      "  Step 8, Current reward: 0.054992\n",
      "  Step 9, Current reward: 0.054992\n",
      "  Step 10, Current reward: 0.054992\n",
      "  Step 11, Current reward: 0.054992\n",
      "  Step 12, Current reward: 0.054992\n",
      "Episode 535/1000 complete - Max Reward: 0.054992\n",
      "Starting episode 536/1000\n",
      "  Step 1, Current reward: 0.273574\n",
      "  Step 2, Current reward: 0.273574\n",
      "  Step 3, Current reward: 0.273574\n",
      "  Step 4, Current reward: 0.273574\n",
      "  Step 5, Current reward: 0.273574\n",
      "  Step 6, Current reward: 0.273574\n",
      "  Step 7, Current reward: 0.273574\n",
      "  Step 8, Current reward: 0.273574\n",
      "  Step 9, Current reward: 0.273574\n",
      "  Step 10, Current reward: 0.273574\n",
      "  Step 11, Current reward: 0.273574\n",
      "  Step 12, Current reward: 0.273574\n",
      "Episode 536/1000 complete - Max Reward: 0.273574\n",
      "Starting episode 537/1000\n",
      "  Step 1, Current reward: 0.003719\n",
      "  Step 2, Current reward: 0.003719\n",
      "  Step 3, Current reward: 0.003719\n",
      "  Step 4, Current reward: 0.003719\n",
      "  Step 5, Current reward: 0.003719\n",
      "  Step 6, Current reward: 0.003719\n",
      "  Step 7, Current reward: 0.003719\n",
      "  Step 8, Current reward: 0.003719\n",
      "  Step 9, Current reward: 0.003719\n",
      "  Step 10, Current reward: 0.003719\n",
      "  Step 11, Current reward: 0.003719\n",
      "  Step 12, Current reward: 0.003719\n",
      "Episode 537/1000 complete - Max Reward: 0.003719\n",
      "Starting episode 538/1000\n",
      "  Step 1, Current reward: 0.028774\n",
      "  Step 2, Current reward: 0.028774\n",
      "  Step 3, Current reward: 0.028774\n",
      "  Step 4, Current reward: 0.028774\n",
      "  Step 5, Current reward: 0.028774\n",
      "  Step 6, Current reward: 0.028774\n",
      "  Step 7, Current reward: 0.028774\n",
      "  Step 8, Current reward: 0.028774\n",
      "  Step 9, Current reward: 0.028774\n",
      "  Step 10, Current reward: 0.028774\n",
      "  Step 11, Current reward: 0.028774\n",
      "  Step 12, Current reward: 0.028774\n",
      "Episode 538/1000 complete - Max Reward: 0.028774\n",
      "Starting episode 539/1000\n",
      "  Step 1, Current reward: 0.041756\n",
      "  Step 2, Current reward: 0.041756\n",
      "  Step 3, Current reward: 0.041756\n",
      "  Step 4, Current reward: 0.041756\n",
      "  Step 5, Current reward: 0.041756\n",
      "  Step 6, Current reward: 0.041756\n",
      "  Step 7, Current reward: 0.041756\n",
      "  Step 8, Current reward: 0.041756\n",
      "  Step 9, Current reward: 0.041756\n",
      "  Step 10, Current reward: 0.041756\n",
      "  Step 11, Current reward: 0.041756\n",
      "  Step 12, Current reward: 0.041756\n",
      "Episode 539/1000 complete - Max Reward: 0.041756\n",
      "Starting episode 540/1000\n",
      "  Step 1, Current reward: 0.002619\n",
      "  Step 2, Current reward: 0.002619\n",
      "  Step 3, Current reward: 0.002619\n",
      "  Step 4, Current reward: 0.002619\n",
      "  Step 5, Current reward: 0.002619\n",
      "  Step 6, Current reward: 0.002619\n",
      "  Step 7, Current reward: 0.002619\n",
      "  Step 8, Current reward: 0.002619\n",
      "  Step 9, Current reward: 0.002619\n",
      "  Step 10, Current reward: 0.002619\n",
      "  Step 11, Current reward: 0.002619\n",
      "  Step 12, Current reward: 0.002619\n",
      "Episode 540/1000 complete - Max Reward: 0.002619\n",
      "Starting episode 541/1000\n",
      "  Step 1, Current reward: 0.042285\n",
      "  Step 2, Current reward: 0.042285\n",
      "  Step 3, Current reward: 0.042285\n",
      "  Step 4, Current reward: 0.042285\n",
      "  Step 5, Current reward: 0.042285\n",
      "  Step 6, Current reward: 0.042285\n",
      "  Step 7, Current reward: 0.042285\n",
      "  Step 8, Current reward: 0.042285\n",
      "  Step 9, Current reward: 0.042285\n",
      "  Step 10, Current reward: 0.042285\n",
      "  Step 11, Current reward: 0.042285\n",
      "  Step 12, Current reward: 0.042285\n",
      "Episode 541/1000 complete - Max Reward: 0.042285\n",
      "Starting episode 542/1000\n",
      "  Step 1, Current reward: 0.021635\n",
      "  Step 2, Current reward: 0.021635\n",
      "  Step 3, Current reward: 0.021635\n",
      "  Step 4, Current reward: 0.021635\n",
      "  Step 5, Current reward: 0.021635\n",
      "  Step 6, Current reward: 0.021635\n",
      "  Step 7, Current reward: 0.021635\n",
      "  Step 8, Current reward: 0.021635\n",
      "  Step 9, Current reward: 0.021635\n",
      "  Step 10, Current reward: 0.021635\n",
      "  Step 11, Current reward: 0.021635\n",
      "  Step 12, Current reward: 0.021635\n",
      "Episode 542/1000 complete - Max Reward: 0.021635\n",
      "Starting episode 543/1000\n",
      "  Step 1, Current reward: 0.216054\n",
      "  Step 2, Current reward: 0.216054\n",
      "  Step 3, Current reward: 0.216054\n",
      "  Step 4, Current reward: 0.216054\n",
      "  Step 5, Current reward: 0.216054\n",
      "  Step 6, Current reward: 0.216054\n",
      "  Step 7, Current reward: 0.216054\n",
      "  Step 8, Current reward: 0.216054\n",
      "  Step 9, Current reward: 0.216054\n",
      "  Step 10, Current reward: 0.216054\n",
      "  Step 11, Current reward: 0.216054\n",
      "  Step 12, Current reward: 0.216054\n",
      "Episode 543/1000 complete - Max Reward: 0.216054\n",
      "Starting episode 544/1000\n",
      "  Step 1, Current reward: 0.069664\n",
      "  Step 2, Current reward: 0.069664\n",
      "  Step 3, Current reward: 0.069664\n",
      "  Step 4, Current reward: 0.069664\n",
      "  Step 5, Current reward: 0.069664\n",
      "  Step 6, Current reward: 0.069664\n",
      "  Step 7, Current reward: 0.069664\n",
      "  Step 8, Current reward: 0.069664\n",
      "  Step 9, Current reward: 0.069664\n",
      "  Step 10, Current reward: 0.069664\n",
      "  Step 11, Current reward: 0.069664\n",
      "  Step 12, Current reward: 0.069664\n",
      "Episode 544/1000 complete - Max Reward: 0.069664\n",
      "Starting episode 545/1000\n",
      "  Step 1, Current reward: 0.100662\n",
      "  Step 2, Current reward: 0.100662\n",
      "  Step 3, Current reward: 0.100662\n",
      "  Step 4, Current reward: 0.100662\n",
      "  Step 5, Current reward: 0.100662\n",
      "  Step 6, Current reward: 0.100662\n",
      "  Step 7, Current reward: 0.100662\n",
      "  Step 8, Current reward: 0.100662\n",
      "  Step 9, Current reward: 0.100662\n",
      "  Step 10, Current reward: 0.100662\n",
      "  Step 11, Current reward: 0.100662\n",
      "  Step 12, Current reward: 0.100662\n",
      "Episode 545/1000 complete - Max Reward: 0.100662\n",
      "Starting episode 546/1000\n",
      "  Step 1, Current reward: 0.006702\n",
      "  Step 2, Current reward: 0.006702\n",
      "  Step 3, Current reward: 0.006702\n",
      "  Step 4, Current reward: 0.006702\n",
      "  Step 5, Current reward: 0.006702\n",
      "  Step 6, Current reward: 0.006702\n",
      "  Step 7, Current reward: 0.006702\n",
      "  Step 8, Current reward: 0.006702\n",
      "  Step 9, Current reward: 0.006702\n",
      "  Step 10, Current reward: 0.006702\n",
      "  Step 11, Current reward: 0.006702\n",
      "  Step 12, Current reward: 0.006702\n",
      "Episode 546/1000 complete - Max Reward: 0.006702\n",
      "Starting episode 547/1000\n",
      "  Step 1, Current reward: 0.055864\n",
      "  Step 2, Current reward: 0.056730\n",
      "  Step 3, Current reward: 0.056730\n",
      "  Step 4, Current reward: 0.056730\n",
      "  Step 5, Current reward: 0.056730\n",
      "  Step 6, Current reward: 0.056730\n",
      "  Step 7, Current reward: 0.056730\n",
      "  Step 8, Current reward: 0.056730\n",
      "  Step 9, Current reward: 0.056730\n",
      "  Step 10, Current reward: 0.056730\n",
      "  Step 11, Current reward: 0.056730\n",
      "  Step 12, Current reward: 0.056730\n",
      "  Step 13, Current reward: 0.056730\n",
      "Episode 547/1000 complete - Max Reward: 0.056730\n",
      "Starting episode 548/1000\n",
      "  Step 1, Current reward: 0.009033\n",
      "  Step 2, Current reward: 0.009033\n",
      "  Step 3, Current reward: 0.009033\n",
      "  Step 4, Current reward: 0.009033\n",
      "  Step 5, Current reward: 0.009033\n",
      "  Step 6, Current reward: 0.009033\n",
      "  Step 7, Current reward: 0.009033\n",
      "  Step 8, Current reward: 0.009033\n",
      "  Step 9, Current reward: 0.009033\n",
      "  Step 10, Current reward: 0.009033\n",
      "  Step 11, Current reward: 0.009033\n",
      "  Step 12, Current reward: 0.009033\n",
      "Episode 548/1000 complete - Max Reward: 0.009033\n",
      "Starting episode 549/1000\n",
      "  Step 1, Current reward: 0.066241\n",
      "  Step 2, Current reward: 0.066241\n",
      "  Step 3, Current reward: 0.066241\n",
      "  Step 4, Current reward: 0.066241\n",
      "  Step 5, Current reward: 0.066241\n",
      "  Step 6, Current reward: 0.066241\n",
      "  Step 7, Current reward: 0.066241\n",
      "  Step 8, Current reward: 0.066241\n",
      "  Step 9, Current reward: 0.066241\n",
      "  Step 10, Current reward: 0.066241\n",
      "  Step 11, Current reward: 0.066241\n",
      "  Step 12, Current reward: 0.066241\n",
      "Episode 549/1000 complete - Max Reward: 0.066241\n",
      "Starting episode 550/1000\n",
      "  Step 1, Current reward: 0.031999\n",
      "  Step 2, Current reward: 0.031999\n",
      "  Step 3, Current reward: 0.031999\n",
      "  Step 4, Current reward: 0.031999\n",
      "  Step 5, Current reward: 0.031999\n",
      "  Step 6, Current reward: 0.031999\n",
      "  Step 7, Current reward: 0.031999\n",
      "  Step 8, Current reward: 0.031999\n",
      "  Step 9, Current reward: 0.031999\n",
      "  Step 10, Current reward: 0.031999\n",
      "  Step 11, Current reward: 0.031999\n",
      "  Step 12, Current reward: 0.031999\n",
      "Episode 550/1000 complete - Max Reward: 0.031999\n",
      "Starting episode 551/1000\n",
      "  Step 1, Current reward: 0.031685\n",
      "  Step 2, Current reward: 0.031685\n",
      "  Step 3, Current reward: 0.031685\n",
      "  Step 4, Current reward: 0.031685\n",
      "  Step 5, Current reward: 0.031685\n",
      "  Step 6, Current reward: 0.031685\n",
      "  Step 7, Current reward: 0.031685\n",
      "  Step 8, Current reward: 0.031685\n",
      "  Step 9, Current reward: 0.031685\n",
      "  Step 10, Current reward: 0.031685\n",
      "  Step 11, Current reward: 0.031685\n",
      "  Step 12, Current reward: 0.031685\n",
      "Episode 551/1000 complete - Max Reward: 0.031685\n",
      "Starting episode 552/1000\n",
      "  Step 1, Current reward: 0.036614\n",
      "  Step 2, Current reward: 0.036614\n",
      "  Step 3, Current reward: 0.036614\n",
      "  Step 4, Current reward: 0.036614\n",
      "  Step 5, Current reward: 0.036614\n",
      "  Step 6, Current reward: 0.036614\n",
      "  Step 7, Current reward: 0.036614\n",
      "  Step 8, Current reward: 0.036614\n",
      "  Step 9, Current reward: 0.036614\n",
      "  Step 10, Current reward: 0.036614\n",
      "  Step 11, Current reward: 0.036614\n",
      "  Step 12, Current reward: 0.036614\n",
      "Episode 552/1000 complete - Max Reward: 0.036614\n",
      "Starting episode 553/1000\n",
      "  Step 1, Current reward: 0.025017\n",
      "  Step 2, Current reward: 0.025017\n",
      "  Step 3, Current reward: 0.025017\n",
      "  Step 4, Current reward: 0.025017\n",
      "  Step 5, Current reward: 0.025017\n",
      "  Step 6, Current reward: 0.025017\n",
      "  Step 7, Current reward: 0.025017\n",
      "  Step 8, Current reward: 0.025017\n",
      "  Step 9, Current reward: 0.025017\n",
      "  Step 10, Current reward: 0.025017\n",
      "  Step 11, Current reward: 0.025017\n",
      "  Step 12, Current reward: 0.025017\n",
      "Episode 553/1000 complete - Max Reward: 0.025017\n",
      "Starting episode 554/1000\n",
      "  Step 1, Current reward: 0.027027\n",
      "  Step 2, Current reward: 0.027027\n",
      "  Step 3, Current reward: 0.027027\n",
      "  Step 4, Current reward: 0.027027\n",
      "  Step 5, Current reward: 0.027027\n",
      "  Step 6, Current reward: 0.027027\n",
      "  Step 7, Current reward: 0.027027\n",
      "  Step 8, Current reward: 0.027027\n",
      "  Step 9, Current reward: 0.027027\n",
      "  Step 10, Current reward: 0.027027\n",
      "  Step 11, Current reward: 0.027027\n",
      "  Step 12, Current reward: 0.027027\n",
      "Episode 554/1000 complete - Max Reward: 0.027027\n",
      "Starting episode 555/1000\n",
      "  Step 1, Current reward: 0.055703\n",
      "  Step 2, Current reward: 0.055703\n",
      "  Step 3, Current reward: 0.055703\n",
      "  Step 4, Current reward: 0.055703\n",
      "  Step 5, Current reward: 0.055703\n",
      "  Step 6, Current reward: 0.055703\n",
      "  Step 7, Current reward: 0.055703\n",
      "  Step 8, Current reward: 0.055703\n",
      "  Step 9, Current reward: 0.055703\n",
      "  Step 10, Current reward: 0.055703\n",
      "  Step 11, Current reward: 0.055703\n",
      "  Step 12, Current reward: 0.055703\n",
      "Episode 555/1000 complete - Max Reward: 0.055703\n",
      "Starting episode 556/1000\n",
      "  Step 1, Current reward: 0.001500\n",
      "  Step 2, Current reward: 0.001500\n",
      "  Step 3, Current reward: 0.001500\n",
      "  Step 4, Current reward: 0.001500\n",
      "  Step 5, Current reward: 0.001500\n",
      "  Step 6, Current reward: 0.001500\n",
      "  Step 7, Current reward: 0.001500\n",
      "  Step 8, Current reward: 0.001500\n",
      "  Step 9, Current reward: 0.001500\n",
      "  Step 10, Current reward: 0.001500\n",
      "  Step 11, Current reward: 0.001500\n",
      "  Step 12, Current reward: 0.001500\n",
      "Episode 556/1000 complete - Max Reward: 0.001500\n",
      "Starting episode 557/1000\n",
      "  Step 1, Current reward: 0.008038\n",
      "  Step 2, Current reward: 0.008038\n",
      "  Step 3, Current reward: 0.008038\n",
      "  Step 4, Current reward: 0.008038\n",
      "  Step 5, Current reward: 0.008038\n",
      "  Step 6, Current reward: 0.008038\n",
      "  Step 7, Current reward: 0.008038\n",
      "  Step 8, Current reward: 0.008038\n",
      "  Step 9, Current reward: 0.008038\n",
      "  Step 10, Current reward: 0.008038\n",
      "  Step 11, Current reward: 0.008038\n",
      "  Step 12, Current reward: 0.008038\n",
      "Episode 557/1000 complete - Max Reward: 0.008038\n",
      "Starting episode 558/1000\n",
      "  Step 1, Current reward: 0.028065\n",
      "  Step 2, Current reward: 0.028065\n",
      "  Step 3, Current reward: 0.028065\n",
      "  Step 4, Current reward: 0.028065\n",
      "  Step 5, Current reward: 0.028065\n",
      "  Step 6, Current reward: 0.028065\n",
      "  Step 7, Current reward: 0.028065\n",
      "  Step 8, Current reward: 0.028065\n",
      "  Step 9, Current reward: 0.028065\n",
      "  Step 10, Current reward: 0.028065\n",
      "  Step 11, Current reward: 0.028065\n",
      "  Step 12, Current reward: 0.028065\n",
      "Episode 558/1000 complete - Max Reward: 0.028065\n",
      "Starting episode 559/1000\n",
      "  Step 1, Current reward: 0.048911\n",
      "  Step 2, Current reward: 0.048911\n",
      "  Step 3, Current reward: 0.048911\n",
      "  Step 4, Current reward: 0.048911\n",
      "  Step 5, Current reward: 0.048911\n",
      "  Step 6, Current reward: 0.048911\n",
      "  Step 7, Current reward: 0.048911\n",
      "  Step 8, Current reward: 0.048911\n",
      "  Step 9, Current reward: 0.048911\n",
      "  Step 10, Current reward: 0.048911\n",
      "  Step 11, Current reward: 0.048911\n",
      "  Step 12, Current reward: 0.048911\n",
      "Episode 559/1000 complete - Max Reward: 0.048911\n",
      "Starting episode 560/1000\n",
      "  Step 1, Current reward: 0.006581\n",
      "  Step 2, Current reward: 0.006581\n",
      "  Step 3, Current reward: 0.006581\n",
      "  Step 4, Current reward: 0.006581\n",
      "  Step 5, Current reward: 0.006581\n",
      "  Step 6, Current reward: 0.006581\n",
      "  Step 7, Current reward: 0.006581\n",
      "  Step 8, Current reward: 0.006581\n",
      "  Step 9, Current reward: 0.006581\n",
      "  Step 10, Current reward: 0.006581\n",
      "  Step 11, Current reward: 0.006581\n",
      "  Step 12, Current reward: 0.006581\n",
      "Episode 560/1000 complete - Max Reward: 0.006581\n",
      "Starting episode 561/1000\n",
      "  Step 1, Current reward: 0.024462\n",
      "  Step 2, Current reward: 0.024462\n",
      "  Step 3, Current reward: 0.024462\n",
      "  Step 4, Current reward: 0.024462\n",
      "  Step 5, Current reward: 0.024462\n",
      "  Step 6, Current reward: 0.024462\n",
      "  Step 7, Current reward: 0.024462\n",
      "  Step 8, Current reward: 0.024462\n",
      "  Step 9, Current reward: 0.024462\n",
      "  Step 10, Current reward: 0.024462\n",
      "  Step 11, Current reward: 0.024462\n",
      "  Step 12, Current reward: 0.024462\n",
      "Episode 561/1000 complete - Max Reward: 0.024462\n",
      "Starting episode 562/1000\n",
      "  Step 1, Current reward: 0.025874\n",
      "  Step 2, Current reward: 0.025874\n",
      "  Step 3, Current reward: 0.025874\n",
      "  Step 4, Current reward: 0.025874\n",
      "  Step 5, Current reward: 0.025874\n",
      "  Step 6, Current reward: 0.025874\n",
      "  Step 7, Current reward: 0.025874\n",
      "  Step 8, Current reward: 0.025874\n",
      "  Step 9, Current reward: 0.025874\n",
      "  Step 10, Current reward: 0.025874\n",
      "  Step 11, Current reward: 0.025874\n",
      "  Step 12, Current reward: 0.025874\n",
      "Episode 562/1000 complete - Max Reward: 0.025874\n",
      "Starting episode 563/1000\n",
      "  Step 1, Current reward: 0.003220\n",
      "  Step 2, Current reward: 0.003239\n",
      "  Step 3, Current reward: 0.003239\n",
      "  Step 4, Current reward: 0.003239\n",
      "  Step 5, Current reward: 0.003239\n",
      "  Step 6, Current reward: 0.003239\n",
      "  Step 7, Current reward: 0.003239\n",
      "  Step 8, Current reward: 0.003239\n",
      "  Step 9, Current reward: 0.003239\n",
      "  Step 10, Current reward: 0.003239\n",
      "  Step 11, Current reward: 0.003239\n",
      "  Step 12, Current reward: 0.003239\n",
      "  Step 13, Current reward: 0.003239\n",
      "Episode 563/1000 complete - Max Reward: 0.003239\n",
      "Starting episode 564/1000\n",
      "  Step 1, Current reward: 0.084082\n",
      "  Step 2, Current reward: 0.084082\n",
      "  Step 3, Current reward: 0.084082\n",
      "  Step 4, Current reward: 0.084082\n",
      "  Step 5, Current reward: 0.084082\n",
      "  Step 6, Current reward: 0.084082\n",
      "  Step 7, Current reward: 0.084082\n",
      "  Step 8, Current reward: 0.084082\n",
      "  Step 9, Current reward: 0.084082\n",
      "  Step 10, Current reward: 0.084082\n",
      "  Step 11, Current reward: 0.084082\n",
      "  Step 12, Current reward: 0.084082\n",
      "Episode 564/1000 complete - Max Reward: 0.084082\n",
      "Starting episode 565/1000\n",
      "  Step 1, Current reward: 0.017699\n",
      "  Step 2, Current reward: 0.017699\n",
      "  Step 3, Current reward: 0.017699\n",
      "  Step 4, Current reward: 0.017699\n",
      "  Step 5, Current reward: 0.017699\n",
      "  Step 6, Current reward: 0.017699\n",
      "  Step 7, Current reward: 0.017699\n",
      "  Step 8, Current reward: 0.017699\n",
      "  Step 9, Current reward: 0.017699\n",
      "  Step 10, Current reward: 0.017699\n",
      "  Step 11, Current reward: 0.017699\n",
      "  Step 12, Current reward: 0.017699\n",
      "Episode 565/1000 complete - Max Reward: 0.017699\n",
      "Starting episode 566/1000\n",
      "  Step 1, Current reward: 0.056352\n",
      "  Step 2, Current reward: 0.056352\n",
      "  Step 3, Current reward: 0.056352\n",
      "  Step 4, Current reward: 0.056352\n",
      "  Step 5, Current reward: 0.056352\n",
      "  Step 6, Current reward: 0.056352\n",
      "  Step 7, Current reward: 0.056352\n",
      "  Step 8, Current reward: 0.056352\n",
      "  Step 9, Current reward: 0.056352\n",
      "  Step 10, Current reward: 0.056352\n",
      "  Step 11, Current reward: 0.056352\n",
      "  Step 12, Current reward: 0.056352\n",
      "Episode 566/1000 complete - Max Reward: 0.056352\n",
      "Starting episode 567/1000\n",
      "  Step 1, Current reward: 0.022060\n",
      "  Step 2, Current reward: 0.022060\n",
      "  Step 3, Current reward: 0.022060\n",
      "  Step 4, Current reward: 0.022060\n",
      "  Step 5, Current reward: 0.022060\n",
      "  Step 6, Current reward: 0.022060\n",
      "  Step 7, Current reward: 0.022060\n",
      "  Step 8, Current reward: 0.022060\n",
      "  Step 9, Current reward: 0.022060\n",
      "  Step 10, Current reward: 0.022060\n",
      "  Step 11, Current reward: 0.022060\n",
      "  Step 12, Current reward: 0.022060\n",
      "Episode 567/1000 complete - Max Reward: 0.022060\n",
      "Starting episode 568/1000\n",
      "  Step 1, Current reward: 0.003261\n",
      "  Step 2, Current reward: 0.003261\n",
      "  Step 3, Current reward: 0.003261\n",
      "  Step 4, Current reward: 0.003261\n",
      "  Step 5, Current reward: 0.003261\n",
      "  Step 6, Current reward: 0.003261\n",
      "  Step 7, Current reward: 0.003261\n",
      "  Step 8, Current reward: 0.003261\n",
      "  Step 9, Current reward: 0.003261\n",
      "  Step 10, Current reward: 0.003261\n",
      "  Step 11, Current reward: 0.003261\n",
      "  Step 12, Current reward: 0.003261\n",
      "Episode 568/1000 complete - Max Reward: 0.003261\n",
      "Starting episode 569/1000\n",
      "  Step 1, Current reward: 0.005329\n",
      "  Step 2, Current reward: 0.005329\n",
      "  Step 3, Current reward: 0.005329\n",
      "  Step 4, Current reward: 0.005329\n",
      "  Step 5, Current reward: 0.005329\n",
      "  Step 6, Current reward: 0.005329\n",
      "  Step 7, Current reward: 0.005329\n",
      "  Step 8, Current reward: 0.005329\n",
      "  Step 9, Current reward: 0.005329\n",
      "  Step 10, Current reward: 0.005329\n",
      "  Step 11, Current reward: 0.005329\n",
      "  Step 12, Current reward: 0.005329\n",
      "Episode 569/1000 complete - Max Reward: 0.005329\n",
      "Starting episode 570/1000\n",
      "  Step 1, Current reward: 0.018627\n",
      "  Step 2, Current reward: 0.018627\n",
      "  Step 3, Current reward: 0.018627\n",
      "  Step 4, Current reward: 0.018627\n",
      "  Step 5, Current reward: 0.018627\n",
      "  Step 6, Current reward: 0.018627\n",
      "  Step 7, Current reward: 0.018627\n",
      "  Step 8, Current reward: 0.018627\n",
      "  Step 9, Current reward: 0.018627\n",
      "  Step 10, Current reward: 0.018627\n",
      "  Step 11, Current reward: 0.018627\n",
      "  Step 12, Current reward: 0.018627\n",
      "Episode 570/1000 complete - Max Reward: 0.018627\n",
      "Starting episode 571/1000\n",
      "  Step 1, Current reward: 0.014537\n",
      "  Step 2, Current reward: 0.014537\n",
      "  Step 3, Current reward: 0.014537\n",
      "  Step 4, Current reward: 0.014537\n",
      "  Step 5, Current reward: 0.014537\n",
      "  Step 6, Current reward: 0.014537\n",
      "  Step 7, Current reward: 0.014537\n",
      "  Step 8, Current reward: 0.014537\n",
      "  Step 9, Current reward: 0.014537\n",
      "  Step 10, Current reward: 0.014537\n",
      "  Step 11, Current reward: 0.014537\n",
      "  Step 12, Current reward: 0.014537\n",
      "Episode 571/1000 complete - Max Reward: 0.014537\n",
      "Starting episode 572/1000\n",
      "  Step 1, Current reward: 0.012152\n",
      "  Step 2, Current reward: 0.012152\n",
      "  Step 3, Current reward: 0.012152\n",
      "  Step 4, Current reward: 0.012152\n",
      "  Step 5, Current reward: 0.012152\n",
      "  Step 6, Current reward: 0.012152\n",
      "  Step 7, Current reward: 0.012152\n",
      "  Step 8, Current reward: 0.012152\n",
      "  Step 9, Current reward: 0.012152\n",
      "  Step 10, Current reward: 0.012152\n",
      "  Step 11, Current reward: 0.012152\n",
      "  Step 12, Current reward: 0.012152\n",
      "Episode 572/1000 complete - Max Reward: 0.012152\n",
      "Starting episode 573/1000\n",
      "  Step 1, Current reward: 0.016390\n",
      "  Step 2, Current reward: 0.016390\n",
      "  Step 3, Current reward: 0.016390\n",
      "  Step 4, Current reward: 0.016390\n",
      "  Step 5, Current reward: 0.016390\n",
      "  Step 6, Current reward: 0.016390\n",
      "  Step 7, Current reward: 0.016390\n",
      "  Step 8, Current reward: 0.016390\n",
      "  Step 9, Current reward: 0.016390\n",
      "  Step 10, Current reward: 0.016390\n",
      "  Step 11, Current reward: 0.016390\n",
      "  Step 12, Current reward: 0.016390\n",
      "Episode 573/1000 complete - Max Reward: 0.016390\n",
      "Starting episode 574/1000\n",
      "  Step 1, Current reward: 0.009776\n",
      "  Step 2, Current reward: 0.009776\n",
      "  Step 3, Current reward: 0.009776\n",
      "  Step 4, Current reward: 0.009776\n",
      "  Step 5, Current reward: 0.009776\n",
      "  Step 6, Current reward: 0.009776\n",
      "  Step 7, Current reward: 0.009776\n",
      "  Step 8, Current reward: 0.009776\n",
      "  Step 9, Current reward: 0.009776\n",
      "  Step 10, Current reward: 0.009776\n",
      "  Step 11, Current reward: 0.009776\n",
      "  Step 12, Current reward: 0.009776\n",
      "Episode 574/1000 complete - Max Reward: 0.009776\n",
      "Starting episode 575/1000\n",
      "  Step 1, Current reward: 0.002901\n",
      "  Step 2, Current reward: 0.002901\n",
      "  Step 3, Current reward: 0.002901\n",
      "  Step 4, Current reward: 0.002901\n",
      "  Step 5, Current reward: 0.002901\n",
      "  Step 6, Current reward: 0.002901\n",
      "  Step 7, Current reward: 0.002901\n",
      "  Step 8, Current reward: 0.002901\n",
      "  Step 9, Current reward: 0.002901\n",
      "  Step 10, Current reward: 0.002901\n",
      "  Step 11, Current reward: 0.002901\n",
      "  Step 12, Current reward: 0.002901\n",
      "Episode 575/1000 complete - Max Reward: 0.002901\n",
      "Starting episode 576/1000\n",
      "  Step 1, Current reward: 0.005693\n",
      "  Step 2, Current reward: 0.005693\n",
      "  Step 3, Current reward: 0.005693\n",
      "  Step 4, Current reward: 0.005693\n",
      "  Step 5, Current reward: 0.005693\n",
      "  Step 6, Current reward: 0.005693\n",
      "  Step 7, Current reward: 0.005693\n",
      "  Step 8, Current reward: 0.005693\n",
      "  Step 9, Current reward: 0.005693\n",
      "  Step 10, Current reward: 0.005693\n",
      "  Step 11, Current reward: 0.005693\n",
      "  Step 12, Current reward: 0.005693\n",
      "Episode 576/1000 complete - Max Reward: 0.005693\n",
      "Starting episode 577/1000\n",
      "  Step 1, Current reward: 0.032059\n",
      "  Step 2, Current reward: 0.032059\n",
      "  Step 3, Current reward: 0.032059\n",
      "  Step 4, Current reward: 0.032059\n",
      "  Step 5, Current reward: 0.032059\n",
      "  Step 6, Current reward: 0.032059\n",
      "  Step 7, Current reward: 0.032059\n",
      "  Step 8, Current reward: 0.032059\n",
      "  Step 9, Current reward: 0.032059\n",
      "  Step 10, Current reward: 0.032059\n",
      "  Step 11, Current reward: 0.032059\n",
      "  Step 12, Current reward: 0.032059\n",
      "Episode 577/1000 complete - Max Reward: 0.032059\n",
      "Starting episode 578/1000\n",
      "  Step 1, Current reward: 0.021788\n",
      "  Step 2, Current reward: 0.021788\n",
      "  Step 3, Current reward: 0.021788\n",
      "  Step 4, Current reward: 0.021788\n",
      "  Step 5, Current reward: 0.021788\n",
      "  Step 6, Current reward: 0.021788\n",
      "  Step 7, Current reward: 0.021788\n",
      "  Step 8, Current reward: 0.021788\n",
      "  Step 9, Current reward: 0.021788\n",
      "  Step 10, Current reward: 0.021788\n",
      "  Step 11, Current reward: 0.021788\n",
      "  Step 12, Current reward: 0.021788\n",
      "Episode 578/1000 complete - Max Reward: 0.021788\n",
      "Starting episode 579/1000\n",
      "  Step 1, Current reward: 0.019761\n",
      "  Step 2, Current reward: 0.019761\n",
      "  Step 3, Current reward: 0.019761\n",
      "  Step 4, Current reward: 0.019761\n",
      "  Step 5, Current reward: 0.019761\n",
      "  Step 6, Current reward: 0.019761\n",
      "  Step 7, Current reward: 0.019761\n",
      "  Step 8, Current reward: 0.019761\n",
      "  Step 9, Current reward: 0.019761\n",
      "  Step 10, Current reward: 0.019761\n",
      "  Step 11, Current reward: 0.019761\n",
      "  Step 12, Current reward: 0.019761\n",
      "Episode 579/1000 complete - Max Reward: 0.019761\n",
      "Starting episode 580/1000\n",
      "  Step 1, Current reward: 0.000541\n",
      "  Step 2, Current reward: 0.000541\n",
      "  Step 3, Current reward: 0.000541\n",
      "  Step 4, Current reward: 0.000541\n",
      "  Step 5, Current reward: 0.000541\n",
      "  Step 6, Current reward: 0.000541\n",
      "  Step 7, Current reward: 0.000541\n",
      "  Step 8, Current reward: 0.000541\n",
      "  Step 9, Current reward: 0.000541\n",
      "  Step 10, Current reward: 0.000541\n",
      "  Step 11, Current reward: 0.000541\n",
      "  Step 12, Current reward: 0.000541\n",
      "Episode 580/1000 complete - Max Reward: 0.000541\n",
      "Starting episode 581/1000\n",
      "  Step 1, Current reward: 0.015155\n",
      "  Step 2, Current reward: 0.015155\n",
      "  Step 3, Current reward: 0.015155\n",
      "  Step 4, Current reward: 0.015155\n",
      "  Step 5, Current reward: 0.015155\n",
      "  Step 6, Current reward: 0.015155\n",
      "  Step 7, Current reward: 0.015155\n",
      "  Step 8, Current reward: 0.015155\n",
      "  Step 9, Current reward: 0.015155\n",
      "  Step 10, Current reward: 0.015155\n",
      "  Step 11, Current reward: 0.015155\n",
      "  Step 12, Current reward: 0.015155\n",
      "Episode 581/1000 complete - Max Reward: 0.015155\n",
      "Starting episode 582/1000\n",
      "  Step 1, Current reward: 0.003522\n",
      "  Step 2, Current reward: 0.003522\n",
      "  Step 3, Current reward: 0.003522\n",
      "  Step 4, Current reward: 0.003522\n",
      "  Step 5, Current reward: 0.003522\n",
      "  Step 6, Current reward: 0.003522\n",
      "  Step 7, Current reward: 0.003522\n",
      "  Step 8, Current reward: 0.003522\n",
      "  Step 9, Current reward: 0.003522\n",
      "  Step 10, Current reward: 0.003522\n",
      "  Step 11, Current reward: 0.003522\n",
      "  Step 12, Current reward: 0.003522\n",
      "Episode 582/1000 complete - Max Reward: 0.003522\n",
      "Starting episode 583/1000\n",
      "  Step 1, Current reward: 0.013764\n",
      "  Step 2, Current reward: 0.013764\n",
      "  Step 3, Current reward: 0.013764\n",
      "  Step 4, Current reward: 0.013764\n",
      "  Step 5, Current reward: 0.013764\n",
      "  Step 6, Current reward: 0.013764\n",
      "  Step 7, Current reward: 0.013764\n",
      "  Step 8, Current reward: 0.013764\n",
      "  Step 9, Current reward: 0.013764\n",
      "  Step 10, Current reward: 0.013764\n",
      "  Step 11, Current reward: 0.013764\n",
      "  Step 12, Current reward: 0.013764\n",
      "Episode 583/1000 complete - Max Reward: 0.013764\n",
      "Starting episode 584/1000\n",
      "  Step 1, Current reward: 0.034010\n",
      "  Step 2, Current reward: 0.034010\n",
      "  Step 3, Current reward: 0.034010\n",
      "  Step 4, Current reward: 0.034010\n",
      "  Step 5, Current reward: 0.034010\n",
      "  Step 6, Current reward: 0.034010\n",
      "  Step 7, Current reward: 0.034010\n",
      "  Step 8, Current reward: 0.034010\n",
      "  Step 9, Current reward: 0.034010\n",
      "  Step 10, Current reward: 0.034010\n",
      "  Step 11, Current reward: 0.034010\n",
      "  Step 12, Current reward: 0.034010\n",
      "Episode 584/1000 complete - Max Reward: 0.034010\n",
      "Starting episode 585/1000\n",
      "  Step 1, Current reward: 0.028007\n",
      "  Step 2, Current reward: 0.028007\n",
      "  Step 3, Current reward: 0.028007\n",
      "  Step 4, Current reward: 0.028007\n",
      "  Step 5, Current reward: 0.028007\n",
      "  Step 6, Current reward: 0.028007\n",
      "  Step 7, Current reward: 0.028007\n",
      "  Step 8, Current reward: 0.028007\n",
      "  Step 9, Current reward: 0.028007\n",
      "  Step 10, Current reward: 0.028007\n",
      "  Step 11, Current reward: 0.028007\n",
      "  Step 12, Current reward: 0.028007\n",
      "Episode 585/1000 complete - Max Reward: 0.028007\n",
      "Starting episode 586/1000\n",
      "  Step 1, Current reward: 0.047023\n",
      "  Step 2, Current reward: 0.047023\n",
      "  Step 3, Current reward: 0.047023\n",
      "  Step 4, Current reward: 0.047023\n",
      "  Step 5, Current reward: 0.047023\n",
      "  Step 6, Current reward: 0.047023\n",
      "  Step 7, Current reward: 0.047023\n",
      "  Step 8, Current reward: 0.047023\n",
      "  Step 9, Current reward: 0.047023\n",
      "  Step 10, Current reward: 0.047023\n",
      "  Step 11, Current reward: 0.047023\n",
      "  Step 12, Current reward: 0.047023\n",
      "Episode 586/1000 complete - Max Reward: 0.047023\n",
      "Starting episode 587/1000\n",
      "  Step 1, Current reward: 0.030806\n",
      "  Step 2, Current reward: 0.030806\n",
      "  Step 3, Current reward: 0.030806\n",
      "  Step 4, Current reward: 0.030806\n",
      "  Step 5, Current reward: 0.030806\n",
      "  Step 6, Current reward: 0.030806\n",
      "  Step 7, Current reward: 0.030806\n",
      "  Step 8, Current reward: 0.030806\n",
      "  Step 9, Current reward: 0.030806\n",
      "  Step 10, Current reward: 0.030806\n",
      "  Step 11, Current reward: 0.030806\n",
      "  Step 12, Current reward: 0.030806\n",
      "Episode 587/1000 complete - Max Reward: 0.030806\n",
      "Starting episode 588/1000\n",
      "  Step 1, Current reward: 0.028897\n",
      "  Step 2, Current reward: 0.028897\n",
      "  Step 3, Current reward: 0.028897\n",
      "  Step 4, Current reward: 0.028897\n",
      "  Step 5, Current reward: 0.028897\n",
      "  Step 6, Current reward: 0.028897\n",
      "  Step 7, Current reward: 0.028897\n",
      "  Step 8, Current reward: 0.028897\n",
      "  Step 9, Current reward: 0.028897\n",
      "  Step 10, Current reward: 0.028897\n",
      "  Step 11, Current reward: 0.028897\n",
      "  Step 12, Current reward: 0.028897\n",
      "Episode 588/1000 complete - Max Reward: 0.028897\n",
      "Starting episode 589/1000\n",
      "  Step 1, Current reward: 0.009990\n",
      "  Step 2, Current reward: 0.009990\n",
      "  Step 3, Current reward: 0.009990\n",
      "  Step 4, Current reward: 0.009990\n",
      "  Step 5, Current reward: 0.009990\n",
      "  Step 6, Current reward: 0.009990\n",
      "  Step 7, Current reward: 0.009990\n",
      "  Step 8, Current reward: 0.009990\n",
      "  Step 9, Current reward: 0.009990\n",
      "  Step 10, Current reward: 0.009990\n",
      "  Step 11, Current reward: 0.009990\n",
      "  Step 12, Current reward: 0.009990\n",
      "Episode 589/1000 complete - Max Reward: 0.009990\n",
      "Starting episode 590/1000\n",
      "  Step 1, Current reward: 0.019815\n",
      "  Step 2, Current reward: 0.019815\n",
      "  Step 3, Current reward: 0.019815\n",
      "  Step 4, Current reward: 0.019815\n",
      "  Step 5, Current reward: 0.019815\n",
      "  Step 6, Current reward: 0.019815\n",
      "  Step 7, Current reward: 0.019815\n",
      "  Step 8, Current reward: 0.019815\n",
      "  Step 9, Current reward: 0.019815\n",
      "  Step 10, Current reward: 0.019815\n",
      "  Step 11, Current reward: 0.019815\n",
      "  Step 12, Current reward: 0.019815\n",
      "Episode 590/1000 complete - Max Reward: 0.019815\n",
      "Starting episode 591/1000\n",
      "  Step 1, Current reward: 0.001675\n",
      "  Step 2, Current reward: 0.001675\n",
      "  Step 3, Current reward: 0.001675\n",
      "  Step 4, Current reward: 0.001675\n",
      "  Step 5, Current reward: 0.001675\n",
      "  Step 6, Current reward: 0.001675\n",
      "  Step 7, Current reward: 0.001675\n",
      "  Step 8, Current reward: 0.001675\n",
      "  Step 9, Current reward: 0.001675\n",
      "  Step 10, Current reward: 0.001675\n",
      "  Step 11, Current reward: 0.001675\n",
      "  Step 12, Current reward: 0.001675\n",
      "Episode 591/1000 complete - Max Reward: 0.001675\n",
      "Starting episode 592/1000\n",
      "  Step 1, Current reward: 0.019846\n",
      "  Step 2, Current reward: 0.019846\n",
      "  Step 3, Current reward: 0.019846\n",
      "  Step 4, Current reward: 0.019846\n",
      "  Step 5, Current reward: 0.019846\n",
      "  Step 6, Current reward: 0.019846\n",
      "  Step 7, Current reward: 0.019846\n",
      "  Step 8, Current reward: 0.019846\n",
      "  Step 9, Current reward: 0.019846\n",
      "  Step 10, Current reward: 0.019846\n",
      "  Step 11, Current reward: 0.019846\n",
      "  Step 12, Current reward: 0.019846\n",
      "Episode 592/1000 complete - Max Reward: 0.019846\n",
      "Starting episode 593/1000\n",
      "  Step 1, Current reward: 0.004169\n",
      "  Step 2, Current reward: 0.004169\n",
      "  Step 3, Current reward: 0.004169\n",
      "  Step 4, Current reward: 0.004169\n",
      "  Step 5, Current reward: 0.004169\n",
      "  Step 6, Current reward: 0.004169\n",
      "  Step 7, Current reward: 0.004169\n",
      "  Step 8, Current reward: 0.004169\n",
      "  Step 9, Current reward: 0.004169\n",
      "  Step 10, Current reward: 0.004169\n",
      "  Step 11, Current reward: 0.004169\n",
      "  Step 12, Current reward: 0.004169\n",
      "Episode 593/1000 complete - Max Reward: 0.004169\n",
      "Starting episode 594/1000\n",
      "  Step 1, Current reward: 0.092872\n",
      "  Step 2, Current reward: 0.092872\n",
      "  Step 3, Current reward: 0.092872\n",
      "  Step 4, Current reward: 0.092872\n",
      "  Step 5, Current reward: 0.092872\n",
      "  Step 6, Current reward: 0.092872\n",
      "  Step 7, Current reward: 0.092872\n",
      "  Step 8, Current reward: 0.092872\n",
      "  Step 9, Current reward: 0.092872\n",
      "  Step 10, Current reward: 0.092872\n",
      "  Step 11, Current reward: 0.092872\n",
      "  Step 12, Current reward: 0.092872\n",
      "Episode 594/1000 complete - Max Reward: 0.092872\n",
      "Starting episode 595/1000\n",
      "  Step 1, Current reward: 0.006942\n",
      "  Step 2, Current reward: 0.006942\n",
      "  Step 3, Current reward: 0.006942\n",
      "  Step 4, Current reward: 0.006942\n",
      "  Step 5, Current reward: 0.006942\n",
      "  Step 6, Current reward: 0.006942\n",
      "  Step 7, Current reward: 0.006942\n",
      "  Step 8, Current reward: 0.006942\n",
      "  Step 9, Current reward: 0.006942\n",
      "  Step 10, Current reward: 0.006942\n",
      "  Step 11, Current reward: 0.006942\n",
      "  Step 12, Current reward: 0.006942\n",
      "Episode 595/1000 complete - Max Reward: 0.006942\n",
      "Starting episode 596/1000\n",
      "  Step 1, Current reward: 0.007711\n",
      "  Step 2, Current reward: 0.007711\n",
      "  Step 3, Current reward: 0.007711\n",
      "  Step 4, Current reward: 0.007711\n",
      "  Step 5, Current reward: 0.007711\n",
      "  Step 6, Current reward: 0.007711\n",
      "  Step 7, Current reward: 0.007711\n",
      "  Step 8, Current reward: 0.007711\n",
      "  Step 9, Current reward: 0.007711\n",
      "  Step 10, Current reward: 0.007711\n",
      "  Step 11, Current reward: 0.007711\n",
      "  Step 12, Current reward: 0.007711\n",
      "Episode 596/1000 complete - Max Reward: 0.007711\n",
      "Starting episode 597/1000\n",
      "  Step 1, Current reward: 0.017153\n",
      "  Step 2, Current reward: 0.017153\n",
      "  Step 3, Current reward: 0.017153\n",
      "  Step 4, Current reward: 0.017153\n",
      "  Step 5, Current reward: 0.017153\n",
      "  Step 6, Current reward: 0.017153\n",
      "  Step 7, Current reward: 0.017153\n",
      "  Step 8, Current reward: 0.017153\n",
      "  Step 9, Current reward: 0.017153\n",
      "  Step 10, Current reward: 0.017153\n",
      "  Step 11, Current reward: 0.017153\n",
      "  Step 12, Current reward: 0.017153\n",
      "Episode 597/1000 complete - Max Reward: 0.017153\n",
      "Starting episode 598/1000\n",
      "  Step 1, Current reward: 0.013253\n",
      "  Step 2, Current reward: 0.013253\n",
      "  Step 3, Current reward: 0.013253\n",
      "  Step 4, Current reward: 0.013253\n",
      "  Step 5, Current reward: 0.013253\n",
      "  Step 6, Current reward: 0.013253\n",
      "  Step 7, Current reward: 0.013253\n",
      "  Step 8, Current reward: 0.013253\n",
      "  Step 9, Current reward: 0.013253\n",
      "  Step 10, Current reward: 0.013253\n",
      "  Step 11, Current reward: 0.013253\n",
      "  Step 12, Current reward: 0.013253\n",
      "Episode 598/1000 complete - Max Reward: 0.013253\n",
      "Starting episode 599/1000\n",
      "  Step 1, Current reward: 0.082966\n",
      "  Step 2, Current reward: 0.082966\n",
      "  Step 3, Current reward: 0.082966\n",
      "  Step 4, Current reward: 0.082966\n",
      "  Step 5, Current reward: 0.082966\n",
      "  Step 6, Current reward: 0.082966\n",
      "  Step 7, Current reward: 0.082966\n",
      "  Step 8, Current reward: 0.082966\n",
      "  Step 9, Current reward: 0.082966\n",
      "  Step 10, Current reward: 0.082966\n",
      "  Step 11, Current reward: 0.082966\n",
      "  Step 12, Current reward: 0.082966\n",
      "Episode 599/1000 complete - Max Reward: 0.082966\n",
      "Starting episode 600/1000\n",
      "  Step 1, Current reward: 0.013338\n",
      "  Step 2, Current reward: 0.013338\n",
      "  Step 3, Current reward: 0.013338\n",
      "  Step 4, Current reward: 0.013338\n",
      "  Step 5, Current reward: 0.013338\n",
      "  Step 6, Current reward: 0.013338\n",
      "  Step 7, Current reward: 0.013338\n",
      "  Step 8, Current reward: 0.013338\n",
      "  Step 9, Current reward: 0.013338\n",
      "  Step 10, Current reward: 0.013338\n",
      "  Step 11, Current reward: 0.013338\n",
      "  Step 12, Current reward: 0.013338\n",
      "Episode 600/1000 complete - Max Reward: 0.013338\n",
      "Starting episode 601/1000\n",
      "  Step 1, Current reward: 0.021960\n",
      "  Step 2, Current reward: 0.021960\n",
      "  Step 3, Current reward: 0.021960\n",
      "  Step 4, Current reward: 0.021960\n",
      "  Step 5, Current reward: 0.021960\n",
      "  Step 6, Current reward: 0.021960\n",
      "  Step 7, Current reward: 0.021960\n",
      "  Step 8, Current reward: 0.021960\n",
      "  Step 9, Current reward: 0.021960\n",
      "  Step 10, Current reward: 0.021960\n",
      "  Step 11, Current reward: 0.021960\n",
      "  Step 12, Current reward: 0.021960\n",
      "Episode 601/1000 complete - Max Reward: 0.021960\n",
      "Starting episode 602/1000\n",
      "  Step 1, Current reward: 0.055469\n",
      "  Step 2, Current reward: 0.055469\n",
      "  Step 3, Current reward: 0.055469\n",
      "  Step 4, Current reward: 0.055469\n",
      "  Step 5, Current reward: 0.055469\n",
      "  Step 6, Current reward: 0.055469\n",
      "  Step 7, Current reward: 0.055469\n",
      "  Step 8, Current reward: 0.055469\n",
      "  Step 9, Current reward: 0.055469\n",
      "  Step 10, Current reward: 0.055469\n",
      "  Step 11, Current reward: 0.055469\n",
      "  Step 12, Current reward: 0.055469\n",
      "Episode 602/1000 complete - Max Reward: 0.055469\n",
      "Starting episode 603/1000\n",
      "  Step 1, Current reward: 0.021664\n",
      "  Step 2, Current reward: 0.021664\n",
      "  Step 3, Current reward: 0.021664\n",
      "  Step 4, Current reward: 0.021664\n",
      "  Step 5, Current reward: 0.021664\n",
      "  Step 6, Current reward: 0.021664\n",
      "  Step 7, Current reward: 0.021664\n",
      "  Step 8, Current reward: 0.021664\n",
      "  Step 9, Current reward: 0.021664\n",
      "  Step 10, Current reward: 0.021664\n",
      "  Step 11, Current reward: 0.021664\n",
      "  Step 12, Current reward: 0.021664\n",
      "Episode 603/1000 complete - Max Reward: 0.021664\n",
      "Starting episode 604/1000\n",
      "  Step 1, Current reward: 0.004818\n",
      "  Step 2, Current reward: 0.004818\n",
      "  Step 3, Current reward: 0.004818\n",
      "  Step 4, Current reward: 0.004818\n",
      "  Step 5, Current reward: 0.004818\n",
      "  Step 6, Current reward: 0.004818\n",
      "  Step 7, Current reward: 0.004818\n",
      "  Step 8, Current reward: 0.004818\n",
      "  Step 9, Current reward: 0.004818\n",
      "  Step 10, Current reward: 0.004818\n",
      "  Step 11, Current reward: 0.004818\n",
      "  Step 12, Current reward: 0.004818\n",
      "Episode 604/1000 complete - Max Reward: 0.004818\n",
      "Starting episode 605/1000\n",
      "  Step 1, Current reward: 0.004288\n",
      "  Step 2, Current reward: 0.004288\n",
      "  Step 3, Current reward: 0.004288\n",
      "  Step 4, Current reward: 0.004288\n",
      "  Step 5, Current reward: 0.004288\n",
      "  Step 6, Current reward: 0.004288\n",
      "  Step 7, Current reward: 0.004288\n",
      "  Step 8, Current reward: 0.004288\n",
      "  Step 9, Current reward: 0.004288\n",
      "  Step 10, Current reward: 0.004288\n",
      "  Step 11, Current reward: 0.004288\n",
      "  Step 12, Current reward: 0.004288\n",
      "Episode 605/1000 complete - Max Reward: 0.004288\n",
      "Starting episode 606/1000\n",
      "  Step 1, Current reward: 0.017188\n",
      "  Step 2, Current reward: 0.017188\n",
      "  Step 3, Current reward: 0.017188\n",
      "  Step 4, Current reward: 0.017188\n",
      "  Step 5, Current reward: 0.017188\n",
      "  Step 6, Current reward: 0.017188\n",
      "  Step 7, Current reward: 0.017188\n",
      "  Step 8, Current reward: 0.017188\n",
      "  Step 9, Current reward: 0.017188\n",
      "  Step 10, Current reward: 0.017188\n",
      "  Step 11, Current reward: 0.017188\n",
      "  Step 12, Current reward: 0.017188\n",
      "Episode 606/1000 complete - Max Reward: 0.017188\n",
      "Starting episode 607/1000\n",
      "  Step 1, Current reward: 0.011277\n",
      "  Step 2, Current reward: 0.011277\n",
      "  Step 3, Current reward: 0.011277\n",
      "  Step 4, Current reward: 0.011277\n",
      "  Step 5, Current reward: 0.011277\n",
      "  Step 6, Current reward: 0.011277\n",
      "  Step 7, Current reward: 0.011277\n",
      "  Step 8, Current reward: 0.011277\n",
      "  Step 9, Current reward: 0.011277\n",
      "  Step 10, Current reward: 0.011277\n",
      "  Step 11, Current reward: 0.011277\n",
      "  Step 12, Current reward: 0.011277\n",
      "Episode 607/1000 complete - Max Reward: 0.011277\n",
      "Starting episode 608/1000\n",
      "  Step 1, Current reward: 0.010288\n",
      "  Step 2, Current reward: 0.010288\n",
      "  Step 3, Current reward: 0.010288\n",
      "  Step 4, Current reward: 0.010288\n",
      "  Step 5, Current reward: 0.010288\n",
      "  Step 6, Current reward: 0.010288\n",
      "  Step 7, Current reward: 0.010288\n",
      "  Step 8, Current reward: 0.010288\n",
      "  Step 9, Current reward: 0.010288\n",
      "  Step 10, Current reward: 0.010288\n",
      "  Step 11, Current reward: 0.010288\n",
      "  Step 12, Current reward: 0.010288\n",
      "Episode 608/1000 complete - Max Reward: 0.010288\n",
      "Starting episode 609/1000\n",
      "  Step 1, Current reward: 0.007993\n",
      "  Step 2, Current reward: 0.007993\n",
      "  Step 3, Current reward: 0.007993\n",
      "  Step 4, Current reward: 0.007993\n",
      "  Step 5, Current reward: 0.007993\n",
      "  Step 6, Current reward: 0.007993\n",
      "  Step 7, Current reward: 0.007993\n",
      "  Step 8, Current reward: 0.007993\n",
      "  Step 9, Current reward: 0.007993\n",
      "  Step 10, Current reward: 0.007993\n",
      "  Step 11, Current reward: 0.007993\n",
      "  Step 12, Current reward: 0.007993\n",
      "Episode 609/1000 complete - Max Reward: 0.007993\n",
      "Starting episode 610/1000\n",
      "  Step 1, Current reward: 0.017919\n",
      "  Step 2, Current reward: 0.017919\n",
      "  Step 3, Current reward: 0.017919\n",
      "  Step 4, Current reward: 0.017919\n",
      "  Step 5, Current reward: 0.017919\n",
      "  Step 6, Current reward: 0.017919\n",
      "  Step 7, Current reward: 0.017919\n",
      "  Step 8, Current reward: 0.017919\n",
      "  Step 9, Current reward: 0.017919\n",
      "  Step 10, Current reward: 0.017919\n",
      "  Step 11, Current reward: 0.017919\n",
      "  Step 12, Current reward: 0.017919\n",
      "Episode 610/1000 complete - Max Reward: 0.017919\n",
      "Starting episode 611/1000\n",
      "  Step 1, Current reward: 0.004160\n",
      "  Step 2, Current reward: 0.004160\n",
      "  Step 3, Current reward: 0.004160\n",
      "  Step 4, Current reward: 0.004160\n",
      "  Step 5, Current reward: 0.004160\n",
      "  Step 6, Current reward: 0.004160\n",
      "  Step 7, Current reward: 0.004160\n",
      "  Step 8, Current reward: 0.004160\n",
      "  Step 9, Current reward: 0.004160\n",
      "  Step 10, Current reward: 0.004160\n",
      "  Step 11, Current reward: 0.004160\n",
      "  Step 12, Current reward: 0.004160\n",
      "Episode 611/1000 complete - Max Reward: 0.004160\n",
      "Starting episode 612/1000\n",
      "  Step 1, Current reward: 0.005128\n",
      "  Step 2, Current reward: 0.005128\n",
      "  Step 3, Current reward: 0.005128\n",
      "  Step 4, Current reward: 0.005128\n",
      "  Step 5, Current reward: 0.005128\n",
      "  Step 6, Current reward: 0.005128\n",
      "  Step 7, Current reward: 0.005128\n",
      "  Step 8, Current reward: 0.005128\n",
      "  Step 9, Current reward: 0.005128\n",
      "  Step 10, Current reward: 0.005128\n",
      "  Step 11, Current reward: 0.005128\n",
      "  Step 12, Current reward: 0.005128\n",
      "Episode 612/1000 complete - Max Reward: 0.005128\n",
      "Starting episode 613/1000\n",
      "  Step 1, Current reward: 0.002626\n",
      "  Step 2, Current reward: 0.002626\n",
      "  Step 3, Current reward: 0.002626\n",
      "  Step 4, Current reward: 0.002626\n",
      "  Step 5, Current reward: 0.002626\n",
      "  Step 6, Current reward: 0.002626\n",
      "  Step 7, Current reward: 0.002626\n",
      "  Step 8, Current reward: 0.002626\n",
      "  Step 9, Current reward: 0.002626\n",
      "  Step 10, Current reward: 0.002626\n",
      "  Step 11, Current reward: 0.002626\n",
      "  Step 12, Current reward: 0.002626\n",
      "Episode 613/1000 complete - Max Reward: 0.002626\n",
      "Starting episode 614/1000\n",
      "  Step 1, Current reward: 0.001502\n",
      "  Step 2, Current reward: 0.001502\n",
      "  Step 3, Current reward: 0.001502\n",
      "  Step 4, Current reward: 0.001502\n",
      "  Step 5, Current reward: 0.001502\n",
      "  Step 6, Current reward: 0.001502\n",
      "  Step 7, Current reward: 0.001502\n",
      "  Step 8, Current reward: 0.001502\n",
      "  Step 9, Current reward: 0.001502\n",
      "  Step 10, Current reward: 0.001502\n",
      "  Step 11, Current reward: 0.001502\n",
      "  Step 12, Current reward: 0.001502\n",
      "Episode 614/1000 complete - Max Reward: 0.001502\n",
      "Starting episode 615/1000\n",
      "  Step 1, Current reward: 0.001536\n",
      "  Step 2, Current reward: 0.001536\n",
      "  Step 3, Current reward: 0.001536\n",
      "  Step 4, Current reward: 0.001536\n",
      "  Step 5, Current reward: 0.001536\n",
      "  Step 6, Current reward: 0.001536\n",
      "  Step 7, Current reward: 0.001536\n",
      "  Step 8, Current reward: 0.001536\n",
      "  Step 9, Current reward: 0.001536\n",
      "  Step 10, Current reward: 0.001536\n",
      "  Step 11, Current reward: 0.001536\n",
      "  Step 12, Current reward: 0.001536\n",
      "Episode 615/1000 complete - Max Reward: 0.001536\n",
      "Starting episode 616/1000\n",
      "  Step 1, Current reward: 0.044899\n",
      "  Step 2, Current reward: 0.044899\n",
      "  Step 3, Current reward: 0.044899\n",
      "  Step 4, Current reward: 0.044899\n",
      "  Step 5, Current reward: 0.044899\n",
      "  Step 6, Current reward: 0.044899\n",
      "  Step 7, Current reward: 0.044899\n",
      "  Step 8, Current reward: 0.044899\n",
      "  Step 9, Current reward: 0.044899\n",
      "  Step 10, Current reward: 0.044899\n",
      "  Step 11, Current reward: 0.044899\n",
      "  Step 12, Current reward: 0.044899\n",
      "Episode 616/1000 complete - Max Reward: 0.044899\n",
      "Starting episode 617/1000\n",
      "  Step 1, Current reward: 0.025082\n",
      "  Step 2, Current reward: 0.025082\n",
      "  Step 3, Current reward: 0.025082\n",
      "  Step 4, Current reward: 0.025082\n",
      "  Step 5, Current reward: 0.025082\n",
      "  Step 6, Current reward: 0.025082\n",
      "  Step 7, Current reward: 0.025082\n",
      "  Step 8, Current reward: 0.025082\n",
      "  Step 9, Current reward: 0.025082\n",
      "  Step 10, Current reward: 0.025082\n",
      "  Step 11, Current reward: 0.025082\n",
      "  Step 12, Current reward: 0.025082\n",
      "Episode 617/1000 complete - Max Reward: 0.025082\n",
      "Starting episode 618/1000\n",
      "  Step 1, Current reward: 0.000123\n",
      "  Step 2, Current reward: 0.000123\n",
      "  Step 3, Current reward: 0.000123\n",
      "  Step 4, Current reward: 0.000123\n",
      "  Step 5, Current reward: 0.000123\n",
      "  Step 6, Current reward: 0.000123\n",
      "  Step 7, Current reward: 0.000123\n",
      "  Step 8, Current reward: 0.000123\n",
      "  Step 9, Current reward: 0.000123\n",
      "  Step 10, Current reward: 0.000123\n",
      "  Step 11, Current reward: 0.000123\n",
      "  Step 12, Current reward: 0.000123\n",
      "Episode 618/1000 complete - Max Reward: 0.000123\n",
      "Starting episode 619/1000\n",
      "  Step 1, Current reward: 0.009221\n",
      "  Step 2, Current reward: 0.009221\n",
      "  Step 3, Current reward: 0.009221\n",
      "  Step 4, Current reward: 0.009221\n",
      "  Step 5, Current reward: 0.009221\n",
      "  Step 6, Current reward: 0.009221\n",
      "  Step 7, Current reward: 0.009221\n",
      "  Step 8, Current reward: 0.009221\n",
      "  Step 9, Current reward: 0.009221\n",
      "  Step 10, Current reward: 0.009221\n",
      "  Step 11, Current reward: 0.009221\n",
      "  Step 12, Current reward: 0.009221\n",
      "Episode 619/1000 complete - Max Reward: 0.009221\n",
      "Starting episode 620/1000\n",
      "  Step 1, Current reward: 0.024922\n",
      "  Step 2, Current reward: 0.024922\n",
      "  Step 3, Current reward: 0.024922\n",
      "  Step 4, Current reward: 0.024922\n",
      "  Step 5, Current reward: 0.024922\n",
      "  Step 6, Current reward: 0.024922\n",
      "  Step 7, Current reward: 0.024922\n",
      "  Step 8, Current reward: 0.024922\n",
      "  Step 9, Current reward: 0.024922\n",
      "  Step 10, Current reward: 0.024922\n",
      "  Step 11, Current reward: 0.024922\n",
      "  Step 12, Current reward: 0.024922\n",
      "Episode 620/1000 complete - Max Reward: 0.024922\n",
      "Starting episode 621/1000\n",
      "  Step 1, Current reward: 0.154634\n",
      "  Step 2, Current reward: 0.154634\n",
      "  Step 3, Current reward: 0.154634\n",
      "  Step 4, Current reward: 0.154634\n",
      "  Step 5, Current reward: 0.154634\n",
      "  Step 6, Current reward: 0.154634\n",
      "  Step 7, Current reward: 0.154634\n",
      "  Step 8, Current reward: 0.154634\n",
      "  Step 9, Current reward: 0.154634\n",
      "  Step 10, Current reward: 0.154634\n",
      "  Step 11, Current reward: 0.154634\n",
      "  Step 12, Current reward: 0.154634\n",
      "Episode 621/1000 complete - Max Reward: 0.154634\n",
      "Starting episode 622/1000\n",
      "  Step 1, Current reward: 0.031485\n",
      "  Step 2, Current reward: 0.031485\n",
      "  Step 3, Current reward: 0.031485\n",
      "  Step 4, Current reward: 0.031485\n",
      "  Step 5, Current reward: 0.031485\n",
      "  Step 6, Current reward: 0.031485\n",
      "  Step 7, Current reward: 0.031485\n",
      "  Step 8, Current reward: 0.031485\n",
      "  Step 9, Current reward: 0.031485\n",
      "  Step 10, Current reward: 0.031485\n",
      "  Step 11, Current reward: 0.031485\n",
      "  Step 12, Current reward: 0.031485\n",
      "Episode 622/1000 complete - Max Reward: 0.031485\n",
      "Starting episode 623/1000\n",
      "  Step 1, Current reward: 0.043768\n",
      "  Step 2, Current reward: 0.043768\n",
      "  Step 3, Current reward: 0.043768\n",
      "  Step 4, Current reward: 0.043768\n",
      "  Step 5, Current reward: 0.043768\n",
      "  Step 6, Current reward: 0.043768\n",
      "  Step 7, Current reward: 0.043768\n",
      "  Step 8, Current reward: 0.043768\n",
      "  Step 9, Current reward: 0.043768\n",
      "  Step 10, Current reward: 0.043768\n",
      "  Step 11, Current reward: 0.043768\n",
      "  Step 12, Current reward: 0.043768\n",
      "Episode 623/1000 complete - Max Reward: 0.043768\n",
      "Starting episode 624/1000\n",
      "  Step 1, Current reward: 0.000574\n",
      "  Step 2, Current reward: 0.000574\n",
      "  Step 3, Current reward: 0.000574\n",
      "  Step 4, Current reward: 0.000574\n",
      "  Step 5, Current reward: 0.000574\n",
      "  Step 6, Current reward: 0.000574\n",
      "  Step 7, Current reward: 0.000574\n",
      "  Step 8, Current reward: 0.000574\n",
      "  Step 9, Current reward: 0.000574\n",
      "  Step 10, Current reward: 0.000574\n",
      "  Step 11, Current reward: 0.000574\n",
      "  Step 12, Current reward: 0.000574\n",
      "Episode 624/1000 complete - Max Reward: 0.000574\n",
      "Starting episode 625/1000\n",
      "  Step 1, Current reward: 0.005886\n",
      "  Step 2, Current reward: 0.005886\n",
      "  Step 3, Current reward: 0.005886\n",
      "  Step 4, Current reward: 0.005886\n",
      "  Step 5, Current reward: 0.005886\n",
      "  Step 6, Current reward: 0.005886\n",
      "  Step 7, Current reward: 0.005886\n",
      "  Step 8, Current reward: 0.005886\n",
      "  Step 9, Current reward: 0.005886\n",
      "  Step 10, Current reward: 0.005886\n",
      "  Step 11, Current reward: 0.005886\n",
      "  Step 12, Current reward: 0.005886\n",
      "Episode 625/1000 complete - Max Reward: 0.005886\n",
      "Starting episode 626/1000\n",
      "  Step 1, Current reward: 0.032651\n",
      "  Step 2, Current reward: 0.032651\n",
      "  Step 3, Current reward: 0.032651\n",
      "  Step 4, Current reward: 0.032651\n",
      "  Step 5, Current reward: 0.032651\n",
      "  Step 6, Current reward: 0.032651\n",
      "  Step 7, Current reward: 0.032651\n",
      "  Step 8, Current reward: 0.032651\n",
      "  Step 9, Current reward: 0.032651\n",
      "  Step 10, Current reward: 0.032651\n",
      "  Step 11, Current reward: 0.032651\n",
      "  Step 12, Current reward: 0.032651\n",
      "Episode 626/1000 complete - Max Reward: 0.032651\n",
      "Starting episode 627/1000\n",
      "  Step 1, Current reward: 0.035784\n",
      "  Step 2, Current reward: 0.035784\n",
      "  Step 3, Current reward: 0.035784\n",
      "  Step 4, Current reward: 0.035784\n",
      "  Step 5, Current reward: 0.035784\n",
      "  Step 6, Current reward: 0.035784\n",
      "  Step 7, Current reward: 0.035784\n",
      "  Step 8, Current reward: 0.035784\n",
      "  Step 9, Current reward: 0.035784\n",
      "  Step 10, Current reward: 0.035784\n",
      "  Step 11, Current reward: 0.035784\n",
      "  Step 12, Current reward: 0.035784\n",
      "Episode 627/1000 complete - Max Reward: 0.035784\n",
      "Starting episode 628/1000\n",
      "  Step 1, Current reward: 0.011125\n",
      "  Step 2, Current reward: 0.011125\n",
      "  Step 3, Current reward: 0.011125\n",
      "  Step 4, Current reward: 0.011125\n",
      "  Step 5, Current reward: 0.011125\n",
      "  Step 6, Current reward: 0.011125\n",
      "  Step 7, Current reward: 0.011125\n",
      "  Step 8, Current reward: 0.011125\n",
      "  Step 9, Current reward: 0.011125\n",
      "  Step 10, Current reward: 0.011125\n",
      "  Step 11, Current reward: 0.011125\n",
      "  Step 12, Current reward: 0.011125\n",
      "Episode 628/1000 complete - Max Reward: 0.011125\n",
      "Starting episode 629/1000\n",
      "  Step 1, Current reward: 0.001219\n",
      "  Step 2, Current reward: 0.001219\n",
      "  Step 3, Current reward: 0.001219\n",
      "  Step 4, Current reward: 0.001219\n",
      "  Step 5, Current reward: 0.001219\n",
      "  Step 6, Current reward: 0.001219\n",
      "  Step 7, Current reward: 0.001219\n",
      "  Step 8, Current reward: 0.001219\n",
      "  Step 9, Current reward: 0.001219\n",
      "  Step 10, Current reward: 0.001219\n",
      "  Step 11, Current reward: 0.001219\n",
      "  Step 12, Current reward: 0.001219\n",
      "Episode 629/1000 complete - Max Reward: 0.001219\n",
      "Starting episode 630/1000\n",
      "  Step 1, Current reward: 0.018804\n",
      "  Step 2, Current reward: 0.018804\n",
      "  Step 3, Current reward: 0.018804\n",
      "  Step 4, Current reward: 0.018804\n",
      "  Step 5, Current reward: 0.018804\n",
      "  Step 6, Current reward: 0.018804\n",
      "  Step 7, Current reward: 0.018804\n",
      "  Step 8, Current reward: 0.018804\n",
      "  Step 9, Current reward: 0.018804\n",
      "  Step 10, Current reward: 0.018804\n",
      "  Step 11, Current reward: 0.018804\n",
      "  Step 12, Current reward: 0.018804\n",
      "Episode 630/1000 complete - Max Reward: 0.018804\n",
      "Starting episode 631/1000\n",
      "  Step 1, Current reward: 0.003164\n",
      "  Step 2, Current reward: 0.003164\n",
      "  Step 3, Current reward: 0.003164\n",
      "  Step 4, Current reward: 0.003164\n",
      "  Step 5, Current reward: 0.003164\n",
      "  Step 6, Current reward: 0.003164\n",
      "  Step 7, Current reward: 0.003164\n",
      "  Step 8, Current reward: 0.003164\n",
      "  Step 9, Current reward: 0.003164\n",
      "  Step 10, Current reward: 0.003164\n",
      "  Step 11, Current reward: 0.003164\n",
      "  Step 12, Current reward: 0.003164\n",
      "Episode 631/1000 complete - Max Reward: 0.003164\n",
      "Starting episode 632/1000\n",
      "  Step 1, Current reward: 0.172442\n",
      "  Step 2, Current reward: 0.172442\n",
      "  Step 3, Current reward: 0.172442\n",
      "  Step 4, Current reward: 0.172442\n",
      "  Step 5, Current reward: 0.172442\n",
      "  Step 6, Current reward: 0.172442\n",
      "  Step 7, Current reward: 0.172442\n",
      "  Step 8, Current reward: 0.172442\n",
      "  Step 9, Current reward: 0.172442\n",
      "  Step 10, Current reward: 0.172442\n",
      "  Step 11, Current reward: 0.172442\n",
      "  Step 12, Current reward: 0.172442\n",
      "Episode 632/1000 complete - Max Reward: 0.172442\n",
      "Starting episode 633/1000\n",
      "  Step 1, Current reward: 0.026187\n",
      "  Step 2, Current reward: 0.026187\n",
      "  Step 3, Current reward: 0.026187\n",
      "  Step 4, Current reward: 0.026187\n",
      "  Step 5, Current reward: 0.026187\n",
      "  Step 6, Current reward: 0.026187\n",
      "  Step 7, Current reward: 0.026187\n",
      "  Step 8, Current reward: 0.026187\n",
      "  Step 9, Current reward: 0.026187\n",
      "  Step 10, Current reward: 0.026187\n",
      "  Step 11, Current reward: 0.026187\n",
      "  Step 12, Current reward: 0.026187\n",
      "Episode 633/1000 complete - Max Reward: 0.026187\n",
      "Starting episode 634/1000\n",
      "  Step 1, Current reward: 0.004077\n",
      "  Step 2, Current reward: 0.004077\n",
      "  Step 3, Current reward: 0.004077\n",
      "  Step 4, Current reward: 0.004077\n",
      "  Step 5, Current reward: 0.004077\n",
      "  Step 6, Current reward: 0.004077\n",
      "  Step 7, Current reward: 0.004077\n",
      "  Step 8, Current reward: 0.004077\n",
      "  Step 9, Current reward: 0.004077\n",
      "  Step 10, Current reward: 0.004077\n",
      "  Step 11, Current reward: 0.004077\n",
      "  Step 12, Current reward: 0.004077\n",
      "Episode 634/1000 complete - Max Reward: 0.004077\n",
      "Starting episode 635/1000\n",
      "  Step 1, Current reward: 0.018295\n",
      "  Step 2, Current reward: 0.018295\n",
      "  Step 3, Current reward: 0.018295\n",
      "  Step 4, Current reward: 0.018295\n",
      "  Step 5, Current reward: 0.018295\n",
      "  Step 6, Current reward: 0.018295\n",
      "  Step 7, Current reward: 0.018295\n",
      "  Step 8, Current reward: 0.018295\n",
      "  Step 9, Current reward: 0.018295\n",
      "  Step 10, Current reward: 0.018295\n",
      "  Step 11, Current reward: 0.018295\n",
      "  Step 12, Current reward: 0.018295\n",
      "Episode 635/1000 complete - Max Reward: 0.018295\n",
      "Starting episode 636/1000\n",
      "  Step 1, Current reward: 0.037634\n",
      "  Step 2, Current reward: 0.037634\n",
      "  Step 3, Current reward: 0.037634\n",
      "  Step 4, Current reward: 0.037634\n",
      "  Step 5, Current reward: 0.037634\n",
      "  Step 6, Current reward: 0.037634\n",
      "  Step 7, Current reward: 0.037634\n",
      "  Step 8, Current reward: 0.037634\n",
      "  Step 9, Current reward: 0.037634\n",
      "  Step 10, Current reward: 0.037634\n",
      "  Step 11, Current reward: 0.037634\n",
      "  Step 12, Current reward: 0.037634\n",
      "Episode 636/1000 complete - Max Reward: 0.037634\n",
      "Starting episode 637/1000\n",
      "  Step 1, Current reward: 0.003324\n",
      "  Step 2, Current reward: 0.003324\n",
      "  Step 3, Current reward: 0.003324\n",
      "  Step 4, Current reward: 0.003324\n",
      "  Step 5, Current reward: 0.003324\n",
      "  Step 6, Current reward: 0.003324\n",
      "  Step 7, Current reward: 0.003324\n",
      "  Step 8, Current reward: 0.003324\n",
      "  Step 9, Current reward: 0.003324\n",
      "  Step 10, Current reward: 0.003324\n",
      "  Step 11, Current reward: 0.003324\n",
      "  Step 12, Current reward: 0.003324\n",
      "Episode 637/1000 complete - Max Reward: 0.003324\n",
      "Starting episode 638/1000\n",
      "  Step 1, Current reward: 0.005619\n",
      "  Step 2, Current reward: 0.005619\n",
      "  Step 3, Current reward: 0.005619\n",
      "  Step 4, Current reward: 0.005619\n",
      "  Step 5, Current reward: 0.005619\n",
      "  Step 6, Current reward: 0.005619\n",
      "  Step 7, Current reward: 0.005619\n",
      "  Step 8, Current reward: 0.005619\n",
      "  Step 9, Current reward: 0.005619\n",
      "  Step 10, Current reward: 0.005619\n",
      "  Step 11, Current reward: 0.005619\n",
      "  Step 12, Current reward: 0.005619\n",
      "Episode 638/1000 complete - Max Reward: 0.005619\n",
      "Starting episode 639/1000\n",
      "  Step 1, Current reward: 0.007734\n",
      "  Step 2, Current reward: 0.007734\n",
      "  Step 3, Current reward: 0.007734\n",
      "  Step 4, Current reward: 0.007734\n",
      "  Step 5, Current reward: 0.007734\n",
      "  Step 6, Current reward: 0.007734\n",
      "  Step 7, Current reward: 0.007734\n",
      "  Step 8, Current reward: 0.007734\n",
      "  Step 9, Current reward: 0.007734\n",
      "  Step 10, Current reward: 0.007734\n",
      "  Step 11, Current reward: 0.007734\n",
      "  Step 12, Current reward: 0.007734\n",
      "Episode 639/1000 complete - Max Reward: 0.007734\n",
      "Starting episode 640/1000\n",
      "  Step 1, Current reward: 0.022848\n",
      "  Step 2, Current reward: 0.022848\n",
      "  Step 3, Current reward: 0.022848\n",
      "  Step 4, Current reward: 0.022848\n",
      "  Step 5, Current reward: 0.022848\n",
      "  Step 6, Current reward: 0.022848\n",
      "  Step 7, Current reward: 0.022848\n",
      "  Step 8, Current reward: 0.022848\n",
      "  Step 9, Current reward: 0.022848\n",
      "  Step 10, Current reward: 0.022848\n",
      "  Step 11, Current reward: 0.022848\n",
      "  Step 12, Current reward: 0.022848\n",
      "Episode 640/1000 complete - Max Reward: 0.022848\n",
      "Starting episode 641/1000\n",
      "  Step 1, Current reward: 0.004358\n",
      "  Step 2, Current reward: 0.004358\n",
      "  Step 3, Current reward: 0.004358\n",
      "  Step 4, Current reward: 0.004358\n",
      "  Step 5, Current reward: 0.004358\n",
      "  Step 6, Current reward: 0.004358\n",
      "  Step 7, Current reward: 0.004358\n",
      "  Step 8, Current reward: 0.004358\n",
      "  Step 9, Current reward: 0.004358\n",
      "  Step 10, Current reward: 0.004358\n",
      "  Step 11, Current reward: 0.004358\n",
      "  Step 12, Current reward: 0.004358\n",
      "Episode 641/1000 complete - Max Reward: 0.004358\n",
      "Starting episode 642/1000\n",
      "  Step 1, Current reward: 0.045137\n",
      "  Step 2, Current reward: 0.045137\n",
      "  Step 3, Current reward: 0.045137\n",
      "  Step 4, Current reward: 0.045137\n",
      "  Step 5, Current reward: 0.045137\n",
      "  Step 6, Current reward: 0.045137\n",
      "  Step 7, Current reward: 0.045137\n",
      "  Step 8, Current reward: 0.045137\n",
      "  Step 9, Current reward: 0.045137\n",
      "  Step 10, Current reward: 0.045137\n",
      "  Step 11, Current reward: 0.045137\n",
      "  Step 12, Current reward: 0.045137\n",
      "Episode 642/1000 complete - Max Reward: 0.045137\n",
      "Starting episode 643/1000\n",
      "  Step 1, Current reward: 0.105553\n",
      "  Step 2, Current reward: 0.105553\n",
      "  Step 3, Current reward: 0.105553\n",
      "  Step 4, Current reward: 0.105553\n",
      "  Step 5, Current reward: 0.105553\n",
      "  Step 6, Current reward: 0.105553\n",
      "  Step 7, Current reward: 0.105553\n",
      "  Step 8, Current reward: 0.105553\n",
      "  Step 9, Current reward: 0.105553\n",
      "  Step 10, Current reward: 0.105553\n",
      "  Step 11, Current reward: 0.105553\n",
      "  Step 12, Current reward: 0.105553\n",
      "Episode 643/1000 complete - Max Reward: 0.105553\n",
      "Starting episode 644/1000\n",
      "  Step 1, Current reward: 0.055016\n",
      "  Step 2, Current reward: 0.055016\n",
      "  Step 3, Current reward: 0.055016\n",
      "  Step 4, Current reward: 0.055016\n",
      "  Step 5, Current reward: 0.055016\n",
      "  Step 6, Current reward: 0.055016\n",
      "  Step 7, Current reward: 0.055016\n",
      "  Step 8, Current reward: 0.055016\n",
      "  Step 9, Current reward: 0.055016\n",
      "  Step 10, Current reward: 0.055016\n",
      "  Step 11, Current reward: 0.055016\n",
      "  Step 12, Current reward: 0.055016\n",
      "Episode 644/1000 complete - Max Reward: 0.055016\n",
      "Starting episode 645/1000\n",
      "  Step 1, Current reward: 0.025103\n",
      "  Step 2, Current reward: 0.025103\n",
      "  Step 3, Current reward: 0.025103\n",
      "  Step 4, Current reward: 0.025103\n",
      "  Step 5, Current reward: 0.025103\n",
      "  Step 6, Current reward: 0.025103\n",
      "  Step 7, Current reward: 0.025103\n",
      "  Step 8, Current reward: 0.025103\n",
      "  Step 9, Current reward: 0.025103\n",
      "  Step 10, Current reward: 0.025103\n",
      "  Step 11, Current reward: 0.025103\n",
      "  Step 12, Current reward: 0.025103\n",
      "Episode 645/1000 complete - Max Reward: 0.025103\n",
      "Starting episode 646/1000\n",
      "  Step 1, Current reward: 0.041309\n",
      "  Step 2, Current reward: 0.041309\n",
      "  Step 3, Current reward: 0.041309\n",
      "  Step 4, Current reward: 0.041309\n",
      "  Step 5, Current reward: 0.041309\n",
      "  Step 6, Current reward: 0.041309\n",
      "  Step 7, Current reward: 0.041309\n",
      "  Step 8, Current reward: 0.041309\n",
      "  Step 9, Current reward: 0.041309\n",
      "  Step 10, Current reward: 0.041309\n",
      "  Step 11, Current reward: 0.041309\n",
      "  Step 12, Current reward: 0.041309\n",
      "Episode 646/1000 complete - Max Reward: 0.041309\n",
      "Starting episode 647/1000\n",
      "  Step 1, Current reward: 0.015764\n",
      "  Step 2, Current reward: 0.015764\n",
      "  Step 3, Current reward: 0.015764\n",
      "  Step 4, Current reward: 0.015764\n",
      "  Step 5, Current reward: 0.015764\n",
      "  Step 6, Current reward: 0.015764\n",
      "  Step 7, Current reward: 0.015764\n",
      "  Step 8, Current reward: 0.015764\n",
      "  Step 9, Current reward: 0.015764\n",
      "  Step 10, Current reward: 0.015764\n",
      "  Step 11, Current reward: 0.015764\n",
      "  Step 12, Current reward: 0.015764\n",
      "Episode 647/1000 complete - Max Reward: 0.015764\n",
      "Starting episode 648/1000\n",
      "  Step 1, Current reward: 0.008966\n",
      "  Step 2, Current reward: 0.008966\n",
      "  Step 3, Current reward: 0.008966\n",
      "  Step 4, Current reward: 0.008966\n",
      "  Step 5, Current reward: 0.008966\n",
      "  Step 6, Current reward: 0.008966\n",
      "  Step 7, Current reward: 0.008966\n",
      "  Step 8, Current reward: 0.008966\n",
      "  Step 9, Current reward: 0.008966\n",
      "  Step 10, Current reward: 0.008966\n",
      "  Step 11, Current reward: 0.008966\n",
      "  Step 12, Current reward: 0.008966\n",
      "Episode 648/1000 complete - Max Reward: 0.008966\n",
      "Starting episode 649/1000\n",
      "  Step 1, Current reward: 0.065525\n",
      "  Step 2, Current reward: 0.065525\n",
      "  Step 3, Current reward: 0.065525\n",
      "  Step 4, Current reward: 0.065525\n",
      "  Step 5, Current reward: 0.065525\n",
      "  Step 6, Current reward: 0.065525\n",
      "  Step 7, Current reward: 0.065525\n",
      "  Step 8, Current reward: 0.065525\n",
      "  Step 9, Current reward: 0.065525\n",
      "  Step 10, Current reward: 0.065525\n",
      "  Step 11, Current reward: 0.065525\n",
      "  Step 12, Current reward: 0.065525\n",
      "Episode 649/1000 complete - Max Reward: 0.065525\n",
      "Starting episode 650/1000\n",
      "  Step 1, Current reward: 0.026337\n",
      "  Step 2, Current reward: 0.026337\n",
      "  Step 3, Current reward: 0.026337\n",
      "  Step 4, Current reward: 0.026337\n",
      "  Step 5, Current reward: 0.026337\n",
      "  Step 6, Current reward: 0.026337\n",
      "  Step 7, Current reward: 0.026337\n",
      "  Step 8, Current reward: 0.026337\n",
      "  Step 9, Current reward: 0.026337\n",
      "  Step 10, Current reward: 0.026337\n",
      "  Step 11, Current reward: 0.026337\n",
      "  Step 12, Current reward: 0.026337\n",
      "Episode 650/1000 complete - Max Reward: 0.026337\n",
      "Starting episode 651/1000\n",
      "  Step 1, Current reward: 0.013986\n",
      "  Step 2, Current reward: 0.013986\n",
      "  Step 3, Current reward: 0.013986\n",
      "  Step 4, Current reward: 0.013986\n",
      "  Step 5, Current reward: 0.013986\n",
      "  Step 6, Current reward: 0.013986\n",
      "  Step 7, Current reward: 0.013986\n",
      "  Step 8, Current reward: 0.013986\n",
      "  Step 9, Current reward: 0.013986\n",
      "  Step 10, Current reward: 0.013986\n",
      "  Step 11, Current reward: 0.013986\n",
      "  Step 12, Current reward: 0.013986\n",
      "Episode 651/1000 complete - Max Reward: 0.013986\n",
      "Starting episode 652/1000\n",
      "  Step 1, Current reward: 0.047833\n",
      "  Step 2, Current reward: 0.047833\n",
      "  Step 3, Current reward: 0.047833\n",
      "  Step 4, Current reward: 0.047833\n",
      "  Step 5, Current reward: 0.047833\n",
      "  Step 6, Current reward: 0.047833\n",
      "  Step 7, Current reward: 0.047833\n",
      "  Step 8, Current reward: 0.047833\n",
      "  Step 9, Current reward: 0.047833\n",
      "  Step 10, Current reward: 0.047833\n",
      "  Step 11, Current reward: 0.047833\n",
      "  Step 12, Current reward: 0.047833\n",
      "Episode 652/1000 complete - Max Reward: 0.047833\n",
      "Starting episode 653/1000\n",
      "  Step 1, Current reward: 0.057548\n",
      "  Step 2, Current reward: 0.057548\n",
      "  Step 3, Current reward: 0.057548\n",
      "  Step 4, Current reward: 0.057548\n",
      "  Step 5, Current reward: 0.057548\n",
      "  Step 6, Current reward: 0.057548\n",
      "  Step 7, Current reward: 0.057548\n",
      "  Step 8, Current reward: 0.057548\n",
      "  Step 9, Current reward: 0.057548\n",
      "  Step 10, Current reward: 0.057548\n",
      "  Step 11, Current reward: 0.057548\n",
      "  Step 12, Current reward: 0.057548\n",
      "Episode 653/1000 complete - Max Reward: 0.057548\n",
      "Starting episode 654/1000\n",
      "  Step 1, Current reward: 0.005317\n",
      "  Step 2, Current reward: 0.005144\n",
      "  Step 3, Current reward: 0.004881\n",
      "  Step 4, Current reward: 0.004568\n",
      "  Step 5, Current reward: 0.004285\n",
      "  Step 6, Current reward: 0.004101\n",
      "  Step 7, Current reward: 0.004027\n",
      "  Step 8, Current reward: 0.004027\n",
      "  Step 9, Current reward: 0.004027\n",
      "  Step 10, Current reward: 0.004027\n",
      "  Step 11, Current reward: 0.004027\n",
      "  Step 12, Current reward: 0.004027\n",
      "Episode 654/1000 complete - Max Reward: 0.005317\n",
      "Starting episode 655/1000\n",
      "  Step 1, Current reward: 0.032820\n",
      "  Step 2, Current reward: 0.032820\n",
      "  Step 3, Current reward: 0.032820\n",
      "  Step 4, Current reward: 0.032820\n",
      "  Step 5, Current reward: 0.032820\n",
      "  Step 6, Current reward: 0.032820\n",
      "  Step 7, Current reward: 0.032820\n",
      "  Step 8, Current reward: 0.032820\n",
      "  Step 9, Current reward: 0.032820\n",
      "  Step 10, Current reward: 0.032820\n",
      "  Step 11, Current reward: 0.032820\n",
      "  Step 12, Current reward: 0.032820\n",
      "Episode 655/1000 complete - Max Reward: 0.032820\n",
      "Starting episode 656/1000\n",
      "  Step 1, Current reward: 0.010327\n",
      "  Step 2, Current reward: 0.010327\n",
      "  Step 3, Current reward: 0.010327\n",
      "  Step 4, Current reward: 0.010327\n",
      "  Step 5, Current reward: 0.010327\n",
      "  Step 6, Current reward: 0.010327\n",
      "  Step 7, Current reward: 0.010327\n",
      "  Step 8, Current reward: 0.010327\n",
      "  Step 9, Current reward: 0.010327\n",
      "  Step 10, Current reward: 0.010327\n",
      "  Step 11, Current reward: 0.010327\n",
      "  Step 12, Current reward: 0.010327\n",
      "Episode 656/1000 complete - Max Reward: 0.010327\n",
      "Starting episode 657/1000\n",
      "  Step 1, Current reward: 0.001240\n",
      "  Step 2, Current reward: 0.001240\n",
      "  Step 3, Current reward: 0.001240\n",
      "  Step 4, Current reward: 0.001240\n",
      "  Step 5, Current reward: 0.001240\n",
      "  Step 6, Current reward: 0.001240\n",
      "  Step 7, Current reward: 0.001240\n",
      "  Step 8, Current reward: 0.001240\n",
      "  Step 9, Current reward: 0.001240\n",
      "  Step 10, Current reward: 0.001240\n",
      "  Step 11, Current reward: 0.001240\n",
      "  Step 12, Current reward: 0.001240\n",
      "Episode 657/1000 complete - Max Reward: 0.001240\n",
      "Starting episode 658/1000\n",
      "  Step 1, Current reward: 0.014266\n",
      "  Step 2, Current reward: 0.014266\n",
      "  Step 3, Current reward: 0.014266\n",
      "  Step 4, Current reward: 0.014266\n",
      "  Step 5, Current reward: 0.014266\n",
      "  Step 6, Current reward: 0.014266\n",
      "  Step 7, Current reward: 0.014266\n",
      "  Step 8, Current reward: 0.014266\n",
      "  Step 9, Current reward: 0.014266\n",
      "  Step 10, Current reward: 0.014266\n",
      "  Step 11, Current reward: 0.014266\n",
      "  Step 12, Current reward: 0.014266\n",
      "Episode 658/1000 complete - Max Reward: 0.014266\n",
      "Starting episode 659/1000\n",
      "  Step 1, Current reward: 0.003088\n",
      "  Step 2, Current reward: 0.003088\n",
      "  Step 3, Current reward: 0.003088\n",
      "  Step 4, Current reward: 0.003088\n",
      "  Step 5, Current reward: 0.003088\n",
      "  Step 6, Current reward: 0.003088\n",
      "  Step 7, Current reward: 0.003088\n",
      "  Step 8, Current reward: 0.003088\n",
      "  Step 9, Current reward: 0.003088\n",
      "  Step 10, Current reward: 0.003088\n",
      "  Step 11, Current reward: 0.003088\n",
      "  Step 12, Current reward: 0.003088\n",
      "Episode 659/1000 complete - Max Reward: 0.003088\n",
      "Starting episode 660/1000\n",
      "  Step 1, Current reward: 0.014621\n",
      "  Step 2, Current reward: 0.014621\n",
      "  Step 3, Current reward: 0.014621\n",
      "  Step 4, Current reward: 0.014621\n",
      "  Step 5, Current reward: 0.014621\n",
      "  Step 6, Current reward: 0.014621\n",
      "  Step 7, Current reward: 0.014621\n",
      "  Step 8, Current reward: 0.014621\n",
      "  Step 9, Current reward: 0.014621\n",
      "  Step 10, Current reward: 0.014621\n",
      "  Step 11, Current reward: 0.014621\n",
      "  Step 12, Current reward: 0.014621\n",
      "Episode 660/1000 complete - Max Reward: 0.014621\n",
      "Starting episode 661/1000\n",
      "  Step 1, Current reward: 0.007677\n",
      "  Step 2, Current reward: 0.007677\n",
      "  Step 3, Current reward: 0.007677\n",
      "  Step 4, Current reward: 0.007677\n",
      "  Step 5, Current reward: 0.007677\n",
      "  Step 6, Current reward: 0.007677\n",
      "  Step 7, Current reward: 0.007677\n",
      "  Step 8, Current reward: 0.007677\n",
      "  Step 9, Current reward: 0.007677\n",
      "  Step 10, Current reward: 0.007677\n",
      "  Step 11, Current reward: 0.007677\n",
      "  Step 12, Current reward: 0.007677\n",
      "Episode 661/1000 complete - Max Reward: 0.007677\n",
      "Starting episode 662/1000\n",
      "  Step 1, Current reward: 0.015615\n",
      "  Step 2, Current reward: 0.015615\n",
      "  Step 3, Current reward: 0.015615\n",
      "  Step 4, Current reward: 0.015615\n",
      "  Step 5, Current reward: 0.015615\n",
      "  Step 6, Current reward: 0.015615\n",
      "  Step 7, Current reward: 0.015615\n",
      "  Step 8, Current reward: 0.015615\n",
      "  Step 9, Current reward: 0.015615\n",
      "  Step 10, Current reward: 0.015615\n",
      "  Step 11, Current reward: 0.015615\n",
      "  Step 12, Current reward: 0.015615\n",
      "Episode 662/1000 complete - Max Reward: 0.015615\n",
      "Starting episode 663/1000\n",
      "  Step 1, Current reward: 0.024060\n",
      "  Step 2, Current reward: 0.024060\n",
      "  Step 3, Current reward: 0.024060\n",
      "  Step 4, Current reward: 0.024060\n",
      "  Step 5, Current reward: 0.024060\n",
      "  Step 6, Current reward: 0.024060\n",
      "  Step 7, Current reward: 0.024060\n",
      "  Step 8, Current reward: 0.024060\n",
      "  Step 9, Current reward: 0.024060\n",
      "  Step 10, Current reward: 0.024060\n",
      "  Step 11, Current reward: 0.024060\n",
      "  Step 12, Current reward: 0.024060\n",
      "Episode 663/1000 complete - Max Reward: 0.024060\n",
      "Starting episode 664/1000\n",
      "  Step 1, Current reward: 0.076523\n",
      "  Step 2, Current reward: 0.076523\n",
      "  Step 3, Current reward: 0.076523\n",
      "  Step 4, Current reward: 0.076523\n",
      "  Step 5, Current reward: 0.076523\n",
      "  Step 6, Current reward: 0.076523\n",
      "  Step 7, Current reward: 0.076523\n",
      "  Step 8, Current reward: 0.076523\n",
      "  Step 9, Current reward: 0.076523\n",
      "  Step 10, Current reward: 0.076523\n",
      "  Step 11, Current reward: 0.076523\n",
      "  Step 12, Current reward: 0.076523\n",
      "Episode 664/1000 complete - Max Reward: 0.076523\n",
      "Starting episode 665/1000\n",
      "  Step 1, Current reward: 0.020054\n",
      "  Step 2, Current reward: 0.020054\n",
      "  Step 3, Current reward: 0.020054\n",
      "  Step 4, Current reward: 0.020054\n",
      "  Step 5, Current reward: 0.020054\n",
      "  Step 6, Current reward: 0.020054\n",
      "  Step 7, Current reward: 0.020054\n",
      "  Step 8, Current reward: 0.020054\n",
      "  Step 9, Current reward: 0.020054\n",
      "  Step 10, Current reward: 0.020054\n",
      "  Step 11, Current reward: 0.020054\n",
      "  Step 12, Current reward: 0.020054\n",
      "Episode 665/1000 complete - Max Reward: 0.020054\n",
      "Starting episode 666/1000\n",
      "  Step 1, Current reward: 0.019770\n",
      "  Step 2, Current reward: 0.019770\n",
      "  Step 3, Current reward: 0.019770\n",
      "  Step 4, Current reward: 0.019770\n",
      "  Step 5, Current reward: 0.019770\n",
      "  Step 6, Current reward: 0.019770\n",
      "  Step 7, Current reward: 0.019770\n",
      "  Step 8, Current reward: 0.019770\n",
      "  Step 9, Current reward: 0.019770\n",
      "  Step 10, Current reward: 0.019770\n",
      "  Step 11, Current reward: 0.019770\n",
      "  Step 12, Current reward: 0.019770\n",
      "Episode 666/1000 complete - Max Reward: 0.019770\n",
      "Starting episode 667/1000\n",
      "  Step 1, Current reward: 0.033937\n",
      "  Step 2, Current reward: 0.033937\n",
      "  Step 3, Current reward: 0.033937\n",
      "  Step 4, Current reward: 0.033937\n",
      "  Step 5, Current reward: 0.033937\n",
      "  Step 6, Current reward: 0.033937\n",
      "  Step 7, Current reward: 0.033937\n",
      "  Step 8, Current reward: 0.033937\n",
      "  Step 9, Current reward: 0.033937\n",
      "  Step 10, Current reward: 0.033937\n",
      "  Step 11, Current reward: 0.033937\n",
      "  Step 12, Current reward: 0.033937\n",
      "Episode 667/1000 complete - Max Reward: 0.033937\n",
      "Starting episode 668/1000\n",
      "  Step 1, Current reward: 0.002105\n",
      "  Step 2, Current reward: 0.002105\n",
      "  Step 3, Current reward: 0.002105\n",
      "  Step 4, Current reward: 0.002105\n",
      "  Step 5, Current reward: 0.002105\n",
      "  Step 6, Current reward: 0.002105\n",
      "  Step 7, Current reward: 0.002105\n",
      "  Step 8, Current reward: 0.002105\n",
      "  Step 9, Current reward: 0.002105\n",
      "  Step 10, Current reward: 0.002105\n",
      "  Step 11, Current reward: 0.002105\n",
      "  Step 12, Current reward: 0.002105\n",
      "Episode 668/1000 complete - Max Reward: 0.002105\n",
      "Starting episode 669/1000\n",
      "  Step 1, Current reward: 0.009997\n",
      "  Step 2, Current reward: 0.009997\n",
      "  Step 3, Current reward: 0.009997\n",
      "  Step 4, Current reward: 0.009997\n",
      "  Step 5, Current reward: 0.009997\n",
      "  Step 6, Current reward: 0.009997\n",
      "  Step 7, Current reward: 0.009997\n",
      "  Step 8, Current reward: 0.009997\n",
      "  Step 9, Current reward: 0.009997\n",
      "  Step 10, Current reward: 0.009997\n",
      "  Step 11, Current reward: 0.009997\n",
      "  Step 12, Current reward: 0.009997\n",
      "Episode 669/1000 complete - Max Reward: 0.009997\n",
      "Starting episode 670/1000\n",
      "  Step 1, Current reward: 0.018975\n",
      "  Step 2, Current reward: 0.018975\n",
      "  Step 3, Current reward: 0.018975\n",
      "  Step 4, Current reward: 0.018975\n",
      "  Step 5, Current reward: 0.018975\n",
      "  Step 6, Current reward: 0.018975\n",
      "  Step 7, Current reward: 0.018975\n",
      "  Step 8, Current reward: 0.018975\n",
      "  Step 9, Current reward: 0.018975\n",
      "  Step 10, Current reward: 0.018975\n",
      "  Step 11, Current reward: 0.018975\n",
      "  Step 12, Current reward: 0.018975\n",
      "Episode 670/1000 complete - Max Reward: 0.018975\n",
      "Starting episode 671/1000\n",
      "  Step 1, Current reward: 0.011015\n",
      "  Step 2, Current reward: 0.011015\n",
      "  Step 3, Current reward: 0.011015\n",
      "  Step 4, Current reward: 0.011015\n",
      "  Step 5, Current reward: 0.011015\n",
      "  Step 6, Current reward: 0.011015\n",
      "  Step 7, Current reward: 0.011015\n",
      "  Step 8, Current reward: 0.011015\n",
      "  Step 9, Current reward: 0.011015\n",
      "  Step 10, Current reward: 0.011015\n",
      "  Step 11, Current reward: 0.011015\n",
      "  Step 12, Current reward: 0.011015\n",
      "Episode 671/1000 complete - Max Reward: 0.011015\n",
      "Starting episode 672/1000\n",
      "  Step 1, Current reward: 0.202278\n",
      "  Step 2, Current reward: 0.202278\n",
      "  Step 3, Current reward: 0.202278\n",
      "  Step 4, Current reward: 0.202278\n",
      "  Step 5, Current reward: 0.202278\n",
      "  Step 6, Current reward: 0.202278\n",
      "  Step 7, Current reward: 0.202278\n",
      "  Step 8, Current reward: 0.202278\n",
      "  Step 9, Current reward: 0.202278\n",
      "  Step 10, Current reward: 0.202278\n",
      "  Step 11, Current reward: 0.202278\n",
      "  Step 12, Current reward: 0.202278\n",
      "Episode 672/1000 complete - Max Reward: 0.202278\n",
      "Starting episode 673/1000\n",
      "  Step 1, Current reward: 0.022454\n",
      "  Step 2, Current reward: 0.022454\n",
      "  Step 3, Current reward: 0.022454\n",
      "  Step 4, Current reward: 0.022454\n",
      "  Step 5, Current reward: 0.022454\n",
      "  Step 6, Current reward: 0.022454\n",
      "  Step 7, Current reward: 0.022454\n",
      "  Step 8, Current reward: 0.022454\n",
      "  Step 9, Current reward: 0.022454\n",
      "  Step 10, Current reward: 0.022454\n",
      "  Step 11, Current reward: 0.022454\n",
      "  Step 12, Current reward: 0.022454\n",
      "Episode 673/1000 complete - Max Reward: 0.022454\n",
      "Starting episode 674/1000\n",
      "  Step 1, Current reward: 0.000170\n",
      "  Step 2, Current reward: 0.000170\n",
      "  Step 3, Current reward: 0.000170\n",
      "  Step 4, Current reward: 0.000170\n",
      "  Step 5, Current reward: 0.000170\n",
      "  Step 6, Current reward: 0.000170\n",
      "  Step 7, Current reward: 0.000170\n",
      "  Step 8, Current reward: 0.000170\n",
      "  Step 9, Current reward: 0.000170\n",
      "  Step 10, Current reward: 0.000170\n",
      "  Step 11, Current reward: 0.000170\n",
      "  Step 12, Current reward: 0.000170\n",
      "Episode 674/1000 complete - Max Reward: 0.000170\n",
      "Starting episode 675/1000\n",
      "  Step 1, Current reward: 0.006836\n",
      "  Step 2, Current reward: 0.006836\n",
      "  Step 3, Current reward: 0.006836\n",
      "  Step 4, Current reward: 0.006836\n",
      "  Step 5, Current reward: 0.006836\n",
      "  Step 6, Current reward: 0.006836\n",
      "  Step 7, Current reward: 0.006836\n",
      "  Step 8, Current reward: 0.006836\n",
      "  Step 9, Current reward: 0.006836\n",
      "  Step 10, Current reward: 0.006836\n",
      "  Step 11, Current reward: 0.006836\n",
      "  Step 12, Current reward: 0.006836\n",
      "Episode 675/1000 complete - Max Reward: 0.006836\n",
      "Starting episode 676/1000\n",
      "  Step 1, Current reward: 0.179887\n",
      "  Step 2, Current reward: 0.179887\n",
      "  Step 3, Current reward: 0.179887\n",
      "  Step 4, Current reward: 0.179887\n",
      "  Step 5, Current reward: 0.179887\n",
      "  Step 6, Current reward: 0.179887\n",
      "  Step 7, Current reward: 0.179887\n",
      "  Step 8, Current reward: 0.179887\n",
      "  Step 9, Current reward: 0.179887\n",
      "  Step 10, Current reward: 0.179887\n",
      "  Step 11, Current reward: 0.179887\n",
      "  Step 12, Current reward: 0.179887\n",
      "Episode 676/1000 complete - Max Reward: 0.179887\n",
      "Starting episode 677/1000\n",
      "  Step 1, Current reward: 0.105109\n",
      "  Step 2, Current reward: 0.105109\n",
      "  Step 3, Current reward: 0.105109\n",
      "  Step 4, Current reward: 0.105109\n",
      "  Step 5, Current reward: 0.105109\n",
      "  Step 6, Current reward: 0.105109\n",
      "  Step 7, Current reward: 0.105109\n",
      "  Step 8, Current reward: 0.105109\n",
      "  Step 9, Current reward: 0.105109\n",
      "  Step 10, Current reward: 0.105109\n",
      "  Step 11, Current reward: 0.105109\n",
      "  Step 12, Current reward: 0.105109\n",
      "Episode 677/1000 complete - Max Reward: 0.105109\n",
      "Starting episode 678/1000\n",
      "  Step 1, Current reward: 0.002285\n",
      "  Step 2, Current reward: 0.002285\n",
      "  Step 3, Current reward: 0.002285\n",
      "  Step 4, Current reward: 0.002285\n",
      "  Step 5, Current reward: 0.002285\n",
      "  Step 6, Current reward: 0.002285\n",
      "  Step 7, Current reward: 0.002285\n",
      "  Step 8, Current reward: 0.002285\n",
      "  Step 9, Current reward: 0.002285\n",
      "  Step 10, Current reward: 0.002285\n",
      "  Step 11, Current reward: 0.002285\n",
      "  Step 12, Current reward: 0.002285\n",
      "Episode 678/1000 complete - Max Reward: 0.002285\n",
      "Starting episode 679/1000\n",
      "  Step 1, Current reward: 0.079900\n",
      "  Step 2, Current reward: 0.079900\n",
      "  Step 3, Current reward: 0.079900\n",
      "  Step 4, Current reward: 0.079900\n",
      "  Step 5, Current reward: 0.079900\n",
      "  Step 6, Current reward: 0.079900\n",
      "  Step 7, Current reward: 0.079900\n",
      "  Step 8, Current reward: 0.079900\n",
      "  Step 9, Current reward: 0.079900\n",
      "  Step 10, Current reward: 0.079900\n",
      "  Step 11, Current reward: 0.079900\n",
      "  Step 12, Current reward: 0.079900\n",
      "Episode 679/1000 complete - Max Reward: 0.079900\n",
      "Starting episode 680/1000\n",
      "  Step 1, Current reward: 0.080533\n",
      "  Step 2, Current reward: 0.080533\n",
      "  Step 3, Current reward: 0.080533\n",
      "  Step 4, Current reward: 0.080533\n",
      "  Step 5, Current reward: 0.080533\n",
      "  Step 6, Current reward: 0.080533\n",
      "  Step 7, Current reward: 0.080533\n",
      "  Step 8, Current reward: 0.080533\n",
      "  Step 9, Current reward: 0.080533\n",
      "  Step 10, Current reward: 0.080533\n",
      "  Step 11, Current reward: 0.080533\n",
      "  Step 12, Current reward: 0.080533\n",
      "Episode 680/1000 complete - Max Reward: 0.080533\n",
      "Starting episode 681/1000\n",
      "  Step 1, Current reward: 0.059783\n",
      "  Step 2, Current reward: 0.059783\n",
      "  Step 3, Current reward: 0.059783\n",
      "  Step 4, Current reward: 0.059783\n",
      "  Step 5, Current reward: 0.059783\n",
      "  Step 6, Current reward: 0.059783\n",
      "  Step 7, Current reward: 0.059783\n",
      "  Step 8, Current reward: 0.059783\n",
      "  Step 9, Current reward: 0.059783\n",
      "  Step 10, Current reward: 0.059783\n",
      "  Step 11, Current reward: 0.059783\n",
      "  Step 12, Current reward: 0.059783\n",
      "Episode 681/1000 complete - Max Reward: 0.059783\n",
      "Starting episode 682/1000\n",
      "  Step 1, Current reward: 0.005862\n",
      "  Step 2, Current reward: 0.005862\n",
      "  Step 3, Current reward: 0.005862\n",
      "  Step 4, Current reward: 0.005862\n",
      "  Step 5, Current reward: 0.005862\n",
      "  Step 6, Current reward: 0.005862\n",
      "  Step 7, Current reward: 0.005862\n",
      "  Step 8, Current reward: 0.005862\n",
      "  Step 9, Current reward: 0.005862\n",
      "  Step 10, Current reward: 0.005862\n",
      "  Step 11, Current reward: 0.005862\n",
      "  Step 12, Current reward: 0.005862\n",
      "Episode 682/1000 complete - Max Reward: 0.005862\n",
      "Starting episode 683/1000\n",
      "  Step 1, Current reward: 0.039540\n",
      "  Step 2, Current reward: 0.039540\n",
      "  Step 3, Current reward: 0.039540\n",
      "  Step 4, Current reward: 0.039540\n",
      "  Step 5, Current reward: 0.039540\n",
      "  Step 6, Current reward: 0.039540\n",
      "  Step 7, Current reward: 0.039540\n",
      "  Step 8, Current reward: 0.039540\n",
      "  Step 9, Current reward: 0.039540\n",
      "  Step 10, Current reward: 0.039540\n",
      "  Step 11, Current reward: 0.039540\n",
      "  Step 12, Current reward: 0.039540\n",
      "Episode 683/1000 complete - Max Reward: 0.039540\n",
      "Starting episode 684/1000\n",
      "  Step 1, Current reward: 0.081728\n",
      "  Step 2, Current reward: 0.081728\n",
      "  Step 3, Current reward: 0.081728\n",
      "  Step 4, Current reward: 0.081728\n",
      "  Step 5, Current reward: 0.081728\n",
      "  Step 6, Current reward: 0.081728\n",
      "  Step 7, Current reward: 0.081728\n",
      "  Step 8, Current reward: 0.081728\n",
      "  Step 9, Current reward: 0.081728\n",
      "  Step 10, Current reward: 0.081728\n",
      "  Step 11, Current reward: 0.081728\n",
      "  Step 12, Current reward: 0.081728\n",
      "Episode 684/1000 complete - Max Reward: 0.081728\n",
      "Starting episode 685/1000\n",
      "  Step 1, Current reward: 0.035495\n",
      "  Step 2, Current reward: 0.035495\n",
      "  Step 3, Current reward: 0.035495\n",
      "  Step 4, Current reward: 0.035495\n",
      "  Step 5, Current reward: 0.035495\n",
      "  Step 6, Current reward: 0.035495\n",
      "  Step 7, Current reward: 0.035495\n",
      "  Step 8, Current reward: 0.035495\n",
      "  Step 9, Current reward: 0.035495\n",
      "  Step 10, Current reward: 0.035495\n",
      "  Step 11, Current reward: 0.035495\n",
      "  Step 12, Current reward: 0.035495\n",
      "Episode 685/1000 complete - Max Reward: 0.035495\n",
      "Starting episode 686/1000\n",
      "  Step 1, Current reward: 0.076029\n",
      "  Step 2, Current reward: 0.076029\n",
      "  Step 3, Current reward: 0.076029\n",
      "  Step 4, Current reward: 0.076029\n",
      "  Step 5, Current reward: 0.076029\n",
      "  Step 6, Current reward: 0.076029\n",
      "  Step 7, Current reward: 0.076029\n",
      "  Step 8, Current reward: 0.076029\n",
      "  Step 9, Current reward: 0.076029\n",
      "  Step 10, Current reward: 0.076029\n",
      "  Step 11, Current reward: 0.076029\n",
      "  Step 12, Current reward: 0.076029\n",
      "Episode 686/1000 complete - Max Reward: 0.076029\n",
      "Starting episode 687/1000\n",
      "  Step 1, Current reward: 0.033443\n",
      "  Step 2, Current reward: 0.032916\n",
      "  Step 3, Current reward: 0.032916\n",
      "  Step 4, Current reward: 0.032916\n",
      "  Step 5, Current reward: 0.032916\n",
      "  Step 6, Current reward: 0.032916\n",
      "  Step 7, Current reward: 0.032916\n",
      "  Step 8, Current reward: 0.032916\n",
      "  Step 9, Current reward: 0.032916\n",
      "  Step 10, Current reward: 0.032916\n",
      "  Step 11, Current reward: 0.032916\n",
      "  Step 12, Current reward: 0.032916\n",
      "Episode 687/1000 complete - Max Reward: 0.033443\n",
      "Starting episode 688/1000\n",
      "  Step 1, Current reward: 0.028694\n",
      "  Step 2, Current reward: 0.028694\n",
      "  Step 3, Current reward: 0.028694\n",
      "  Step 4, Current reward: 0.028694\n",
      "  Step 5, Current reward: 0.028694\n",
      "  Step 6, Current reward: 0.028694\n",
      "  Step 7, Current reward: 0.028694\n",
      "  Step 8, Current reward: 0.028694\n",
      "  Step 9, Current reward: 0.028694\n",
      "  Step 10, Current reward: 0.028694\n",
      "  Step 11, Current reward: 0.028694\n",
      "  Step 12, Current reward: 0.028694\n",
      "Episode 688/1000 complete - Max Reward: 0.028694\n",
      "Starting episode 689/1000\n",
      "  Step 1, Current reward: 0.023472\n",
      "  Step 2, Current reward: 0.023472\n",
      "  Step 3, Current reward: 0.023472\n",
      "  Step 4, Current reward: 0.023472\n",
      "  Step 5, Current reward: 0.023472\n",
      "  Step 6, Current reward: 0.023472\n",
      "  Step 7, Current reward: 0.023472\n",
      "  Step 8, Current reward: 0.023472\n",
      "  Step 9, Current reward: 0.023472\n",
      "  Step 10, Current reward: 0.023472\n",
      "  Step 11, Current reward: 0.023472\n",
      "  Step 12, Current reward: 0.023472\n",
      "Episode 689/1000 complete - Max Reward: 0.023472\n",
      "Starting episode 690/1000\n",
      "  Step 1, Current reward: 0.056274\n",
      "  Step 2, Current reward: 0.056274\n",
      "  Step 3, Current reward: 0.056274\n",
      "  Step 4, Current reward: 0.056274\n",
      "  Step 5, Current reward: 0.056274\n",
      "  Step 6, Current reward: 0.056274\n",
      "  Step 7, Current reward: 0.056274\n",
      "  Step 8, Current reward: 0.056274\n",
      "  Step 9, Current reward: 0.056274\n",
      "  Step 10, Current reward: 0.056274\n",
      "  Step 11, Current reward: 0.056274\n",
      "  Step 12, Current reward: 0.056274\n",
      "Episode 690/1000 complete - Max Reward: 0.056274\n",
      "Starting episode 691/1000\n",
      "  Step 1, Current reward: 0.004658\n",
      "  Step 2, Current reward: 0.004658\n",
      "  Step 3, Current reward: 0.004658\n",
      "  Step 4, Current reward: 0.004658\n",
      "  Step 5, Current reward: 0.004658\n",
      "  Step 6, Current reward: 0.004658\n",
      "  Step 7, Current reward: 0.004658\n",
      "  Step 8, Current reward: 0.004658\n",
      "  Step 9, Current reward: 0.004658\n",
      "  Step 10, Current reward: 0.004658\n",
      "  Step 11, Current reward: 0.004658\n",
      "  Step 12, Current reward: 0.004658\n",
      "Episode 691/1000 complete - Max Reward: 0.004658\n",
      "Starting episode 692/1000\n",
      "  Step 1, Current reward: 0.015708\n",
      "  Step 2, Current reward: 0.015708\n",
      "  Step 3, Current reward: 0.015708\n",
      "  Step 4, Current reward: 0.015708\n",
      "  Step 5, Current reward: 0.015708\n",
      "  Step 6, Current reward: 0.015708\n",
      "  Step 7, Current reward: 0.015708\n",
      "  Step 8, Current reward: 0.015708\n",
      "  Step 9, Current reward: 0.015708\n",
      "  Step 10, Current reward: 0.015708\n",
      "  Step 11, Current reward: 0.015708\n",
      "  Step 12, Current reward: 0.015708\n",
      "Episode 692/1000 complete - Max Reward: 0.015708\n",
      "Starting episode 693/1000\n",
      "  Step 1, Current reward: 0.026238\n",
      "  Step 2, Current reward: 0.026238\n",
      "  Step 3, Current reward: 0.026238\n",
      "  Step 4, Current reward: 0.026238\n",
      "  Step 5, Current reward: 0.026238\n",
      "  Step 6, Current reward: 0.026238\n",
      "  Step 7, Current reward: 0.026238\n",
      "  Step 8, Current reward: 0.026238\n",
      "  Step 9, Current reward: 0.026238\n",
      "  Step 10, Current reward: 0.026238\n",
      "  Step 11, Current reward: 0.026238\n",
      "  Step 12, Current reward: 0.026238\n",
      "Episode 693/1000 complete - Max Reward: 0.026238\n",
      "Starting episode 694/1000\n",
      "  Step 1, Current reward: 0.002078\n",
      "  Step 2, Current reward: 0.002078\n",
      "  Step 3, Current reward: 0.002078\n",
      "  Step 4, Current reward: 0.002078\n",
      "  Step 5, Current reward: 0.002078\n",
      "  Step 6, Current reward: 0.002078\n",
      "  Step 7, Current reward: 0.002078\n",
      "  Step 8, Current reward: 0.002078\n",
      "  Step 9, Current reward: 0.002078\n",
      "  Step 10, Current reward: 0.002078\n",
      "  Step 11, Current reward: 0.002078\n",
      "  Step 12, Current reward: 0.002078\n",
      "Episode 694/1000 complete - Max Reward: 0.002078\n",
      "Starting episode 695/1000\n",
      "  Step 1, Current reward: 0.027713\n",
      "  Step 2, Current reward: 0.027713\n",
      "  Step 3, Current reward: 0.027713\n",
      "  Step 4, Current reward: 0.027713\n",
      "  Step 5, Current reward: 0.027713\n",
      "  Step 6, Current reward: 0.027713\n",
      "  Step 7, Current reward: 0.027713\n",
      "  Step 8, Current reward: 0.027713\n",
      "  Step 9, Current reward: 0.027713\n",
      "  Step 10, Current reward: 0.027713\n",
      "  Step 11, Current reward: 0.027713\n",
      "  Step 12, Current reward: 0.027713\n",
      "Episode 695/1000 complete - Max Reward: 0.027713\n",
      "Starting episode 696/1000\n",
      "  Step 1, Current reward: 0.030644\n",
      "  Step 2, Current reward: 0.030644\n",
      "  Step 3, Current reward: 0.030644\n",
      "  Step 4, Current reward: 0.030644\n",
      "  Step 5, Current reward: 0.030644\n",
      "  Step 6, Current reward: 0.030644\n",
      "  Step 7, Current reward: 0.030644\n",
      "  Step 8, Current reward: 0.030644\n",
      "  Step 9, Current reward: 0.030644\n",
      "  Step 10, Current reward: 0.030644\n",
      "  Step 11, Current reward: 0.030644\n",
      "  Step 12, Current reward: 0.030644\n",
      "Episode 696/1000 complete - Max Reward: 0.030644\n",
      "Starting episode 697/1000\n",
      "  Step 1, Current reward: 0.151410\n",
      "  Step 2, Current reward: 0.151410\n",
      "  Step 3, Current reward: 0.151410\n",
      "  Step 4, Current reward: 0.151410\n",
      "  Step 5, Current reward: 0.151410\n",
      "  Step 6, Current reward: 0.151410\n",
      "  Step 7, Current reward: 0.151410\n",
      "  Step 8, Current reward: 0.151410\n",
      "  Step 9, Current reward: 0.151410\n",
      "  Step 10, Current reward: 0.151410\n",
      "  Step 11, Current reward: 0.151410\n",
      "  Step 12, Current reward: 0.151410\n",
      "Episode 697/1000 complete - Max Reward: 0.151410\n",
      "Starting episode 698/1000\n",
      "  Step 1, Current reward: 0.058036\n",
      "  Step 2, Current reward: 0.058036\n",
      "  Step 3, Current reward: 0.058036\n",
      "  Step 4, Current reward: 0.058036\n",
      "  Step 5, Current reward: 0.058036\n",
      "  Step 6, Current reward: 0.058036\n",
      "  Step 7, Current reward: 0.058036\n",
      "  Step 8, Current reward: 0.058036\n",
      "  Step 9, Current reward: 0.058036\n",
      "  Step 10, Current reward: 0.058036\n",
      "  Step 11, Current reward: 0.058036\n",
      "  Step 12, Current reward: 0.058036\n",
      "Episode 698/1000 complete - Max Reward: 0.058036\n",
      "Starting episode 699/1000\n",
      "  Step 1, Current reward: 0.007647\n",
      "  Step 2, Current reward: 0.007647\n",
      "  Step 3, Current reward: 0.007647\n",
      "  Step 4, Current reward: 0.007647\n",
      "  Step 5, Current reward: 0.007647\n",
      "  Step 6, Current reward: 0.007647\n",
      "  Step 7, Current reward: 0.007647\n",
      "  Step 8, Current reward: 0.007647\n",
      "  Step 9, Current reward: 0.007647\n",
      "  Step 10, Current reward: 0.007647\n",
      "  Step 11, Current reward: 0.007647\n",
      "  Step 12, Current reward: 0.007647\n",
      "Episode 699/1000 complete - Max Reward: 0.007647\n",
      "Starting episode 700/1000\n",
      "  Step 1, Current reward: 0.039545\n",
      "  Step 2, Current reward: 0.039545\n",
      "  Step 3, Current reward: 0.039545\n",
      "  Step 4, Current reward: 0.039545\n",
      "  Step 5, Current reward: 0.039545\n",
      "  Step 6, Current reward: 0.039545\n",
      "  Step 7, Current reward: 0.039545\n",
      "  Step 8, Current reward: 0.039545\n",
      "  Step 9, Current reward: 0.039545\n",
      "  Step 10, Current reward: 0.039545\n",
      "  Step 11, Current reward: 0.039545\n",
      "  Step 12, Current reward: 0.039545\n",
      "Episode 700/1000 complete - Max Reward: 0.039545\n",
      "Starting episode 701/1000\n",
      "  Step 1, Current reward: 0.056036\n",
      "  Step 2, Current reward: 0.056036\n",
      "  Step 3, Current reward: 0.056036\n",
      "  Step 4, Current reward: 0.056036\n",
      "  Step 5, Current reward: 0.056036\n",
      "  Step 6, Current reward: 0.056036\n",
      "  Step 7, Current reward: 0.056036\n",
      "  Step 8, Current reward: 0.056036\n",
      "  Step 9, Current reward: 0.056036\n",
      "  Step 10, Current reward: 0.056036\n",
      "  Step 11, Current reward: 0.056036\n",
      "  Step 12, Current reward: 0.056036\n",
      "Episode 701/1000 complete - Max Reward: 0.056036\n",
      "Starting episode 702/1000\n",
      "  Step 1, Current reward: 0.026689\n",
      "  Step 2, Current reward: 0.026689\n",
      "  Step 3, Current reward: 0.026689\n",
      "  Step 4, Current reward: 0.026689\n",
      "  Step 5, Current reward: 0.026689\n",
      "  Step 6, Current reward: 0.026689\n",
      "  Step 7, Current reward: 0.026689\n",
      "  Step 8, Current reward: 0.026689\n",
      "  Step 9, Current reward: 0.026689\n",
      "  Step 10, Current reward: 0.026689\n",
      "  Step 11, Current reward: 0.026689\n",
      "  Step 12, Current reward: 0.026689\n",
      "Episode 702/1000 complete - Max Reward: 0.026689\n",
      "Starting episode 703/1000\n",
      "  Step 1, Current reward: 0.023810\n",
      "  Step 2, Current reward: 0.023810\n",
      "  Step 3, Current reward: 0.023810\n",
      "  Step 4, Current reward: 0.023810\n",
      "  Step 5, Current reward: 0.023810\n",
      "  Step 6, Current reward: 0.023810\n",
      "  Step 7, Current reward: 0.023810\n",
      "  Step 8, Current reward: 0.023810\n",
      "  Step 9, Current reward: 0.023810\n",
      "  Step 10, Current reward: 0.023810\n",
      "  Step 11, Current reward: 0.023810\n",
      "  Step 12, Current reward: 0.023810\n",
      "Episode 703/1000 complete - Max Reward: 0.023810\n",
      "Starting episode 704/1000\n",
      "  Step 1, Current reward: 0.033983\n",
      "  Step 2, Current reward: 0.033983\n",
      "  Step 3, Current reward: 0.033983\n",
      "  Step 4, Current reward: 0.033983\n",
      "  Step 5, Current reward: 0.033983\n",
      "  Step 6, Current reward: 0.033983\n",
      "  Step 7, Current reward: 0.033983\n",
      "  Step 8, Current reward: 0.033983\n",
      "  Step 9, Current reward: 0.033983\n",
      "  Step 10, Current reward: 0.033983\n",
      "  Step 11, Current reward: 0.033983\n",
      "  Step 12, Current reward: 0.033983\n",
      "Episode 704/1000 complete - Max Reward: 0.033983\n",
      "Starting episode 705/1000\n",
      "  Step 1, Current reward: 0.000834\n",
      "  Step 2, Current reward: 0.000834\n",
      "  Step 3, Current reward: 0.000834\n",
      "  Step 4, Current reward: 0.000834\n",
      "  Step 5, Current reward: 0.000834\n",
      "  Step 6, Current reward: 0.000834\n",
      "  Step 7, Current reward: 0.000834\n",
      "  Step 8, Current reward: 0.000834\n",
      "  Step 9, Current reward: 0.000834\n",
      "  Step 10, Current reward: 0.000834\n",
      "  Step 11, Current reward: 0.000834\n",
      "  Step 12, Current reward: 0.000834\n",
      "Episode 705/1000 complete - Max Reward: 0.000834\n",
      "Starting episode 706/1000\n",
      "  Step 1, Current reward: 0.013820\n",
      "  Step 2, Current reward: 0.013820\n",
      "  Step 3, Current reward: 0.013820\n",
      "  Step 4, Current reward: 0.013820\n",
      "  Step 5, Current reward: 0.013820\n",
      "  Step 6, Current reward: 0.013820\n",
      "  Step 7, Current reward: 0.013820\n",
      "  Step 8, Current reward: 0.013820\n",
      "  Step 9, Current reward: 0.013820\n",
      "  Step 10, Current reward: 0.013820\n",
      "  Step 11, Current reward: 0.013820\n",
      "  Step 12, Current reward: 0.013820\n",
      "Episode 706/1000 complete - Max Reward: 0.013820\n",
      "Starting episode 707/1000\n",
      "  Step 1, Current reward: 0.023303\n",
      "  Step 2, Current reward: 0.023303\n",
      "  Step 3, Current reward: 0.023303\n",
      "  Step 4, Current reward: 0.023303\n",
      "  Step 5, Current reward: 0.023303\n",
      "  Step 6, Current reward: 0.023303\n",
      "  Step 7, Current reward: 0.023303\n",
      "  Step 8, Current reward: 0.023303\n",
      "  Step 9, Current reward: 0.023303\n",
      "  Step 10, Current reward: 0.023303\n",
      "  Step 11, Current reward: 0.023303\n",
      "  Step 12, Current reward: 0.023303\n",
      "Episode 707/1000 complete - Max Reward: 0.023303\n",
      "Starting episode 708/1000\n",
      "  Step 1, Current reward: 0.169551\n",
      "  Step 2, Current reward: 0.169551\n",
      "  Step 3, Current reward: 0.169551\n",
      "  Step 4, Current reward: 0.169551\n",
      "  Step 5, Current reward: 0.169551\n",
      "  Step 6, Current reward: 0.169551\n",
      "  Step 7, Current reward: 0.169551\n",
      "  Step 8, Current reward: 0.169551\n",
      "  Step 9, Current reward: 0.169551\n",
      "  Step 10, Current reward: 0.169551\n",
      "  Step 11, Current reward: 0.169551\n",
      "  Step 12, Current reward: 0.169551\n",
      "Episode 708/1000 complete - Max Reward: 0.169551\n",
      "Starting episode 709/1000\n",
      "  Step 1, Current reward: 0.004764\n",
      "  Step 2, Current reward: 0.004764\n",
      "  Step 3, Current reward: 0.004764\n",
      "  Step 4, Current reward: 0.004764\n",
      "  Step 5, Current reward: 0.004764\n",
      "  Step 6, Current reward: 0.004764\n",
      "  Step 7, Current reward: 0.004764\n",
      "  Step 8, Current reward: 0.004764\n",
      "  Step 9, Current reward: 0.004764\n",
      "  Step 10, Current reward: 0.004764\n",
      "  Step 11, Current reward: 0.004764\n",
      "  Step 12, Current reward: 0.004764\n",
      "Episode 709/1000 complete - Max Reward: 0.004764\n",
      "Starting episode 710/1000\n",
      "  Step 1, Current reward: 0.014008\n",
      "  Step 2, Current reward: 0.014008\n",
      "  Step 3, Current reward: 0.014008\n",
      "  Step 4, Current reward: 0.014008\n",
      "  Step 5, Current reward: 0.014008\n",
      "  Step 6, Current reward: 0.014008\n",
      "  Step 7, Current reward: 0.014008\n",
      "  Step 8, Current reward: 0.014008\n",
      "  Step 9, Current reward: 0.014008\n",
      "  Step 10, Current reward: 0.014008\n",
      "  Step 11, Current reward: 0.014008\n",
      "  Step 12, Current reward: 0.014008\n",
      "Episode 710/1000 complete - Max Reward: 0.014008\n",
      "Starting episode 711/1000\n",
      "  Step 1, Current reward: 0.031405\n",
      "  Step 2, Current reward: 0.031405\n",
      "  Step 3, Current reward: 0.031405\n",
      "  Step 4, Current reward: 0.031405\n",
      "  Step 5, Current reward: 0.031405\n",
      "  Step 6, Current reward: 0.031405\n",
      "  Step 7, Current reward: 0.031405\n",
      "  Step 8, Current reward: 0.031405\n",
      "  Step 9, Current reward: 0.031405\n",
      "  Step 10, Current reward: 0.031405\n",
      "  Step 11, Current reward: 0.031405\n",
      "  Step 12, Current reward: 0.031405\n",
      "Episode 711/1000 complete - Max Reward: 0.031405\n",
      "Starting episode 712/1000\n",
      "  Step 1, Current reward: 0.001065\n",
      "  Step 2, Current reward: 0.001065\n",
      "  Step 3, Current reward: 0.001065\n",
      "  Step 4, Current reward: 0.001065\n",
      "  Step 5, Current reward: 0.001065\n",
      "  Step 6, Current reward: 0.001065\n",
      "  Step 7, Current reward: 0.001065\n",
      "  Step 8, Current reward: 0.001065\n",
      "  Step 9, Current reward: 0.001065\n",
      "  Step 10, Current reward: 0.001065\n",
      "  Step 11, Current reward: 0.001065\n",
      "  Step 12, Current reward: 0.001065\n",
      "Episode 712/1000 complete - Max Reward: 0.001065\n",
      "Starting episode 713/1000\n",
      "  Step 1, Current reward: 0.034324\n",
      "  Step 2, Current reward: 0.034324\n",
      "  Step 3, Current reward: 0.034324\n",
      "  Step 4, Current reward: 0.034324\n",
      "  Step 5, Current reward: 0.034324\n",
      "  Step 6, Current reward: 0.034324\n",
      "  Step 7, Current reward: 0.034324\n",
      "  Step 8, Current reward: 0.034324\n",
      "  Step 9, Current reward: 0.034324\n",
      "  Step 10, Current reward: 0.034324\n",
      "  Step 11, Current reward: 0.034324\n",
      "  Step 12, Current reward: 0.034324\n",
      "Episode 713/1000 complete - Max Reward: 0.034324\n",
      "Starting episode 714/1000\n",
      "  Step 1, Current reward: 0.015649\n",
      "  Step 2, Current reward: 0.015649\n",
      "  Step 3, Current reward: 0.015649\n",
      "  Step 4, Current reward: 0.015649\n",
      "  Step 5, Current reward: 0.015649\n",
      "  Step 6, Current reward: 0.015649\n",
      "  Step 7, Current reward: 0.015649\n",
      "  Step 8, Current reward: 0.015649\n",
      "  Step 9, Current reward: 0.015649\n",
      "  Step 10, Current reward: 0.015649\n",
      "  Step 11, Current reward: 0.015649\n",
      "  Step 12, Current reward: 0.015649\n",
      "Episode 714/1000 complete - Max Reward: 0.015649\n",
      "Starting episode 715/1000\n",
      "  Step 1, Current reward: 0.004124\n",
      "  Step 2, Current reward: 0.004011\n",
      "  Step 3, Current reward: 0.003897\n",
      "  Step 4, Current reward: 0.003897\n",
      "  Step 5, Current reward: 0.003897\n",
      "  Step 6, Current reward: 0.003897\n",
      "  Step 7, Current reward: 0.003897\n",
      "  Step 8, Current reward: 0.003897\n",
      "  Step 9, Current reward: 0.003897\n",
      "  Step 10, Current reward: 0.003897\n",
      "  Step 11, Current reward: 0.003897\n",
      "  Step 12, Current reward: 0.003897\n",
      "Episode 715/1000 complete - Max Reward: 0.004124\n",
      "Starting episode 716/1000\n",
      "  Step 1, Current reward: 0.013954\n",
      "  Step 2, Current reward: 0.013954\n",
      "  Step 3, Current reward: 0.013954\n",
      "  Step 4, Current reward: 0.013954\n",
      "  Step 5, Current reward: 0.013954\n",
      "  Step 6, Current reward: 0.013954\n",
      "  Step 7, Current reward: 0.013954\n",
      "  Step 8, Current reward: 0.013954\n",
      "  Step 9, Current reward: 0.013954\n",
      "  Step 10, Current reward: 0.013954\n",
      "  Step 11, Current reward: 0.013954\n",
      "  Step 12, Current reward: 0.013954\n",
      "Episode 716/1000 complete - Max Reward: 0.013954\n",
      "Starting episode 717/1000\n",
      "  Step 1, Current reward: 0.083827\n",
      "  Step 2, Current reward: 0.083827\n",
      "  Step 3, Current reward: 0.083827\n",
      "  Step 4, Current reward: 0.083827\n",
      "  Step 5, Current reward: 0.083827\n",
      "  Step 6, Current reward: 0.083827\n",
      "  Step 7, Current reward: 0.083827\n",
      "  Step 8, Current reward: 0.083827\n",
      "  Step 9, Current reward: 0.083827\n",
      "  Step 10, Current reward: 0.083827\n",
      "  Step 11, Current reward: 0.083827\n",
      "  Step 12, Current reward: 0.083827\n",
      "Episode 717/1000 complete - Max Reward: 0.083827\n",
      "Starting episode 718/1000\n",
      "  Step 1, Current reward: 0.026299\n",
      "  Step 2, Current reward: 0.026299\n",
      "  Step 3, Current reward: 0.026299\n",
      "  Step 4, Current reward: 0.026299\n",
      "  Step 5, Current reward: 0.026299\n",
      "  Step 6, Current reward: 0.026299\n",
      "  Step 7, Current reward: 0.026299\n",
      "  Step 8, Current reward: 0.026299\n",
      "  Step 9, Current reward: 0.026299\n",
      "  Step 10, Current reward: 0.026299\n",
      "  Step 11, Current reward: 0.026299\n",
      "  Step 12, Current reward: 0.026299\n",
      "Episode 718/1000 complete - Max Reward: 0.026299\n",
      "Starting episode 719/1000\n",
      "  Step 1, Current reward: 0.000534\n",
      "  Step 2, Current reward: 0.000534\n",
      "  Step 3, Current reward: 0.000534\n",
      "  Step 4, Current reward: 0.000534\n",
      "  Step 5, Current reward: 0.000534\n",
      "  Step 6, Current reward: 0.000534\n",
      "  Step 7, Current reward: 0.000534\n",
      "  Step 8, Current reward: 0.000534\n",
      "  Step 9, Current reward: 0.000534\n",
      "  Step 10, Current reward: 0.000534\n",
      "  Step 11, Current reward: 0.000534\n",
      "  Step 12, Current reward: 0.000534\n",
      "Episode 719/1000 complete - Max Reward: 0.000534\n",
      "Starting episode 720/1000\n",
      "  Step 1, Current reward: 0.234205\n",
      "  Step 2, Current reward: 0.234205\n",
      "  Step 3, Current reward: 0.234205\n",
      "  Step 4, Current reward: 0.234205\n",
      "  Step 5, Current reward: 0.234205\n",
      "  Step 6, Current reward: 0.234205\n",
      "  Step 7, Current reward: 0.234205\n",
      "  Step 8, Current reward: 0.234205\n",
      "  Step 9, Current reward: 0.234205\n",
      "  Step 10, Current reward: 0.234205\n",
      "  Step 11, Current reward: 0.234205\n",
      "  Step 12, Current reward: 0.234205\n",
      "Episode 720/1000 complete - Max Reward: 0.234205\n",
      "Starting episode 721/1000\n",
      "  Step 1, Current reward: 0.170877\n",
      "  Step 2, Current reward: 0.170877\n",
      "  Step 3, Current reward: 0.170877\n",
      "  Step 4, Current reward: 0.170877\n",
      "  Step 5, Current reward: 0.170877\n",
      "  Step 6, Current reward: 0.170877\n",
      "  Step 7, Current reward: 0.170877\n",
      "  Step 8, Current reward: 0.170877\n",
      "  Step 9, Current reward: 0.170877\n",
      "  Step 10, Current reward: 0.170877\n",
      "  Step 11, Current reward: 0.170877\n",
      "  Step 12, Current reward: 0.170877\n",
      "Episode 721/1000 complete - Max Reward: 0.170877\n",
      "Starting episode 722/1000\n",
      "  Step 1, Current reward: 0.036611\n",
      "  Step 2, Current reward: 0.036611\n",
      "  Step 3, Current reward: 0.036611\n",
      "  Step 4, Current reward: 0.036611\n",
      "  Step 5, Current reward: 0.036611\n",
      "  Step 6, Current reward: 0.036611\n",
      "  Step 7, Current reward: 0.036611\n",
      "  Step 8, Current reward: 0.036611\n",
      "  Step 9, Current reward: 0.036611\n",
      "  Step 10, Current reward: 0.036611\n",
      "  Step 11, Current reward: 0.036611\n",
      "  Step 12, Current reward: 0.036611\n",
      "Episode 722/1000 complete - Max Reward: 0.036611\n",
      "Starting episode 723/1000\n",
      "  Step 1, Current reward: 0.009550\n",
      "  Step 2, Current reward: 0.009550\n",
      "  Step 3, Current reward: 0.009550\n",
      "  Step 4, Current reward: 0.009550\n",
      "  Step 5, Current reward: 0.009550\n",
      "  Step 6, Current reward: 0.009550\n",
      "  Step 7, Current reward: 0.009550\n",
      "  Step 8, Current reward: 0.009550\n",
      "  Step 9, Current reward: 0.009550\n",
      "  Step 10, Current reward: 0.009550\n",
      "  Step 11, Current reward: 0.009550\n",
      "  Step 12, Current reward: 0.009550\n",
      "Episode 723/1000 complete - Max Reward: 0.009550\n",
      "Starting episode 724/1000\n",
      "  Step 1, Current reward: 0.058877\n",
      "  Step 2, Current reward: 0.058877\n",
      "  Step 3, Current reward: 0.058877\n",
      "  Step 4, Current reward: 0.058877\n",
      "  Step 5, Current reward: 0.058877\n",
      "  Step 6, Current reward: 0.058877\n",
      "  Step 7, Current reward: 0.058877\n",
      "  Step 8, Current reward: 0.058877\n",
      "  Step 9, Current reward: 0.058877\n",
      "  Step 10, Current reward: 0.058877\n",
      "  Step 11, Current reward: 0.058877\n",
      "  Step 12, Current reward: 0.058877\n",
      "Episode 724/1000 complete - Max Reward: 0.058877\n",
      "Starting episode 725/1000\n",
      "  Step 1, Current reward: 0.204391\n",
      "  Step 2, Current reward: 0.204391\n",
      "  Step 3, Current reward: 0.204391\n",
      "  Step 4, Current reward: 0.204391\n",
      "  Step 5, Current reward: 0.204391\n",
      "  Step 6, Current reward: 0.204391\n",
      "  Step 7, Current reward: 0.204391\n",
      "  Step 8, Current reward: 0.204391\n",
      "  Step 9, Current reward: 0.204391\n",
      "  Step 10, Current reward: 0.204391\n",
      "  Step 11, Current reward: 0.204391\n",
      "  Step 12, Current reward: 0.204391\n",
      "Episode 725/1000 complete - Max Reward: 0.204391\n",
      "Starting episode 726/1000\n",
      "  Step 1, Current reward: 0.059407\n",
      "  Step 2, Current reward: 0.059407\n",
      "  Step 3, Current reward: 0.059407\n",
      "  Step 4, Current reward: 0.059407\n",
      "  Step 5, Current reward: 0.059407\n",
      "  Step 6, Current reward: 0.059407\n",
      "  Step 7, Current reward: 0.059407\n",
      "  Step 8, Current reward: 0.059407\n",
      "  Step 9, Current reward: 0.059407\n",
      "  Step 10, Current reward: 0.059407\n",
      "  Step 11, Current reward: 0.059407\n",
      "  Step 12, Current reward: 0.059407\n",
      "Episode 726/1000 complete - Max Reward: 0.059407\n",
      "Starting episode 727/1000\n",
      "  Step 1, Current reward: 0.033618\n",
      "  Step 2, Current reward: 0.033618\n",
      "  Step 3, Current reward: 0.033618\n",
      "  Step 4, Current reward: 0.033618\n",
      "  Step 5, Current reward: 0.033618\n",
      "  Step 6, Current reward: 0.033618\n",
      "  Step 7, Current reward: 0.033618\n",
      "  Step 8, Current reward: 0.033618\n",
      "  Step 9, Current reward: 0.033618\n",
      "  Step 10, Current reward: 0.033618\n",
      "  Step 11, Current reward: 0.033618\n",
      "  Step 12, Current reward: 0.033618\n",
      "Episode 727/1000 complete - Max Reward: 0.033618\n",
      "Starting episode 728/1000\n",
      "  Step 1, Current reward: 0.031554\n",
      "  Step 2, Current reward: 0.031554\n",
      "  Step 3, Current reward: 0.031554\n",
      "  Step 4, Current reward: 0.031554\n",
      "  Step 5, Current reward: 0.031554\n",
      "  Step 6, Current reward: 0.031554\n",
      "  Step 7, Current reward: 0.031554\n",
      "  Step 8, Current reward: 0.031554\n",
      "  Step 9, Current reward: 0.031554\n",
      "  Step 10, Current reward: 0.031554\n",
      "  Step 11, Current reward: 0.031554\n",
      "  Step 12, Current reward: 0.031554\n",
      "Episode 728/1000 complete - Max Reward: 0.031554\n",
      "Starting episode 729/1000\n",
      "  Step 1, Current reward: 0.005164\n",
      "  Step 2, Current reward: 0.005164\n",
      "  Step 3, Current reward: 0.005164\n",
      "  Step 4, Current reward: 0.005164\n",
      "  Step 5, Current reward: 0.005164\n",
      "  Step 6, Current reward: 0.005164\n",
      "  Step 7, Current reward: 0.005164\n",
      "  Step 8, Current reward: 0.005164\n",
      "  Step 9, Current reward: 0.005164\n",
      "  Step 10, Current reward: 0.005164\n",
      "  Step 11, Current reward: 0.005164\n",
      "  Step 12, Current reward: 0.005164\n",
      "Episode 729/1000 complete - Max Reward: 0.005164\n",
      "Starting episode 730/1000\n",
      "  Step 1, Current reward: 0.108579\n",
      "  Step 2, Current reward: 0.108579\n",
      "  Step 3, Current reward: 0.108579\n",
      "  Step 4, Current reward: 0.108579\n",
      "  Step 5, Current reward: 0.108579\n",
      "  Step 6, Current reward: 0.108579\n",
      "  Step 7, Current reward: 0.108579\n",
      "  Step 8, Current reward: 0.108579\n",
      "  Step 9, Current reward: 0.108579\n",
      "  Step 10, Current reward: 0.108579\n",
      "  Step 11, Current reward: 0.108579\n",
      "  Step 12, Current reward: 0.108579\n",
      "Episode 730/1000 complete - Max Reward: 0.108579\n",
      "Starting episode 731/1000\n",
      "  Step 1, Current reward: 0.044597\n",
      "  Step 2, Current reward: 0.044597\n",
      "  Step 3, Current reward: 0.044597\n",
      "  Step 4, Current reward: 0.044597\n",
      "  Step 5, Current reward: 0.044597\n",
      "  Step 6, Current reward: 0.044597\n",
      "  Step 7, Current reward: 0.044597\n",
      "  Step 8, Current reward: 0.044597\n",
      "  Step 9, Current reward: 0.044597\n",
      "  Step 10, Current reward: 0.044597\n",
      "  Step 11, Current reward: 0.044597\n",
      "  Step 12, Current reward: 0.044597\n",
      "Episode 731/1000 complete - Max Reward: 0.044597\n",
      "Starting episode 732/1000\n",
      "  Step 1, Current reward: 0.001987\n",
      "  Step 2, Current reward: 0.001987\n",
      "  Step 3, Current reward: 0.001987\n",
      "  Step 4, Current reward: 0.001987\n",
      "  Step 5, Current reward: 0.001987\n",
      "  Step 6, Current reward: 0.001987\n",
      "  Step 7, Current reward: 0.001987\n",
      "  Step 8, Current reward: 0.001987\n",
      "  Step 9, Current reward: 0.001987\n",
      "  Step 10, Current reward: 0.001987\n",
      "  Step 11, Current reward: 0.001987\n",
      "  Step 12, Current reward: 0.001987\n",
      "Episode 732/1000 complete - Max Reward: 0.001987\n",
      "Starting episode 733/1000\n",
      "  Step 1, Current reward: 0.000458\n",
      "  Step 2, Current reward: 0.000400\n",
      "  Step 3, Current reward: 0.000350\n",
      "  Step 4, Current reward: 0.000350\n",
      "  Step 5, Current reward: 0.000350\n",
      "  Step 6, Current reward: 0.000350\n",
      "  Step 7, Current reward: 0.000350\n",
      "  Step 8, Current reward: 0.000350\n",
      "  Step 9, Current reward: 0.000350\n",
      "  Step 10, Current reward: 0.000350\n",
      "  Step 11, Current reward: 0.000350\n",
      "  Step 12, Current reward: 0.000350\n",
      "Episode 733/1000 complete - Max Reward: 0.000458\n",
      "Starting episode 734/1000\n",
      "  Step 1, Current reward: 0.010782\n",
      "  Step 2, Current reward: 0.010782\n",
      "  Step 3, Current reward: 0.010782\n",
      "  Step 4, Current reward: 0.010782\n",
      "  Step 5, Current reward: 0.010782\n",
      "  Step 6, Current reward: 0.010782\n",
      "  Step 7, Current reward: 0.010782\n",
      "  Step 8, Current reward: 0.010782\n",
      "  Step 9, Current reward: 0.010782\n",
      "  Step 10, Current reward: 0.010782\n",
      "  Step 11, Current reward: 0.010782\n",
      "  Step 12, Current reward: 0.010782\n",
      "Episode 734/1000 complete - Max Reward: 0.010782\n",
      "Starting episode 735/1000\n",
      "  Step 1, Current reward: 0.004879\n",
      "  Step 2, Current reward: 0.004879\n",
      "  Step 3, Current reward: 0.004879\n",
      "  Step 4, Current reward: 0.004879\n",
      "  Step 5, Current reward: 0.004879\n",
      "  Step 6, Current reward: 0.004879\n",
      "  Step 7, Current reward: 0.004879\n",
      "  Step 8, Current reward: 0.004879\n",
      "  Step 9, Current reward: 0.004879\n",
      "  Step 10, Current reward: 0.004879\n",
      "  Step 11, Current reward: 0.004879\n",
      "  Step 12, Current reward: 0.004879\n",
      "Episode 735/1000 complete - Max Reward: 0.004879\n",
      "Starting episode 736/1000\n",
      "  Step 1, Current reward: 0.033613\n",
      "  Step 2, Current reward: 0.033613\n",
      "  Step 3, Current reward: 0.033613\n",
      "  Step 4, Current reward: 0.033613\n",
      "  Step 5, Current reward: 0.033613\n",
      "  Step 6, Current reward: 0.033613\n",
      "  Step 7, Current reward: 0.033613\n",
      "  Step 8, Current reward: 0.033613\n",
      "  Step 9, Current reward: 0.033613\n",
      "  Step 10, Current reward: 0.033613\n",
      "  Step 11, Current reward: 0.033613\n",
      "  Step 12, Current reward: 0.033613\n",
      "Episode 736/1000 complete - Max Reward: 0.033613\n",
      "Starting episode 737/1000\n",
      "  Step 1, Current reward: 0.014392\n",
      "  Step 2, Current reward: 0.014392\n",
      "  Step 3, Current reward: 0.014392\n",
      "  Step 4, Current reward: 0.014392\n",
      "  Step 5, Current reward: 0.014392\n",
      "  Step 6, Current reward: 0.014392\n",
      "  Step 7, Current reward: 0.014392\n",
      "  Step 8, Current reward: 0.014392\n",
      "  Step 9, Current reward: 0.014392\n",
      "  Step 10, Current reward: 0.014392\n",
      "  Step 11, Current reward: 0.014392\n",
      "  Step 12, Current reward: 0.014392\n",
      "Episode 737/1000 complete - Max Reward: 0.014392\n",
      "Starting episode 738/1000\n",
      "  Step 1, Current reward: 0.008441\n",
      "  Step 2, Current reward: 0.008441\n",
      "  Step 3, Current reward: 0.008441\n",
      "  Step 4, Current reward: 0.008441\n",
      "  Step 5, Current reward: 0.008441\n",
      "  Step 6, Current reward: 0.008441\n",
      "  Step 7, Current reward: 0.008441\n",
      "  Step 8, Current reward: 0.008441\n",
      "  Step 9, Current reward: 0.008441\n",
      "  Step 10, Current reward: 0.008441\n",
      "  Step 11, Current reward: 0.008441\n",
      "  Step 12, Current reward: 0.008441\n",
      "Episode 738/1000 complete - Max Reward: 0.008441\n",
      "Starting episode 739/1000\n",
      "  Step 1, Current reward: 0.123709\n",
      "  Step 2, Current reward: 0.123709\n",
      "  Step 3, Current reward: 0.123709\n",
      "  Step 4, Current reward: 0.123709\n",
      "  Step 5, Current reward: 0.123709\n",
      "  Step 6, Current reward: 0.123709\n",
      "  Step 7, Current reward: 0.123709\n",
      "  Step 8, Current reward: 0.123709\n",
      "  Step 9, Current reward: 0.123709\n",
      "  Step 10, Current reward: 0.123709\n",
      "  Step 11, Current reward: 0.123709\n",
      "  Step 12, Current reward: 0.123709\n",
      "Episode 739/1000 complete - Max Reward: 0.123709\n",
      "Starting episode 740/1000\n",
      "  Step 1, Current reward: 0.012394\n",
      "  Step 2, Current reward: 0.012394\n",
      "  Step 3, Current reward: 0.012394\n",
      "  Step 4, Current reward: 0.012394\n",
      "  Step 5, Current reward: 0.012394\n",
      "  Step 6, Current reward: 0.012394\n",
      "  Step 7, Current reward: 0.012394\n",
      "  Step 8, Current reward: 0.012394\n",
      "  Step 9, Current reward: 0.012394\n",
      "  Step 10, Current reward: 0.012394\n",
      "  Step 11, Current reward: 0.012394\n",
      "  Step 12, Current reward: 0.012394\n",
      "Episode 740/1000 complete - Max Reward: 0.012394\n",
      "Starting episode 741/1000\n",
      "  Step 1, Current reward: 0.048815\n",
      "  Step 2, Current reward: 0.048815\n",
      "  Step 3, Current reward: 0.048815\n",
      "  Step 4, Current reward: 0.048815\n",
      "  Step 5, Current reward: 0.048815\n",
      "  Step 6, Current reward: 0.048815\n",
      "  Step 7, Current reward: 0.048815\n",
      "  Step 8, Current reward: 0.048815\n",
      "  Step 9, Current reward: 0.048815\n",
      "  Step 10, Current reward: 0.048815\n",
      "  Step 11, Current reward: 0.048815\n",
      "  Step 12, Current reward: 0.048815\n",
      "Episode 741/1000 complete - Max Reward: 0.048815\n",
      "Starting episode 742/1000\n",
      "  Step 1, Current reward: 0.009388\n",
      "  Step 2, Current reward: 0.009388\n",
      "  Step 3, Current reward: 0.009388\n",
      "  Step 4, Current reward: 0.009388\n",
      "  Step 5, Current reward: 0.009388\n",
      "  Step 6, Current reward: 0.009388\n",
      "  Step 7, Current reward: 0.009388\n",
      "  Step 8, Current reward: 0.009388\n",
      "  Step 9, Current reward: 0.009388\n",
      "  Step 10, Current reward: 0.009388\n",
      "  Step 11, Current reward: 0.009388\n",
      "  Step 12, Current reward: 0.009388\n",
      "Episode 742/1000 complete - Max Reward: 0.009388\n",
      "Starting episode 743/1000\n",
      "  Step 1, Current reward: 0.011903\n",
      "  Step 2, Current reward: 0.011903\n",
      "  Step 3, Current reward: 0.011903\n",
      "  Step 4, Current reward: 0.011903\n",
      "  Step 5, Current reward: 0.011903\n",
      "  Step 6, Current reward: 0.011903\n",
      "  Step 7, Current reward: 0.011903\n",
      "  Step 8, Current reward: 0.011903\n",
      "  Step 9, Current reward: 0.011903\n",
      "  Step 10, Current reward: 0.011903\n",
      "  Step 11, Current reward: 0.011903\n",
      "  Step 12, Current reward: 0.011903\n",
      "Episode 743/1000 complete - Max Reward: 0.011903\n",
      "Starting episode 744/1000\n",
      "  Step 1, Current reward: 0.041343\n",
      "  Step 2, Current reward: 0.041343\n",
      "  Step 3, Current reward: 0.041343\n",
      "  Step 4, Current reward: 0.041343\n",
      "  Step 5, Current reward: 0.041343\n",
      "  Step 6, Current reward: 0.041343\n",
      "  Step 7, Current reward: 0.041343\n",
      "  Step 8, Current reward: 0.041343\n",
      "  Step 9, Current reward: 0.041343\n",
      "  Step 10, Current reward: 0.041343\n",
      "  Step 11, Current reward: 0.041343\n",
      "  Step 12, Current reward: 0.041343\n",
      "Episode 744/1000 complete - Max Reward: 0.041343\n",
      "Starting episode 745/1000\n",
      "  Step 1, Current reward: 0.005386\n",
      "  Step 2, Current reward: 0.005602\n",
      "  Step 3, Current reward: 0.005771\n",
      "  Step 4, Current reward: 0.005771\n",
      "  Step 5, Current reward: 0.005771\n",
      "  Step 6, Current reward: 0.005771\n",
      "  Step 7, Current reward: 0.005771\n",
      "  Step 8, Current reward: 0.005771\n",
      "  Step 9, Current reward: 0.005771\n",
      "  Step 10, Current reward: 0.005771\n",
      "  Step 11, Current reward: 0.005771\n",
      "  Step 12, Current reward: 0.005771\n",
      "  Step 13, Current reward: 0.005771\n",
      "  Step 14, Current reward: 0.005771\n",
      "Episode 745/1000 complete - Max Reward: 0.005771\n",
      "Starting episode 746/1000\n",
      "  Step 1, Current reward: 0.022906\n",
      "  Step 2, Current reward: 0.022906\n",
      "  Step 3, Current reward: 0.022906\n",
      "  Step 4, Current reward: 0.022906\n",
      "  Step 5, Current reward: 0.022906\n",
      "  Step 6, Current reward: 0.022906\n",
      "  Step 7, Current reward: 0.022906\n",
      "  Step 8, Current reward: 0.022906\n",
      "  Step 9, Current reward: 0.022906\n",
      "  Step 10, Current reward: 0.022906\n",
      "  Step 11, Current reward: 0.022906\n",
      "  Step 12, Current reward: 0.022906\n",
      "Episode 746/1000 complete - Max Reward: 0.022906\n",
      "Starting episode 747/1000\n",
      "  Step 1, Current reward: 0.001383\n",
      "  Step 2, Current reward: 0.001383\n",
      "  Step 3, Current reward: 0.001383\n",
      "  Step 4, Current reward: 0.001383\n",
      "  Step 5, Current reward: 0.001383\n",
      "  Step 6, Current reward: 0.001383\n",
      "  Step 7, Current reward: 0.001383\n",
      "  Step 8, Current reward: 0.001383\n",
      "  Step 9, Current reward: 0.001383\n",
      "  Step 10, Current reward: 0.001383\n",
      "  Step 11, Current reward: 0.001383\n",
      "  Step 12, Current reward: 0.001383\n",
      "Episode 747/1000 complete - Max Reward: 0.001383\n",
      "Starting episode 748/1000\n",
      "  Step 1, Current reward: 0.006283\n",
      "  Step 2, Current reward: 0.006283\n",
      "  Step 3, Current reward: 0.006283\n",
      "  Step 4, Current reward: 0.006283\n",
      "  Step 5, Current reward: 0.006283\n",
      "  Step 6, Current reward: 0.006283\n",
      "  Step 7, Current reward: 0.006283\n",
      "  Step 8, Current reward: 0.006283\n",
      "  Step 9, Current reward: 0.006283\n",
      "  Step 10, Current reward: 0.006283\n",
      "  Step 11, Current reward: 0.006283\n",
      "  Step 12, Current reward: 0.006283\n",
      "Episode 748/1000 complete - Max Reward: 0.006283\n",
      "Starting episode 749/1000\n",
      "  Step 1, Current reward: 0.021178\n",
      "  Step 2, Current reward: 0.021178\n",
      "  Step 3, Current reward: 0.021178\n",
      "  Step 4, Current reward: 0.021178\n",
      "  Step 5, Current reward: 0.021178\n",
      "  Step 6, Current reward: 0.021178\n",
      "  Step 7, Current reward: 0.021178\n",
      "  Step 8, Current reward: 0.021178\n",
      "  Step 9, Current reward: 0.021178\n",
      "  Step 10, Current reward: 0.021178\n",
      "  Step 11, Current reward: 0.021178\n",
      "  Step 12, Current reward: 0.021178\n",
      "Episode 749/1000 complete - Max Reward: 0.021178\n",
      "Starting episode 750/1000\n",
      "  Step 1, Current reward: 0.007147\n",
      "  Step 2, Current reward: 0.007147\n",
      "  Step 3, Current reward: 0.007147\n",
      "  Step 4, Current reward: 0.007147\n",
      "  Step 5, Current reward: 0.007147\n",
      "  Step 6, Current reward: 0.007147\n",
      "  Step 7, Current reward: 0.007147\n",
      "  Step 8, Current reward: 0.007147\n",
      "  Step 9, Current reward: 0.007147\n",
      "  Step 10, Current reward: 0.007147\n",
      "  Step 11, Current reward: 0.007147\n",
      "  Step 12, Current reward: 0.007147\n",
      "Episode 750/1000 complete - Max Reward: 0.007147\n",
      "Starting episode 751/1000\n",
      "  Step 1, Current reward: 0.007419\n",
      "  Step 2, Current reward: 0.007419\n",
      "  Step 3, Current reward: 0.007419\n",
      "  Step 4, Current reward: 0.007419\n",
      "  Step 5, Current reward: 0.007419\n",
      "  Step 6, Current reward: 0.007419\n",
      "  Step 7, Current reward: 0.007419\n",
      "  Step 8, Current reward: 0.007419\n",
      "  Step 9, Current reward: 0.007419\n",
      "  Step 10, Current reward: 0.007419\n",
      "  Step 11, Current reward: 0.007419\n",
      "  Step 12, Current reward: 0.007419\n",
      "Episode 751/1000 complete - Max Reward: 0.007419\n",
      "Starting episode 752/1000\n",
      "  Step 1, Current reward: 0.007927\n",
      "  Step 2, Current reward: 0.007927\n",
      "  Step 3, Current reward: 0.007927\n",
      "  Step 4, Current reward: 0.007927\n",
      "  Step 5, Current reward: 0.007927\n",
      "  Step 6, Current reward: 0.007927\n",
      "  Step 7, Current reward: 0.007927\n",
      "  Step 8, Current reward: 0.007927\n",
      "  Step 9, Current reward: 0.007927\n",
      "  Step 10, Current reward: 0.007927\n",
      "  Step 11, Current reward: 0.007927\n",
      "  Step 12, Current reward: 0.007927\n",
      "Episode 752/1000 complete - Max Reward: 0.007927\n",
      "Starting episode 753/1000\n",
      "  Step 1, Current reward: 0.057552\n",
      "  Step 2, Current reward: 0.057552\n",
      "  Step 3, Current reward: 0.057552\n",
      "  Step 4, Current reward: 0.057552\n",
      "  Step 5, Current reward: 0.057552\n",
      "  Step 6, Current reward: 0.057552\n",
      "  Step 7, Current reward: 0.057552\n",
      "  Step 8, Current reward: 0.057552\n",
      "  Step 9, Current reward: 0.057552\n",
      "  Step 10, Current reward: 0.057552\n",
      "  Step 11, Current reward: 0.057552\n",
      "  Step 12, Current reward: 0.057552\n",
      "Episode 753/1000 complete - Max Reward: 0.057552\n",
      "Starting episode 754/1000\n",
      "  Step 1, Current reward: 0.013180\n",
      "  Step 2, Current reward: 0.013180\n",
      "  Step 3, Current reward: 0.013180\n",
      "  Step 4, Current reward: 0.013180\n",
      "  Step 5, Current reward: 0.013180\n",
      "  Step 6, Current reward: 0.013180\n",
      "  Step 7, Current reward: 0.013180\n",
      "  Step 8, Current reward: 0.013180\n",
      "  Step 9, Current reward: 0.013180\n",
      "  Step 10, Current reward: 0.013180\n",
      "  Step 11, Current reward: 0.013180\n",
      "  Step 12, Current reward: 0.013180\n",
      "Episode 754/1000 complete - Max Reward: 0.013180\n",
      "Starting episode 755/1000\n",
      "  Step 1, Current reward: 0.041204\n",
      "  Step 2, Current reward: 0.041204\n",
      "  Step 3, Current reward: 0.041204\n",
      "  Step 4, Current reward: 0.041204\n",
      "  Step 5, Current reward: 0.041204\n",
      "  Step 6, Current reward: 0.041204\n",
      "  Step 7, Current reward: 0.041204\n",
      "  Step 8, Current reward: 0.041204\n",
      "  Step 9, Current reward: 0.041204\n",
      "  Step 10, Current reward: 0.041204\n",
      "  Step 11, Current reward: 0.041204\n",
      "  Step 12, Current reward: 0.041204\n",
      "Episode 755/1000 complete - Max Reward: 0.041204\n",
      "Starting episode 756/1000\n",
      "  Step 1, Current reward: 0.000280\n",
      "  Step 2, Current reward: 0.000280\n",
      "  Step 3, Current reward: 0.000280\n",
      "  Step 4, Current reward: 0.000280\n",
      "  Step 5, Current reward: 0.000280\n",
      "  Step 6, Current reward: 0.000280\n",
      "  Step 7, Current reward: 0.000280\n",
      "  Step 8, Current reward: 0.000280\n",
      "  Step 9, Current reward: 0.000280\n",
      "  Step 10, Current reward: 0.000280\n",
      "  Step 11, Current reward: 0.000280\n",
      "  Step 12, Current reward: 0.000280\n",
      "Episode 756/1000 complete - Max Reward: 0.000280\n",
      "Starting episode 757/1000\n",
      "  Step 1, Current reward: 0.025807\n",
      "  Step 2, Current reward: 0.025807\n",
      "  Step 3, Current reward: 0.025807\n",
      "  Step 4, Current reward: 0.025807\n",
      "  Step 5, Current reward: 0.025807\n",
      "  Step 6, Current reward: 0.025807\n",
      "  Step 7, Current reward: 0.025807\n",
      "  Step 8, Current reward: 0.025807\n",
      "  Step 9, Current reward: 0.025807\n",
      "  Step 10, Current reward: 0.025807\n",
      "  Step 11, Current reward: 0.025807\n",
      "  Step 12, Current reward: 0.025807\n",
      "Episode 757/1000 complete - Max Reward: 0.025807\n",
      "Starting episode 758/1000\n",
      "  Step 1, Current reward: 0.012006\n",
      "  Step 2, Current reward: 0.012006\n",
      "  Step 3, Current reward: 0.012006\n",
      "  Step 4, Current reward: 0.012006\n",
      "  Step 5, Current reward: 0.012006\n",
      "  Step 6, Current reward: 0.012006\n",
      "  Step 7, Current reward: 0.012006\n",
      "  Step 8, Current reward: 0.012006\n",
      "  Step 9, Current reward: 0.012006\n",
      "  Step 10, Current reward: 0.012006\n",
      "  Step 11, Current reward: 0.012006\n",
      "  Step 12, Current reward: 0.012006\n",
      "Episode 758/1000 complete - Max Reward: 0.012006\n",
      "Starting episode 759/1000\n",
      "  Step 1, Current reward: 0.004559\n",
      "  Step 2, Current reward: 0.004559\n",
      "  Step 3, Current reward: 0.004559\n",
      "  Step 4, Current reward: 0.004559\n",
      "  Step 5, Current reward: 0.004559\n",
      "  Step 6, Current reward: 0.004559\n",
      "  Step 7, Current reward: 0.004559\n",
      "  Step 8, Current reward: 0.004559\n",
      "  Step 9, Current reward: 0.004559\n",
      "  Step 10, Current reward: 0.004559\n",
      "  Step 11, Current reward: 0.004559\n",
      "  Step 12, Current reward: 0.004559\n",
      "Episode 759/1000 complete - Max Reward: 0.004559\n",
      "Starting episode 760/1000\n",
      "  Step 1, Current reward: 0.009747\n",
      "  Step 2, Current reward: 0.009747\n",
      "  Step 3, Current reward: 0.009747\n",
      "  Step 4, Current reward: 0.009747\n",
      "  Step 5, Current reward: 0.009747\n",
      "  Step 6, Current reward: 0.009747\n",
      "  Step 7, Current reward: 0.009747\n",
      "  Step 8, Current reward: 0.009747\n",
      "  Step 9, Current reward: 0.009747\n",
      "  Step 10, Current reward: 0.009747\n",
      "  Step 11, Current reward: 0.009747\n",
      "  Step 12, Current reward: 0.009747\n",
      "Episode 760/1000 complete - Max Reward: 0.009747\n",
      "Starting episode 761/1000\n",
      "  Step 1, Current reward: 0.019233\n",
      "  Step 2, Current reward: 0.019233\n",
      "  Step 3, Current reward: 0.019233\n",
      "  Step 4, Current reward: 0.019233\n",
      "  Step 5, Current reward: 0.019233\n",
      "  Step 6, Current reward: 0.019233\n",
      "  Step 7, Current reward: 0.019233\n",
      "  Step 8, Current reward: 0.019233\n",
      "  Step 9, Current reward: 0.019233\n",
      "  Step 10, Current reward: 0.019233\n",
      "  Step 11, Current reward: 0.019233\n",
      "  Step 12, Current reward: 0.019233\n",
      "Episode 761/1000 complete - Max Reward: 0.019233\n",
      "Starting episode 762/1000\n",
      "  Step 1, Current reward: 0.028115\n",
      "  Step 2, Current reward: 0.028115\n",
      "  Step 3, Current reward: 0.028115\n",
      "  Step 4, Current reward: 0.028115\n",
      "  Step 5, Current reward: 0.028115\n",
      "  Step 6, Current reward: 0.028115\n",
      "  Step 7, Current reward: 0.028115\n",
      "  Step 8, Current reward: 0.028115\n",
      "  Step 9, Current reward: 0.028115\n",
      "  Step 10, Current reward: 0.028115\n",
      "  Step 11, Current reward: 0.028115\n",
      "  Step 12, Current reward: 0.028115\n",
      "Episode 762/1000 complete - Max Reward: 0.028115\n",
      "Starting episode 763/1000\n",
      "  Step 1, Current reward: 0.012055\n",
      "  Step 2, Current reward: 0.012055\n",
      "  Step 3, Current reward: 0.012055\n",
      "  Step 4, Current reward: 0.012055\n",
      "  Step 5, Current reward: 0.012055\n",
      "  Step 6, Current reward: 0.012055\n",
      "  Step 7, Current reward: 0.012055\n",
      "  Step 8, Current reward: 0.012055\n",
      "  Step 9, Current reward: 0.012055\n",
      "  Step 10, Current reward: 0.012055\n",
      "  Step 11, Current reward: 0.012055\n",
      "  Step 12, Current reward: 0.012055\n",
      "Episode 763/1000 complete - Max Reward: 0.012055\n",
      "Starting episode 764/1000\n",
      "  Step 1, Current reward: 0.029917\n",
      "  Step 2, Current reward: 0.029917\n",
      "  Step 3, Current reward: 0.029917\n",
      "  Step 4, Current reward: 0.029917\n",
      "  Step 5, Current reward: 0.029917\n",
      "  Step 6, Current reward: 0.029917\n",
      "  Step 7, Current reward: 0.029917\n",
      "  Step 8, Current reward: 0.029917\n",
      "  Step 9, Current reward: 0.029917\n",
      "  Step 10, Current reward: 0.029917\n",
      "  Step 11, Current reward: 0.029917\n",
      "  Step 12, Current reward: 0.029917\n",
      "Episode 764/1000 complete - Max Reward: 0.029917\n",
      "Starting episode 765/1000\n",
      "  Step 1, Current reward: 0.007217\n",
      "  Step 2, Current reward: 0.007217\n",
      "  Step 3, Current reward: 0.007217\n",
      "  Step 4, Current reward: 0.007217\n",
      "  Step 5, Current reward: 0.007217\n",
      "  Step 6, Current reward: 0.007217\n",
      "  Step 7, Current reward: 0.007217\n",
      "  Step 8, Current reward: 0.007217\n",
      "  Step 9, Current reward: 0.007217\n",
      "  Step 10, Current reward: 0.007217\n",
      "  Step 11, Current reward: 0.007217\n",
      "  Step 12, Current reward: 0.007217\n",
      "Episode 765/1000 complete - Max Reward: 0.007217\n",
      "Starting episode 766/1000\n",
      "  Step 1, Current reward: 0.061737\n",
      "  Step 2, Current reward: 0.061737\n",
      "  Step 3, Current reward: 0.061737\n",
      "  Step 4, Current reward: 0.061737\n",
      "  Step 5, Current reward: 0.061737\n",
      "  Step 6, Current reward: 0.061737\n",
      "  Step 7, Current reward: 0.061737\n",
      "  Step 8, Current reward: 0.061737\n",
      "  Step 9, Current reward: 0.061737\n",
      "  Step 10, Current reward: 0.061737\n",
      "  Step 11, Current reward: 0.061737\n",
      "  Step 12, Current reward: 0.061737\n",
      "Episode 766/1000 complete - Max Reward: 0.061737\n",
      "Starting episode 767/1000\n",
      "  Step 1, Current reward: 0.003119\n",
      "  Step 2, Current reward: 0.003119\n",
      "  Step 3, Current reward: 0.003119\n",
      "  Step 4, Current reward: 0.003119\n",
      "  Step 5, Current reward: 0.003119\n",
      "  Step 6, Current reward: 0.003119\n",
      "  Step 7, Current reward: 0.003119\n",
      "  Step 8, Current reward: 0.003119\n",
      "  Step 9, Current reward: 0.003119\n",
      "  Step 10, Current reward: 0.003119\n",
      "  Step 11, Current reward: 0.003119\n",
      "  Step 12, Current reward: 0.003119\n",
      "Episode 767/1000 complete - Max Reward: 0.003119\n",
      "Starting episode 768/1000\n",
      "  Step 1, Current reward: 0.010817\n",
      "  Step 2, Current reward: 0.010817\n",
      "  Step 3, Current reward: 0.010817\n",
      "  Step 4, Current reward: 0.010817\n",
      "  Step 5, Current reward: 0.010817\n",
      "  Step 6, Current reward: 0.010817\n",
      "  Step 7, Current reward: 0.010817\n",
      "  Step 8, Current reward: 0.010817\n",
      "  Step 9, Current reward: 0.010817\n",
      "  Step 10, Current reward: 0.010817\n",
      "  Step 11, Current reward: 0.010817\n",
      "  Step 12, Current reward: 0.010817\n",
      "Episode 768/1000 complete - Max Reward: 0.010817\n",
      "Starting episode 769/1000\n",
      "  Step 1, Current reward: 0.041205\n",
      "  Step 2, Current reward: 0.041205\n",
      "  Step 3, Current reward: 0.041205\n",
      "  Step 4, Current reward: 0.041205\n",
      "  Step 5, Current reward: 0.041205\n",
      "  Step 6, Current reward: 0.041205\n",
      "  Step 7, Current reward: 0.041205\n",
      "  Step 8, Current reward: 0.041205\n",
      "  Step 9, Current reward: 0.041205\n",
      "  Step 10, Current reward: 0.041205\n",
      "  Step 11, Current reward: 0.041205\n",
      "  Step 12, Current reward: 0.041205\n",
      "Episode 769/1000 complete - Max Reward: 0.041205\n",
      "Starting episode 770/1000\n",
      "  Step 1, Current reward: 0.013914\n",
      "  Step 2, Current reward: 0.013914\n",
      "  Step 3, Current reward: 0.013914\n",
      "  Step 4, Current reward: 0.013914\n",
      "  Step 5, Current reward: 0.013914\n",
      "  Step 6, Current reward: 0.013914\n",
      "  Step 7, Current reward: 0.013914\n",
      "  Step 8, Current reward: 0.013914\n",
      "  Step 9, Current reward: 0.013914\n",
      "  Step 10, Current reward: 0.013914\n",
      "  Step 11, Current reward: 0.013914\n",
      "  Step 12, Current reward: 0.013914\n",
      "Episode 770/1000 complete - Max Reward: 0.013914\n",
      "Starting episode 771/1000\n",
      "  Step 1, Current reward: 0.039825\n",
      "  Step 2, Current reward: 0.039825\n",
      "  Step 3, Current reward: 0.039825\n",
      "  Step 4, Current reward: 0.039825\n",
      "  Step 5, Current reward: 0.039825\n",
      "  Step 6, Current reward: 0.039825\n",
      "  Step 7, Current reward: 0.039825\n",
      "  Step 8, Current reward: 0.039825\n",
      "  Step 9, Current reward: 0.039825\n",
      "  Step 10, Current reward: 0.039825\n",
      "  Step 11, Current reward: 0.039825\n",
      "  Step 12, Current reward: 0.039825\n",
      "Episode 771/1000 complete - Max Reward: 0.039825\n",
      "Starting episode 772/1000\n",
      "  Step 1, Current reward: 0.010630\n",
      "  Step 2, Current reward: 0.010630\n",
      "  Step 3, Current reward: 0.010630\n",
      "  Step 4, Current reward: 0.010630\n",
      "  Step 5, Current reward: 0.010630\n",
      "  Step 6, Current reward: 0.010630\n",
      "  Step 7, Current reward: 0.010630\n",
      "  Step 8, Current reward: 0.010630\n",
      "  Step 9, Current reward: 0.010630\n",
      "  Step 10, Current reward: 0.010630\n",
      "  Step 11, Current reward: 0.010630\n",
      "  Step 12, Current reward: 0.010630\n",
      "Episode 772/1000 complete - Max Reward: 0.010630\n",
      "Starting episode 773/1000\n",
      "  Step 1, Current reward: 0.005110\n",
      "  Step 2, Current reward: 0.005110\n",
      "  Step 3, Current reward: 0.005110\n",
      "  Step 4, Current reward: 0.005110\n",
      "  Step 5, Current reward: 0.005110\n",
      "  Step 6, Current reward: 0.005110\n",
      "  Step 7, Current reward: 0.005110\n",
      "  Step 8, Current reward: 0.005110\n",
      "  Step 9, Current reward: 0.005110\n",
      "  Step 10, Current reward: 0.005110\n",
      "  Step 11, Current reward: 0.005110\n",
      "  Step 12, Current reward: 0.005110\n",
      "Episode 773/1000 complete - Max Reward: 0.005110\n",
      "Starting episode 774/1000\n",
      "  Step 1, Current reward: 0.022765\n",
      "  Step 2, Current reward: 0.022765\n",
      "  Step 3, Current reward: 0.022765\n",
      "  Step 4, Current reward: 0.022765\n",
      "  Step 5, Current reward: 0.022765\n",
      "  Step 6, Current reward: 0.022765\n",
      "  Step 7, Current reward: 0.022765\n",
      "  Step 8, Current reward: 0.022765\n",
      "  Step 9, Current reward: 0.022765\n",
      "  Step 10, Current reward: 0.022765\n",
      "  Step 11, Current reward: 0.022765\n",
      "  Step 12, Current reward: 0.022765\n",
      "Episode 774/1000 complete - Max Reward: 0.022765\n",
      "Starting episode 775/1000\n",
      "  Step 1, Current reward: 0.104985\n",
      "  Step 2, Current reward: 0.104985\n",
      "  Step 3, Current reward: 0.104985\n",
      "  Step 4, Current reward: 0.104985\n",
      "  Step 5, Current reward: 0.104985\n",
      "  Step 6, Current reward: 0.104985\n",
      "  Step 7, Current reward: 0.104985\n",
      "  Step 8, Current reward: 0.104985\n",
      "  Step 9, Current reward: 0.104985\n",
      "  Step 10, Current reward: 0.104985\n",
      "  Step 11, Current reward: 0.104985\n",
      "  Step 12, Current reward: 0.104985\n",
      "Episode 775/1000 complete - Max Reward: 0.104985\n",
      "Starting episode 776/1000\n",
      "  Step 1, Current reward: 0.006766\n",
      "  Step 2, Current reward: 0.006766\n",
      "  Step 3, Current reward: 0.006766\n",
      "  Step 4, Current reward: 0.006766\n",
      "  Step 5, Current reward: 0.006766\n",
      "  Step 6, Current reward: 0.006766\n",
      "  Step 7, Current reward: 0.006766\n",
      "  Step 8, Current reward: 0.006766\n",
      "  Step 9, Current reward: 0.006766\n",
      "  Step 10, Current reward: 0.006766\n",
      "  Step 11, Current reward: 0.006766\n",
      "  Step 12, Current reward: 0.006766\n",
      "Episode 776/1000 complete - Max Reward: 0.006766\n",
      "Starting episode 777/1000\n",
      "  Step 1, Current reward: 0.010578\n",
      "  Step 2, Current reward: 0.010578\n",
      "  Step 3, Current reward: 0.010578\n",
      "  Step 4, Current reward: 0.010578\n",
      "  Step 5, Current reward: 0.010578\n",
      "  Step 6, Current reward: 0.010578\n",
      "  Step 7, Current reward: 0.010578\n",
      "  Step 8, Current reward: 0.010578\n",
      "  Step 9, Current reward: 0.010578\n",
      "  Step 10, Current reward: 0.010578\n",
      "  Step 11, Current reward: 0.010578\n",
      "  Step 12, Current reward: 0.010578\n",
      "Episode 777/1000 complete - Max Reward: 0.010578\n",
      "Starting episode 778/1000\n",
      "  Step 1, Current reward: 0.001399\n",
      "  Step 2, Current reward: 0.001399\n",
      "  Step 3, Current reward: 0.001399\n",
      "  Step 4, Current reward: 0.001399\n",
      "  Step 5, Current reward: 0.001399\n",
      "  Step 6, Current reward: 0.001399\n",
      "  Step 7, Current reward: 0.001399\n",
      "  Step 8, Current reward: 0.001399\n",
      "  Step 9, Current reward: 0.001399\n",
      "  Step 10, Current reward: 0.001399\n",
      "  Step 11, Current reward: 0.001399\n",
      "  Step 12, Current reward: 0.001399\n",
      "Episode 778/1000 complete - Max Reward: 0.001399\n",
      "Starting episode 779/1000\n",
      "  Step 1, Current reward: 0.009585\n",
      "  Step 2, Current reward: 0.009585\n",
      "  Step 3, Current reward: 0.009585\n",
      "  Step 4, Current reward: 0.009585\n",
      "  Step 5, Current reward: 0.009585\n",
      "  Step 6, Current reward: 0.009585\n",
      "  Step 7, Current reward: 0.009585\n",
      "  Step 8, Current reward: 0.009585\n",
      "  Step 9, Current reward: 0.009585\n",
      "  Step 10, Current reward: 0.009585\n",
      "  Step 11, Current reward: 0.009585\n",
      "  Step 12, Current reward: 0.009585\n",
      "Episode 779/1000 complete - Max Reward: 0.009585\n",
      "Starting episode 780/1000\n",
      "  Step 1, Current reward: 0.001127\n",
      "  Step 2, Current reward: 0.000870\n",
      "  Step 3, Current reward: 0.000870\n",
      "  Step 4, Current reward: 0.000870\n",
      "  Step 5, Current reward: 0.000870\n",
      "  Step 6, Current reward: 0.000870\n",
      "  Step 7, Current reward: 0.000870\n",
      "  Step 8, Current reward: 0.000870\n",
      "  Step 9, Current reward: 0.000870\n",
      "  Step 10, Current reward: 0.000870\n",
      "  Step 11, Current reward: 0.000870\n",
      "  Step 12, Current reward: 0.000870\n",
      "Episode 780/1000 complete - Max Reward: 0.001127\n",
      "Starting episode 781/1000\n",
      "  Step 1, Current reward: 0.017130\n",
      "  Step 2, Current reward: 0.017130\n",
      "  Step 3, Current reward: 0.017130\n",
      "  Step 4, Current reward: 0.017130\n",
      "  Step 5, Current reward: 0.017130\n",
      "  Step 6, Current reward: 0.017130\n",
      "  Step 7, Current reward: 0.017130\n",
      "  Step 8, Current reward: 0.017130\n",
      "  Step 9, Current reward: 0.017130\n",
      "  Step 10, Current reward: 0.017130\n",
      "  Step 11, Current reward: 0.017130\n",
      "  Step 12, Current reward: 0.017130\n",
      "Episode 781/1000 complete - Max Reward: 0.017130\n",
      "Starting episode 782/1000\n",
      "  Step 1, Current reward: 0.070898\n",
      "  Step 2, Current reward: 0.070898\n",
      "  Step 3, Current reward: 0.070898\n",
      "  Step 4, Current reward: 0.070898\n",
      "  Step 5, Current reward: 0.070898\n",
      "  Step 6, Current reward: 0.070898\n",
      "  Step 7, Current reward: 0.070898\n",
      "  Step 8, Current reward: 0.070898\n",
      "  Step 9, Current reward: 0.070898\n",
      "  Step 10, Current reward: 0.070898\n",
      "  Step 11, Current reward: 0.070898\n",
      "  Step 12, Current reward: 0.070898\n",
      "Episode 782/1000 complete - Max Reward: 0.070898\n",
      "Starting episode 783/1000\n",
      "  Step 1, Current reward: 0.109507\n",
      "  Step 2, Current reward: 0.109507\n",
      "  Step 3, Current reward: 0.109507\n",
      "  Step 4, Current reward: 0.109507\n",
      "  Step 5, Current reward: 0.109507\n",
      "  Step 6, Current reward: 0.109507\n",
      "  Step 7, Current reward: 0.109507\n",
      "  Step 8, Current reward: 0.109507\n",
      "  Step 9, Current reward: 0.109507\n",
      "  Step 10, Current reward: 0.109507\n",
      "  Step 11, Current reward: 0.109507\n",
      "  Step 12, Current reward: 0.109507\n",
      "Episode 783/1000 complete - Max Reward: 0.109507\n",
      "Starting episode 784/1000\n",
      "  Step 1, Current reward: 0.016513\n",
      "  Step 2, Current reward: 0.016513\n",
      "  Step 3, Current reward: 0.016513\n",
      "  Step 4, Current reward: 0.016513\n",
      "  Step 5, Current reward: 0.016513\n",
      "  Step 6, Current reward: 0.016513\n",
      "  Step 7, Current reward: 0.016513\n",
      "  Step 8, Current reward: 0.016513\n",
      "  Step 9, Current reward: 0.016513\n",
      "  Step 10, Current reward: 0.016513\n",
      "  Step 11, Current reward: 0.016513\n",
      "  Step 12, Current reward: 0.016513\n",
      "Episode 784/1000 complete - Max Reward: 0.016513\n",
      "Starting episode 785/1000\n",
      "  Step 1, Current reward: 0.014952\n",
      "  Step 2, Current reward: 0.014952\n",
      "  Step 3, Current reward: 0.014952\n",
      "  Step 4, Current reward: 0.014952\n",
      "  Step 5, Current reward: 0.014952\n",
      "  Step 6, Current reward: 0.014952\n",
      "  Step 7, Current reward: 0.014952\n",
      "  Step 8, Current reward: 0.014952\n",
      "  Step 9, Current reward: 0.014952\n",
      "  Step 10, Current reward: 0.014952\n",
      "  Step 11, Current reward: 0.014952\n",
      "  Step 12, Current reward: 0.014952\n",
      "Episode 785/1000 complete - Max Reward: 0.014952\n",
      "Starting episode 786/1000\n",
      "  Step 1, Current reward: 0.006357\n",
      "  Step 2, Current reward: 0.006357\n",
      "  Step 3, Current reward: 0.006357\n",
      "  Step 4, Current reward: 0.006357\n",
      "  Step 5, Current reward: 0.006357\n",
      "  Step 6, Current reward: 0.006357\n",
      "  Step 7, Current reward: 0.006357\n",
      "  Step 8, Current reward: 0.006357\n",
      "  Step 9, Current reward: 0.006357\n",
      "  Step 10, Current reward: 0.006357\n",
      "  Step 11, Current reward: 0.006357\n",
      "  Step 12, Current reward: 0.006357\n",
      "Episode 786/1000 complete - Max Reward: 0.006357\n",
      "Starting episode 787/1000\n",
      "  Step 1, Current reward: 0.048186\n",
      "  Step 2, Current reward: 0.048186\n",
      "  Step 3, Current reward: 0.048186\n",
      "  Step 4, Current reward: 0.048186\n",
      "  Step 5, Current reward: 0.048186\n",
      "  Step 6, Current reward: 0.048186\n",
      "  Step 7, Current reward: 0.048186\n",
      "  Step 8, Current reward: 0.048186\n",
      "  Step 9, Current reward: 0.048186\n",
      "  Step 10, Current reward: 0.048186\n",
      "  Step 11, Current reward: 0.048186\n",
      "  Step 12, Current reward: 0.048186\n",
      "Episode 787/1000 complete - Max Reward: 0.048186\n",
      "Starting episode 788/1000\n",
      "  Step 1, Current reward: 0.000717\n",
      "  Step 2, Current reward: 0.000717\n",
      "  Step 3, Current reward: 0.000717\n",
      "  Step 4, Current reward: 0.000717\n",
      "  Step 5, Current reward: 0.000717\n",
      "  Step 6, Current reward: 0.000717\n",
      "  Step 7, Current reward: 0.000717\n",
      "  Step 8, Current reward: 0.000717\n",
      "  Step 9, Current reward: 0.000717\n",
      "  Step 10, Current reward: 0.000717\n",
      "  Step 11, Current reward: 0.000717\n",
      "  Step 12, Current reward: 0.000717\n",
      "Episode 788/1000 complete - Max Reward: 0.000717\n",
      "Starting episode 789/1000\n",
      "  Step 1, Current reward: 0.005613\n",
      "  Step 2, Current reward: 0.005613\n",
      "  Step 3, Current reward: 0.005613\n",
      "  Step 4, Current reward: 0.005613\n",
      "  Step 5, Current reward: 0.005613\n",
      "  Step 6, Current reward: 0.005613\n",
      "  Step 7, Current reward: 0.005613\n",
      "  Step 8, Current reward: 0.005613\n",
      "  Step 9, Current reward: 0.005613\n",
      "  Step 10, Current reward: 0.005613\n",
      "  Step 11, Current reward: 0.005613\n",
      "  Step 12, Current reward: 0.005613\n",
      "Episode 789/1000 complete - Max Reward: 0.005613\n",
      "Starting episode 790/1000\n",
      "  Step 1, Current reward: 0.021626\n",
      "  Step 2, Current reward: 0.021626\n",
      "  Step 3, Current reward: 0.021626\n",
      "  Step 4, Current reward: 0.021626\n",
      "  Step 5, Current reward: 0.021626\n",
      "  Step 6, Current reward: 0.021626\n",
      "  Step 7, Current reward: 0.021626\n",
      "  Step 8, Current reward: 0.021626\n",
      "  Step 9, Current reward: 0.021626\n",
      "  Step 10, Current reward: 0.021626\n",
      "  Step 11, Current reward: 0.021626\n",
      "  Step 12, Current reward: 0.021626\n",
      "Episode 790/1000 complete - Max Reward: 0.021626\n",
      "Starting episode 791/1000\n",
      "  Step 1, Current reward: 0.010774\n",
      "  Step 2, Current reward: 0.010774\n",
      "  Step 3, Current reward: 0.010774\n",
      "  Step 4, Current reward: 0.010774\n",
      "  Step 5, Current reward: 0.010774\n",
      "  Step 6, Current reward: 0.010774\n",
      "  Step 7, Current reward: 0.010774\n",
      "  Step 8, Current reward: 0.010774\n",
      "  Step 9, Current reward: 0.010774\n",
      "  Step 10, Current reward: 0.010774\n",
      "  Step 11, Current reward: 0.010774\n",
      "  Step 12, Current reward: 0.010774\n",
      "Episode 791/1000 complete - Max Reward: 0.010774\n",
      "Starting episode 792/1000\n",
      "  Step 1, Current reward: 0.070977\n",
      "  Step 2, Current reward: 0.070977\n",
      "  Step 3, Current reward: 0.070977\n",
      "  Step 4, Current reward: 0.070977\n",
      "  Step 5, Current reward: 0.070977\n",
      "  Step 6, Current reward: 0.070977\n",
      "  Step 7, Current reward: 0.070977\n",
      "  Step 8, Current reward: 0.070977\n",
      "  Step 9, Current reward: 0.070977\n",
      "  Step 10, Current reward: 0.070977\n",
      "  Step 11, Current reward: 0.070977\n",
      "  Step 12, Current reward: 0.070977\n",
      "Episode 792/1000 complete - Max Reward: 0.070977\n",
      "Starting episode 793/1000\n",
      "  Step 1, Current reward: 0.012003\n",
      "  Step 2, Current reward: 0.012003\n",
      "  Step 3, Current reward: 0.012003\n",
      "  Step 4, Current reward: 0.012003\n",
      "  Step 5, Current reward: 0.012003\n",
      "  Step 6, Current reward: 0.012003\n",
      "  Step 7, Current reward: 0.012003\n",
      "  Step 8, Current reward: 0.012003\n",
      "  Step 9, Current reward: 0.012003\n",
      "  Step 10, Current reward: 0.012003\n",
      "  Step 11, Current reward: 0.012003\n",
      "  Step 12, Current reward: 0.012003\n",
      "Episode 793/1000 complete - Max Reward: 0.012003\n",
      "Starting episode 794/1000\n",
      "  Step 1, Current reward: 0.031431\n",
      "  Step 2, Current reward: 0.031431\n",
      "  Step 3, Current reward: 0.031431\n",
      "  Step 4, Current reward: 0.031431\n",
      "  Step 5, Current reward: 0.031431\n",
      "  Step 6, Current reward: 0.031431\n",
      "  Step 7, Current reward: 0.031431\n",
      "  Step 8, Current reward: 0.031431\n",
      "  Step 9, Current reward: 0.031431\n",
      "  Step 10, Current reward: 0.031431\n",
      "  Step 11, Current reward: 0.031431\n",
      "  Step 12, Current reward: 0.031431\n",
      "Episode 794/1000 complete - Max Reward: 0.031431\n",
      "Starting episode 795/1000\n",
      "  Step 1, Current reward: 0.029967\n",
      "  Step 2, Current reward: 0.029967\n",
      "  Step 3, Current reward: 0.029967\n",
      "  Step 4, Current reward: 0.029967\n",
      "  Step 5, Current reward: 0.029967\n",
      "  Step 6, Current reward: 0.029967\n",
      "  Step 7, Current reward: 0.029967\n",
      "  Step 8, Current reward: 0.029967\n",
      "  Step 9, Current reward: 0.029967\n",
      "  Step 10, Current reward: 0.029967\n",
      "  Step 11, Current reward: 0.029967\n",
      "  Step 12, Current reward: 0.029967\n",
      "Episode 795/1000 complete - Max Reward: 0.029967\n",
      "Starting episode 796/1000\n",
      "  Step 1, Current reward: 0.021403\n",
      "  Step 2, Current reward: 0.021403\n",
      "  Step 3, Current reward: 0.021403\n",
      "  Step 4, Current reward: 0.021403\n",
      "  Step 5, Current reward: 0.021403\n",
      "  Step 6, Current reward: 0.021403\n",
      "  Step 7, Current reward: 0.021403\n",
      "  Step 8, Current reward: 0.021403\n",
      "  Step 9, Current reward: 0.021403\n",
      "  Step 10, Current reward: 0.021403\n",
      "  Step 11, Current reward: 0.021403\n",
      "  Step 12, Current reward: 0.021403\n",
      "Episode 796/1000 complete - Max Reward: 0.021403\n",
      "Starting episode 797/1000\n",
      "  Step 1, Current reward: 0.014085\n",
      "  Step 2, Current reward: 0.014085\n",
      "  Step 3, Current reward: 0.014085\n",
      "  Step 4, Current reward: 0.014085\n",
      "  Step 5, Current reward: 0.014085\n",
      "  Step 6, Current reward: 0.014085\n",
      "  Step 7, Current reward: 0.014085\n",
      "  Step 8, Current reward: 0.014085\n",
      "  Step 9, Current reward: 0.014085\n",
      "  Step 10, Current reward: 0.014085\n",
      "  Step 11, Current reward: 0.014085\n",
      "  Step 12, Current reward: 0.014085\n",
      "Episode 797/1000 complete - Max Reward: 0.014085\n",
      "Starting episode 798/1000\n",
      "  Step 1, Current reward: 0.019135\n",
      "  Step 2, Current reward: 0.019135\n",
      "  Step 3, Current reward: 0.019135\n",
      "  Step 4, Current reward: 0.019135\n",
      "  Step 5, Current reward: 0.019135\n",
      "  Step 6, Current reward: 0.019135\n",
      "  Step 7, Current reward: 0.019135\n",
      "  Step 8, Current reward: 0.019135\n",
      "  Step 9, Current reward: 0.019135\n",
      "  Step 10, Current reward: 0.019135\n",
      "  Step 11, Current reward: 0.019135\n",
      "  Step 12, Current reward: 0.019135\n",
      "Episode 798/1000 complete - Max Reward: 0.019135\n",
      "Starting episode 799/1000\n",
      "  Step 1, Current reward: 0.020164\n",
      "  Step 2, Current reward: 0.020164\n",
      "  Step 3, Current reward: 0.020164\n",
      "  Step 4, Current reward: 0.020164\n",
      "  Step 5, Current reward: 0.020164\n",
      "  Step 6, Current reward: 0.020164\n",
      "  Step 7, Current reward: 0.020164\n",
      "  Step 8, Current reward: 0.020164\n",
      "  Step 9, Current reward: 0.020164\n",
      "  Step 10, Current reward: 0.020164\n",
      "  Step 11, Current reward: 0.020164\n",
      "  Step 12, Current reward: 0.020164\n",
      "Episode 799/1000 complete - Max Reward: 0.020164\n",
      "Starting episode 800/1000\n",
      "  Step 1, Current reward: 0.023326\n",
      "  Step 2, Current reward: 0.023326\n",
      "  Step 3, Current reward: 0.023326\n",
      "  Step 4, Current reward: 0.023326\n",
      "  Step 5, Current reward: 0.023326\n",
      "  Step 6, Current reward: 0.023326\n",
      "  Step 7, Current reward: 0.023326\n",
      "  Step 8, Current reward: 0.023326\n",
      "  Step 9, Current reward: 0.023326\n",
      "  Step 10, Current reward: 0.023326\n",
      "  Step 11, Current reward: 0.023326\n",
      "  Step 12, Current reward: 0.023326\n",
      "Episode 800/1000 complete - Max Reward: 0.023326\n",
      "Starting episode 801/1000\n",
      "  Step 1, Current reward: 0.002298\n",
      "  Step 2, Current reward: 0.002298\n",
      "  Step 3, Current reward: 0.002298\n",
      "  Step 4, Current reward: 0.002298\n",
      "  Step 5, Current reward: 0.002298\n",
      "  Step 6, Current reward: 0.002298\n",
      "  Step 7, Current reward: 0.002298\n",
      "  Step 8, Current reward: 0.002298\n",
      "  Step 9, Current reward: 0.002298\n",
      "  Step 10, Current reward: 0.002298\n",
      "  Step 11, Current reward: 0.002298\n",
      "  Step 12, Current reward: 0.002298\n",
      "Episode 801/1000 complete - Max Reward: 0.002298\n",
      "Starting episode 802/1000\n",
      "  Step 1, Current reward: 0.065146\n",
      "  Step 2, Current reward: 0.065146\n",
      "  Step 3, Current reward: 0.065146\n",
      "  Step 4, Current reward: 0.065146\n",
      "  Step 5, Current reward: 0.065146\n",
      "  Step 6, Current reward: 0.065146\n",
      "  Step 7, Current reward: 0.065146\n",
      "  Step 8, Current reward: 0.065146\n",
      "  Step 9, Current reward: 0.065146\n",
      "  Step 10, Current reward: 0.065146\n",
      "  Step 11, Current reward: 0.065146\n",
      "  Step 12, Current reward: 0.065146\n",
      "Episode 802/1000 complete - Max Reward: 0.065146\n",
      "Starting episode 803/1000\n",
      "  Step 1, Current reward: 0.004549\n",
      "  Step 2, Current reward: 0.004549\n",
      "  Step 3, Current reward: 0.004549\n",
      "  Step 4, Current reward: 0.004549\n",
      "  Step 5, Current reward: 0.004549\n",
      "  Step 6, Current reward: 0.004549\n",
      "  Step 7, Current reward: 0.004549\n",
      "  Step 8, Current reward: 0.004549\n",
      "  Step 9, Current reward: 0.004549\n",
      "  Step 10, Current reward: 0.004549\n",
      "  Step 11, Current reward: 0.004549\n",
      "  Step 12, Current reward: 0.004549\n",
      "Episode 803/1000 complete - Max Reward: 0.004549\n",
      "Starting episode 804/1000\n",
      "  Step 1, Current reward: 0.161847\n",
      "  Step 2, Current reward: 0.161847\n",
      "  Step 3, Current reward: 0.161847\n",
      "  Step 4, Current reward: 0.161847\n",
      "  Step 5, Current reward: 0.161847\n",
      "  Step 6, Current reward: 0.161847\n",
      "  Step 7, Current reward: 0.161847\n",
      "  Step 8, Current reward: 0.161847\n",
      "  Step 9, Current reward: 0.161847\n",
      "  Step 10, Current reward: 0.161847\n",
      "  Step 11, Current reward: 0.161847\n",
      "  Step 12, Current reward: 0.161847\n",
      "Episode 804/1000 complete - Max Reward: 0.161847\n",
      "Starting episode 805/1000\n",
      "  Step 1, Current reward: 0.001147\n",
      "  Step 2, Current reward: 0.001009\n",
      "  Step 3, Current reward: 0.000892\n",
      "  Step 4, Current reward: 0.000795\n",
      "  Step 5, Current reward: 0.000707\n",
      "  Step 6, Current reward: 0.000612\n",
      "  Step 7, Current reward: 0.000497\n",
      "  Step 8, Current reward: 0.000365\n",
      "  Step 9, Current reward: 0.000239\n",
      "  Step 10, Current reward: 0.000141\n",
      "  Step 11, Current reward: 0.000080\n",
      "  Step 12, Current reward: 0.000050\n",
      "Episode 805/1000 complete - Max Reward: 0.001147\n",
      "Starting episode 806/1000\n",
      "  Step 1, Current reward: 0.023025\n",
      "  Step 2, Current reward: 0.023025\n",
      "  Step 3, Current reward: 0.023025\n",
      "  Step 4, Current reward: 0.023025\n",
      "  Step 5, Current reward: 0.023025\n",
      "  Step 6, Current reward: 0.023025\n",
      "  Step 7, Current reward: 0.023025\n",
      "  Step 8, Current reward: 0.023025\n",
      "  Step 9, Current reward: 0.023025\n",
      "  Step 10, Current reward: 0.023025\n",
      "  Step 11, Current reward: 0.023025\n",
      "  Step 12, Current reward: 0.023025\n",
      "Episode 806/1000 complete - Max Reward: 0.023025\n",
      "Starting episode 807/1000\n",
      "  Step 1, Current reward: 0.010248\n",
      "  Step 2, Current reward: 0.010248\n",
      "  Step 3, Current reward: 0.010248\n",
      "  Step 4, Current reward: 0.010248\n",
      "  Step 5, Current reward: 0.010248\n",
      "  Step 6, Current reward: 0.010248\n",
      "  Step 7, Current reward: 0.010248\n",
      "  Step 8, Current reward: 0.010248\n",
      "  Step 9, Current reward: 0.010248\n",
      "  Step 10, Current reward: 0.010248\n",
      "  Step 11, Current reward: 0.010248\n",
      "  Step 12, Current reward: 0.010248\n",
      "Episode 807/1000 complete - Max Reward: 0.010248\n",
      "Starting episode 808/1000\n",
      "  Step 1, Current reward: 0.004585\n",
      "  Step 2, Current reward: 0.004585\n",
      "  Step 3, Current reward: 0.004585\n",
      "  Step 4, Current reward: 0.004585\n",
      "  Step 5, Current reward: 0.004585\n",
      "  Step 6, Current reward: 0.004585\n",
      "  Step 7, Current reward: 0.004585\n",
      "  Step 8, Current reward: 0.004585\n",
      "  Step 9, Current reward: 0.004585\n",
      "  Step 10, Current reward: 0.004585\n",
      "  Step 11, Current reward: 0.004585\n",
      "  Step 12, Current reward: 0.004585\n",
      "Episode 808/1000 complete - Max Reward: 0.004585\n",
      "Starting episode 809/1000\n",
      "  Step 1, Current reward: 0.108823\n",
      "  Step 2, Current reward: 0.108823\n",
      "  Step 3, Current reward: 0.108823\n",
      "  Step 4, Current reward: 0.108823\n",
      "  Step 5, Current reward: 0.108823\n",
      "  Step 6, Current reward: 0.108823\n",
      "  Step 7, Current reward: 0.108823\n",
      "  Step 8, Current reward: 0.108823\n",
      "  Step 9, Current reward: 0.108823\n",
      "  Step 10, Current reward: 0.108823\n",
      "  Step 11, Current reward: 0.108823\n",
      "  Step 12, Current reward: 0.108823\n",
      "Episode 809/1000 complete - Max Reward: 0.108823\n",
      "Starting episode 810/1000\n",
      "  Step 1, Current reward: 0.038834\n",
      "  Step 2, Current reward: 0.038834\n",
      "  Step 3, Current reward: 0.038834\n",
      "  Step 4, Current reward: 0.038834\n",
      "  Step 5, Current reward: 0.038834\n",
      "  Step 6, Current reward: 0.038834\n",
      "  Step 7, Current reward: 0.038834\n",
      "  Step 8, Current reward: 0.038834\n",
      "  Step 9, Current reward: 0.038834\n",
      "  Step 10, Current reward: 0.038834\n",
      "  Step 11, Current reward: 0.038834\n",
      "  Step 12, Current reward: 0.038834\n",
      "Episode 810/1000 complete - Max Reward: 0.038834\n",
      "Starting episode 811/1000\n",
      "  Step 1, Current reward: 0.020139\n",
      "  Step 2, Current reward: 0.019275\n",
      "  Step 3, Current reward: 0.019275\n",
      "  Step 4, Current reward: 0.019275\n",
      "  Step 5, Current reward: 0.019275\n",
      "  Step 6, Current reward: 0.019275\n",
      "  Step 7, Current reward: 0.019275\n",
      "  Step 8, Current reward: 0.019275\n",
      "  Step 9, Current reward: 0.019275\n",
      "  Step 10, Current reward: 0.019275\n",
      "  Step 11, Current reward: 0.019275\n",
      "  Step 12, Current reward: 0.019275\n",
      "Episode 811/1000 complete - Max Reward: 0.020139\n",
      "Starting episode 812/1000\n",
      "  Step 1, Current reward: 0.004477\n",
      "  Step 2, Current reward: 0.004477\n",
      "  Step 3, Current reward: 0.004477\n",
      "  Step 4, Current reward: 0.004477\n",
      "  Step 5, Current reward: 0.004477\n",
      "  Step 6, Current reward: 0.004477\n",
      "  Step 7, Current reward: 0.004477\n",
      "  Step 8, Current reward: 0.004477\n",
      "  Step 9, Current reward: 0.004477\n",
      "  Step 10, Current reward: 0.004477\n",
      "  Step 11, Current reward: 0.004477\n",
      "  Step 12, Current reward: 0.004477\n",
      "Episode 812/1000 complete - Max Reward: 0.004477\n",
      "Starting episode 813/1000\n",
      "  Step 1, Current reward: 0.013272\n",
      "  Step 2, Current reward: 0.013272\n",
      "  Step 3, Current reward: 0.013272\n",
      "  Step 4, Current reward: 0.013272\n",
      "  Step 5, Current reward: 0.013272\n",
      "  Step 6, Current reward: 0.013272\n",
      "  Step 7, Current reward: 0.013272\n",
      "  Step 8, Current reward: 0.013272\n",
      "  Step 9, Current reward: 0.013272\n",
      "  Step 10, Current reward: 0.013272\n",
      "  Step 11, Current reward: 0.013272\n",
      "  Step 12, Current reward: 0.013272\n",
      "Episode 813/1000 complete - Max Reward: 0.013272\n",
      "Starting episode 814/1000\n",
      "  Step 1, Current reward: 0.169697\n",
      "  Step 2, Current reward: 0.169697\n",
      "  Step 3, Current reward: 0.169697\n",
      "  Step 4, Current reward: 0.169697\n",
      "  Step 5, Current reward: 0.169697\n",
      "  Step 6, Current reward: 0.169697\n",
      "  Step 7, Current reward: 0.169697\n",
      "  Step 8, Current reward: 0.169697\n",
      "  Step 9, Current reward: 0.169697\n",
      "  Step 10, Current reward: 0.169697\n",
      "  Step 11, Current reward: 0.169697\n",
      "  Step 12, Current reward: 0.169697\n",
      "Episode 814/1000 complete - Max Reward: 0.169697\n",
      "Starting episode 815/1000\n",
      "  Step 1, Current reward: 0.057963\n",
      "  Step 2, Current reward: 0.057963\n",
      "  Step 3, Current reward: 0.057963\n",
      "  Step 4, Current reward: 0.057963\n",
      "  Step 5, Current reward: 0.057963\n",
      "  Step 6, Current reward: 0.057963\n",
      "  Step 7, Current reward: 0.057963\n",
      "  Step 8, Current reward: 0.057963\n",
      "  Step 9, Current reward: 0.057963\n",
      "  Step 10, Current reward: 0.057963\n",
      "  Step 11, Current reward: 0.057963\n",
      "  Step 12, Current reward: 0.057963\n",
      "Episode 815/1000 complete - Max Reward: 0.057963\n",
      "Starting episode 816/1000\n",
      "  Step 1, Current reward: 0.008655\n",
      "  Step 2, Current reward: 0.008655\n",
      "  Step 3, Current reward: 0.008655\n",
      "  Step 4, Current reward: 0.008655\n",
      "  Step 5, Current reward: 0.008655\n",
      "  Step 6, Current reward: 0.008655\n",
      "  Step 7, Current reward: 0.008655\n",
      "  Step 8, Current reward: 0.008655\n",
      "  Step 9, Current reward: 0.008655\n",
      "  Step 10, Current reward: 0.008655\n",
      "  Step 11, Current reward: 0.008655\n",
      "  Step 12, Current reward: 0.008655\n",
      "Episode 816/1000 complete - Max Reward: 0.008655\n",
      "Starting episode 817/1000\n",
      "  Step 1, Current reward: 0.044854\n",
      "  Step 2, Current reward: 0.044854\n",
      "  Step 3, Current reward: 0.044854\n",
      "  Step 4, Current reward: 0.044854\n",
      "  Step 5, Current reward: 0.044854\n",
      "  Step 6, Current reward: 0.044854\n",
      "  Step 7, Current reward: 0.044854\n",
      "  Step 8, Current reward: 0.044854\n",
      "  Step 9, Current reward: 0.044854\n",
      "  Step 10, Current reward: 0.044854\n",
      "  Step 11, Current reward: 0.044854\n",
      "  Step 12, Current reward: 0.044854\n",
      "Episode 817/1000 complete - Max Reward: 0.044854\n",
      "Starting episode 818/1000\n",
      "  Step 1, Current reward: 0.002405\n",
      "  Step 2, Current reward: 0.002342\n",
      "  Step 3, Current reward: 0.002260\n",
      "  Step 4, Current reward: 0.002203\n",
      "  Step 5, Current reward: 0.002207\n",
      "  Step 6, Current reward: 0.002266\n",
      "  Step 7, Current reward: 0.002318\n",
      "  Step 8, Current reward: 0.002258\n",
      "  Step 9, Current reward: 0.001995\n",
      "  Step 10, Current reward: 0.001521\n",
      "  Step 11, Current reward: 0.000954\n",
      "  Step 12, Current reward: 0.000482\n",
      "Episode 818/1000 complete - Max Reward: 0.002405\n",
      "Starting episode 819/1000\n",
      "  Step 1, Current reward: 0.010826\n",
      "  Step 2, Current reward: 0.010826\n",
      "  Step 3, Current reward: 0.010826\n",
      "  Step 4, Current reward: 0.010826\n",
      "  Step 5, Current reward: 0.010826\n",
      "  Step 6, Current reward: 0.010826\n",
      "  Step 7, Current reward: 0.010826\n",
      "  Step 8, Current reward: 0.010826\n",
      "  Step 9, Current reward: 0.010826\n",
      "  Step 10, Current reward: 0.010826\n",
      "  Step 11, Current reward: 0.010826\n",
      "  Step 12, Current reward: 0.010826\n",
      "Episode 819/1000 complete - Max Reward: 0.010826\n",
      "Starting episode 820/1000\n",
      "  Step 1, Current reward: 0.013960\n",
      "  Step 2, Current reward: 0.013960\n",
      "  Step 3, Current reward: 0.013960\n",
      "  Step 4, Current reward: 0.013960\n",
      "  Step 5, Current reward: 0.013960\n",
      "  Step 6, Current reward: 0.013960\n",
      "  Step 7, Current reward: 0.013960\n",
      "  Step 8, Current reward: 0.013960\n",
      "  Step 9, Current reward: 0.013960\n",
      "  Step 10, Current reward: 0.013960\n",
      "  Step 11, Current reward: 0.013960\n",
      "  Step 12, Current reward: 0.013960\n",
      "Episode 820/1000 complete - Max Reward: 0.013960\n",
      "Starting episode 821/1000\n",
      "  Step 1, Current reward: 0.010979\n",
      "  Step 2, Current reward: 0.011285\n",
      "  Step 3, Current reward: 0.011550\n",
      "  Step 4, Current reward: 0.011769\n",
      "  Step 5, Current reward: 0.011952\n",
      "  Step 6, Current reward: 0.012069\n",
      "  Step 7, Current reward: 0.012067\n",
      "  Step 8, Current reward: 0.012067\n",
      "  Step 9, Current reward: 0.012067\n",
      "  Step 10, Current reward: 0.012067\n",
      "  Step 11, Current reward: 0.012067\n",
      "  Step 12, Current reward: 0.012067\n",
      "  Step 13, Current reward: 0.012067\n",
      "  Step 14, Current reward: 0.012067\n",
      "  Step 15, Current reward: 0.012067\n",
      "  Step 16, Current reward: 0.012067\n",
      "  Step 17, Current reward: 0.012067\n",
      "Episode 821/1000 complete - Max Reward: 0.012069\n",
      "Starting episode 822/1000\n",
      "  Step 1, Current reward: 0.033031\n",
      "  Step 2, Current reward: 0.033031\n",
      "  Step 3, Current reward: 0.033031\n",
      "  Step 4, Current reward: 0.033031\n",
      "  Step 5, Current reward: 0.033031\n",
      "  Step 6, Current reward: 0.033031\n",
      "  Step 7, Current reward: 0.033031\n",
      "  Step 8, Current reward: 0.033031\n",
      "  Step 9, Current reward: 0.033031\n",
      "  Step 10, Current reward: 0.033031\n",
      "  Step 11, Current reward: 0.033031\n",
      "  Step 12, Current reward: 0.033031\n",
      "Episode 822/1000 complete - Max Reward: 0.033031\n",
      "Starting episode 823/1000\n",
      "  Step 1, Current reward: 0.009125\n",
      "  Step 2, Current reward: 0.009125\n",
      "  Step 3, Current reward: 0.009125\n",
      "  Step 4, Current reward: 0.009125\n",
      "  Step 5, Current reward: 0.009125\n",
      "  Step 6, Current reward: 0.009125\n",
      "  Step 7, Current reward: 0.009125\n",
      "  Step 8, Current reward: 0.009125\n",
      "  Step 9, Current reward: 0.009125\n",
      "  Step 10, Current reward: 0.009125\n",
      "  Step 11, Current reward: 0.009125\n",
      "  Step 12, Current reward: 0.009125\n",
      "Episode 823/1000 complete - Max Reward: 0.009125\n",
      "Starting episode 824/1000\n",
      "  Step 1, Current reward: 0.033139\n",
      "  Step 2, Current reward: 0.033139\n",
      "  Step 3, Current reward: 0.033139\n",
      "  Step 4, Current reward: 0.033139\n",
      "  Step 5, Current reward: 0.033139\n",
      "  Step 6, Current reward: 0.033139\n",
      "  Step 7, Current reward: 0.033139\n",
      "  Step 8, Current reward: 0.033139\n",
      "  Step 9, Current reward: 0.033139\n",
      "  Step 10, Current reward: 0.033139\n",
      "  Step 11, Current reward: 0.033139\n",
      "  Step 12, Current reward: 0.033139\n",
      "Episode 824/1000 complete - Max Reward: 0.033139\n",
      "Starting episode 825/1000\n",
      "  Step 1, Current reward: 0.000085\n",
      "  Step 2, Current reward: 0.000085\n",
      "  Step 3, Current reward: 0.000085\n",
      "  Step 4, Current reward: 0.000085\n",
      "  Step 5, Current reward: 0.000085\n",
      "  Step 6, Current reward: 0.000085\n",
      "  Step 7, Current reward: 0.000085\n",
      "  Step 8, Current reward: 0.000085\n",
      "  Step 9, Current reward: 0.000085\n",
      "  Step 10, Current reward: 0.000085\n",
      "  Step 11, Current reward: 0.000085\n",
      "  Step 12, Current reward: 0.000085\n",
      "Episode 825/1000 complete - Max Reward: 0.000085\n",
      "Starting episode 826/1000\n",
      "  Step 1, Current reward: 0.091324\n",
      "  Step 2, Current reward: 0.091324\n",
      "  Step 3, Current reward: 0.091324\n",
      "  Step 4, Current reward: 0.091324\n",
      "  Step 5, Current reward: 0.091324\n",
      "  Step 6, Current reward: 0.091324\n",
      "  Step 7, Current reward: 0.091324\n",
      "  Step 8, Current reward: 0.091324\n",
      "  Step 9, Current reward: 0.091324\n",
      "  Step 10, Current reward: 0.091324\n",
      "  Step 11, Current reward: 0.091324\n",
      "  Step 12, Current reward: 0.091324\n",
      "Episode 826/1000 complete - Max Reward: 0.091324\n",
      "Starting episode 827/1000\n",
      "  Step 1, Current reward: 0.007722\n",
      "  Step 2, Current reward: 0.007722\n",
      "  Step 3, Current reward: 0.007722\n",
      "  Step 4, Current reward: 0.007722\n",
      "  Step 5, Current reward: 0.007722\n",
      "  Step 6, Current reward: 0.007722\n",
      "  Step 7, Current reward: 0.007722\n",
      "  Step 8, Current reward: 0.007722\n",
      "  Step 9, Current reward: 0.007722\n",
      "  Step 10, Current reward: 0.007722\n",
      "  Step 11, Current reward: 0.007722\n",
      "  Step 12, Current reward: 0.007722\n",
      "Episode 827/1000 complete - Max Reward: 0.007722\n",
      "Starting episode 828/1000\n",
      "  Step 1, Current reward: 0.082510\n",
      "  Step 2, Current reward: 0.082510\n",
      "  Step 3, Current reward: 0.082510\n",
      "  Step 4, Current reward: 0.082510\n",
      "  Step 5, Current reward: 0.082510\n",
      "  Step 6, Current reward: 0.082510\n",
      "  Step 7, Current reward: 0.082510\n",
      "  Step 8, Current reward: 0.082510\n",
      "  Step 9, Current reward: 0.082510\n",
      "  Step 10, Current reward: 0.082510\n",
      "  Step 11, Current reward: 0.082510\n",
      "  Step 12, Current reward: 0.082510\n",
      "Episode 828/1000 complete - Max Reward: 0.082510\n",
      "Starting episode 829/1000\n",
      "  Step 1, Current reward: 0.000071\n",
      "  Step 2, Current reward: 0.000071\n",
      "  Step 3, Current reward: 0.000071\n",
      "  Step 4, Current reward: 0.000071\n",
      "  Step 5, Current reward: 0.000071\n",
      "  Step 6, Current reward: 0.000071\n",
      "  Step 7, Current reward: 0.000071\n",
      "  Step 8, Current reward: 0.000071\n",
      "  Step 9, Current reward: 0.000071\n",
      "  Step 10, Current reward: 0.000071\n",
      "  Step 11, Current reward: 0.000071\n",
      "  Step 12, Current reward: 0.000071\n",
      "Episode 829/1000 complete - Max Reward: 0.000071\n",
      "Starting episode 830/1000\n",
      "  Step 1, Current reward: 0.019402\n",
      "  Step 2, Current reward: 0.019402\n",
      "  Step 3, Current reward: 0.019402\n",
      "  Step 4, Current reward: 0.019402\n",
      "  Step 5, Current reward: 0.019402\n",
      "  Step 6, Current reward: 0.019402\n",
      "  Step 7, Current reward: 0.019402\n",
      "  Step 8, Current reward: 0.019402\n",
      "  Step 9, Current reward: 0.019402\n",
      "  Step 10, Current reward: 0.019402\n",
      "  Step 11, Current reward: 0.019402\n",
      "  Step 12, Current reward: 0.019402\n",
      "Episode 830/1000 complete - Max Reward: 0.019402\n",
      "Starting episode 831/1000\n",
      "  Step 1, Current reward: 0.049273\n",
      "  Step 2, Current reward: 0.049273\n",
      "  Step 3, Current reward: 0.049273\n",
      "  Step 4, Current reward: 0.049273\n",
      "  Step 5, Current reward: 0.049273\n",
      "  Step 6, Current reward: 0.049273\n",
      "  Step 7, Current reward: 0.049273\n",
      "  Step 8, Current reward: 0.049273\n",
      "  Step 9, Current reward: 0.049273\n",
      "  Step 10, Current reward: 0.049273\n",
      "  Step 11, Current reward: 0.049273\n",
      "  Step 12, Current reward: 0.049273\n",
      "Episode 831/1000 complete - Max Reward: 0.049273\n",
      "Starting episode 832/1000\n",
      "  Step 1, Current reward: 0.094836\n",
      "  Step 2, Current reward: 0.094836\n",
      "  Step 3, Current reward: 0.094836\n",
      "  Step 4, Current reward: 0.094836\n",
      "  Step 5, Current reward: 0.094836\n",
      "  Step 6, Current reward: 0.094836\n",
      "  Step 7, Current reward: 0.094836\n",
      "  Step 8, Current reward: 0.094836\n",
      "  Step 9, Current reward: 0.094836\n",
      "  Step 10, Current reward: 0.094836\n",
      "  Step 11, Current reward: 0.094836\n",
      "  Step 12, Current reward: 0.094836\n",
      "Episode 832/1000 complete - Max Reward: 0.094836\n",
      "Starting episode 833/1000\n",
      "  Step 1, Current reward: 0.001619\n",
      "  Step 2, Current reward: 0.001619\n",
      "  Step 3, Current reward: 0.001619\n",
      "  Step 4, Current reward: 0.001619\n",
      "  Step 5, Current reward: 0.001619\n",
      "  Step 6, Current reward: 0.001619\n",
      "  Step 7, Current reward: 0.001619\n",
      "  Step 8, Current reward: 0.001619\n",
      "  Step 9, Current reward: 0.001619\n",
      "  Step 10, Current reward: 0.001619\n",
      "  Step 11, Current reward: 0.001619\n",
      "  Step 12, Current reward: 0.001619\n",
      "Episode 833/1000 complete - Max Reward: 0.001619\n",
      "Starting episode 834/1000\n",
      "  Step 1, Current reward: 0.020712\n",
      "  Step 2, Current reward: 0.020712\n",
      "  Step 3, Current reward: 0.020712\n",
      "  Step 4, Current reward: 0.020712\n",
      "  Step 5, Current reward: 0.020712\n",
      "  Step 6, Current reward: 0.020712\n",
      "  Step 7, Current reward: 0.020712\n",
      "  Step 8, Current reward: 0.020712\n",
      "  Step 9, Current reward: 0.020712\n",
      "  Step 10, Current reward: 0.020712\n",
      "  Step 11, Current reward: 0.020712\n",
      "  Step 12, Current reward: 0.020712\n",
      "Episode 834/1000 complete - Max Reward: 0.020712\n",
      "Starting episode 835/1000\n",
      "  Step 1, Current reward: 0.036256\n",
      "  Step 2, Current reward: 0.036256\n",
      "  Step 3, Current reward: 0.036256\n",
      "  Step 4, Current reward: 0.036256\n",
      "  Step 5, Current reward: 0.036256\n",
      "  Step 6, Current reward: 0.036256\n",
      "  Step 7, Current reward: 0.036256\n",
      "  Step 8, Current reward: 0.036256\n",
      "  Step 9, Current reward: 0.036256\n",
      "  Step 10, Current reward: 0.036256\n",
      "  Step 11, Current reward: 0.036256\n",
      "  Step 12, Current reward: 0.036256\n",
      "Episode 835/1000 complete - Max Reward: 0.036256\n",
      "Starting episode 836/1000\n",
      "  Step 1, Current reward: 0.009631\n",
      "  Step 2, Current reward: 0.009631\n",
      "  Step 3, Current reward: 0.009631\n",
      "  Step 4, Current reward: 0.009631\n",
      "  Step 5, Current reward: 0.009631\n",
      "  Step 6, Current reward: 0.009631\n",
      "  Step 7, Current reward: 0.009631\n",
      "  Step 8, Current reward: 0.009631\n",
      "  Step 9, Current reward: 0.009631\n",
      "  Step 10, Current reward: 0.009631\n",
      "  Step 11, Current reward: 0.009631\n",
      "  Step 12, Current reward: 0.009631\n",
      "Episode 836/1000 complete - Max Reward: 0.009631\n",
      "Starting episode 837/1000\n",
      "  Step 1, Current reward: 0.000968\n",
      "  Step 2, Current reward: 0.000852\n",
      "  Step 3, Current reward: 0.000781\n",
      "  Step 4, Current reward: 0.000757\n",
      "  Step 5, Current reward: 0.000787\n",
      "  Step 6, Current reward: 0.000853\n",
      "  Step 7, Current reward: 0.000900\n",
      "  Step 8, Current reward: 0.000900\n",
      "  Step 9, Current reward: 0.000900\n",
      "  Step 10, Current reward: 0.000900\n",
      "  Step 11, Current reward: 0.000900\n",
      "  Step 12, Current reward: 0.000900\n",
      "Episode 837/1000 complete - Max Reward: 0.000968\n",
      "Starting episode 838/1000\n",
      "  Step 1, Current reward: 0.008230\n",
      "  Step 2, Current reward: 0.008230\n",
      "  Step 3, Current reward: 0.008230\n",
      "  Step 4, Current reward: 0.008230\n",
      "  Step 5, Current reward: 0.008230\n",
      "  Step 6, Current reward: 0.008230\n",
      "  Step 7, Current reward: 0.008230\n",
      "  Step 8, Current reward: 0.008230\n",
      "  Step 9, Current reward: 0.008230\n",
      "  Step 10, Current reward: 0.008230\n",
      "  Step 11, Current reward: 0.008230\n",
      "  Step 12, Current reward: 0.008230\n",
      "Episode 838/1000 complete - Max Reward: 0.008230\n",
      "Starting episode 839/1000\n",
      "  Step 1, Current reward: 0.001028\n",
      "  Step 2, Current reward: 0.001111\n",
      "  Step 3, Current reward: 0.001211\n",
      "  Step 4, Current reward: 0.001330\n",
      "  Step 5, Current reward: 0.001330\n",
      "  Step 6, Current reward: 0.001330\n",
      "  Step 7, Current reward: 0.001330\n",
      "  Step 8, Current reward: 0.001330\n",
      "  Step 9, Current reward: 0.001330\n",
      "  Step 10, Current reward: 0.001330\n",
      "  Step 11, Current reward: 0.001330\n",
      "  Step 12, Current reward: 0.001330\n",
      "  Step 13, Current reward: 0.001330\n",
      "  Step 14, Current reward: 0.001330\n",
      "  Step 15, Current reward: 0.001330\n",
      "Episode 839/1000 complete - Max Reward: 0.001330\n",
      "Starting episode 840/1000\n",
      "  Step 1, Current reward: 0.026770\n",
      "  Step 2, Current reward: 0.026770\n",
      "  Step 3, Current reward: 0.026770\n",
      "  Step 4, Current reward: 0.026770\n",
      "  Step 5, Current reward: 0.026770\n",
      "  Step 6, Current reward: 0.026770\n",
      "  Step 7, Current reward: 0.026770\n",
      "  Step 8, Current reward: 0.026770\n",
      "  Step 9, Current reward: 0.026770\n",
      "  Step 10, Current reward: 0.026770\n",
      "  Step 11, Current reward: 0.026770\n",
      "  Step 12, Current reward: 0.026770\n",
      "Episode 840/1000 complete - Max Reward: 0.026770\n",
      "Starting episode 841/1000\n",
      "  Step 1, Current reward: 0.069097\n",
      "  Step 2, Current reward: 0.069097\n",
      "  Step 3, Current reward: 0.069097\n",
      "  Step 4, Current reward: 0.069097\n",
      "  Step 5, Current reward: 0.069097\n",
      "  Step 6, Current reward: 0.069097\n",
      "  Step 7, Current reward: 0.069097\n",
      "  Step 8, Current reward: 0.069097\n",
      "  Step 9, Current reward: 0.069097\n",
      "  Step 10, Current reward: 0.069097\n",
      "  Step 11, Current reward: 0.069097\n",
      "  Step 12, Current reward: 0.069097\n",
      "Episode 841/1000 complete - Max Reward: 0.069097\n",
      "Starting episode 842/1000\n",
      "  Step 1, Current reward: 0.040461\n",
      "  Step 2, Current reward: 0.040461\n",
      "  Step 3, Current reward: 0.040461\n",
      "  Step 4, Current reward: 0.040461\n",
      "  Step 5, Current reward: 0.040461\n",
      "  Step 6, Current reward: 0.040461\n",
      "  Step 7, Current reward: 0.040461\n",
      "  Step 8, Current reward: 0.040461\n",
      "  Step 9, Current reward: 0.040461\n",
      "  Step 10, Current reward: 0.040461\n",
      "  Step 11, Current reward: 0.040461\n",
      "  Step 12, Current reward: 0.040461\n",
      "Episode 842/1000 complete - Max Reward: 0.040461\n",
      "Starting episode 843/1000\n",
      "  Step 1, Current reward: 0.017118\n",
      "  Step 2, Current reward: 0.017118\n",
      "  Step 3, Current reward: 0.017118\n",
      "  Step 4, Current reward: 0.017118\n",
      "  Step 5, Current reward: 0.017118\n",
      "  Step 6, Current reward: 0.017118\n",
      "  Step 7, Current reward: 0.017118\n",
      "  Step 8, Current reward: 0.017118\n",
      "  Step 9, Current reward: 0.017118\n",
      "  Step 10, Current reward: 0.017118\n",
      "  Step 11, Current reward: 0.017118\n",
      "  Step 12, Current reward: 0.017118\n",
      "Episode 843/1000 complete - Max Reward: 0.017118\n",
      "Starting episode 844/1000\n",
      "  Step 1, Current reward: 0.006577\n",
      "  Step 2, Current reward: 0.006577\n",
      "  Step 3, Current reward: 0.006577\n",
      "  Step 4, Current reward: 0.006577\n",
      "  Step 5, Current reward: 0.006577\n",
      "  Step 6, Current reward: 0.006577\n",
      "  Step 7, Current reward: 0.006577\n",
      "  Step 8, Current reward: 0.006577\n",
      "  Step 9, Current reward: 0.006577\n",
      "  Step 10, Current reward: 0.006577\n",
      "  Step 11, Current reward: 0.006577\n",
      "  Step 12, Current reward: 0.006577\n",
      "Episode 844/1000 complete - Max Reward: 0.006577\n",
      "Starting episode 845/1000\n",
      "  Step 1, Current reward: 0.113458\n",
      "  Step 2, Current reward: 0.113458\n",
      "  Step 3, Current reward: 0.113458\n",
      "  Step 4, Current reward: 0.113458\n",
      "  Step 5, Current reward: 0.113458\n",
      "  Step 6, Current reward: 0.113458\n",
      "  Step 7, Current reward: 0.113458\n",
      "  Step 8, Current reward: 0.113458\n",
      "  Step 9, Current reward: 0.113458\n",
      "  Step 10, Current reward: 0.113458\n",
      "  Step 11, Current reward: 0.113458\n",
      "  Step 12, Current reward: 0.113458\n",
      "Episode 845/1000 complete - Max Reward: 0.113458\n",
      "Starting episode 846/1000\n",
      "  Step 1, Current reward: 0.019977\n",
      "  Step 2, Current reward: 0.019977\n",
      "  Step 3, Current reward: 0.019977\n",
      "  Step 4, Current reward: 0.019977\n",
      "  Step 5, Current reward: 0.019977\n",
      "  Step 6, Current reward: 0.019977\n",
      "  Step 7, Current reward: 0.019977\n",
      "  Step 8, Current reward: 0.019977\n",
      "  Step 9, Current reward: 0.019977\n",
      "  Step 10, Current reward: 0.019977\n",
      "  Step 11, Current reward: 0.019977\n",
      "  Step 12, Current reward: 0.019977\n",
      "Episode 846/1000 complete - Max Reward: 0.019977\n",
      "Starting episode 847/1000\n",
      "  Step 1, Current reward: 0.003627\n",
      "  Step 2, Current reward: 0.003627\n",
      "  Step 3, Current reward: 0.003627\n",
      "  Step 4, Current reward: 0.003627\n",
      "  Step 5, Current reward: 0.003627\n",
      "  Step 6, Current reward: 0.003627\n",
      "  Step 7, Current reward: 0.003627\n",
      "  Step 8, Current reward: 0.003627\n",
      "  Step 9, Current reward: 0.003627\n",
      "  Step 10, Current reward: 0.003627\n",
      "  Step 11, Current reward: 0.003627\n",
      "  Step 12, Current reward: 0.003627\n",
      "Episode 847/1000 complete - Max Reward: 0.003627\n",
      "Starting episode 848/1000\n",
      "  Step 1, Current reward: 0.026309\n",
      "  Step 2, Current reward: 0.026309\n",
      "  Step 3, Current reward: 0.026309\n",
      "  Step 4, Current reward: 0.026309\n",
      "  Step 5, Current reward: 0.026309\n",
      "  Step 6, Current reward: 0.026309\n",
      "  Step 7, Current reward: 0.026309\n",
      "  Step 8, Current reward: 0.026309\n",
      "  Step 9, Current reward: 0.026309\n",
      "  Step 10, Current reward: 0.026309\n",
      "  Step 11, Current reward: 0.026309\n",
      "  Step 12, Current reward: 0.026309\n",
      "Episode 848/1000 complete - Max Reward: 0.026309\n",
      "Starting episode 849/1000\n",
      "  Step 1, Current reward: 0.033388\n",
      "  Step 2, Current reward: 0.033388\n",
      "  Step 3, Current reward: 0.033388\n",
      "  Step 4, Current reward: 0.033388\n",
      "  Step 5, Current reward: 0.033388\n",
      "  Step 6, Current reward: 0.033388\n",
      "  Step 7, Current reward: 0.033388\n",
      "  Step 8, Current reward: 0.033388\n",
      "  Step 9, Current reward: 0.033388\n",
      "  Step 10, Current reward: 0.033388\n",
      "  Step 11, Current reward: 0.033388\n",
      "  Step 12, Current reward: 0.033388\n",
      "Episode 849/1000 complete - Max Reward: 0.033388\n",
      "Starting episode 850/1000\n",
      "  Step 1, Current reward: 0.005206\n",
      "  Step 2, Current reward: 0.005206\n",
      "  Step 3, Current reward: 0.005206\n",
      "  Step 4, Current reward: 0.005206\n",
      "  Step 5, Current reward: 0.005206\n",
      "  Step 6, Current reward: 0.005206\n",
      "  Step 7, Current reward: 0.005206\n",
      "  Step 8, Current reward: 0.005206\n",
      "  Step 9, Current reward: 0.005206\n",
      "  Step 10, Current reward: 0.005206\n",
      "  Step 11, Current reward: 0.005206\n",
      "  Step 12, Current reward: 0.005206\n",
      "Episode 850/1000 complete - Max Reward: 0.005206\n",
      "Starting episode 851/1000\n",
      "  Step 1, Current reward: 0.000715\n",
      "  Step 2, Current reward: 0.000715\n",
      "  Step 3, Current reward: 0.000715\n",
      "  Step 4, Current reward: 0.000715\n",
      "  Step 5, Current reward: 0.000715\n",
      "  Step 6, Current reward: 0.000715\n",
      "  Step 7, Current reward: 0.000715\n",
      "  Step 8, Current reward: 0.000715\n",
      "  Step 9, Current reward: 0.000715\n",
      "  Step 10, Current reward: 0.000715\n",
      "  Step 11, Current reward: 0.000715\n",
      "  Step 12, Current reward: 0.000715\n",
      "Episode 851/1000 complete - Max Reward: 0.000715\n",
      "Starting episode 852/1000\n",
      "  Step 1, Current reward: 0.155567\n",
      "  Step 2, Current reward: 0.155567\n",
      "  Step 3, Current reward: 0.155567\n",
      "  Step 4, Current reward: 0.155567\n",
      "  Step 5, Current reward: 0.155567\n",
      "  Step 6, Current reward: 0.155567\n",
      "  Step 7, Current reward: 0.155567\n",
      "  Step 8, Current reward: 0.155567\n",
      "  Step 9, Current reward: 0.155567\n",
      "  Step 10, Current reward: 0.155567\n",
      "  Step 11, Current reward: 0.155567\n",
      "  Step 12, Current reward: 0.155567\n",
      "Episode 852/1000 complete - Max Reward: 0.155567\n",
      "Starting episode 853/1000\n",
      "  Step 1, Current reward: 0.008847\n",
      "  Step 2, Current reward: 0.008847\n",
      "  Step 3, Current reward: 0.008847\n",
      "  Step 4, Current reward: 0.008847\n",
      "  Step 5, Current reward: 0.008847\n",
      "  Step 6, Current reward: 0.008847\n",
      "  Step 7, Current reward: 0.008847\n",
      "  Step 8, Current reward: 0.008847\n",
      "  Step 9, Current reward: 0.008847\n",
      "  Step 10, Current reward: 0.008847\n",
      "  Step 11, Current reward: 0.008847\n",
      "  Step 12, Current reward: 0.008847\n",
      "Episode 853/1000 complete - Max Reward: 0.008847\n",
      "Starting episode 854/1000\n",
      "  Step 1, Current reward: 0.005572\n",
      "  Step 2, Current reward: 0.005572\n",
      "  Step 3, Current reward: 0.005572\n",
      "  Step 4, Current reward: 0.005572\n",
      "  Step 5, Current reward: 0.005572\n",
      "  Step 6, Current reward: 0.005572\n",
      "  Step 7, Current reward: 0.005572\n",
      "  Step 8, Current reward: 0.005572\n",
      "  Step 9, Current reward: 0.005572\n",
      "  Step 10, Current reward: 0.005572\n",
      "  Step 11, Current reward: 0.005572\n",
      "  Step 12, Current reward: 0.005572\n",
      "Episode 854/1000 complete - Max Reward: 0.005572\n",
      "Starting episode 855/1000\n",
      "  Step 1, Current reward: 0.020247\n",
      "  Step 2, Current reward: 0.020247\n",
      "  Step 3, Current reward: 0.020247\n",
      "  Step 4, Current reward: 0.020247\n",
      "  Step 5, Current reward: 0.020247\n",
      "  Step 6, Current reward: 0.020247\n",
      "  Step 7, Current reward: 0.020247\n",
      "  Step 8, Current reward: 0.020247\n",
      "  Step 9, Current reward: 0.020247\n",
      "  Step 10, Current reward: 0.020247\n",
      "  Step 11, Current reward: 0.020247\n",
      "  Step 12, Current reward: 0.020247\n",
      "Episode 855/1000 complete - Max Reward: 0.020247\n",
      "Starting episode 856/1000\n",
      "  Step 1, Current reward: 0.029629\n",
      "  Step 2, Current reward: 0.029629\n",
      "  Step 3, Current reward: 0.029629\n",
      "  Step 4, Current reward: 0.029629\n",
      "  Step 5, Current reward: 0.029629\n",
      "  Step 6, Current reward: 0.029629\n",
      "  Step 7, Current reward: 0.029629\n",
      "  Step 8, Current reward: 0.029629\n",
      "  Step 9, Current reward: 0.029629\n",
      "  Step 10, Current reward: 0.029629\n",
      "  Step 11, Current reward: 0.029629\n",
      "  Step 12, Current reward: 0.029629\n",
      "Episode 856/1000 complete - Max Reward: 0.029629\n",
      "Starting episode 857/1000\n",
      "  Step 1, Current reward: 0.052547\n",
      "  Step 2, Current reward: 0.052547\n",
      "  Step 3, Current reward: 0.052547\n",
      "  Step 4, Current reward: 0.052547\n",
      "  Step 5, Current reward: 0.052547\n",
      "  Step 6, Current reward: 0.052547\n",
      "  Step 7, Current reward: 0.052547\n",
      "  Step 8, Current reward: 0.052547\n",
      "  Step 9, Current reward: 0.052547\n",
      "  Step 10, Current reward: 0.052547\n",
      "  Step 11, Current reward: 0.052547\n",
      "  Step 12, Current reward: 0.052547\n",
      "Episode 857/1000 complete - Max Reward: 0.052547\n",
      "Starting episode 858/1000\n",
      "  Step 1, Current reward: 0.001984\n",
      "  Step 2, Current reward: 0.001984\n",
      "  Step 3, Current reward: 0.001984\n",
      "  Step 4, Current reward: 0.001984\n",
      "  Step 5, Current reward: 0.001984\n",
      "  Step 6, Current reward: 0.001984\n",
      "  Step 7, Current reward: 0.001984\n",
      "  Step 8, Current reward: 0.001984\n",
      "  Step 9, Current reward: 0.001984\n",
      "  Step 10, Current reward: 0.001984\n",
      "  Step 11, Current reward: 0.001984\n",
      "  Step 12, Current reward: 0.001984\n",
      "Episode 858/1000 complete - Max Reward: 0.001984\n",
      "Starting episode 859/1000\n",
      "  Step 1, Current reward: 0.036539\n",
      "  Step 2, Current reward: 0.036539\n",
      "  Step 3, Current reward: 0.036539\n",
      "  Step 4, Current reward: 0.036539\n",
      "  Step 5, Current reward: 0.036539\n",
      "  Step 6, Current reward: 0.036539\n",
      "  Step 7, Current reward: 0.036539\n",
      "  Step 8, Current reward: 0.036539\n",
      "  Step 9, Current reward: 0.036539\n",
      "  Step 10, Current reward: 0.036539\n",
      "  Step 11, Current reward: 0.036539\n",
      "  Step 12, Current reward: 0.036539\n",
      "Episode 859/1000 complete - Max Reward: 0.036539\n",
      "Starting episode 860/1000\n",
      "  Step 1, Current reward: 0.040991\n",
      "  Step 2, Current reward: 0.040991\n",
      "  Step 3, Current reward: 0.040991\n",
      "  Step 4, Current reward: 0.040991\n",
      "  Step 5, Current reward: 0.040991\n",
      "  Step 6, Current reward: 0.040991\n",
      "  Step 7, Current reward: 0.040991\n",
      "  Step 8, Current reward: 0.040991\n",
      "  Step 9, Current reward: 0.040991\n",
      "  Step 10, Current reward: 0.040991\n",
      "  Step 11, Current reward: 0.040991\n",
      "  Step 12, Current reward: 0.040991\n",
      "Episode 860/1000 complete - Max Reward: 0.040991\n",
      "Starting episode 861/1000\n",
      "  Step 1, Current reward: 0.054623\n",
      "  Step 2, Current reward: 0.054623\n",
      "  Step 3, Current reward: 0.054623\n",
      "  Step 4, Current reward: 0.054623\n",
      "  Step 5, Current reward: 0.054623\n",
      "  Step 6, Current reward: 0.054623\n",
      "  Step 7, Current reward: 0.054623\n",
      "  Step 8, Current reward: 0.054623\n",
      "  Step 9, Current reward: 0.054623\n",
      "  Step 10, Current reward: 0.054623\n",
      "  Step 11, Current reward: 0.054623\n",
      "  Step 12, Current reward: 0.054623\n",
      "Episode 861/1000 complete - Max Reward: 0.054623\n",
      "Starting episode 862/1000\n",
      "  Step 1, Current reward: 0.182616\n",
      "  Step 2, Current reward: 0.182616\n",
      "  Step 3, Current reward: 0.182616\n",
      "  Step 4, Current reward: 0.182616\n",
      "  Step 5, Current reward: 0.182616\n",
      "  Step 6, Current reward: 0.182616\n",
      "  Step 7, Current reward: 0.182616\n",
      "  Step 8, Current reward: 0.182616\n",
      "  Step 9, Current reward: 0.182616\n",
      "  Step 10, Current reward: 0.182616\n",
      "  Step 11, Current reward: 0.182616\n",
      "  Step 12, Current reward: 0.182616\n",
      "Episode 862/1000 complete - Max Reward: 0.182616\n",
      "Starting episode 863/1000\n",
      "  Step 1, Current reward: 0.020894\n",
      "  Step 2, Current reward: 0.020894\n",
      "  Step 3, Current reward: 0.020894\n",
      "  Step 4, Current reward: 0.020894\n",
      "  Step 5, Current reward: 0.020894\n",
      "  Step 6, Current reward: 0.020894\n",
      "  Step 7, Current reward: 0.020894\n",
      "  Step 8, Current reward: 0.020894\n",
      "  Step 9, Current reward: 0.020894\n",
      "  Step 10, Current reward: 0.020894\n",
      "  Step 11, Current reward: 0.020894\n",
      "  Step 12, Current reward: 0.020894\n",
      "Episode 863/1000 complete - Max Reward: 0.020894\n",
      "Starting episode 864/1000\n",
      "  Step 1, Current reward: 0.027436\n",
      "  Step 2, Current reward: 0.027436\n",
      "  Step 3, Current reward: 0.027436\n",
      "  Step 4, Current reward: 0.027436\n",
      "  Step 5, Current reward: 0.027436\n",
      "  Step 6, Current reward: 0.027436\n",
      "  Step 7, Current reward: 0.027436\n",
      "  Step 8, Current reward: 0.027436\n",
      "  Step 9, Current reward: 0.027436\n",
      "  Step 10, Current reward: 0.027436\n",
      "  Step 11, Current reward: 0.027436\n",
      "  Step 12, Current reward: 0.027436\n",
      "Episode 864/1000 complete - Max Reward: 0.027436\n",
      "Starting episode 865/1000\n",
      "  Step 1, Current reward: 0.058190\n",
      "  Step 2, Current reward: 0.058190\n",
      "  Step 3, Current reward: 0.058190\n",
      "  Step 4, Current reward: 0.058190\n",
      "  Step 5, Current reward: 0.058190\n",
      "  Step 6, Current reward: 0.058190\n",
      "  Step 7, Current reward: 0.058190\n",
      "  Step 8, Current reward: 0.058190\n",
      "  Step 9, Current reward: 0.058190\n",
      "  Step 10, Current reward: 0.058190\n",
      "  Step 11, Current reward: 0.058190\n",
      "  Step 12, Current reward: 0.058190\n",
      "Episode 865/1000 complete - Max Reward: 0.058190\n",
      "Starting episode 866/1000\n",
      "  Step 1, Current reward: 0.027513\n",
      "  Step 2, Current reward: 0.027513\n",
      "  Step 3, Current reward: 0.027513\n",
      "  Step 4, Current reward: 0.027513\n",
      "  Step 5, Current reward: 0.027513\n",
      "  Step 6, Current reward: 0.027513\n",
      "  Step 7, Current reward: 0.027513\n",
      "  Step 8, Current reward: 0.027513\n",
      "  Step 9, Current reward: 0.027513\n",
      "  Step 10, Current reward: 0.027513\n",
      "  Step 11, Current reward: 0.027513\n",
      "  Step 12, Current reward: 0.027513\n",
      "Episode 866/1000 complete - Max Reward: 0.027513\n",
      "Starting episode 867/1000\n",
      "  Step 1, Current reward: 0.072106\n",
      "  Step 2, Current reward: 0.072106\n",
      "  Step 3, Current reward: 0.072106\n",
      "  Step 4, Current reward: 0.072106\n",
      "  Step 5, Current reward: 0.072106\n",
      "  Step 6, Current reward: 0.072106\n",
      "  Step 7, Current reward: 0.072106\n",
      "  Step 8, Current reward: 0.072106\n",
      "  Step 9, Current reward: 0.072106\n",
      "  Step 10, Current reward: 0.072106\n",
      "  Step 11, Current reward: 0.072106\n",
      "  Step 12, Current reward: 0.072106\n",
      "Episode 867/1000 complete - Max Reward: 0.072106\n",
      "Starting episode 868/1000\n",
      "  Step 1, Current reward: 0.008965\n",
      "  Step 2, Current reward: 0.008965\n",
      "  Step 3, Current reward: 0.008965\n",
      "  Step 4, Current reward: 0.008965\n",
      "  Step 5, Current reward: 0.008965\n",
      "  Step 6, Current reward: 0.008965\n",
      "  Step 7, Current reward: 0.008965\n",
      "  Step 8, Current reward: 0.008965\n",
      "  Step 9, Current reward: 0.008965\n",
      "  Step 10, Current reward: 0.008965\n",
      "  Step 11, Current reward: 0.008965\n",
      "  Step 12, Current reward: 0.008965\n",
      "Episode 868/1000 complete - Max Reward: 0.008965\n",
      "Starting episode 869/1000\n",
      "  Step 1, Current reward: 0.038939\n",
      "  Step 2, Current reward: 0.038939\n",
      "  Step 3, Current reward: 0.038939\n",
      "  Step 4, Current reward: 0.038939\n",
      "  Step 5, Current reward: 0.038939\n",
      "  Step 6, Current reward: 0.038939\n",
      "  Step 7, Current reward: 0.038939\n",
      "  Step 8, Current reward: 0.038939\n",
      "  Step 9, Current reward: 0.038939\n",
      "  Step 10, Current reward: 0.038939\n",
      "  Step 11, Current reward: 0.038939\n",
      "  Step 12, Current reward: 0.038939\n",
      "Episode 869/1000 complete - Max Reward: 0.038939\n",
      "Starting episode 870/1000\n",
      "  Step 1, Current reward: 0.013821\n",
      "  Step 2, Current reward: 0.013821\n",
      "  Step 3, Current reward: 0.013821\n",
      "  Step 4, Current reward: 0.013821\n",
      "  Step 5, Current reward: 0.013821\n",
      "  Step 6, Current reward: 0.013821\n",
      "  Step 7, Current reward: 0.013821\n",
      "  Step 8, Current reward: 0.013821\n",
      "  Step 9, Current reward: 0.013821\n",
      "  Step 10, Current reward: 0.013821\n",
      "  Step 11, Current reward: 0.013821\n",
      "  Step 12, Current reward: 0.013821\n",
      "Episode 870/1000 complete - Max Reward: 0.013821\n",
      "Starting episode 871/1000\n",
      "  Step 1, Current reward: 0.008450\n",
      "  Step 2, Current reward: 0.008450\n",
      "  Step 3, Current reward: 0.008450\n",
      "  Step 4, Current reward: 0.008450\n",
      "  Step 5, Current reward: 0.008450\n",
      "  Step 6, Current reward: 0.008450\n",
      "  Step 7, Current reward: 0.008450\n",
      "  Step 8, Current reward: 0.008450\n",
      "  Step 9, Current reward: 0.008450\n",
      "  Step 10, Current reward: 0.008450\n",
      "  Step 11, Current reward: 0.008450\n",
      "  Step 12, Current reward: 0.008450\n",
      "Episode 871/1000 complete - Max Reward: 0.008450\n",
      "Starting episode 872/1000\n",
      "  Step 1, Current reward: 0.028800\n",
      "  Step 2, Current reward: 0.028800\n",
      "  Step 3, Current reward: 0.028800\n",
      "  Step 4, Current reward: 0.028800\n",
      "  Step 5, Current reward: 0.028800\n",
      "  Step 6, Current reward: 0.028800\n",
      "  Step 7, Current reward: 0.028800\n",
      "  Step 8, Current reward: 0.028800\n",
      "  Step 9, Current reward: 0.028800\n",
      "  Step 10, Current reward: 0.028800\n",
      "  Step 11, Current reward: 0.028800\n",
      "  Step 12, Current reward: 0.028800\n",
      "Episode 872/1000 complete - Max Reward: 0.028800\n",
      "Starting episode 873/1000\n",
      "  Step 1, Current reward: 0.029597\n",
      "  Step 2, Current reward: 0.029597\n",
      "  Step 3, Current reward: 0.029597\n",
      "  Step 4, Current reward: 0.029597\n",
      "  Step 5, Current reward: 0.029597\n",
      "  Step 6, Current reward: 0.029597\n",
      "  Step 7, Current reward: 0.029597\n",
      "  Step 8, Current reward: 0.029597\n",
      "  Step 9, Current reward: 0.029597\n",
      "  Step 10, Current reward: 0.029597\n",
      "  Step 11, Current reward: 0.029597\n",
      "  Step 12, Current reward: 0.029597\n",
      "Episode 873/1000 complete - Max Reward: 0.029597\n",
      "Starting episode 874/1000\n",
      "  Step 1, Current reward: 0.022279\n",
      "  Step 2, Current reward: 0.022279\n",
      "  Step 3, Current reward: 0.022279\n",
      "  Step 4, Current reward: 0.022279\n",
      "  Step 5, Current reward: 0.022279\n",
      "  Step 6, Current reward: 0.022279\n",
      "  Step 7, Current reward: 0.022279\n",
      "  Step 8, Current reward: 0.022279\n",
      "  Step 9, Current reward: 0.022279\n",
      "  Step 10, Current reward: 0.022279\n",
      "  Step 11, Current reward: 0.022279\n",
      "  Step 12, Current reward: 0.022279\n",
      "Episode 874/1000 complete - Max Reward: 0.022279\n",
      "Starting episode 875/1000\n",
      "  Step 1, Current reward: 0.026590\n",
      "  Step 2, Current reward: 0.026590\n",
      "  Step 3, Current reward: 0.026590\n",
      "  Step 4, Current reward: 0.026590\n",
      "  Step 5, Current reward: 0.026590\n",
      "  Step 6, Current reward: 0.026590\n",
      "  Step 7, Current reward: 0.026590\n",
      "  Step 8, Current reward: 0.026590\n",
      "  Step 9, Current reward: 0.026590\n",
      "  Step 10, Current reward: 0.026590\n",
      "  Step 11, Current reward: 0.026590\n",
      "  Step 12, Current reward: 0.026590\n",
      "Episode 875/1000 complete - Max Reward: 0.026590\n",
      "Starting episode 876/1000\n",
      "  Step 1, Current reward: 0.017093\n",
      "  Step 2, Current reward: 0.017093\n",
      "  Step 3, Current reward: 0.017093\n",
      "  Step 4, Current reward: 0.017093\n",
      "  Step 5, Current reward: 0.017093\n",
      "  Step 6, Current reward: 0.017093\n",
      "  Step 7, Current reward: 0.017093\n",
      "  Step 8, Current reward: 0.017093\n",
      "  Step 9, Current reward: 0.017093\n",
      "  Step 10, Current reward: 0.017093\n",
      "  Step 11, Current reward: 0.017093\n",
      "  Step 12, Current reward: 0.017093\n",
      "Episode 876/1000 complete - Max Reward: 0.017093\n",
      "Starting episode 877/1000\n",
      "  Step 1, Current reward: 0.009141\n",
      "  Step 2, Current reward: 0.009141\n",
      "  Step 3, Current reward: 0.009141\n",
      "  Step 4, Current reward: 0.009141\n",
      "  Step 5, Current reward: 0.009141\n",
      "  Step 6, Current reward: 0.009141\n",
      "  Step 7, Current reward: 0.009141\n",
      "  Step 8, Current reward: 0.009141\n",
      "  Step 9, Current reward: 0.009141\n",
      "  Step 10, Current reward: 0.009141\n",
      "  Step 11, Current reward: 0.009141\n",
      "  Step 12, Current reward: 0.009141\n",
      "Episode 877/1000 complete - Max Reward: 0.009141\n",
      "Starting episode 878/1000\n",
      "  Step 1, Current reward: 0.012266\n",
      "  Step 2, Current reward: 0.012266\n",
      "  Step 3, Current reward: 0.012266\n",
      "  Step 4, Current reward: 0.012266\n",
      "  Step 5, Current reward: 0.012266\n",
      "  Step 6, Current reward: 0.012266\n",
      "  Step 7, Current reward: 0.012266\n",
      "  Step 8, Current reward: 0.012266\n",
      "  Step 9, Current reward: 0.012266\n",
      "  Step 10, Current reward: 0.012266\n",
      "  Step 11, Current reward: 0.012266\n",
      "  Step 12, Current reward: 0.012266\n",
      "Episode 878/1000 complete - Max Reward: 0.012266\n",
      "Starting episode 879/1000\n",
      "  Step 1, Current reward: 0.018742\n",
      "  Step 2, Current reward: 0.018742\n",
      "  Step 3, Current reward: 0.018742\n",
      "  Step 4, Current reward: 0.018742\n",
      "  Step 5, Current reward: 0.018742\n",
      "  Step 6, Current reward: 0.018742\n",
      "  Step 7, Current reward: 0.018742\n",
      "  Step 8, Current reward: 0.018742\n",
      "  Step 9, Current reward: 0.018742\n",
      "  Step 10, Current reward: 0.018742\n",
      "  Step 11, Current reward: 0.018742\n",
      "  Step 12, Current reward: 0.018742\n",
      "Episode 879/1000 complete - Max Reward: 0.018742\n",
      "Starting episode 880/1000\n",
      "  Step 1, Current reward: 0.003017\n",
      "  Step 2, Current reward: 0.003017\n",
      "  Step 3, Current reward: 0.003017\n",
      "  Step 4, Current reward: 0.003017\n",
      "  Step 5, Current reward: 0.003017\n",
      "  Step 6, Current reward: 0.003017\n",
      "  Step 7, Current reward: 0.003017\n",
      "  Step 8, Current reward: 0.003017\n",
      "  Step 9, Current reward: 0.003017\n",
      "  Step 10, Current reward: 0.003017\n",
      "  Step 11, Current reward: 0.003017\n",
      "  Step 12, Current reward: 0.003017\n",
      "Episode 880/1000 complete - Max Reward: 0.003017\n",
      "Starting episode 881/1000\n",
      "  Step 1, Current reward: 0.011114\n",
      "  Step 2, Current reward: 0.011114\n",
      "  Step 3, Current reward: 0.011114\n",
      "  Step 4, Current reward: 0.011114\n",
      "  Step 5, Current reward: 0.011114\n",
      "  Step 6, Current reward: 0.011114\n",
      "  Step 7, Current reward: 0.011114\n",
      "  Step 8, Current reward: 0.011114\n",
      "  Step 9, Current reward: 0.011114\n",
      "  Step 10, Current reward: 0.011114\n",
      "  Step 11, Current reward: 0.011114\n",
      "  Step 12, Current reward: 0.011114\n",
      "Episode 881/1000 complete - Max Reward: 0.011114\n",
      "Starting episode 882/1000\n",
      "  Step 1, Current reward: 0.008651\n",
      "  Step 2, Current reward: 0.008651\n",
      "  Step 3, Current reward: 0.008651\n",
      "  Step 4, Current reward: 0.008651\n",
      "  Step 5, Current reward: 0.008651\n",
      "  Step 6, Current reward: 0.008651\n",
      "  Step 7, Current reward: 0.008651\n",
      "  Step 8, Current reward: 0.008651\n",
      "  Step 9, Current reward: 0.008651\n",
      "  Step 10, Current reward: 0.008651\n",
      "  Step 11, Current reward: 0.008651\n",
      "  Step 12, Current reward: 0.008651\n",
      "Episode 882/1000 complete - Max Reward: 0.008651\n",
      "Starting episode 883/1000\n",
      "  Step 1, Current reward: 0.080583\n",
      "  Step 2, Current reward: 0.080583\n",
      "  Step 3, Current reward: 0.080583\n",
      "  Step 4, Current reward: 0.080583\n",
      "  Step 5, Current reward: 0.080583\n",
      "  Step 6, Current reward: 0.080583\n",
      "  Step 7, Current reward: 0.080583\n",
      "  Step 8, Current reward: 0.080583\n",
      "  Step 9, Current reward: 0.080583\n",
      "  Step 10, Current reward: 0.080583\n",
      "  Step 11, Current reward: 0.080583\n",
      "  Step 12, Current reward: 0.080583\n",
      "Episode 883/1000 complete - Max Reward: 0.080583\n",
      "Starting episode 884/1000\n",
      "  Step 1, Current reward: 0.013985\n",
      "  Step 2, Current reward: 0.013985\n",
      "  Step 3, Current reward: 0.013985\n",
      "  Step 4, Current reward: 0.013985\n",
      "  Step 5, Current reward: 0.013985\n",
      "  Step 6, Current reward: 0.013985\n",
      "  Step 7, Current reward: 0.013985\n",
      "  Step 8, Current reward: 0.013985\n",
      "  Step 9, Current reward: 0.013985\n",
      "  Step 10, Current reward: 0.013985\n",
      "  Step 11, Current reward: 0.013985\n",
      "  Step 12, Current reward: 0.013985\n",
      "Episode 884/1000 complete - Max Reward: 0.013985\n",
      "Starting episode 885/1000\n",
      "  Step 1, Current reward: 0.015417\n",
      "  Step 2, Current reward: 0.015417\n",
      "  Step 3, Current reward: 0.015417\n",
      "  Step 4, Current reward: 0.015417\n",
      "  Step 5, Current reward: 0.015417\n",
      "  Step 6, Current reward: 0.015417\n",
      "  Step 7, Current reward: 0.015417\n",
      "  Step 8, Current reward: 0.015417\n",
      "  Step 9, Current reward: 0.015417\n",
      "  Step 10, Current reward: 0.015417\n",
      "  Step 11, Current reward: 0.015417\n",
      "  Step 12, Current reward: 0.015417\n",
      "Episode 885/1000 complete - Max Reward: 0.015417\n",
      "Starting episode 886/1000\n",
      "  Step 1, Current reward: 0.004738\n",
      "  Step 2, Current reward: 0.004738\n",
      "  Step 3, Current reward: 0.004738\n",
      "  Step 4, Current reward: 0.004738\n",
      "  Step 5, Current reward: 0.004738\n",
      "  Step 6, Current reward: 0.004738\n",
      "  Step 7, Current reward: 0.004738\n",
      "  Step 8, Current reward: 0.004738\n",
      "  Step 9, Current reward: 0.004738\n",
      "  Step 10, Current reward: 0.004738\n",
      "  Step 11, Current reward: 0.004738\n",
      "  Step 12, Current reward: 0.004738\n",
      "Episode 886/1000 complete - Max Reward: 0.004738\n",
      "Starting episode 887/1000\n",
      "  Step 1, Current reward: 0.001590\n",
      "  Step 2, Current reward: 0.001590\n",
      "  Step 3, Current reward: 0.001590\n",
      "  Step 4, Current reward: 0.001590\n",
      "  Step 5, Current reward: 0.001590\n",
      "  Step 6, Current reward: 0.001590\n",
      "  Step 7, Current reward: 0.001590\n",
      "  Step 8, Current reward: 0.001590\n",
      "  Step 9, Current reward: 0.001590\n",
      "  Step 10, Current reward: 0.001590\n",
      "  Step 11, Current reward: 0.001590\n",
      "  Step 12, Current reward: 0.001590\n",
      "Episode 887/1000 complete - Max Reward: 0.001590\n",
      "Starting episode 888/1000\n",
      "  Step 1, Current reward: 0.016883\n",
      "  Step 2, Current reward: 0.016883\n",
      "  Step 3, Current reward: 0.016883\n",
      "  Step 4, Current reward: 0.016883\n",
      "  Step 5, Current reward: 0.016883\n",
      "  Step 6, Current reward: 0.016883\n",
      "  Step 7, Current reward: 0.016883\n",
      "  Step 8, Current reward: 0.016883\n",
      "  Step 9, Current reward: 0.016883\n",
      "  Step 10, Current reward: 0.016883\n",
      "  Step 11, Current reward: 0.016883\n",
      "  Step 12, Current reward: 0.016883\n",
      "Episode 888/1000 complete - Max Reward: 0.016883\n",
      "Starting episode 889/1000\n",
      "  Step 1, Current reward: 0.167093\n",
      "  Step 2, Current reward: 0.167093\n",
      "  Step 3, Current reward: 0.167093\n",
      "  Step 4, Current reward: 0.167093\n",
      "  Step 5, Current reward: 0.167093\n",
      "  Step 6, Current reward: 0.167093\n",
      "  Step 7, Current reward: 0.167093\n",
      "  Step 8, Current reward: 0.167093\n",
      "  Step 9, Current reward: 0.167093\n",
      "  Step 10, Current reward: 0.167093\n",
      "  Step 11, Current reward: 0.167093\n",
      "  Step 12, Current reward: 0.167093\n",
      "Episode 889/1000 complete - Max Reward: 0.167093\n",
      "Starting episode 890/1000\n",
      "  Step 1, Current reward: 0.015013\n",
      "  Step 2, Current reward: 0.015013\n",
      "  Step 3, Current reward: 0.015013\n",
      "  Step 4, Current reward: 0.015013\n",
      "  Step 5, Current reward: 0.015013\n",
      "  Step 6, Current reward: 0.015013\n",
      "  Step 7, Current reward: 0.015013\n",
      "  Step 8, Current reward: 0.015013\n",
      "  Step 9, Current reward: 0.015013\n",
      "  Step 10, Current reward: 0.015013\n",
      "  Step 11, Current reward: 0.015013\n",
      "  Step 12, Current reward: 0.015013\n",
      "Episode 890/1000 complete - Max Reward: 0.015013\n",
      "Starting episode 891/1000\n",
      "  Step 1, Current reward: 0.021891\n",
      "  Step 2, Current reward: 0.021891\n",
      "  Step 3, Current reward: 0.021891\n",
      "  Step 4, Current reward: 0.021891\n",
      "  Step 5, Current reward: 0.021891\n",
      "  Step 6, Current reward: 0.021891\n",
      "  Step 7, Current reward: 0.021891\n",
      "  Step 8, Current reward: 0.021891\n",
      "  Step 9, Current reward: 0.021891\n",
      "  Step 10, Current reward: 0.021891\n",
      "  Step 11, Current reward: 0.021891\n",
      "  Step 12, Current reward: 0.021891\n",
      "Episode 891/1000 complete - Max Reward: 0.021891\n",
      "Starting episode 892/1000\n",
      "  Step 1, Current reward: 0.042786\n",
      "  Step 2, Current reward: 0.042786\n",
      "  Step 3, Current reward: 0.042786\n",
      "  Step 4, Current reward: 0.042786\n",
      "  Step 5, Current reward: 0.042786\n",
      "  Step 6, Current reward: 0.042786\n",
      "  Step 7, Current reward: 0.042786\n",
      "  Step 8, Current reward: 0.042786\n",
      "  Step 9, Current reward: 0.042786\n",
      "  Step 10, Current reward: 0.042786\n",
      "  Step 11, Current reward: 0.042786\n",
      "  Step 12, Current reward: 0.042786\n",
      "Episode 892/1000 complete - Max Reward: 0.042786\n",
      "Starting episode 893/1000\n",
      "  Step 1, Current reward: 0.013445\n",
      "  Step 2, Current reward: 0.013445\n",
      "  Step 3, Current reward: 0.013445\n",
      "  Step 4, Current reward: 0.013445\n",
      "  Step 5, Current reward: 0.013445\n",
      "  Step 6, Current reward: 0.013445\n",
      "  Step 7, Current reward: 0.013445\n",
      "  Step 8, Current reward: 0.013445\n",
      "  Step 9, Current reward: 0.013445\n",
      "  Step 10, Current reward: 0.013445\n",
      "  Step 11, Current reward: 0.013445\n",
      "  Step 12, Current reward: 0.013445\n",
      "Episode 893/1000 complete - Max Reward: 0.013445\n",
      "Starting episode 894/1000\n",
      "  Step 1, Current reward: 0.002805\n",
      "  Step 2, Current reward: 0.002805\n",
      "  Step 3, Current reward: 0.002805\n",
      "  Step 4, Current reward: 0.002805\n",
      "  Step 5, Current reward: 0.002805\n",
      "  Step 6, Current reward: 0.002805\n",
      "  Step 7, Current reward: 0.002805\n",
      "  Step 8, Current reward: 0.002805\n",
      "  Step 9, Current reward: 0.002805\n",
      "  Step 10, Current reward: 0.002805\n",
      "  Step 11, Current reward: 0.002805\n",
      "  Step 12, Current reward: 0.002805\n",
      "Episode 894/1000 complete - Max Reward: 0.002805\n",
      "Starting episode 895/1000\n",
      "  Step 1, Current reward: 0.061800\n",
      "  Step 2, Current reward: 0.061800\n",
      "  Step 3, Current reward: 0.061800\n",
      "  Step 4, Current reward: 0.061800\n",
      "  Step 5, Current reward: 0.061800\n",
      "  Step 6, Current reward: 0.061800\n",
      "  Step 7, Current reward: 0.061800\n",
      "  Step 8, Current reward: 0.061800\n",
      "  Step 9, Current reward: 0.061800\n",
      "  Step 10, Current reward: 0.061800\n",
      "  Step 11, Current reward: 0.061800\n",
      "  Step 12, Current reward: 0.061800\n",
      "Episode 895/1000 complete - Max Reward: 0.061800\n",
      "Starting episode 896/1000\n",
      "  Step 1, Current reward: 0.057211\n",
      "  Step 2, Current reward: 0.057211\n",
      "  Step 3, Current reward: 0.057211\n",
      "  Step 4, Current reward: 0.057211\n",
      "  Step 5, Current reward: 0.057211\n",
      "  Step 6, Current reward: 0.057211\n",
      "  Step 7, Current reward: 0.057211\n",
      "  Step 8, Current reward: 0.057211\n",
      "  Step 9, Current reward: 0.057211\n",
      "  Step 10, Current reward: 0.057211\n",
      "  Step 11, Current reward: 0.057211\n",
      "  Step 12, Current reward: 0.057211\n",
      "Episode 896/1000 complete - Max Reward: 0.057211\n",
      "Starting episode 897/1000\n",
      "  Step 1, Current reward: 0.005461\n",
      "  Step 2, Current reward: 0.005461\n",
      "  Step 3, Current reward: 0.005461\n",
      "  Step 4, Current reward: 0.005461\n",
      "  Step 5, Current reward: 0.005461\n",
      "  Step 6, Current reward: 0.005461\n",
      "  Step 7, Current reward: 0.005461\n",
      "  Step 8, Current reward: 0.005461\n",
      "  Step 9, Current reward: 0.005461\n",
      "  Step 10, Current reward: 0.005461\n",
      "  Step 11, Current reward: 0.005461\n",
      "  Step 12, Current reward: 0.005461\n",
      "Episode 897/1000 complete - Max Reward: 0.005461\n",
      "Starting episode 898/1000\n",
      "  Step 1, Current reward: 0.023647\n",
      "  Step 2, Current reward: 0.023647\n",
      "  Step 3, Current reward: 0.023647\n",
      "  Step 4, Current reward: 0.023647\n",
      "  Step 5, Current reward: 0.023647\n",
      "  Step 6, Current reward: 0.023647\n",
      "  Step 7, Current reward: 0.023647\n",
      "  Step 8, Current reward: 0.023647\n",
      "  Step 9, Current reward: 0.023647\n",
      "  Step 10, Current reward: 0.023647\n",
      "  Step 11, Current reward: 0.023647\n",
      "  Step 12, Current reward: 0.023647\n",
      "Episode 898/1000 complete - Max Reward: 0.023647\n",
      "Starting episode 899/1000\n",
      "  Step 1, Current reward: 0.017180\n",
      "  Step 2, Current reward: 0.017180\n",
      "  Step 3, Current reward: 0.017180\n",
      "  Step 4, Current reward: 0.017180\n",
      "  Step 5, Current reward: 0.017180\n",
      "  Step 6, Current reward: 0.017180\n",
      "  Step 7, Current reward: 0.017180\n",
      "  Step 8, Current reward: 0.017180\n",
      "  Step 9, Current reward: 0.017180\n",
      "  Step 10, Current reward: 0.017180\n",
      "  Step 11, Current reward: 0.017180\n",
      "  Step 12, Current reward: 0.017180\n",
      "Episode 899/1000 complete - Max Reward: 0.017180\n",
      "Starting episode 900/1000\n",
      "  Step 1, Current reward: 0.003091\n",
      "  Step 2, Current reward: 0.003091\n",
      "  Step 3, Current reward: 0.003091\n",
      "  Step 4, Current reward: 0.003091\n",
      "  Step 5, Current reward: 0.003091\n",
      "  Step 6, Current reward: 0.003091\n",
      "  Step 7, Current reward: 0.003091\n",
      "  Step 8, Current reward: 0.003091\n",
      "  Step 9, Current reward: 0.003091\n",
      "  Step 10, Current reward: 0.003091\n",
      "  Step 11, Current reward: 0.003091\n",
      "  Step 12, Current reward: 0.003091\n",
      "Episode 900/1000 complete - Max Reward: 0.003091\n",
      "Starting episode 901/1000\n",
      "  Step 1, Current reward: 0.030635\n",
      "  Step 2, Current reward: 0.030635\n",
      "  Step 3, Current reward: 0.030635\n",
      "  Step 4, Current reward: 0.030635\n",
      "  Step 5, Current reward: 0.030635\n",
      "  Step 6, Current reward: 0.030635\n",
      "  Step 7, Current reward: 0.030635\n",
      "  Step 8, Current reward: 0.030635\n",
      "  Step 9, Current reward: 0.030635\n",
      "  Step 10, Current reward: 0.030635\n",
      "  Step 11, Current reward: 0.030635\n",
      "  Step 12, Current reward: 0.030635\n",
      "Episode 901/1000 complete - Max Reward: 0.030635\n",
      "Starting episode 902/1000\n",
      "  Step 1, Current reward: 0.008469\n",
      "  Step 2, Current reward: 0.008469\n",
      "  Step 3, Current reward: 0.008469\n",
      "  Step 4, Current reward: 0.008469\n",
      "  Step 5, Current reward: 0.008469\n",
      "  Step 6, Current reward: 0.008469\n",
      "  Step 7, Current reward: 0.008469\n",
      "  Step 8, Current reward: 0.008469\n",
      "  Step 9, Current reward: 0.008469\n",
      "  Step 10, Current reward: 0.008469\n",
      "  Step 11, Current reward: 0.008469\n",
      "  Step 12, Current reward: 0.008469\n",
      "Episode 902/1000 complete - Max Reward: 0.008469\n",
      "Starting episode 903/1000\n",
      "  Step 1, Current reward: 0.006597\n",
      "  Step 2, Current reward: 0.006597\n",
      "  Step 3, Current reward: 0.006597\n",
      "  Step 4, Current reward: 0.006597\n",
      "  Step 5, Current reward: 0.006597\n",
      "  Step 6, Current reward: 0.006597\n",
      "  Step 7, Current reward: 0.006597\n",
      "  Step 8, Current reward: 0.006597\n",
      "  Step 9, Current reward: 0.006597\n",
      "  Step 10, Current reward: 0.006597\n",
      "  Step 11, Current reward: 0.006597\n",
      "  Step 12, Current reward: 0.006597\n",
      "Episode 903/1000 complete - Max Reward: 0.006597\n",
      "Starting episode 904/1000\n",
      "  Step 1, Current reward: 0.034127\n",
      "  Step 2, Current reward: 0.034127\n",
      "  Step 3, Current reward: 0.034127\n",
      "  Step 4, Current reward: 0.034127\n",
      "  Step 5, Current reward: 0.034127\n",
      "  Step 6, Current reward: 0.034127\n",
      "  Step 7, Current reward: 0.034127\n",
      "  Step 8, Current reward: 0.034127\n",
      "  Step 9, Current reward: 0.034127\n",
      "  Step 10, Current reward: 0.034127\n",
      "  Step 11, Current reward: 0.034127\n",
      "  Step 12, Current reward: 0.034127\n",
      "Episode 904/1000 complete - Max Reward: 0.034127\n",
      "Starting episode 905/1000\n",
      "  Step 1, Current reward: 0.010532\n",
      "  Step 2, Current reward: 0.010532\n",
      "  Step 3, Current reward: 0.010532\n",
      "  Step 4, Current reward: 0.010532\n",
      "  Step 5, Current reward: 0.010532\n",
      "  Step 6, Current reward: 0.010532\n",
      "  Step 7, Current reward: 0.010532\n",
      "  Step 8, Current reward: 0.010532\n",
      "  Step 9, Current reward: 0.010532\n",
      "  Step 10, Current reward: 0.010532\n",
      "  Step 11, Current reward: 0.010532\n",
      "  Step 12, Current reward: 0.010532\n",
      "Episode 905/1000 complete - Max Reward: 0.010532\n",
      "Starting episode 906/1000\n",
      "  Step 1, Current reward: 0.014968\n",
      "  Step 2, Current reward: 0.014968\n",
      "  Step 3, Current reward: 0.014968\n",
      "  Step 4, Current reward: 0.014968\n",
      "  Step 5, Current reward: 0.014968\n",
      "  Step 6, Current reward: 0.014968\n",
      "  Step 7, Current reward: 0.014968\n",
      "  Step 8, Current reward: 0.014968\n",
      "  Step 9, Current reward: 0.014968\n",
      "  Step 10, Current reward: 0.014968\n",
      "  Step 11, Current reward: 0.014968\n",
      "  Step 12, Current reward: 0.014968\n",
      "Episode 906/1000 complete - Max Reward: 0.014968\n",
      "Starting episode 907/1000\n",
      "  Step 1, Current reward: 0.022219\n",
      "  Step 2, Current reward: 0.021691\n",
      "  Step 3, Current reward: 0.021081\n",
      "  Step 4, Current reward: 0.020407\n",
      "  Step 5, Current reward: 0.019677\n",
      "  Step 6, Current reward: 0.018898\n",
      "  Step 7, Current reward: 0.018091\n",
      "  Step 8, Current reward: 0.017304\n",
      "  Step 9, Current reward: 0.017304\n",
      "  Step 10, Current reward: 0.017304\n",
      "  Step 11, Current reward: 0.017304\n",
      "  Step 12, Current reward: 0.017304\n",
      "Episode 907/1000 complete - Max Reward: 0.022219\n",
      "Starting episode 908/1000\n",
      "  Step 1, Current reward: 0.040748\n",
      "  Step 2, Current reward: 0.040748\n",
      "  Step 3, Current reward: 0.040748\n",
      "  Step 4, Current reward: 0.040748\n",
      "  Step 5, Current reward: 0.040748\n",
      "  Step 6, Current reward: 0.040748\n",
      "  Step 7, Current reward: 0.040748\n",
      "  Step 8, Current reward: 0.040748\n",
      "  Step 9, Current reward: 0.040748\n",
      "  Step 10, Current reward: 0.040748\n",
      "  Step 11, Current reward: 0.040748\n",
      "  Step 12, Current reward: 0.040748\n",
      "Episode 908/1000 complete - Max Reward: 0.040748\n",
      "Starting episode 909/1000\n",
      "  Step 1, Current reward: 0.029089\n",
      "  Step 2, Current reward: 0.029089\n",
      "  Step 3, Current reward: 0.029089\n",
      "  Step 4, Current reward: 0.029089\n",
      "  Step 5, Current reward: 0.029089\n",
      "  Step 6, Current reward: 0.029089\n",
      "  Step 7, Current reward: 0.029089\n",
      "  Step 8, Current reward: 0.029089\n",
      "  Step 9, Current reward: 0.029089\n",
      "  Step 10, Current reward: 0.029089\n",
      "  Step 11, Current reward: 0.029089\n",
      "  Step 12, Current reward: 0.029089\n",
      "Episode 909/1000 complete - Max Reward: 0.029089\n",
      "Starting episode 910/1000\n",
      "  Step 1, Current reward: 0.019160\n",
      "  Step 2, Current reward: 0.019160\n",
      "  Step 3, Current reward: 0.019160\n",
      "  Step 4, Current reward: 0.019160\n",
      "  Step 5, Current reward: 0.019160\n",
      "  Step 6, Current reward: 0.019160\n",
      "  Step 7, Current reward: 0.019160\n",
      "  Step 8, Current reward: 0.019160\n",
      "  Step 9, Current reward: 0.019160\n",
      "  Step 10, Current reward: 0.019160\n",
      "  Step 11, Current reward: 0.019160\n",
      "  Step 12, Current reward: 0.019160\n",
      "Episode 910/1000 complete - Max Reward: 0.019160\n",
      "Starting episode 911/1000\n",
      "  Step 1, Current reward: 0.017272\n",
      "  Step 2, Current reward: 0.017272\n",
      "  Step 3, Current reward: 0.017272\n",
      "  Step 4, Current reward: 0.017272\n",
      "  Step 5, Current reward: 0.017272\n",
      "  Step 6, Current reward: 0.017272\n",
      "  Step 7, Current reward: 0.017272\n",
      "  Step 8, Current reward: 0.017272\n",
      "  Step 9, Current reward: 0.017272\n",
      "  Step 10, Current reward: 0.017272\n",
      "  Step 11, Current reward: 0.017272\n",
      "  Step 12, Current reward: 0.017272\n",
      "Episode 911/1000 complete - Max Reward: 0.017272\n",
      "Starting episode 912/1000\n",
      "  Step 1, Current reward: 0.010190\n",
      "  Step 2, Current reward: 0.010190\n",
      "  Step 3, Current reward: 0.010190\n",
      "  Step 4, Current reward: 0.010190\n",
      "  Step 5, Current reward: 0.010190\n",
      "  Step 6, Current reward: 0.010190\n",
      "  Step 7, Current reward: 0.010190\n",
      "  Step 8, Current reward: 0.010190\n",
      "  Step 9, Current reward: 0.010190\n",
      "  Step 10, Current reward: 0.010190\n",
      "  Step 11, Current reward: 0.010190\n",
      "  Step 12, Current reward: 0.010190\n",
      "Episode 912/1000 complete - Max Reward: 0.010190\n",
      "Starting episode 913/1000\n",
      "  Step 1, Current reward: 0.008421\n",
      "  Step 2, Current reward: 0.008421\n",
      "  Step 3, Current reward: 0.008421\n",
      "  Step 4, Current reward: 0.008421\n",
      "  Step 5, Current reward: 0.008421\n",
      "  Step 6, Current reward: 0.008421\n",
      "  Step 7, Current reward: 0.008421\n",
      "  Step 8, Current reward: 0.008421\n",
      "  Step 9, Current reward: 0.008421\n",
      "  Step 10, Current reward: 0.008421\n",
      "  Step 11, Current reward: 0.008421\n",
      "  Step 12, Current reward: 0.008421\n",
      "Episode 913/1000 complete - Max Reward: 0.008421\n",
      "Starting episode 914/1000\n",
      "  Step 1, Current reward: 0.026656\n",
      "  Step 2, Current reward: 0.026656\n",
      "  Step 3, Current reward: 0.026656\n",
      "  Step 4, Current reward: 0.026656\n",
      "  Step 5, Current reward: 0.026656\n",
      "  Step 6, Current reward: 0.026656\n",
      "  Step 7, Current reward: 0.026656\n",
      "  Step 8, Current reward: 0.026656\n",
      "  Step 9, Current reward: 0.026656\n",
      "  Step 10, Current reward: 0.026656\n",
      "  Step 11, Current reward: 0.026656\n",
      "  Step 12, Current reward: 0.026656\n",
      "Episode 914/1000 complete - Max Reward: 0.026656\n",
      "Starting episode 915/1000\n",
      "  Step 1, Current reward: 0.002409\n",
      "  Step 2, Current reward: 0.002409\n",
      "  Step 3, Current reward: 0.002409\n",
      "  Step 4, Current reward: 0.002409\n",
      "  Step 5, Current reward: 0.002409\n",
      "  Step 6, Current reward: 0.002409\n",
      "  Step 7, Current reward: 0.002409\n",
      "  Step 8, Current reward: 0.002409\n",
      "  Step 9, Current reward: 0.002409\n",
      "  Step 10, Current reward: 0.002409\n",
      "  Step 11, Current reward: 0.002409\n",
      "  Step 12, Current reward: 0.002409\n",
      "Episode 915/1000 complete - Max Reward: 0.002409\n",
      "Starting episode 916/1000\n",
      "  Step 1, Current reward: 0.064573\n",
      "  Step 2, Current reward: 0.064573\n",
      "  Step 3, Current reward: 0.064573\n",
      "  Step 4, Current reward: 0.064573\n",
      "  Step 5, Current reward: 0.064573\n",
      "  Step 6, Current reward: 0.064573\n",
      "  Step 7, Current reward: 0.064573\n",
      "  Step 8, Current reward: 0.064573\n",
      "  Step 9, Current reward: 0.064573\n",
      "  Step 10, Current reward: 0.064573\n",
      "  Step 11, Current reward: 0.064573\n",
      "  Step 12, Current reward: 0.064573\n",
      "Episode 916/1000 complete - Max Reward: 0.064573\n",
      "Starting episode 917/1000\n",
      "  Step 1, Current reward: 0.015748\n",
      "  Step 2, Current reward: 0.015748\n",
      "  Step 3, Current reward: 0.015748\n",
      "  Step 4, Current reward: 0.015748\n",
      "  Step 5, Current reward: 0.015748\n",
      "  Step 6, Current reward: 0.015748\n",
      "  Step 7, Current reward: 0.015748\n",
      "  Step 8, Current reward: 0.015748\n",
      "  Step 9, Current reward: 0.015748\n",
      "  Step 10, Current reward: 0.015748\n",
      "  Step 11, Current reward: 0.015748\n",
      "  Step 12, Current reward: 0.015748\n",
      "Episode 917/1000 complete - Max Reward: 0.015748\n",
      "Starting episode 918/1000\n",
      "  Step 1, Current reward: 0.031054\n",
      "  Step 2, Current reward: 0.031054\n",
      "  Step 3, Current reward: 0.031054\n",
      "  Step 4, Current reward: 0.031054\n",
      "  Step 5, Current reward: 0.031054\n",
      "  Step 6, Current reward: 0.031054\n",
      "  Step 7, Current reward: 0.031054\n",
      "  Step 8, Current reward: 0.031054\n",
      "  Step 9, Current reward: 0.031054\n",
      "  Step 10, Current reward: 0.031054\n",
      "  Step 11, Current reward: 0.031054\n",
      "  Step 12, Current reward: 0.031054\n",
      "Episode 918/1000 complete - Max Reward: 0.031054\n",
      "Starting episode 919/1000\n",
      "  Step 1, Current reward: 0.096478\n",
      "  Step 2, Current reward: 0.096478\n",
      "  Step 3, Current reward: 0.096478\n",
      "  Step 4, Current reward: 0.096478\n",
      "  Step 5, Current reward: 0.096478\n",
      "  Step 6, Current reward: 0.096478\n",
      "  Step 7, Current reward: 0.096478\n",
      "  Step 8, Current reward: 0.096478\n",
      "  Step 9, Current reward: 0.096478\n",
      "  Step 10, Current reward: 0.096478\n",
      "  Step 11, Current reward: 0.096478\n",
      "  Step 12, Current reward: 0.096478\n",
      "Episode 919/1000 complete - Max Reward: 0.096478\n",
      "Starting episode 920/1000\n",
      "  Step 1, Current reward: 0.002592\n",
      "  Step 2, Current reward: 0.002592\n",
      "  Step 3, Current reward: 0.002592\n",
      "  Step 4, Current reward: 0.002592\n",
      "  Step 5, Current reward: 0.002592\n",
      "  Step 6, Current reward: 0.002592\n",
      "  Step 7, Current reward: 0.002592\n",
      "  Step 8, Current reward: 0.002592\n",
      "  Step 9, Current reward: 0.002592\n",
      "  Step 10, Current reward: 0.002592\n",
      "  Step 11, Current reward: 0.002592\n",
      "  Step 12, Current reward: 0.002592\n",
      "Episode 920/1000 complete - Max Reward: 0.002592\n",
      "Starting episode 921/1000\n",
      "  Step 1, Current reward: 0.026209\n",
      "  Step 2, Current reward: 0.026209\n",
      "  Step 3, Current reward: 0.026209\n",
      "  Step 4, Current reward: 0.026209\n",
      "  Step 5, Current reward: 0.026209\n",
      "  Step 6, Current reward: 0.026209\n",
      "  Step 7, Current reward: 0.026209\n",
      "  Step 8, Current reward: 0.026209\n",
      "  Step 9, Current reward: 0.026209\n",
      "  Step 10, Current reward: 0.026209\n",
      "  Step 11, Current reward: 0.026209\n",
      "  Step 12, Current reward: 0.026209\n",
      "Episode 921/1000 complete - Max Reward: 0.026209\n",
      "Starting episode 922/1000\n",
      "  Step 1, Current reward: 0.006200\n",
      "  Step 2, Current reward: 0.006200\n",
      "  Step 3, Current reward: 0.006200\n",
      "  Step 4, Current reward: 0.006200\n",
      "  Step 5, Current reward: 0.006200\n",
      "  Step 6, Current reward: 0.006200\n",
      "  Step 7, Current reward: 0.006200\n",
      "  Step 8, Current reward: 0.006200\n",
      "  Step 9, Current reward: 0.006200\n",
      "  Step 10, Current reward: 0.006200\n",
      "  Step 11, Current reward: 0.006200\n",
      "  Step 12, Current reward: 0.006200\n",
      "Episode 922/1000 complete - Max Reward: 0.006200\n",
      "Starting episode 923/1000\n",
      "  Step 1, Current reward: 0.005510\n",
      "  Step 2, Current reward: 0.005510\n",
      "  Step 3, Current reward: 0.005510\n",
      "  Step 4, Current reward: 0.005510\n",
      "  Step 5, Current reward: 0.005510\n",
      "  Step 6, Current reward: 0.005510\n",
      "  Step 7, Current reward: 0.005510\n",
      "  Step 8, Current reward: 0.005510\n",
      "  Step 9, Current reward: 0.005510\n",
      "  Step 10, Current reward: 0.005510\n",
      "  Step 11, Current reward: 0.005510\n",
      "  Step 12, Current reward: 0.005510\n",
      "Episode 923/1000 complete - Max Reward: 0.005510\n",
      "Starting episode 924/1000\n",
      "  Step 1, Current reward: 0.003736\n",
      "  Step 2, Current reward: 0.003736\n",
      "  Step 3, Current reward: 0.003736\n",
      "  Step 4, Current reward: 0.003736\n",
      "  Step 5, Current reward: 0.003736\n",
      "  Step 6, Current reward: 0.003736\n",
      "  Step 7, Current reward: 0.003736\n",
      "  Step 8, Current reward: 0.003736\n",
      "  Step 9, Current reward: 0.003736\n",
      "  Step 10, Current reward: 0.003736\n",
      "  Step 11, Current reward: 0.003736\n",
      "  Step 12, Current reward: 0.003736\n",
      "Episode 924/1000 complete - Max Reward: 0.003736\n",
      "Starting episode 925/1000\n",
      "  Step 1, Current reward: 0.011227\n",
      "  Step 2, Current reward: 0.011227\n",
      "  Step 3, Current reward: 0.011227\n",
      "  Step 4, Current reward: 0.011227\n",
      "  Step 5, Current reward: 0.011227\n",
      "  Step 6, Current reward: 0.011227\n",
      "  Step 7, Current reward: 0.011227\n",
      "  Step 8, Current reward: 0.011227\n",
      "  Step 9, Current reward: 0.011227\n",
      "  Step 10, Current reward: 0.011227\n",
      "  Step 11, Current reward: 0.011227\n",
      "  Step 12, Current reward: 0.011227\n",
      "Episode 925/1000 complete - Max Reward: 0.011227\n",
      "Starting episode 926/1000\n",
      "  Step 1, Current reward: 0.016960\n",
      "  Step 2, Current reward: 0.016960\n",
      "  Step 3, Current reward: 0.016960\n",
      "  Step 4, Current reward: 0.016960\n",
      "  Step 5, Current reward: 0.016960\n",
      "  Step 6, Current reward: 0.016960\n",
      "  Step 7, Current reward: 0.016960\n",
      "  Step 8, Current reward: 0.016960\n",
      "  Step 9, Current reward: 0.016960\n",
      "  Step 10, Current reward: 0.016960\n",
      "  Step 11, Current reward: 0.016960\n",
      "  Step 12, Current reward: 0.016960\n",
      "Episode 926/1000 complete - Max Reward: 0.016960\n",
      "Starting episode 927/1000\n",
      "  Step 1, Current reward: 0.091873\n",
      "  Step 2, Current reward: 0.091873\n",
      "  Step 3, Current reward: 0.091873\n",
      "  Step 4, Current reward: 0.091873\n",
      "  Step 5, Current reward: 0.091873\n",
      "  Step 6, Current reward: 0.091873\n",
      "  Step 7, Current reward: 0.091873\n",
      "  Step 8, Current reward: 0.091873\n",
      "  Step 9, Current reward: 0.091873\n",
      "  Step 10, Current reward: 0.091873\n",
      "  Step 11, Current reward: 0.091873\n",
      "  Step 12, Current reward: 0.091873\n",
      "Episode 927/1000 complete - Max Reward: 0.091873\n",
      "Starting episode 928/1000\n",
      "  Step 1, Current reward: 0.009453\n",
      "  Step 2, Current reward: 0.009453\n",
      "  Step 3, Current reward: 0.009453\n",
      "  Step 4, Current reward: 0.009453\n",
      "  Step 5, Current reward: 0.009453\n",
      "  Step 6, Current reward: 0.009453\n",
      "  Step 7, Current reward: 0.009453\n",
      "  Step 8, Current reward: 0.009453\n",
      "  Step 9, Current reward: 0.009453\n",
      "  Step 10, Current reward: 0.009453\n",
      "  Step 11, Current reward: 0.009453\n",
      "  Step 12, Current reward: 0.009453\n",
      "Episode 928/1000 complete - Max Reward: 0.009453\n",
      "Starting episode 929/1000\n",
      "  Step 1, Current reward: 0.003401\n",
      "  Step 2, Current reward: 0.003401\n",
      "  Step 3, Current reward: 0.003401\n",
      "  Step 4, Current reward: 0.003401\n",
      "  Step 5, Current reward: 0.003401\n",
      "  Step 6, Current reward: 0.003401\n",
      "  Step 7, Current reward: 0.003401\n",
      "  Step 8, Current reward: 0.003401\n",
      "  Step 9, Current reward: 0.003401\n",
      "  Step 10, Current reward: 0.003401\n",
      "  Step 11, Current reward: 0.003401\n",
      "  Step 12, Current reward: 0.003401\n",
      "Episode 929/1000 complete - Max Reward: 0.003401\n",
      "Starting episode 930/1000\n",
      "  Step 1, Current reward: 0.011912\n",
      "  Step 2, Current reward: 0.011912\n",
      "  Step 3, Current reward: 0.011912\n",
      "  Step 4, Current reward: 0.011912\n",
      "  Step 5, Current reward: 0.011912\n",
      "  Step 6, Current reward: 0.011912\n",
      "  Step 7, Current reward: 0.011912\n",
      "  Step 8, Current reward: 0.011912\n",
      "  Step 9, Current reward: 0.011912\n",
      "  Step 10, Current reward: 0.011912\n",
      "  Step 11, Current reward: 0.011912\n",
      "  Step 12, Current reward: 0.011912\n",
      "Episode 930/1000 complete - Max Reward: 0.011912\n",
      "Starting episode 931/1000\n",
      "  Step 1, Current reward: 0.004606\n",
      "  Step 2, Current reward: 0.004617\n",
      "  Step 3, Current reward: 0.004558\n",
      "  Step 4, Current reward: 0.004558\n",
      "  Step 5, Current reward: 0.004558\n",
      "  Step 6, Current reward: 0.004558\n",
      "  Step 7, Current reward: 0.004558\n",
      "  Step 8, Current reward: 0.004558\n",
      "  Step 9, Current reward: 0.004558\n",
      "  Step 10, Current reward: 0.004558\n",
      "  Step 11, Current reward: 0.004558\n",
      "  Step 12, Current reward: 0.004558\n",
      "  Step 13, Current reward: 0.004558\n",
      "Episode 931/1000 complete - Max Reward: 0.004617\n",
      "Starting episode 932/1000\n",
      "  Step 1, Current reward: 0.021916\n",
      "  Step 2, Current reward: 0.021916\n",
      "  Step 3, Current reward: 0.021916\n",
      "  Step 4, Current reward: 0.021916\n",
      "  Step 5, Current reward: 0.021916\n",
      "  Step 6, Current reward: 0.021916\n",
      "  Step 7, Current reward: 0.021916\n",
      "  Step 8, Current reward: 0.021916\n",
      "  Step 9, Current reward: 0.021916\n",
      "  Step 10, Current reward: 0.021916\n",
      "  Step 11, Current reward: 0.021916\n",
      "  Step 12, Current reward: 0.021916\n",
      "Episode 932/1000 complete - Max Reward: 0.021916\n",
      "Starting episode 933/1000\n",
      "  Step 1, Current reward: 0.122227\n",
      "  Step 2, Current reward: 0.122227\n",
      "  Step 3, Current reward: 0.122227\n",
      "  Step 4, Current reward: 0.122227\n",
      "  Step 5, Current reward: 0.122227\n",
      "  Step 6, Current reward: 0.122227\n",
      "  Step 7, Current reward: 0.122227\n",
      "  Step 8, Current reward: 0.122227\n",
      "  Step 9, Current reward: 0.122227\n",
      "  Step 10, Current reward: 0.122227\n",
      "  Step 11, Current reward: 0.122227\n",
      "  Step 12, Current reward: 0.122227\n",
      "Episode 933/1000 complete - Max Reward: 0.122227\n",
      "Starting episode 934/1000\n",
      "  Step 1, Current reward: 0.017782\n",
      "  Step 2, Current reward: 0.017782\n",
      "  Step 3, Current reward: 0.017782\n",
      "  Step 4, Current reward: 0.017782\n",
      "  Step 5, Current reward: 0.017782\n",
      "  Step 6, Current reward: 0.017782\n",
      "  Step 7, Current reward: 0.017782\n",
      "  Step 8, Current reward: 0.017782\n",
      "  Step 9, Current reward: 0.017782\n",
      "  Step 10, Current reward: 0.017782\n",
      "  Step 11, Current reward: 0.017782\n",
      "  Step 12, Current reward: 0.017782\n",
      "Episode 934/1000 complete - Max Reward: 0.017782\n",
      "Starting episode 935/1000\n",
      "  Step 1, Current reward: 0.016070\n",
      "  Step 2, Current reward: 0.016070\n",
      "  Step 3, Current reward: 0.016070\n",
      "  Step 4, Current reward: 0.016070\n",
      "  Step 5, Current reward: 0.016070\n",
      "  Step 6, Current reward: 0.016070\n",
      "  Step 7, Current reward: 0.016070\n",
      "  Step 8, Current reward: 0.016070\n",
      "  Step 9, Current reward: 0.016070\n",
      "  Step 10, Current reward: 0.016070\n",
      "  Step 11, Current reward: 0.016070\n",
      "  Step 12, Current reward: 0.016070\n",
      "Episode 935/1000 complete - Max Reward: 0.016070\n",
      "Starting episode 936/1000\n",
      "  Step 1, Current reward: 0.003237\n",
      "  Step 2, Current reward: 0.003237\n",
      "  Step 3, Current reward: 0.003237\n",
      "  Step 4, Current reward: 0.003237\n",
      "  Step 5, Current reward: 0.003237\n",
      "  Step 6, Current reward: 0.003237\n",
      "  Step 7, Current reward: 0.003237\n",
      "  Step 8, Current reward: 0.003237\n",
      "  Step 9, Current reward: 0.003237\n",
      "  Step 10, Current reward: 0.003237\n",
      "  Step 11, Current reward: 0.003237\n",
      "  Step 12, Current reward: 0.003237\n",
      "Episode 936/1000 complete - Max Reward: 0.003237\n",
      "Starting episode 937/1000\n",
      "  Step 1, Current reward: 0.000862\n",
      "  Step 2, Current reward: 0.000862\n",
      "  Step 3, Current reward: 0.000862\n",
      "  Step 4, Current reward: 0.000862\n",
      "  Step 5, Current reward: 0.000862\n",
      "  Step 6, Current reward: 0.000862\n",
      "  Step 7, Current reward: 0.000862\n",
      "  Step 8, Current reward: 0.000862\n",
      "  Step 9, Current reward: 0.000862\n",
      "  Step 10, Current reward: 0.000862\n",
      "  Step 11, Current reward: 0.000862\n",
      "  Step 12, Current reward: 0.000862\n",
      "Episode 937/1000 complete - Max Reward: 0.000862\n",
      "Starting episode 938/1000\n",
      "  Step 1, Current reward: 0.039569\n",
      "  Step 2, Current reward: 0.039569\n",
      "  Step 3, Current reward: 0.039569\n",
      "  Step 4, Current reward: 0.039569\n",
      "  Step 5, Current reward: 0.039569\n",
      "  Step 6, Current reward: 0.039569\n",
      "  Step 7, Current reward: 0.039569\n",
      "  Step 8, Current reward: 0.039569\n",
      "  Step 9, Current reward: 0.039569\n",
      "  Step 10, Current reward: 0.039569\n",
      "  Step 11, Current reward: 0.039569\n",
      "  Step 12, Current reward: 0.039569\n",
      "Episode 938/1000 complete - Max Reward: 0.039569\n",
      "Starting episode 939/1000\n",
      "  Step 1, Current reward: 0.168728\n",
      "  Step 2, Current reward: 0.168728\n",
      "  Step 3, Current reward: 0.168728\n",
      "  Step 4, Current reward: 0.168728\n",
      "  Step 5, Current reward: 0.168728\n",
      "  Step 6, Current reward: 0.168728\n",
      "  Step 7, Current reward: 0.168728\n",
      "  Step 8, Current reward: 0.168728\n",
      "  Step 9, Current reward: 0.168728\n",
      "  Step 10, Current reward: 0.168728\n",
      "  Step 11, Current reward: 0.168728\n",
      "  Step 12, Current reward: 0.168728\n",
      "Episode 939/1000 complete - Max Reward: 0.168728\n",
      "Starting episode 940/1000\n",
      "  Step 1, Current reward: 0.006315\n",
      "  Step 2, Current reward: 0.006315\n",
      "  Step 3, Current reward: 0.006315\n",
      "  Step 4, Current reward: 0.006315\n",
      "  Step 5, Current reward: 0.006315\n",
      "  Step 6, Current reward: 0.006315\n",
      "  Step 7, Current reward: 0.006315\n",
      "  Step 8, Current reward: 0.006315\n",
      "  Step 9, Current reward: 0.006315\n",
      "  Step 10, Current reward: 0.006315\n",
      "  Step 11, Current reward: 0.006315\n",
      "  Step 12, Current reward: 0.006315\n",
      "Episode 940/1000 complete - Max Reward: 0.006315\n",
      "Starting episode 941/1000\n",
      "  Step 1, Current reward: 0.004199\n",
      "  Step 2, Current reward: 0.004199\n",
      "  Step 3, Current reward: 0.004199\n",
      "  Step 4, Current reward: 0.004199\n",
      "  Step 5, Current reward: 0.004199\n",
      "  Step 6, Current reward: 0.004199\n",
      "  Step 7, Current reward: 0.004199\n",
      "  Step 8, Current reward: 0.004199\n",
      "  Step 9, Current reward: 0.004199\n",
      "  Step 10, Current reward: 0.004199\n",
      "  Step 11, Current reward: 0.004199\n",
      "  Step 12, Current reward: 0.004199\n",
      "Episode 941/1000 complete - Max Reward: 0.004199\n",
      "Starting episode 942/1000\n",
      "  Step 1, Current reward: 0.007767\n",
      "  Step 2, Current reward: 0.007767\n",
      "  Step 3, Current reward: 0.007767\n",
      "  Step 4, Current reward: 0.007767\n",
      "  Step 5, Current reward: 0.007767\n",
      "  Step 6, Current reward: 0.007767\n",
      "  Step 7, Current reward: 0.007767\n",
      "  Step 8, Current reward: 0.007767\n",
      "  Step 9, Current reward: 0.007767\n",
      "  Step 10, Current reward: 0.007767\n",
      "  Step 11, Current reward: 0.007767\n",
      "  Step 12, Current reward: 0.007767\n",
      "Episode 942/1000 complete - Max Reward: 0.007767\n",
      "Starting episode 943/1000\n",
      "  Step 1, Current reward: 0.203656\n",
      "  Step 2, Current reward: 0.203656\n",
      "  Step 3, Current reward: 0.203656\n",
      "  Step 4, Current reward: 0.203656\n",
      "  Step 5, Current reward: 0.203656\n",
      "  Step 6, Current reward: 0.203656\n",
      "  Step 7, Current reward: 0.203656\n",
      "  Step 8, Current reward: 0.203656\n",
      "  Step 9, Current reward: 0.203656\n",
      "  Step 10, Current reward: 0.203656\n",
      "  Step 11, Current reward: 0.203656\n",
      "  Step 12, Current reward: 0.203656\n",
      "Episode 943/1000 complete - Max Reward: 0.203656\n",
      "Starting episode 944/1000\n",
      "  Step 1, Current reward: 0.003410\n",
      "  Step 2, Current reward: 0.003410\n",
      "  Step 3, Current reward: 0.003410\n",
      "  Step 4, Current reward: 0.003410\n",
      "  Step 5, Current reward: 0.003410\n",
      "  Step 6, Current reward: 0.003410\n",
      "  Step 7, Current reward: 0.003410\n",
      "  Step 8, Current reward: 0.003410\n",
      "  Step 9, Current reward: 0.003410\n",
      "  Step 10, Current reward: 0.003410\n",
      "  Step 11, Current reward: 0.003410\n",
      "  Step 12, Current reward: 0.003410\n",
      "Episode 944/1000 complete - Max Reward: 0.003410\n",
      "Starting episode 945/1000\n",
      "  Step 1, Current reward: 0.008187\n",
      "  Step 2, Current reward: 0.008187\n",
      "  Step 3, Current reward: 0.008187\n",
      "  Step 4, Current reward: 0.008187\n",
      "  Step 5, Current reward: 0.008187\n",
      "  Step 6, Current reward: 0.008187\n",
      "  Step 7, Current reward: 0.008187\n",
      "  Step 8, Current reward: 0.008187\n",
      "  Step 9, Current reward: 0.008187\n",
      "  Step 10, Current reward: 0.008187\n",
      "  Step 11, Current reward: 0.008187\n",
      "  Step 12, Current reward: 0.008187\n",
      "Episode 945/1000 complete - Max Reward: 0.008187\n",
      "Starting episode 946/1000\n",
      "  Step 1, Current reward: 0.010552\n",
      "  Step 2, Current reward: 0.010552\n",
      "  Step 3, Current reward: 0.010552\n",
      "  Step 4, Current reward: 0.010552\n",
      "  Step 5, Current reward: 0.010552\n",
      "  Step 6, Current reward: 0.010552\n",
      "  Step 7, Current reward: 0.010552\n",
      "  Step 8, Current reward: 0.010552\n",
      "  Step 9, Current reward: 0.010552\n",
      "  Step 10, Current reward: 0.010552\n",
      "  Step 11, Current reward: 0.010552\n",
      "  Step 12, Current reward: 0.010552\n",
      "Episode 946/1000 complete - Max Reward: 0.010552\n",
      "Starting episode 947/1000\n",
      "  Step 1, Current reward: 0.006140\n",
      "  Step 2, Current reward: 0.006140\n",
      "  Step 3, Current reward: 0.006140\n",
      "  Step 4, Current reward: 0.006140\n",
      "  Step 5, Current reward: 0.006140\n",
      "  Step 6, Current reward: 0.006140\n",
      "  Step 7, Current reward: 0.006140\n",
      "  Step 8, Current reward: 0.006140\n",
      "  Step 9, Current reward: 0.006140\n",
      "  Step 10, Current reward: 0.006140\n",
      "  Step 11, Current reward: 0.006140\n",
      "  Step 12, Current reward: 0.006140\n",
      "Episode 947/1000 complete - Max Reward: 0.006140\n",
      "Starting episode 948/1000\n",
      "  Step 1, Current reward: 0.042224\n",
      "  Step 2, Current reward: 0.042224\n",
      "  Step 3, Current reward: 0.042224\n",
      "  Step 4, Current reward: 0.042224\n",
      "  Step 5, Current reward: 0.042224\n",
      "  Step 6, Current reward: 0.042224\n",
      "  Step 7, Current reward: 0.042224\n",
      "  Step 8, Current reward: 0.042224\n",
      "  Step 9, Current reward: 0.042224\n",
      "  Step 10, Current reward: 0.042224\n",
      "  Step 11, Current reward: 0.042224\n",
      "  Step 12, Current reward: 0.042224\n",
      "Episode 948/1000 complete - Max Reward: 0.042224\n",
      "Starting episode 949/1000\n",
      "  Step 1, Current reward: 0.023196\n",
      "  Step 2, Current reward: 0.023196\n",
      "  Step 3, Current reward: 0.023196\n",
      "  Step 4, Current reward: 0.023196\n",
      "  Step 5, Current reward: 0.023196\n",
      "  Step 6, Current reward: 0.023196\n",
      "  Step 7, Current reward: 0.023196\n",
      "  Step 8, Current reward: 0.023196\n",
      "  Step 9, Current reward: 0.023196\n",
      "  Step 10, Current reward: 0.023196\n",
      "  Step 11, Current reward: 0.023196\n",
      "  Step 12, Current reward: 0.023196\n",
      "Episode 949/1000 complete - Max Reward: 0.023196\n",
      "Starting episode 950/1000\n",
      "  Step 1, Current reward: 0.001156\n",
      "  Step 2, Current reward: 0.001156\n",
      "  Step 3, Current reward: 0.001156\n",
      "  Step 4, Current reward: 0.001156\n",
      "  Step 5, Current reward: 0.001156\n",
      "  Step 6, Current reward: 0.001156\n",
      "  Step 7, Current reward: 0.001156\n",
      "  Step 8, Current reward: 0.001156\n",
      "  Step 9, Current reward: 0.001156\n",
      "  Step 10, Current reward: 0.001156\n",
      "  Step 11, Current reward: 0.001156\n",
      "  Step 12, Current reward: 0.001156\n",
      "Episode 950/1000 complete - Max Reward: 0.001156\n",
      "Starting episode 951/1000\n",
      "  Step 1, Current reward: 0.097283\n",
      "  Step 2, Current reward: 0.097283\n",
      "  Step 3, Current reward: 0.097283\n",
      "  Step 4, Current reward: 0.097283\n",
      "  Step 5, Current reward: 0.097283\n",
      "  Step 6, Current reward: 0.097283\n",
      "  Step 7, Current reward: 0.097283\n",
      "  Step 8, Current reward: 0.097283\n",
      "  Step 9, Current reward: 0.097283\n",
      "  Step 10, Current reward: 0.097283\n",
      "  Step 11, Current reward: 0.097283\n",
      "  Step 12, Current reward: 0.097283\n",
      "Episode 951/1000 complete - Max Reward: 0.097283\n",
      "Starting episode 952/1000\n",
      "  Step 1, Current reward: 0.007891\n",
      "  Step 2, Current reward: 0.007891\n",
      "  Step 3, Current reward: 0.007891\n",
      "  Step 4, Current reward: 0.007891\n",
      "  Step 5, Current reward: 0.007891\n",
      "  Step 6, Current reward: 0.007891\n",
      "  Step 7, Current reward: 0.007891\n",
      "  Step 8, Current reward: 0.007891\n",
      "  Step 9, Current reward: 0.007891\n",
      "  Step 10, Current reward: 0.007891\n",
      "  Step 11, Current reward: 0.007891\n",
      "  Step 12, Current reward: 0.007891\n",
      "Episode 952/1000 complete - Max Reward: 0.007891\n",
      "Starting episode 953/1000\n",
      "  Step 1, Current reward: 0.062369\n",
      "  Step 2, Current reward: 0.062369\n",
      "  Step 3, Current reward: 0.062369\n",
      "  Step 4, Current reward: 0.062369\n",
      "  Step 5, Current reward: 0.062369\n",
      "  Step 6, Current reward: 0.062369\n",
      "  Step 7, Current reward: 0.062369\n",
      "  Step 8, Current reward: 0.062369\n",
      "  Step 9, Current reward: 0.062369\n",
      "  Step 10, Current reward: 0.062369\n",
      "  Step 11, Current reward: 0.062369\n",
      "  Step 12, Current reward: 0.062369\n",
      "Episode 953/1000 complete - Max Reward: 0.062369\n",
      "Starting episode 954/1000\n",
      "  Step 1, Current reward: 0.024985\n",
      "  Step 2, Current reward: 0.024985\n",
      "  Step 3, Current reward: 0.024985\n",
      "  Step 4, Current reward: 0.024985\n",
      "  Step 5, Current reward: 0.024985\n",
      "  Step 6, Current reward: 0.024985\n",
      "  Step 7, Current reward: 0.024985\n",
      "  Step 8, Current reward: 0.024985\n",
      "  Step 9, Current reward: 0.024985\n",
      "  Step 10, Current reward: 0.024985\n",
      "  Step 11, Current reward: 0.024985\n",
      "  Step 12, Current reward: 0.024985\n",
      "Episode 954/1000 complete - Max Reward: 0.024985\n",
      "Starting episode 955/1000\n",
      "  Step 1, Current reward: 0.000189\n",
      "  Step 2, Current reward: 0.000189\n",
      "  Step 3, Current reward: 0.000189\n",
      "  Step 4, Current reward: 0.000189\n",
      "  Step 5, Current reward: 0.000189\n",
      "  Step 6, Current reward: 0.000189\n",
      "  Step 7, Current reward: 0.000189\n",
      "  Step 8, Current reward: 0.000189\n",
      "  Step 9, Current reward: 0.000189\n",
      "  Step 10, Current reward: 0.000189\n",
      "  Step 11, Current reward: 0.000189\n",
      "  Step 12, Current reward: 0.000189\n",
      "Episode 955/1000 complete - Max Reward: 0.000189\n",
      "Starting episode 956/1000\n",
      "  Step 1, Current reward: 0.279399\n",
      "  Step 2, Current reward: 0.279399\n",
      "  Step 3, Current reward: 0.279399\n",
      "  Step 4, Current reward: 0.279399\n",
      "  Step 5, Current reward: 0.279399\n",
      "  Step 6, Current reward: 0.279399\n",
      "  Step 7, Current reward: 0.279399\n",
      "  Step 8, Current reward: 0.279399\n",
      "  Step 9, Current reward: 0.279399\n",
      "  Step 10, Current reward: 0.279399\n",
      "  Step 11, Current reward: 0.279399\n",
      "  Step 12, Current reward: 0.279399\n",
      "Episode 956/1000 complete - Max Reward: 0.279399\n",
      "Starting episode 957/1000\n",
      "  Step 1, Current reward: 0.002045\n",
      "  Step 2, Current reward: 0.002045\n",
      "  Step 3, Current reward: 0.002045\n",
      "  Step 4, Current reward: 0.002045\n",
      "  Step 5, Current reward: 0.002045\n",
      "  Step 6, Current reward: 0.002045\n",
      "  Step 7, Current reward: 0.002045\n",
      "  Step 8, Current reward: 0.002045\n",
      "  Step 9, Current reward: 0.002045\n",
      "  Step 10, Current reward: 0.002045\n",
      "  Step 11, Current reward: 0.002045\n",
      "  Step 12, Current reward: 0.002045\n",
      "Episode 957/1000 complete - Max Reward: 0.002045\n",
      "Starting episode 958/1000\n",
      "  Step 1, Current reward: 0.029146\n",
      "  Step 2, Current reward: 0.029146\n",
      "  Step 3, Current reward: 0.029146\n",
      "  Step 4, Current reward: 0.029146\n",
      "  Step 5, Current reward: 0.029146\n",
      "  Step 6, Current reward: 0.029146\n",
      "  Step 7, Current reward: 0.029146\n",
      "  Step 8, Current reward: 0.029146\n",
      "  Step 9, Current reward: 0.029146\n",
      "  Step 10, Current reward: 0.029146\n",
      "  Step 11, Current reward: 0.029146\n",
      "  Step 12, Current reward: 0.029146\n",
      "Episode 958/1000 complete - Max Reward: 0.029146\n",
      "Starting episode 959/1000\n",
      "  Step 1, Current reward: 0.009973\n",
      "  Step 2, Current reward: 0.009973\n",
      "  Step 3, Current reward: 0.009973\n",
      "  Step 4, Current reward: 0.009973\n",
      "  Step 5, Current reward: 0.009973\n",
      "  Step 6, Current reward: 0.009973\n",
      "  Step 7, Current reward: 0.009973\n",
      "  Step 8, Current reward: 0.009973\n",
      "  Step 9, Current reward: 0.009973\n",
      "  Step 10, Current reward: 0.009973\n",
      "  Step 11, Current reward: 0.009973\n",
      "  Step 12, Current reward: 0.009973\n",
      "Episode 959/1000 complete - Max Reward: 0.009973\n",
      "Starting episode 960/1000\n",
      "  Step 1, Current reward: 0.002318\n",
      "  Step 2, Current reward: 0.002318\n",
      "  Step 3, Current reward: 0.002318\n",
      "  Step 4, Current reward: 0.002318\n",
      "  Step 5, Current reward: 0.002318\n",
      "  Step 6, Current reward: 0.002318\n",
      "  Step 7, Current reward: 0.002318\n",
      "  Step 8, Current reward: 0.002318\n",
      "  Step 9, Current reward: 0.002318\n",
      "  Step 10, Current reward: 0.002318\n",
      "  Step 11, Current reward: 0.002318\n",
      "  Step 12, Current reward: 0.002318\n",
      "Episode 960/1000 complete - Max Reward: 0.002318\n",
      "Starting episode 961/1000\n",
      "  Step 1, Current reward: 0.002825\n",
      "  Step 2, Current reward: 0.002825\n",
      "  Step 3, Current reward: 0.002825\n",
      "  Step 4, Current reward: 0.002825\n",
      "  Step 5, Current reward: 0.002825\n",
      "  Step 6, Current reward: 0.002825\n",
      "  Step 7, Current reward: 0.002825\n",
      "  Step 8, Current reward: 0.002825\n",
      "  Step 9, Current reward: 0.002825\n",
      "  Step 10, Current reward: 0.002825\n",
      "  Step 11, Current reward: 0.002825\n",
      "  Step 12, Current reward: 0.002825\n",
      "Episode 961/1000 complete - Max Reward: 0.002825\n",
      "Starting episode 962/1000\n",
      "  Step 1, Current reward: 0.021267\n",
      "  Step 2, Current reward: 0.021267\n",
      "  Step 3, Current reward: 0.021267\n",
      "  Step 4, Current reward: 0.021267\n",
      "  Step 5, Current reward: 0.021267\n",
      "  Step 6, Current reward: 0.021267\n",
      "  Step 7, Current reward: 0.021267\n",
      "  Step 8, Current reward: 0.021267\n",
      "  Step 9, Current reward: 0.021267\n",
      "  Step 10, Current reward: 0.021267\n",
      "  Step 11, Current reward: 0.021267\n",
      "  Step 12, Current reward: 0.021267\n",
      "Episode 962/1000 complete - Max Reward: 0.021267\n",
      "Starting episode 963/1000\n",
      "  Step 1, Current reward: 0.023870\n",
      "  Step 2, Current reward: 0.023870\n",
      "  Step 3, Current reward: 0.023870\n",
      "  Step 4, Current reward: 0.023870\n",
      "  Step 5, Current reward: 0.023870\n",
      "  Step 6, Current reward: 0.023870\n",
      "  Step 7, Current reward: 0.023870\n",
      "  Step 8, Current reward: 0.023870\n",
      "  Step 9, Current reward: 0.023870\n",
      "  Step 10, Current reward: 0.023870\n",
      "  Step 11, Current reward: 0.023870\n",
      "  Step 12, Current reward: 0.023870\n",
      "Episode 963/1000 complete - Max Reward: 0.023870\n",
      "Starting episode 964/1000\n",
      "  Step 1, Current reward: 0.000205\n",
      "  Step 2, Current reward: 0.000205\n",
      "  Step 3, Current reward: 0.000205\n",
      "  Step 4, Current reward: 0.000205\n",
      "  Step 5, Current reward: 0.000205\n",
      "  Step 6, Current reward: 0.000205\n",
      "  Step 7, Current reward: 0.000205\n",
      "  Step 8, Current reward: 0.000205\n",
      "  Step 9, Current reward: 0.000205\n",
      "  Step 10, Current reward: 0.000205\n",
      "  Step 11, Current reward: 0.000205\n",
      "  Step 12, Current reward: 0.000205\n",
      "Episode 964/1000 complete - Max Reward: 0.000205\n",
      "Starting episode 965/1000\n",
      "  Step 1, Current reward: 0.011113\n",
      "  Step 2, Current reward: 0.011113\n",
      "  Step 3, Current reward: 0.011113\n",
      "  Step 4, Current reward: 0.011113\n",
      "  Step 5, Current reward: 0.011113\n",
      "  Step 6, Current reward: 0.011113\n",
      "  Step 7, Current reward: 0.011113\n",
      "  Step 8, Current reward: 0.011113\n",
      "  Step 9, Current reward: 0.011113\n",
      "  Step 10, Current reward: 0.011113\n",
      "  Step 11, Current reward: 0.011113\n",
      "  Step 12, Current reward: 0.011113\n",
      "Episode 965/1000 complete - Max Reward: 0.011113\n",
      "Starting episode 966/1000\n",
      "  Step 1, Current reward: 0.011576\n",
      "  Step 2, Current reward: 0.011576\n",
      "  Step 3, Current reward: 0.011576\n",
      "  Step 4, Current reward: 0.011576\n",
      "  Step 5, Current reward: 0.011576\n",
      "  Step 6, Current reward: 0.011576\n",
      "  Step 7, Current reward: 0.011576\n",
      "  Step 8, Current reward: 0.011576\n",
      "  Step 9, Current reward: 0.011576\n",
      "  Step 10, Current reward: 0.011576\n",
      "  Step 11, Current reward: 0.011576\n",
      "  Step 12, Current reward: 0.011576\n",
      "Episode 966/1000 complete - Max Reward: 0.011576\n",
      "Starting episode 967/1000\n",
      "  Step 1, Current reward: 0.014299\n",
      "  Step 2, Current reward: 0.014299\n",
      "  Step 3, Current reward: 0.014299\n",
      "  Step 4, Current reward: 0.014299\n",
      "  Step 5, Current reward: 0.014299\n",
      "  Step 6, Current reward: 0.014299\n",
      "  Step 7, Current reward: 0.014299\n",
      "  Step 8, Current reward: 0.014299\n",
      "  Step 9, Current reward: 0.014299\n",
      "  Step 10, Current reward: 0.014299\n",
      "  Step 11, Current reward: 0.014299\n",
      "  Step 12, Current reward: 0.014299\n",
      "Episode 967/1000 complete - Max Reward: 0.014299\n",
      "Starting episode 968/1000\n",
      "  Step 1, Current reward: 0.040221\n",
      "  Step 2, Current reward: 0.040221\n",
      "  Step 3, Current reward: 0.040221\n",
      "  Step 4, Current reward: 0.040221\n",
      "  Step 5, Current reward: 0.040221\n",
      "  Step 6, Current reward: 0.040221\n",
      "  Step 7, Current reward: 0.040221\n",
      "  Step 8, Current reward: 0.040221\n",
      "  Step 9, Current reward: 0.040221\n",
      "  Step 10, Current reward: 0.040221\n",
      "  Step 11, Current reward: 0.040221\n",
      "  Step 12, Current reward: 0.040221\n",
      "Episode 968/1000 complete - Max Reward: 0.040221\n",
      "Starting episode 969/1000\n",
      "  Step 1, Current reward: 0.111337\n",
      "  Step 2, Current reward: 0.111337\n",
      "  Step 3, Current reward: 0.111337\n",
      "  Step 4, Current reward: 0.111337\n",
      "  Step 5, Current reward: 0.111337\n",
      "  Step 6, Current reward: 0.111337\n",
      "  Step 7, Current reward: 0.111337\n",
      "  Step 8, Current reward: 0.111337\n",
      "  Step 9, Current reward: 0.111337\n",
      "  Step 10, Current reward: 0.111337\n",
      "  Step 11, Current reward: 0.111337\n",
      "  Step 12, Current reward: 0.111337\n",
      "Episode 969/1000 complete - Max Reward: 0.111337\n",
      "Starting episode 970/1000\n",
      "  Step 1, Current reward: 0.012778\n",
      "  Step 2, Current reward: 0.012778\n",
      "  Step 3, Current reward: 0.012778\n",
      "  Step 4, Current reward: 0.012778\n",
      "  Step 5, Current reward: 0.012778\n",
      "  Step 6, Current reward: 0.012778\n",
      "  Step 7, Current reward: 0.012778\n",
      "  Step 8, Current reward: 0.012778\n",
      "  Step 9, Current reward: 0.012778\n",
      "  Step 10, Current reward: 0.012778\n",
      "  Step 11, Current reward: 0.012778\n",
      "  Step 12, Current reward: 0.012778\n",
      "Episode 970/1000 complete - Max Reward: 0.012778\n",
      "Starting episode 971/1000\n",
      "  Step 1, Current reward: 0.102704\n",
      "  Step 2, Current reward: 0.102704\n",
      "  Step 3, Current reward: 0.102704\n",
      "  Step 4, Current reward: 0.102704\n",
      "  Step 5, Current reward: 0.102704\n",
      "  Step 6, Current reward: 0.102704\n",
      "  Step 7, Current reward: 0.102704\n",
      "  Step 8, Current reward: 0.102704\n",
      "  Step 9, Current reward: 0.102704\n",
      "  Step 10, Current reward: 0.102704\n",
      "  Step 11, Current reward: 0.102704\n",
      "  Step 12, Current reward: 0.102704\n",
      "Episode 971/1000 complete - Max Reward: 0.102704\n",
      "Starting episode 972/1000\n",
      "  Step 1, Current reward: 0.033435\n",
      "  Step 2, Current reward: 0.033435\n",
      "  Step 3, Current reward: 0.033435\n",
      "  Step 4, Current reward: 0.033435\n",
      "  Step 5, Current reward: 0.033435\n",
      "  Step 6, Current reward: 0.033435\n",
      "  Step 7, Current reward: 0.033435\n",
      "  Step 8, Current reward: 0.033435\n",
      "  Step 9, Current reward: 0.033435\n",
      "  Step 10, Current reward: 0.033435\n",
      "  Step 11, Current reward: 0.033435\n",
      "  Step 12, Current reward: 0.033435\n",
      "Episode 972/1000 complete - Max Reward: 0.033435\n",
      "Starting episode 973/1000\n",
      "  Step 1, Current reward: 0.009544\n",
      "  Step 2, Current reward: 0.009544\n",
      "  Step 3, Current reward: 0.009544\n",
      "  Step 4, Current reward: 0.009544\n",
      "  Step 5, Current reward: 0.009544\n",
      "  Step 6, Current reward: 0.009544\n",
      "  Step 7, Current reward: 0.009544\n",
      "  Step 8, Current reward: 0.009544\n",
      "  Step 9, Current reward: 0.009544\n",
      "  Step 10, Current reward: 0.009544\n",
      "  Step 11, Current reward: 0.009544\n",
      "  Step 12, Current reward: 0.009544\n",
      "Episode 973/1000 complete - Max Reward: 0.009544\n",
      "Starting episode 974/1000\n",
      "  Step 1, Current reward: 0.022715\n",
      "  Step 2, Current reward: 0.022715\n",
      "  Step 3, Current reward: 0.022715\n",
      "  Step 4, Current reward: 0.022715\n",
      "  Step 5, Current reward: 0.022715\n",
      "  Step 6, Current reward: 0.022715\n",
      "  Step 7, Current reward: 0.022715\n",
      "  Step 8, Current reward: 0.022715\n",
      "  Step 9, Current reward: 0.022715\n",
      "  Step 10, Current reward: 0.022715\n",
      "  Step 11, Current reward: 0.022715\n",
      "  Step 12, Current reward: 0.022715\n",
      "Episode 974/1000 complete - Max Reward: 0.022715\n",
      "Starting episode 975/1000\n",
      "  Step 1, Current reward: 0.004775\n",
      "  Step 2, Current reward: 0.004775\n",
      "  Step 3, Current reward: 0.004775\n",
      "  Step 4, Current reward: 0.004775\n",
      "  Step 5, Current reward: 0.004775\n",
      "  Step 6, Current reward: 0.004775\n",
      "  Step 7, Current reward: 0.004775\n",
      "  Step 8, Current reward: 0.004775\n",
      "  Step 9, Current reward: 0.004775\n",
      "  Step 10, Current reward: 0.004775\n",
      "  Step 11, Current reward: 0.004775\n",
      "  Step 12, Current reward: 0.004775\n",
      "Episode 975/1000 complete - Max Reward: 0.004775\n",
      "Starting episode 976/1000\n",
      "  Step 1, Current reward: 0.000891\n",
      "  Step 2, Current reward: 0.000891\n",
      "  Step 3, Current reward: 0.000891\n",
      "  Step 4, Current reward: 0.000891\n",
      "  Step 5, Current reward: 0.000891\n",
      "  Step 6, Current reward: 0.000891\n",
      "  Step 7, Current reward: 0.000891\n",
      "  Step 8, Current reward: 0.000891\n",
      "  Step 9, Current reward: 0.000891\n",
      "  Step 10, Current reward: 0.000891\n",
      "  Step 11, Current reward: 0.000891\n",
      "  Step 12, Current reward: 0.000891\n",
      "Episode 976/1000 complete - Max Reward: 0.000891\n",
      "Starting episode 977/1000\n",
      "  Step 1, Current reward: 0.005623\n",
      "  Step 2, Current reward: 0.005623\n",
      "  Step 3, Current reward: 0.005623\n",
      "  Step 4, Current reward: 0.005623\n",
      "  Step 5, Current reward: 0.005623\n",
      "  Step 6, Current reward: 0.005623\n",
      "  Step 7, Current reward: 0.005623\n",
      "  Step 8, Current reward: 0.005623\n",
      "  Step 9, Current reward: 0.005623\n",
      "  Step 10, Current reward: 0.005623\n",
      "  Step 11, Current reward: 0.005623\n",
      "  Step 12, Current reward: 0.005623\n",
      "Episode 977/1000 complete - Max Reward: 0.005623\n",
      "Starting episode 978/1000\n",
      "  Step 1, Current reward: 0.023148\n",
      "  Step 2, Current reward: 0.023148\n",
      "  Step 3, Current reward: 0.023148\n",
      "  Step 4, Current reward: 0.023148\n",
      "  Step 5, Current reward: 0.023148\n",
      "  Step 6, Current reward: 0.023148\n",
      "  Step 7, Current reward: 0.023148\n",
      "  Step 8, Current reward: 0.023148\n",
      "  Step 9, Current reward: 0.023148\n",
      "  Step 10, Current reward: 0.023148\n",
      "  Step 11, Current reward: 0.023148\n",
      "  Step 12, Current reward: 0.023148\n",
      "Episode 978/1000 complete - Max Reward: 0.023148\n",
      "Starting episode 979/1000\n",
      "  Step 1, Current reward: 0.003944\n",
      "  Step 2, Current reward: 0.003944\n",
      "  Step 3, Current reward: 0.003944\n",
      "  Step 4, Current reward: 0.003944\n",
      "  Step 5, Current reward: 0.003944\n",
      "  Step 6, Current reward: 0.003944\n",
      "  Step 7, Current reward: 0.003944\n",
      "  Step 8, Current reward: 0.003944\n",
      "  Step 9, Current reward: 0.003944\n",
      "  Step 10, Current reward: 0.003944\n",
      "  Step 11, Current reward: 0.003944\n",
      "  Step 12, Current reward: 0.003944\n",
      "Episode 979/1000 complete - Max Reward: 0.003944\n",
      "Starting episode 980/1000\n",
      "  Step 1, Current reward: 0.003752\n",
      "  Step 2, Current reward: 0.003752\n",
      "  Step 3, Current reward: 0.003752\n",
      "  Step 4, Current reward: 0.003752\n",
      "  Step 5, Current reward: 0.003752\n",
      "  Step 6, Current reward: 0.003752\n",
      "  Step 7, Current reward: 0.003752\n",
      "  Step 8, Current reward: 0.003752\n",
      "  Step 9, Current reward: 0.003752\n",
      "  Step 10, Current reward: 0.003752\n",
      "  Step 11, Current reward: 0.003752\n",
      "  Step 12, Current reward: 0.003752\n",
      "Episode 980/1000 complete - Max Reward: 0.003752\n",
      "Starting episode 981/1000\n",
      "  Step 1, Current reward: 0.009545\n",
      "  Step 2, Current reward: 0.009545\n",
      "  Step 3, Current reward: 0.009545\n",
      "  Step 4, Current reward: 0.009545\n",
      "  Step 5, Current reward: 0.009545\n",
      "  Step 6, Current reward: 0.009545\n",
      "  Step 7, Current reward: 0.009545\n",
      "  Step 8, Current reward: 0.009545\n",
      "  Step 9, Current reward: 0.009545\n",
      "  Step 10, Current reward: 0.009545\n",
      "  Step 11, Current reward: 0.009545\n",
      "  Step 12, Current reward: 0.009545\n",
      "Episode 981/1000 complete - Max Reward: 0.009545\n",
      "Starting episode 982/1000\n",
      "  Step 1, Current reward: 0.009326\n",
      "  Step 2, Current reward: 0.009326\n",
      "  Step 3, Current reward: 0.009326\n",
      "  Step 4, Current reward: 0.009326\n",
      "  Step 5, Current reward: 0.009326\n",
      "  Step 6, Current reward: 0.009326\n",
      "  Step 7, Current reward: 0.009326\n",
      "  Step 8, Current reward: 0.009326\n",
      "  Step 9, Current reward: 0.009326\n",
      "  Step 10, Current reward: 0.009326\n",
      "  Step 11, Current reward: 0.009326\n",
      "  Step 12, Current reward: 0.009326\n",
      "Episode 982/1000 complete - Max Reward: 0.009326\n",
      "Starting episode 983/1000\n",
      "  Step 1, Current reward: 0.005414\n",
      "  Step 2, Current reward: 0.005414\n",
      "  Step 3, Current reward: 0.005414\n",
      "  Step 4, Current reward: 0.005414\n",
      "  Step 5, Current reward: 0.005414\n",
      "  Step 6, Current reward: 0.005414\n",
      "  Step 7, Current reward: 0.005414\n",
      "  Step 8, Current reward: 0.005414\n",
      "  Step 9, Current reward: 0.005414\n",
      "  Step 10, Current reward: 0.005414\n",
      "  Step 11, Current reward: 0.005414\n",
      "  Step 12, Current reward: 0.005414\n",
      "Episode 983/1000 complete - Max Reward: 0.005414\n",
      "Starting episode 984/1000\n",
      "  Step 1, Current reward: 0.117763\n",
      "  Step 2, Current reward: 0.117763\n",
      "  Step 3, Current reward: 0.117763\n",
      "  Step 4, Current reward: 0.117763\n",
      "  Step 5, Current reward: 0.117763\n",
      "  Step 6, Current reward: 0.117763\n",
      "  Step 7, Current reward: 0.117763\n",
      "  Step 8, Current reward: 0.117763\n",
      "  Step 9, Current reward: 0.117763\n",
      "  Step 10, Current reward: 0.117763\n",
      "  Step 11, Current reward: 0.117763\n",
      "  Step 12, Current reward: 0.117763\n",
      "Episode 984/1000 complete - Max Reward: 0.117763\n",
      "Starting episode 985/1000\n",
      "  Step 1, Current reward: 0.096279\n",
      "  Step 2, Current reward: 0.096279\n",
      "  Step 3, Current reward: 0.096279\n",
      "  Step 4, Current reward: 0.096279\n",
      "  Step 5, Current reward: 0.096279\n",
      "  Step 6, Current reward: 0.096279\n",
      "  Step 7, Current reward: 0.096279\n",
      "  Step 8, Current reward: 0.096279\n",
      "  Step 9, Current reward: 0.096279\n",
      "  Step 10, Current reward: 0.096279\n",
      "  Step 11, Current reward: 0.096279\n",
      "  Step 12, Current reward: 0.096279\n",
      "Episode 985/1000 complete - Max Reward: 0.096279\n",
      "Starting episode 986/1000\n",
      "  Step 1, Current reward: 0.019044\n",
      "  Step 2, Current reward: 0.019044\n",
      "  Step 3, Current reward: 0.019044\n",
      "  Step 4, Current reward: 0.019044\n",
      "  Step 5, Current reward: 0.019044\n",
      "  Step 6, Current reward: 0.019044\n",
      "  Step 7, Current reward: 0.019044\n",
      "  Step 8, Current reward: 0.019044\n",
      "  Step 9, Current reward: 0.019044\n",
      "  Step 10, Current reward: 0.019044\n",
      "  Step 11, Current reward: 0.019044\n",
      "  Step 12, Current reward: 0.019044\n",
      "Episode 986/1000 complete - Max Reward: 0.019044\n",
      "Starting episode 987/1000\n",
      "  Step 1, Current reward: 0.018250\n",
      "  Step 2, Current reward: 0.018250\n",
      "  Step 3, Current reward: 0.018250\n",
      "  Step 4, Current reward: 0.018250\n",
      "  Step 5, Current reward: 0.018250\n",
      "  Step 6, Current reward: 0.018250\n",
      "  Step 7, Current reward: 0.018250\n",
      "  Step 8, Current reward: 0.018250\n",
      "  Step 9, Current reward: 0.018250\n",
      "  Step 10, Current reward: 0.018250\n",
      "  Step 11, Current reward: 0.018250\n",
      "  Step 12, Current reward: 0.018250\n",
      "Episode 987/1000 complete - Max Reward: 0.018250\n",
      "Starting episode 988/1000\n",
      "  Step 1, Current reward: 0.007105\n",
      "  Step 2, Current reward: 0.007105\n",
      "  Step 3, Current reward: 0.007105\n",
      "  Step 4, Current reward: 0.007105\n",
      "  Step 5, Current reward: 0.007105\n",
      "  Step 6, Current reward: 0.007105\n",
      "  Step 7, Current reward: 0.007105\n",
      "  Step 8, Current reward: 0.007105\n",
      "  Step 9, Current reward: 0.007105\n",
      "  Step 10, Current reward: 0.007105\n",
      "  Step 11, Current reward: 0.007105\n",
      "  Step 12, Current reward: 0.007105\n",
      "Episode 988/1000 complete - Max Reward: 0.007105\n",
      "Starting episode 989/1000\n",
      "  Step 1, Current reward: 0.012113\n",
      "  Step 2, Current reward: 0.012113\n",
      "  Step 3, Current reward: 0.012113\n",
      "  Step 4, Current reward: 0.012113\n",
      "  Step 5, Current reward: 0.012113\n",
      "  Step 6, Current reward: 0.012113\n",
      "  Step 7, Current reward: 0.012113\n",
      "  Step 8, Current reward: 0.012113\n",
      "  Step 9, Current reward: 0.012113\n",
      "  Step 10, Current reward: 0.012113\n",
      "  Step 11, Current reward: 0.012113\n",
      "  Step 12, Current reward: 0.012113\n",
      "Episode 989/1000 complete - Max Reward: 0.012113\n",
      "Starting episode 990/1000\n",
      "  Step 1, Current reward: 0.019385\n",
      "  Step 2, Current reward: 0.019385\n",
      "  Step 3, Current reward: 0.019385\n",
      "  Step 4, Current reward: 0.019385\n",
      "  Step 5, Current reward: 0.019385\n",
      "  Step 6, Current reward: 0.019385\n",
      "  Step 7, Current reward: 0.019385\n",
      "  Step 8, Current reward: 0.019385\n",
      "  Step 9, Current reward: 0.019385\n",
      "  Step 10, Current reward: 0.019385\n",
      "  Step 11, Current reward: 0.019385\n",
      "  Step 12, Current reward: 0.019385\n",
      "Episode 990/1000 complete - Max Reward: 0.019385\n",
      "Starting episode 991/1000\n",
      "  Step 1, Current reward: 0.166818\n",
      "  Step 2, Current reward: 0.166818\n",
      "  Step 3, Current reward: 0.166818\n",
      "  Step 4, Current reward: 0.166818\n",
      "  Step 5, Current reward: 0.166818\n",
      "  Step 6, Current reward: 0.166818\n",
      "  Step 7, Current reward: 0.166818\n",
      "  Step 8, Current reward: 0.166818\n",
      "  Step 9, Current reward: 0.166818\n",
      "  Step 10, Current reward: 0.166818\n",
      "  Step 11, Current reward: 0.166818\n",
      "  Step 12, Current reward: 0.166818\n",
      "Episode 991/1000 complete - Max Reward: 0.166818\n",
      "Starting episode 992/1000\n",
      "  Step 1, Current reward: 0.064259\n",
      "  Step 2, Current reward: 0.064259\n",
      "  Step 3, Current reward: 0.064259\n",
      "  Step 4, Current reward: 0.064259\n",
      "  Step 5, Current reward: 0.064259\n",
      "  Step 6, Current reward: 0.064259\n",
      "  Step 7, Current reward: 0.064259\n",
      "  Step 8, Current reward: 0.064259\n",
      "  Step 9, Current reward: 0.064259\n",
      "  Step 10, Current reward: 0.064259\n",
      "  Step 11, Current reward: 0.064259\n",
      "  Step 12, Current reward: 0.064259\n",
      "Episode 992/1000 complete - Max Reward: 0.064259\n",
      "Starting episode 993/1000\n",
      "  Step 1, Current reward: 0.009945\n",
      "  Step 2, Current reward: 0.009945\n",
      "  Step 3, Current reward: 0.009945\n",
      "  Step 4, Current reward: 0.009945\n",
      "  Step 5, Current reward: 0.009945\n",
      "  Step 6, Current reward: 0.009945\n",
      "  Step 7, Current reward: 0.009945\n",
      "  Step 8, Current reward: 0.009945\n",
      "  Step 9, Current reward: 0.009945\n",
      "  Step 10, Current reward: 0.009945\n",
      "  Step 11, Current reward: 0.009945\n",
      "  Step 12, Current reward: 0.009945\n",
      "Episode 993/1000 complete - Max Reward: 0.009945\n",
      "Starting episode 994/1000\n",
      "  Step 1, Current reward: 0.010009\n",
      "  Step 2, Current reward: 0.010009\n",
      "  Step 3, Current reward: 0.010009\n",
      "  Step 4, Current reward: 0.010009\n",
      "  Step 5, Current reward: 0.010009\n",
      "  Step 6, Current reward: 0.010009\n",
      "  Step 7, Current reward: 0.010009\n",
      "  Step 8, Current reward: 0.010009\n",
      "  Step 9, Current reward: 0.010009\n",
      "  Step 10, Current reward: 0.010009\n",
      "  Step 11, Current reward: 0.010009\n",
      "  Step 12, Current reward: 0.010009\n",
      "Episode 994/1000 complete - Max Reward: 0.010009\n",
      "Starting episode 995/1000\n",
      "  Step 1, Current reward: 0.000376\n",
      "  Step 2, Current reward: 0.000376\n",
      "  Step 3, Current reward: 0.000376\n",
      "  Step 4, Current reward: 0.000376\n",
      "  Step 5, Current reward: 0.000376\n",
      "  Step 6, Current reward: 0.000376\n",
      "  Step 7, Current reward: 0.000376\n",
      "  Step 8, Current reward: 0.000376\n",
      "  Step 9, Current reward: 0.000376\n",
      "  Step 10, Current reward: 0.000376\n",
      "  Step 11, Current reward: 0.000376\n",
      "  Step 12, Current reward: 0.000376\n",
      "Episode 995/1000 complete - Max Reward: 0.000376\n",
      "Starting episode 996/1000\n",
      "  Step 1, Current reward: 0.010148\n",
      "  Step 2, Current reward: 0.010148\n",
      "  Step 3, Current reward: 0.010148\n",
      "  Step 4, Current reward: 0.010148\n",
      "  Step 5, Current reward: 0.010148\n",
      "  Step 6, Current reward: 0.010148\n",
      "  Step 7, Current reward: 0.010148\n",
      "  Step 8, Current reward: 0.010148\n",
      "  Step 9, Current reward: 0.010148\n",
      "  Step 10, Current reward: 0.010148\n",
      "  Step 11, Current reward: 0.010148\n",
      "  Step 12, Current reward: 0.010148\n",
      "Episode 996/1000 complete - Max Reward: 0.010148\n",
      "Starting episode 997/1000\n",
      "  Step 1, Current reward: 0.009182\n",
      "  Step 2, Current reward: 0.009182\n",
      "  Step 3, Current reward: 0.009182\n",
      "  Step 4, Current reward: 0.009182\n",
      "  Step 5, Current reward: 0.009182\n",
      "  Step 6, Current reward: 0.009182\n",
      "  Step 7, Current reward: 0.009182\n",
      "  Step 8, Current reward: 0.009182\n",
      "  Step 9, Current reward: 0.009182\n",
      "  Step 10, Current reward: 0.009182\n",
      "  Step 11, Current reward: 0.009182\n",
      "  Step 12, Current reward: 0.009182\n",
      "Episode 997/1000 complete - Max Reward: 0.009182\n",
      "Starting episode 998/1000\n",
      "  Step 1, Current reward: 0.025957\n",
      "  Step 2, Current reward: 0.025221\n",
      "  Step 3, Current reward: 0.025221\n",
      "  Step 4, Current reward: 0.025221\n",
      "  Step 5, Current reward: 0.025221\n",
      "  Step 6, Current reward: 0.025221\n",
      "  Step 7, Current reward: 0.025221\n",
      "  Step 8, Current reward: 0.025221\n",
      "  Step 9, Current reward: 0.025221\n",
      "  Step 10, Current reward: 0.025221\n",
      "  Step 11, Current reward: 0.025221\n",
      "  Step 12, Current reward: 0.025221\n",
      "Episode 998/1000 complete - Max Reward: 0.025957\n",
      "Starting episode 999/1000\n",
      "  Step 1, Current reward: 0.008591\n",
      "  Step 2, Current reward: 0.008591\n",
      "  Step 3, Current reward: 0.008591\n",
      "  Step 4, Current reward: 0.008591\n",
      "  Step 5, Current reward: 0.008591\n",
      "  Step 6, Current reward: 0.008591\n",
      "  Step 7, Current reward: 0.008591\n",
      "  Step 8, Current reward: 0.008591\n",
      "  Step 9, Current reward: 0.008591\n",
      "  Step 10, Current reward: 0.008591\n",
      "  Step 11, Current reward: 0.008591\n",
      "  Step 12, Current reward: 0.008591\n",
      "Episode 999/1000 complete - Max Reward: 0.008591\n",
      "Starting episode 1000/1000\n",
      "  Step 1, Current reward: 0.015681\n",
      "  Step 2, Current reward: 0.015681\n",
      "  Step 3, Current reward: 0.015681\n",
      "  Step 4, Current reward: 0.015681\n",
      "  Step 5, Current reward: 0.015681\n",
      "  Step 6, Current reward: 0.015681\n",
      "  Step 7, Current reward: 0.015681\n",
      "  Step 8, Current reward: 0.015681\n",
      "  Step 9, Current reward: 0.015681\n",
      "  Step 10, Current reward: 0.015681\n",
      "  Step 11, Current reward: 0.015681\n",
      "  Step 12, Current reward: 0.015681\n",
      "Episode 1000/1000 complete - Max Reward: 0.015681\n"
     ]
    }
   ],
   "source": [
    "adr_all_ep_rewards, adr_best_rewards, adr_optimal_states_all = adv_dqn.evaluate(num_episodes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739bff2e-655a-4b8c-8c50-e054469b6fc3",
   "metadata": {},
   "source": [
    "## Burgers Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c61e0b5-fdd0-43ce-a37a-c9dfeb8b2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = None\n",
    "ib_config = Burgers2DConfig()\n",
    "ib_eq = Burgers2D(ib_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c92c7ba9-a4ca-49e3-9cd2-e73401b7c899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "gym_config = OEDGymConfig()\n",
    "gym_config.n_sensor = 10\n",
    "gym_config.n_components_rewards = 4\n",
    "ib_dqn = DQN_OED(seed, pde_system=ib_eq, gym_config=gym_config, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "647dc2fd-2683-4db2-b4d1-f0366bcbba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tensorboard/DQN_27\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 0.455    |\n",
      "|    exploration_rate | 0.588    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2171     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00067  |\n",
      "|    n_updates        | 517      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 0.277    |\n",
      "|    exploration_rate | 0.143    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 841      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 4510     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000478 |\n",
      "|    n_updates        | 1102     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | 0.188    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 803      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 6159     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000783 |\n",
      "|    n_updates        | 1514     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 0.3      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 775      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 8071     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000278 |\n",
      "|    n_updates        | 1992     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | 0.18     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 765      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 9782     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000515 |\n",
      "|    n_updates        | 2420     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 0.306    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 754      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 11774    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000437 |\n",
      "|    n_updates        | 2918     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 0.283    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 744      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 13533    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0003   |\n",
      "|    n_updates        | 3358     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | 0.261    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 736      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 15253    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 3788     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | 0.264    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 735      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 16981    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000571 |\n",
      "|    n_updates        | 4220     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | 0.324    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 734      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 18712    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000829 |\n",
      "|    n_updates        | 4652     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 0.248    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 733      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 20616    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 5128     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 0.334    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 732      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 22583    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 5620     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 0.271    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 731      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 24610    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000953 |\n",
      "|    n_updates        | 6127     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 0.141    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 731      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 26250    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00056  |\n",
      "|    n_updates        | 6537     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 0.227    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 731      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 28152    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000319 |\n",
      "|    n_updates        | 7012     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 0.297    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 729      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 30010    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000661 |\n",
      "|    n_updates        | 7477     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | 0.225    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 729      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 31856    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 7938     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 0.319    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 729      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 33877    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000959 |\n",
      "|    n_updates        | 8444     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 0.269    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 729      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 35669    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00092  |\n",
      "|    n_updates        | 8892     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.4     |\n",
      "|    ep_rew_mean      | 0.293    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 721      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 37505    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000169 |\n",
      "|    n_updates        | 9351     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 0.229    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 39311    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000719 |\n",
      "|    n_updates        | 9802     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 0.359    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 41169    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 10267    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 0.186    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 721      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 42978    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 10719    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 0.263    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 721      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 44914    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000545 |\n",
      "|    n_updates        | 11203    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 0.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 722      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 46812    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000583 |\n",
      "|    n_updates        | 11677    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 0.335    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 722      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 48825    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000704 |\n",
      "|    n_updates        | 12181    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ib_dqn_1\"\n",
    "ib_dqn.train(model_name, total_timesteps=50000, log_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d2a08f4-ca83-45d3-8327-158c3e452912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode 1/100\n",
      "  Step 1, Current reward: 0.038457\n",
      "  Step 2, Current reward: 0.040669\n",
      "  Step 3, Current reward: 0.051874\n",
      "  Step 4, Current reward: 0.064399\n",
      "  Step 5, Current reward: 0.075063\n",
      "  Step 6, Current reward: 0.082071\n",
      "  Step 7, Current reward: 0.084809\n",
      "  Step 8, Current reward: 0.082127\n",
      "  Step 9, Current reward: 0.080818\n",
      "  Step 10, Current reward: 0.076626\n",
      "  Step 11, Current reward: 0.091957\n",
      "  Step 12, Current reward: 0.125208\n",
      "  Step 13, Current reward: 0.116829\n",
      "  Step 14, Current reward: 0.107123\n",
      "  Step 15, Current reward: 0.097632\n",
      "  Step 16, Current reward: 0.089347\n",
      "  Step 17, Current reward: 0.089347\n",
      "  Step 18, Current reward: 0.089347\n",
      "  Step 19, Current reward: 0.089347\n",
      "  Step 20, Current reward: 0.089347\n",
      "  Step 21, Current reward: 0.089347\n",
      "  Step 22, Current reward: 0.089347\n",
      "  Step 23, Current reward: 0.089347\n",
      "Episode 1/100 complete - Max Reward: 0.125208\n",
      "Starting episode 2/100\n",
      "  Step 1, Current reward: 0.000622\n",
      "  Step 2, Current reward: 0.000622\n",
      "  Step 3, Current reward: 0.000622\n",
      "  Step 4, Current reward: 0.000622\n",
      "  Step 5, Current reward: 0.000622\n",
      "  Step 6, Current reward: 0.000622\n",
      "  Step 7, Current reward: 0.000622\n",
      "  Step 8, Current reward: 0.000622\n",
      "  Step 9, Current reward: 0.000622\n",
      "  Step 10, Current reward: 0.000622\n",
      "  Step 11, Current reward: 0.000622\n",
      "  Step 12, Current reward: 0.000622\n",
      "Episode 2/100 complete - Max Reward: 0.000622\n",
      "Starting episode 3/100\n",
      "  Step 1, Current reward: 0.002217\n",
      "  Step 2, Current reward: 0.002163\n",
      "  Step 3, Current reward: 0.002077\n",
      "  Step 4, Current reward: 0.002058\n",
      "  Step 5, Current reward: 0.002038\n",
      "  Step 6, Current reward: 0.002017\n",
      "  Step 7, Current reward: 0.001998\n",
      "  Step 8, Current reward: 0.001978\n",
      "  Step 9, Current reward: 0.001956\n",
      "  Step 10, Current reward: 0.001890\n",
      "  Step 11, Current reward: 0.001747\n",
      "  Step 12, Current reward: 0.001407\n",
      "Episode 3/100 complete - Max Reward: 0.002217\n",
      "Starting episode 4/100\n",
      "  Step 1, Current reward: 0.016152\n",
      "  Step 2, Current reward: 0.015039\n",
      "  Step 3, Current reward: 0.015378\n",
      "  Step 4, Current reward: 0.015676\n",
      "  Step 5, Current reward: 0.015926\n",
      "  Step 6, Current reward: 0.016639\n",
      "  Step 7, Current reward: 0.020413\n",
      "  Step 8, Current reward: 0.028009\n",
      "  Step 9, Current reward: 0.039403\n",
      "  Step 10, Current reward: 0.053407\n",
      "  Step 11, Current reward: 0.067517\n",
      "  Step 12, Current reward: 0.078284\n",
      "  Step 13, Current reward: 0.082280\n",
      "  Step 14, Current reward: 0.077420\n",
      "  Step 15, Current reward: 0.073331\n",
      "  Step 16, Current reward: 0.068347\n",
      "  Step 17, Current reward: 0.062817\n",
      "  Step 18, Current reward: 0.051627\n",
      "  Step 19, Current reward: 0.036297\n",
      "  Step 20, Current reward: 0.020970\n",
      "  Step 21, Current reward: 0.009970\n",
      "  Step 22, Current reward: 0.006079\n",
      "  Step 23, Current reward: 0.006058\n",
      "  Step 24, Current reward: 0.005809\n",
      "Episode 4/100 complete - Max Reward: 0.082280\n",
      "Starting episode 5/100\n",
      "  Step 1, Current reward: 0.006393\n",
      "  Step 2, Current reward: 0.005804\n",
      "  Step 3, Current reward: 0.005301\n",
      "  Step 4, Current reward: 0.004876\n",
      "  Step 5, Current reward: 0.004520\n",
      "  Step 6, Current reward: 0.004227\n",
      "  Step 7, Current reward: 0.003986\n",
      "  Step 8, Current reward: 0.004625\n",
      "  Step 9, Current reward: 0.004611\n",
      "  Step 10, Current reward: 0.004521\n",
      "  Step 11, Current reward: 0.003689\n",
      "  Step 12, Current reward: 0.003509\n",
      "Episode 5/100 complete - Max Reward: 0.006393\n",
      "Starting episode 6/100\n",
      "  Step 1, Current reward: 0.001166\n",
      "  Step 2, Current reward: 0.001219\n",
      "  Step 3, Current reward: 0.001109\n",
      "  Step 4, Current reward: 0.001412\n",
      "  Step 5, Current reward: 0.001232\n",
      "  Step 6, Current reward: 0.000862\n",
      "  Step 7, Current reward: 0.000687\n",
      "  Step 8, Current reward: 0.000698\n",
      "  Step 9, Current reward: 0.000687\n",
      "  Step 10, Current reward: 0.000671\n",
      "  Step 11, Current reward: 0.000650\n",
      "  Step 12, Current reward: 0.000627\n",
      "  Step 13, Current reward: 0.000601\n",
      "  Step 14, Current reward: 0.000575\n",
      "  Step 15, Current reward: 0.000545\n",
      "Episode 6/100 complete - Max Reward: 0.001412\n",
      "Starting episode 7/100\n",
      "  Step 1, Current reward: 0.002117\n",
      "  Step 2, Current reward: 0.002041\n",
      "  Step 3, Current reward: 0.001972\n",
      "  Step 4, Current reward: 0.001914\n",
      "  Step 5, Current reward: 0.001659\n",
      "  Step 6, Current reward: 0.001452\n",
      "  Step 7, Current reward: 0.001414\n",
      "  Step 8, Current reward: 0.003219\n",
      "  Step 9, Current reward: 0.006930\n",
      "  Step 10, Current reward: 0.011930\n",
      "  Step 11, Current reward: 0.017113\n",
      "  Step 12, Current reward: 0.021303\n",
      "  Step 13, Current reward: 0.023636\n",
      "  Step 14, Current reward: 0.023737\n",
      "  Step 15, Current reward: 0.021728\n",
      "  Step 16, Current reward: 0.018337\n",
      "  Step 17, Current reward: 0.014305\n",
      "  Step 18, Current reward: 0.020798\n",
      "  Step 19, Current reward: 0.020798\n",
      "  Step 20, Current reward: 0.020798\n",
      "  Step 21, Current reward: 0.020798\n",
      "  Step 22, Current reward: 0.020798\n",
      "  Step 23, Current reward: 0.020798\n",
      "  Step 24, Current reward: 0.020798\n",
      "  Step 25, Current reward: 0.020798\n",
      "Episode 7/100 complete - Max Reward: 0.023737\n",
      "Starting episode 8/100\n",
      "  Step 1, Current reward: 0.078661\n",
      "  Step 2, Current reward: 0.079948\n",
      "  Step 3, Current reward: 0.080417\n",
      "  Step 4, Current reward: 0.079814\n",
      "  Step 5, Current reward: 0.079814\n",
      "  Step 6, Current reward: 0.079814\n",
      "  Step 7, Current reward: 0.079814\n",
      "  Step 8, Current reward: 0.079814\n",
      "  Step 9, Current reward: 0.079814\n",
      "  Step 10, Current reward: 0.079814\n",
      "  Step 11, Current reward: 0.079814\n",
      "  Step 12, Current reward: 0.079814\n",
      "  Step 13, Current reward: 0.079814\n",
      "  Step 14, Current reward: 0.079814\n",
      "Episode 8/100 complete - Max Reward: 0.080417\n",
      "Starting episode 9/100\n",
      "  Step 1, Current reward: 0.031805\n",
      "  Step 2, Current reward: 0.031805\n",
      "  Step 3, Current reward: 0.031805\n",
      "  Step 4, Current reward: 0.031805\n",
      "  Step 5, Current reward: 0.031805\n",
      "  Step 6, Current reward: 0.031805\n",
      "  Step 7, Current reward: 0.031805\n",
      "  Step 8, Current reward: 0.031805\n",
      "  Step 9, Current reward: 0.031805\n",
      "  Step 10, Current reward: 0.031805\n",
      "  Step 11, Current reward: 0.031805\n",
      "  Step 12, Current reward: 0.031805\n",
      "Episode 9/100 complete - Max Reward: 0.031805\n",
      "Starting episode 10/100\n",
      "  Step 1, Current reward: 0.001282\n",
      "  Step 2, Current reward: 0.001428\n",
      "  Step 3, Current reward: 0.001579\n",
      "  Step 4, Current reward: 0.001728\n",
      "  Step 5, Current reward: 0.001868\n",
      "  Step 6, Current reward: 0.001990\n",
      "  Step 7, Current reward: 0.002083\n",
      "  Step 8, Current reward: 0.002134\n",
      "  Step 9, Current reward: 0.002133\n",
      "  Step 10, Current reward: 0.002071\n",
      "  Step 11, Current reward: 0.001945\n",
      "  Step 12, Current reward: 0.001755\n",
      "  Step 13, Current reward: 0.001503\n",
      "  Step 14, Current reward: 0.001200\n",
      "  Step 15, Current reward: 0.000877\n",
      "  Step 16, Current reward: 0.000595\n",
      "  Step 17, Current reward: 0.000429\n",
      "  Step 18, Current reward: 0.000449\n",
      "  Step 19, Current reward: 0.000449\n",
      "Episode 10/100 complete - Max Reward: 0.002134\n",
      "Starting episode 11/100\n",
      "  Step 1, Current reward: 0.090516\n",
      "  Step 2, Current reward: 0.091687\n",
      "  Step 3, Current reward: 0.089424\n",
      "  Step 4, Current reward: 0.102881\n",
      "  Step 5, Current reward: 0.118542\n",
      "  Step 6, Current reward: 0.134824\n",
      "  Step 7, Current reward: 0.150488\n",
      "  Step 8, Current reward: 0.134824\n",
      "  Step 9, Current reward: 0.150488\n",
      "  Step 10, Current reward: 0.134824\n",
      "  Step 11, Current reward: 0.150488\n",
      "  Step 12, Current reward: 0.134824\n",
      "  Step 13, Current reward: 0.150488\n",
      "  Step 14, Current reward: 0.134824\n",
      "  Step 15, Current reward: 0.150488\n",
      "  Step 16, Current reward: 0.134824\n",
      "  Step 17, Current reward: 0.150488\n",
      "  Step 18, Current reward: 0.134824\n",
      "Episode 11/100 complete - Max Reward: 0.150488\n",
      "Starting episode 12/100\n",
      "  Step 1, Current reward: 0.005351\n",
      "  Step 2, Current reward: 0.005351\n",
      "  Step 3, Current reward: 0.005351\n",
      "  Step 4, Current reward: 0.005351\n",
      "  Step 5, Current reward: 0.005351\n",
      "  Step 6, Current reward: 0.005351\n",
      "  Step 7, Current reward: 0.005351\n",
      "  Step 8, Current reward: 0.005351\n",
      "  Step 9, Current reward: 0.005351\n",
      "  Step 10, Current reward: 0.005351\n",
      "  Step 11, Current reward: 0.005351\n",
      "  Step 12, Current reward: 0.005351\n",
      "Episode 12/100 complete - Max Reward: 0.005351\n",
      "Starting episode 13/100\n",
      "  Step 1, Current reward: 0.004636\n",
      "  Step 2, Current reward: 0.003978\n",
      "  Step 3, Current reward: 0.004591\n",
      "  Step 4, Current reward: 0.004893\n",
      "  Step 5, Current reward: 0.005027\n",
      "  Step 6, Current reward: 0.005873\n",
      "  Step 7, Current reward: 0.005894\n",
      "  Step 8, Current reward: 0.005684\n",
      "  Step 9, Current reward: 0.005275\n",
      "  Step 10, Current reward: 0.004774\n",
      "  Step 11, Current reward: 0.005548\n",
      "  Step 12, Current reward: 0.006466\n",
      "  Step 13, Current reward: 0.007537\n",
      "  Step 14, Current reward: 0.006796\n",
      "  Step 15, Current reward: 0.006021\n",
      "  Step 16, Current reward: 0.005250\n",
      "  Step 17, Current reward: 0.004521\n",
      "  Step 18, Current reward: 0.005296\n",
      "  Step 19, Current reward: 0.004526\n",
      "  Step 20, Current reward: 0.003855\n",
      "  Step 21, Current reward: 0.004523\n",
      "  Step 22, Current reward: 0.003847\n",
      "  Step 23, Current reward: 0.003284\n",
      "  Step 24, Current reward: 0.003215\n",
      "Episode 13/100 complete - Max Reward: 0.007537\n",
      "Starting episode 14/100\n",
      "  Step 1, Current reward: 0.001985\n",
      "  Step 2, Current reward: 0.002291\n",
      "  Step 3, Current reward: 0.002608\n",
      "  Step 4, Current reward: 0.002918\n",
      "  Step 5, Current reward: 0.003220\n",
      "  Step 6, Current reward: 0.003523\n",
      "  Step 7, Current reward: 0.003842\n",
      "  Step 8, Current reward: 0.001251\n",
      "  Step 9, Current reward: 0.001279\n",
      "  Step 10, Current reward: 0.001410\n",
      "  Step 11, Current reward: 0.001278\n",
      "  Step 12, Current reward: 0.000786\n",
      "  Step 13, Current reward: 0.000401\n",
      "  Step 14, Current reward: 0.000359\n",
      "  Step 15, Current reward: 0.000381\n",
      "  Step 16, Current reward: 0.000392\n",
      "  Step 17, Current reward: 0.000401\n",
      "  Step 18, Current reward: 0.000412\n",
      "Episode 14/100 complete - Max Reward: 0.003842\n",
      "Starting episode 15/100\n",
      "  Step 1, Current reward: 0.009616\n",
      "  Step 2, Current reward: 0.011075\n",
      "  Step 3, Current reward: 0.012327\n",
      "  Step 4, Current reward: 0.009692\n",
      "  Step 5, Current reward: 0.008859\n",
      "  Step 6, Current reward: 0.007832\n",
      "  Step 7, Current reward: 0.007973\n",
      "  Step 8, Current reward: 0.010156\n",
      "  Step 9, Current reward: 0.013118\n",
      "  Step 10, Current reward: 0.014110\n",
      "  Step 11, Current reward: 0.013935\n",
      "  Step 12, Current reward: 0.012506\n",
      "  Step 13, Current reward: 0.013461\n",
      "  Step 14, Current reward: 0.014458\n",
      "  Step 15, Current reward: 0.015507\n",
      "  Step 16, Current reward: 0.018263\n",
      "  Step 17, Current reward: 0.018448\n",
      "  Step 18, Current reward: 0.018630\n",
      "  Step 19, Current reward: 0.018804\n",
      "  Step 20, Current reward: 0.018967\n",
      "  Step 21, Current reward: 0.019116\n",
      "  Step 22, Current reward: 0.019248\n",
      "  Step 23, Current reward: 0.019359\n",
      "  Step 24, Current reward: 0.019447\n",
      "  Step 25, Current reward: 0.019509\n",
      "  Step 26, Current reward: 0.019544\n",
      "  Step 27, Current reward: 0.019549\n",
      "  Step 28, Current reward: 0.019522\n",
      "  Step 29, Current reward: 0.019465\n",
      "  Step 30, Current reward: 0.019376\n",
      "  Step 31, Current reward: 0.019253\n",
      "  Step 32, Current reward: 0.019095\n",
      "  Step 33, Current reward: 0.018911\n",
      "  Step 34, Current reward: 0.018713\n",
      "  Step 35, Current reward: 0.018501\n",
      "  Step 36, Current reward: 0.018258\n",
      "  Step 37, Current reward: 0.017979\n",
      "  Step 38, Current reward: 0.014978\n",
      "Episode 15/100 complete - Max Reward: 0.019549\n",
      "Starting episode 16/100\n",
      "  Step 1, Current reward: 0.003291\n",
      "  Step 2, Current reward: 0.003432\n",
      "  Step 3, Current reward: 0.003600\n",
      "  Step 4, Current reward: 0.003801\n",
      "  Step 5, Current reward: 0.003610\n",
      "  Step 6, Current reward: 0.003462\n",
      "  Step 7, Current reward: 0.003346\n",
      "  Step 8, Current reward: 0.003583\n",
      "  Step 9, Current reward: 0.003865\n",
      "  Step 10, Current reward: 0.004197\n",
      "  Step 11, Current reward: 0.004582\n",
      "  Step 12, Current reward: 0.005022\n",
      "  Step 13, Current reward: 0.005515\n",
      "  Step 14, Current reward: 0.006055\n",
      "  Step 15, Current reward: 0.005962\n",
      "  Step 16, Current reward: 0.005865\n",
      "  Step 17, Current reward: 0.005971\n",
      "  Step 18, Current reward: 0.006127\n",
      "  Step 19, Current reward: 0.006322\n",
      "  Step 20, Current reward: 0.006539\n",
      "  Step 21, Current reward: 0.006767\n",
      "  Step 22, Current reward: 0.007003\n",
      "  Step 23, Current reward: 0.007249\n",
      "  Step 24, Current reward: 0.007507\n",
      "  Step 25, Current reward: 0.007781\n",
      "  Step 26, Current reward: 0.008072\n",
      "  Step 27, Current reward: 0.008167\n",
      "  Step 28, Current reward: 0.008862\n",
      "  Step 29, Current reward: 0.009568\n",
      "  Step 30, Current reward: 0.009975\n",
      "  Step 31, Current reward: 0.010955\n",
      "  Step 32, Current reward: 0.011962\n",
      "  Step 33, Current reward: 0.012952\n",
      "  Step 34, Current reward: 0.013863\n",
      "  Step 35, Current reward: 0.014624\n",
      "  Step 36, Current reward: 0.015160\n",
      "  Step 37, Current reward: 0.015402\n",
      "  Step 38, Current reward: 0.015293\n",
      "  Step 39, Current reward: 0.014773\n",
      "  Step 40, Current reward: 0.013787\n",
      "  Step 41, Current reward: 0.012316\n",
      "  Step 42, Current reward: 0.010448\n",
      "  Step 43, Current reward: 0.008423\n",
      "  Step 44, Current reward: 0.006606\n",
      "  Step 45, Current reward: 0.005479\n",
      "  Step 46, Current reward: 0.005479\n",
      "  Step 47, Current reward: 0.005479\n",
      "  Step 48, Current reward: 0.005479\n",
      "Episode 16/100 complete - Max Reward: 0.015402\n",
      "Starting episode 17/100\n",
      "  Step 1, Current reward: 0.052873\n",
      "  Step 2, Current reward: 0.052873\n",
      "  Step 3, Current reward: 0.052873\n",
      "  Step 4, Current reward: 0.052873\n",
      "  Step 5, Current reward: 0.052873\n",
      "  Step 6, Current reward: 0.052873\n",
      "  Step 7, Current reward: 0.052873\n",
      "  Step 8, Current reward: 0.052873\n",
      "  Step 9, Current reward: 0.052873\n",
      "  Step 10, Current reward: 0.052873\n",
      "  Step 11, Current reward: 0.052873\n",
      "  Step 12, Current reward: 0.052873\n",
      "Episode 17/100 complete - Max Reward: 0.052873\n",
      "Starting episode 18/100\n",
      "  Step 1, Current reward: 0.001612\n",
      "  Step 2, Current reward: 0.001634\n",
      "  Step 3, Current reward: 0.001648\n",
      "  Step 4, Current reward: 0.001660\n",
      "  Step 5, Current reward: 0.001660\n",
      "  Step 6, Current reward: 0.001632\n",
      "  Step 7, Current reward: 0.001597\n",
      "  Step 8, Current reward: 0.001511\n",
      "  Step 9, Current reward: 0.001416\n",
      "  Step 10, Current reward: 0.001416\n",
      "  Step 11, Current reward: 0.001416\n",
      "  Step 12, Current reward: 0.001416\n",
      "  Step 13, Current reward: 0.001416\n",
      "  Step 14, Current reward: 0.001416\n",
      "  Step 15, Current reward: 0.001416\n",
      "Episode 18/100 complete - Max Reward: 0.001660\n",
      "Starting episode 19/100\n",
      "  Step 1, Current reward: 0.007761\n",
      "  Step 2, Current reward: 0.007761\n",
      "  Step 3, Current reward: 0.007761\n",
      "  Step 4, Current reward: 0.007761\n",
      "  Step 5, Current reward: 0.007761\n",
      "  Step 6, Current reward: 0.007761\n",
      "  Step 7, Current reward: 0.007761\n",
      "  Step 8, Current reward: 0.007761\n",
      "  Step 9, Current reward: 0.007761\n",
      "  Step 10, Current reward: 0.007761\n",
      "  Step 11, Current reward: 0.007761\n",
      "  Step 12, Current reward: 0.007761\n",
      "Episode 19/100 complete - Max Reward: 0.007761\n",
      "Starting episode 20/100\n",
      "  Step 1, Current reward: 0.002150\n",
      "  Step 2, Current reward: 0.002250\n",
      "  Step 3, Current reward: 0.002451\n",
      "  Step 4, Current reward: 0.002505\n",
      "  Step 5, Current reward: 0.002376\n",
      "  Step 6, Current reward: 0.002249\n",
      "  Step 7, Current reward: 0.002249\n",
      "  Step 8, Current reward: 0.002249\n",
      "  Step 9, Current reward: 0.002249\n",
      "  Step 10, Current reward: 0.002249\n",
      "  Step 11, Current reward: 0.002249\n",
      "  Step 12, Current reward: 0.002249\n",
      "  Step 13, Current reward: 0.002249\n",
      "  Step 14, Current reward: 0.002249\n",
      "  Step 15, Current reward: 0.002249\n",
      "Episode 20/100 complete - Max Reward: 0.002505\n",
      "Starting episode 21/100\n",
      "  Step 1, Current reward: 0.003068\n",
      "  Step 2, Current reward: 0.003068\n",
      "  Step 3, Current reward: 0.003068\n",
      "  Step 4, Current reward: 0.003068\n",
      "  Step 5, Current reward: 0.003068\n",
      "  Step 6, Current reward: 0.003068\n",
      "  Step 7, Current reward: 0.003068\n",
      "  Step 8, Current reward: 0.003068\n",
      "  Step 9, Current reward: 0.003068\n",
      "  Step 10, Current reward: 0.003068\n",
      "  Step 11, Current reward: 0.003068\n",
      "  Step 12, Current reward: 0.003068\n",
      "Episode 21/100 complete - Max Reward: 0.003068\n",
      "Starting episode 22/100\n",
      "  Step 1, Current reward: 0.032510\n",
      "  Step 2, Current reward: 0.036986\n",
      "  Step 3, Current reward: 0.041611\n",
      "  Step 4, Current reward: 0.036986\n",
      "  Step 5, Current reward: 0.041611\n",
      "  Step 6, Current reward: 0.036986\n",
      "  Step 7, Current reward: 0.041611\n",
      "  Step 8, Current reward: 0.036986\n",
      "  Step 9, Current reward: 0.041611\n",
      "  Step 10, Current reward: 0.036986\n",
      "  Step 11, Current reward: 0.041611\n",
      "  Step 12, Current reward: 0.036986\n",
      "  Step 13, Current reward: 0.041611\n",
      "  Step 14, Current reward: 0.036986\n",
      "Episode 22/100 complete - Max Reward: 0.041611\n",
      "Starting episode 23/100\n",
      "  Step 1, Current reward: 0.031932\n",
      "  Step 2, Current reward: 0.030898\n",
      "  Step 3, Current reward: 0.041406\n",
      "  Step 4, Current reward: 0.044912\n",
      "  Step 5, Current reward: 0.046921\n",
      "  Step 6, Current reward: 0.047049\n",
      "  Step 7, Current reward: 0.045682\n",
      "  Step 8, Current reward: 0.046117\n",
      "  Step 9, Current reward: 0.046680\n",
      "  Step 10, Current reward: 0.047412\n",
      "  Step 11, Current reward: 0.048362\n",
      "  Step 12, Current reward: 0.049567\n",
      "  Step 13, Current reward: 0.051088\n",
      "  Step 14, Current reward: 0.053004\n",
      "  Step 15, Current reward: 0.055391\n",
      "  Step 16, Current reward: 0.058318\n",
      "  Step 17, Current reward: 0.061880\n",
      "  Step 18, Current reward: 0.066189\n",
      "  Step 19, Current reward: 0.071375\n",
      "  Step 20, Current reward: 0.077585\n",
      "  Step 21, Current reward: 0.084974\n",
      "  Step 22, Current reward: 0.093702\n",
      "  Step 23, Current reward: 0.103908\n",
      "  Step 24, Current reward: 0.115670\n",
      "  Step 25, Current reward: 0.128936\n",
      "  Step 26, Current reward: 0.143302\n",
      "  Step 27, Current reward: 0.158011\n",
      "  Step 28, Current reward: 0.171950\n",
      "  Step 29, Current reward: 0.183703\n",
      "  Step 30, Current reward: 0.192323\n",
      "  Step 31, Current reward: 0.196865\n",
      "  Step 32, Current reward: 0.196256\n",
      "  Step 33, Current reward: 0.189610\n",
      "  Step 34, Current reward: 0.176636\n",
      "  Step 35, Current reward: 0.158024\n",
      "  Step 36, Current reward: 0.136152\n",
      "  Step 37, Current reward: 0.136152\n",
      "  Step 38, Current reward: 0.136152\n",
      "  Step 39, Current reward: 0.136152\n",
      "  Step 40, Current reward: 0.136152\n",
      "  Step 41, Current reward: 0.136152\n",
      "  Step 42, Current reward: 0.136152\n",
      "Episode 23/100 complete - Max Reward: 0.196865\n",
      "Starting episode 24/100\n",
      "  Step 1, Current reward: 0.001579\n",
      "  Step 2, Current reward: 0.000934\n",
      "  Step 3, Current reward: 0.000901\n",
      "  Step 4, Current reward: 0.000868\n",
      "  Step 5, Current reward: 0.000835\n",
      "  Step 6, Current reward: 0.000805\n",
      "  Step 7, Current reward: 0.000781\n",
      "  Step 8, Current reward: 0.000765\n",
      "  Step 9, Current reward: 0.000757\n",
      "  Step 10, Current reward: 0.000756\n",
      "  Step 11, Current reward: 0.000757\n",
      "  Step 12, Current reward: 0.000757\n",
      "Episode 24/100 complete - Max Reward: 0.001579\n",
      "Starting episode 25/100\n",
      "  Step 1, Current reward: 0.000530\n",
      "  Step 2, Current reward: 0.000575\n",
      "  Step 3, Current reward: 0.000623\n",
      "  Step 4, Current reward: 0.000673\n",
      "  Step 5, Current reward: 0.000722\n",
      "  Step 6, Current reward: 0.000770\n",
      "  Step 7, Current reward: 0.000818\n",
      "  Step 8, Current reward: 0.000782\n",
      "  Step 9, Current reward: 0.001233\n",
      "  Step 10, Current reward: 0.001593\n",
      "  Step 11, Current reward: 0.002763\n",
      "  Step 12, Current reward: 0.002735\n",
      "  Step 13, Current reward: 0.002796\n",
      "  Step 14, Current reward: 0.002885\n",
      "  Step 15, Current reward: 0.003008\n",
      "  Step 16, Current reward: 0.003172\n",
      "  Step 17, Current reward: 0.003392\n",
      "  Step 18, Current reward: 0.003689\n",
      "  Step 19, Current reward: 0.004076\n",
      "  Step 20, Current reward: 0.004097\n",
      "  Step 21, Current reward: 0.004154\n",
      "  Step 22, Current reward: 0.004220\n",
      "  Step 23, Current reward: 0.004291\n",
      "  Step 24, Current reward: 0.004367\n",
      "  Step 25, Current reward: 0.004452\n",
      "  Step 26, Current reward: 0.004544\n",
      "  Step 27, Current reward: 0.004644\n",
      "  Step 28, Current reward: 0.004754\n",
      "  Step 29, Current reward: 0.004230\n",
      "  Step 30, Current reward: 0.004334\n",
      "  Step 31, Current reward: 0.004438\n",
      "  Step 32, Current reward: 0.004501\n",
      "  Step 33, Current reward: 0.004576\n",
      "  Step 34, Current reward: 0.004678\n",
      "  Step 35, Current reward: 0.002790\n",
      "  Step 36, Current reward: 0.002848\n",
      "  Step 37, Current reward: 0.002903\n",
      "  Step 38, Current reward: 0.002953\n",
      "  Step 39, Current reward: 0.002894\n",
      "Episode 25/100 complete - Max Reward: 0.004754\n",
      "Starting episode 26/100\n",
      "  Step 1, Current reward: 0.007572\n",
      "  Step 2, Current reward: 0.007340\n",
      "  Step 3, Current reward: 0.007166\n",
      "  Step 4, Current reward: 0.007352\n",
      "  Step 5, Current reward: 0.007526\n",
      "  Step 6, Current reward: 0.007697\n",
      "  Step 7, Current reward: 0.007854\n",
      "  Step 8, Current reward: 0.008004\n",
      "  Step 9, Current reward: 0.007854\n",
      "  Step 10, Current reward: 0.008004\n",
      "  Step 11, Current reward: 0.007854\n",
      "  Step 12, Current reward: 0.008004\n",
      "  Step 13, Current reward: 0.007854\n",
      "  Step 14, Current reward: 0.008004\n",
      "  Step 15, Current reward: 0.007854\n",
      "  Step 16, Current reward: 0.008004\n",
      "  Step 17, Current reward: 0.007854\n",
      "  Step 18, Current reward: 0.008004\n",
      "  Step 19, Current reward: 0.007854\n",
      "Episode 26/100 complete - Max Reward: 0.008004\n",
      "Starting episode 27/100\n",
      "  Step 1, Current reward: 0.023467\n",
      "  Step 2, Current reward: 0.029082\n",
      "  Step 3, Current reward: 0.030456\n",
      "  Step 4, Current reward: 0.027471\n",
      "  Step 5, Current reward: 0.021329\n",
      "  Step 6, Current reward: 0.013958\n",
      "  Step 7, Current reward: 0.007294\n",
      "  Step 8, Current reward: 0.002753\n",
      "  Step 9, Current reward: 0.001011\n",
      "  Step 10, Current reward: 0.002064\n",
      "  Step 11, Current reward: 0.005346\n",
      "  Step 12, Current reward: 0.009836\n",
      "  Step 13, Current reward: 0.014564\n",
      "  Step 14, Current reward: 0.018253\n",
      "Episode 27/100 complete - Max Reward: 0.030456\n",
      "Starting episode 28/100\n",
      "  Step 1, Current reward: 0.033393\n",
      "  Step 2, Current reward: 0.033179\n",
      "  Step 3, Current reward: 0.033267\n",
      "  Step 4, Current reward: 0.033246\n",
      "  Step 5, Current reward: 0.031267\n",
      "  Step 6, Current reward: 0.029235\n",
      "  Step 7, Current reward: 0.031997\n",
      "  Step 8, Current reward: 0.031143\n",
      "  Step 9, Current reward: 0.031283\n",
      "  Step 10, Current reward: 0.032581\n",
      "  Step 11, Current reward: 0.032453\n",
      "  Step 12, Current reward: 0.031731\n",
      "Episode 28/100 complete - Max Reward: 0.033393\n",
      "Starting episode 29/100\n",
      "  Step 1, Current reward: 0.000006\n",
      "  Step 2, Current reward: 0.000005\n",
      "  Step 3, Current reward: 0.000006\n",
      "  Step 4, Current reward: 0.000006\n",
      "  Step 5, Current reward: 0.000006\n",
      "  Step 6, Current reward: 0.000005\n",
      "  Step 7, Current reward: 0.000005\n",
      "  Step 8, Current reward: 0.000006\n",
      "  Step 9, Current reward: 0.000006\n",
      "  Step 10, Current reward: 0.000007\n",
      "  Step 11, Current reward: 0.000006\n",
      "  Step 12, Current reward: 0.000006\n",
      "  Step 13, Current reward: 0.000006\n",
      "  Step 14, Current reward: 0.000006\n",
      "  Step 15, Current reward: 0.000006\n",
      "  Step 16, Current reward: 0.000006\n",
      "  Step 17, Current reward: 0.000006\n",
      "  Step 18, Current reward: 0.000006\n",
      "  Step 19, Current reward: 0.000006\n",
      "  Step 20, Current reward: 0.000006\n",
      "  Step 21, Current reward: 0.000007\n",
      "Episode 29/100 complete - Max Reward: 0.000007\n",
      "Starting episode 30/100\n",
      "  Step 1, Current reward: 0.006232\n",
      "  Step 2, Current reward: 0.006232\n",
      "  Step 3, Current reward: 0.006232\n",
      "  Step 4, Current reward: 0.006232\n",
      "  Step 5, Current reward: 0.006232\n",
      "  Step 6, Current reward: 0.006232\n",
      "  Step 7, Current reward: 0.006232\n",
      "  Step 8, Current reward: 0.006232\n",
      "  Step 9, Current reward: 0.006232\n",
      "  Step 10, Current reward: 0.006232\n",
      "  Step 11, Current reward: 0.006232\n",
      "  Step 12, Current reward: 0.006232\n",
      "Episode 30/100 complete - Max Reward: 0.006232\n",
      "Starting episode 31/100\n",
      "  Step 1, Current reward: 0.021114\n",
      "  Step 2, Current reward: 0.020583\n",
      "  Step 3, Current reward: 0.020008\n",
      "  Step 4, Current reward: 0.019389\n",
      "  Step 5, Current reward: 0.018728\n",
      "  Step 6, Current reward: 0.018061\n",
      "  Step 7, Current reward: 0.017416\n",
      "  Step 8, Current reward: 0.016777\n",
      "  Step 9, Current reward: 0.016140\n",
      "  Step 10, Current reward: 0.015561\n",
      "  Step 11, Current reward: 0.015158\n",
      "  Step 12, Current reward: 0.015094\n",
      "Episode 31/100 complete - Max Reward: 0.021114\n",
      "Starting episode 32/100\n",
      "  Step 1, Current reward: 0.008363\n",
      "  Step 2, Current reward: 0.008319\n",
      "  Step 3, Current reward: 0.008281\n",
      "  Step 4, Current reward: 0.008236\n",
      "  Step 5, Current reward: 0.008173\n",
      "  Step 6, Current reward: 0.008426\n",
      "  Step 7, Current reward: 0.009261\n",
      "  Step 8, Current reward: 0.010656\n",
      "  Step 9, Current reward: 0.014496\n",
      "  Step 10, Current reward: 0.022223\n",
      "  Step 11, Current reward: 0.022415\n",
      "  Step 12, Current reward: 0.030799\n",
      "  Step 13, Current reward: 0.033481\n",
      "  Step 14, Current reward: 0.027717\n",
      "  Step 15, Current reward: 0.017958\n",
      "  Step 16, Current reward: 0.012520\n",
      "  Step 17, Current reward: 0.016558\n",
      "  Step 18, Current reward: 0.027840\n",
      "  Step 19, Current reward: 0.039127\n",
      "  Step 20, Current reward: 0.043464\n",
      "  Step 21, Current reward: 0.039400\n",
      "  Step 22, Current reward: 0.039400\n",
      "  Step 23, Current reward: 0.039400\n",
      "  Step 24, Current reward: 0.039400\n",
      "  Step 25, Current reward: 0.039400\n",
      "  Step 26, Current reward: 0.039400\n",
      "  Step 27, Current reward: 0.039400\n",
      "  Step 28, Current reward: 0.039400\n",
      "  Step 29, Current reward: 0.039400\n",
      "  Step 30, Current reward: 0.039400\n",
      "  Step 31, Current reward: 0.039400\n",
      "Episode 32/100 complete - Max Reward: 0.043464\n",
      "Starting episode 33/100\n",
      "  Step 1, Current reward: 0.001497\n",
      "  Step 2, Current reward: 0.002954\n",
      "  Step 3, Current reward: 0.004478\n",
      "  Step 4, Current reward: 0.005569\n",
      "  Step 5, Current reward: 0.005821\n",
      "  Step 6, Current reward: 0.005107\n",
      "  Step 7, Current reward: 0.003652\n",
      "  Step 8, Current reward: 0.001956\n",
      "  Step 9, Current reward: 0.002011\n",
      "  Step 10, Current reward: 0.000652\n",
      "  Step 11, Current reward: 0.000669\n",
      "  Step 12, Current reward: 0.000638\n",
      "  Step 13, Current reward: 0.000613\n",
      "  Step 14, Current reward: 0.000626\n",
      "  Step 15, Current reward: 0.000627\n",
      "  Step 16, Current reward: 0.000632\n",
      "Episode 33/100 complete - Max Reward: 0.005821\n",
      "Starting episode 34/100\n",
      "  Step 1, Current reward: 0.087655\n",
      "  Step 2, Current reward: 0.086111\n",
      "  Step 3, Current reward: 0.084637\n",
      "  Step 4, Current reward: 0.083105\n",
      "  Step 5, Current reward: 0.063042\n",
      "  Step 6, Current reward: 0.062501\n",
      "  Step 7, Current reward: 0.043630\n",
      "  Step 8, Current reward: 0.041979\n",
      "  Step 9, Current reward: 0.043630\n",
      "  Step 10, Current reward: 0.041979\n",
      "  Step 11, Current reward: 0.043630\n",
      "  Step 12, Current reward: 0.041979\n",
      "Episode 34/100 complete - Max Reward: 0.087655\n",
      "Starting episode 35/100\n",
      "  Step 1, Current reward: 0.009874\n",
      "  Step 2, Current reward: 0.012149\n",
      "  Step 3, Current reward: 0.009874\n",
      "  Step 4, Current reward: 0.012149\n",
      "  Step 5, Current reward: 0.009874\n",
      "  Step 6, Current reward: 0.012149\n",
      "  Step 7, Current reward: 0.009874\n",
      "  Step 8, Current reward: 0.012149\n",
      "  Step 9, Current reward: 0.009874\n",
      "  Step 10, Current reward: 0.012149\n",
      "  Step 11, Current reward: 0.009874\n",
      "  Step 12, Current reward: 0.012149\n",
      "  Step 13, Current reward: 0.009874\n",
      "Episode 35/100 complete - Max Reward: 0.012149\n",
      "Starting episode 36/100\n",
      "  Step 1, Current reward: 0.000264\n",
      "  Step 2, Current reward: 0.000266\n",
      "  Step 3, Current reward: 0.000052\n",
      "  Step 4, Current reward: 0.000205\n",
      "  Step 5, Current reward: 0.000784\n",
      "  Step 6, Current reward: 0.000962\n",
      "  Step 7, Current reward: 0.001141\n",
      "  Step 8, Current reward: 0.001658\n",
      "  Step 9, Current reward: 0.001561\n",
      "  Step 10, Current reward: 0.001005\n",
      "  Step 11, Current reward: 0.000459\n",
      "  Step 12, Current reward: 0.000264\n",
      "  Step 13, Current reward: 0.000401\n",
      "  Step 14, Current reward: 0.000618\n",
      "  Step 15, Current reward: 0.000698\n",
      "  Step 16, Current reward: 0.000698\n",
      "  Step 17, Current reward: 0.000698\n",
      "  Step 18, Current reward: 0.000698\n",
      "  Step 19, Current reward: 0.000698\n",
      "Episode 36/100 complete - Max Reward: 0.001658\n",
      "Starting episode 37/100\n",
      "  Step 1, Current reward: 0.068801\n",
      "  Step 2, Current reward: 0.070502\n",
      "  Step 3, Current reward: 0.072649\n",
      "  Step 4, Current reward: 0.075287\n",
      "  Step 5, Current reward: 0.078509\n",
      "  Step 6, Current reward: 0.084152\n",
      "  Step 7, Current reward: 0.090385\n",
      "  Step 8, Current reward: 0.096797\n",
      "  Step 9, Current reward: 0.102688\n",
      "  Step 10, Current reward: 0.107582\n",
      "  Step 11, Current reward: 0.111055\n",
      "  Step 12, Current reward: 0.112617\n",
      "  Step 13, Current reward: 0.111890\n",
      "  Step 14, Current reward: 0.108877\n",
      "  Step 15, Current reward: 0.104221\n",
      "  Step 16, Current reward: 0.099583\n",
      "  Step 17, Current reward: 0.099583\n",
      "  Step 18, Current reward: 0.099583\n",
      "  Step 19, Current reward: 0.099583\n",
      "  Step 20, Current reward: 0.099583\n",
      "  Step 21, Current reward: 0.099583\n",
      "  Step 22, Current reward: 0.099583\n",
      "  Step 23, Current reward: 0.099583\n",
      "Episode 37/100 complete - Max Reward: 0.112617\n",
      "Starting episode 38/100\n",
      "  Step 1, Current reward: 0.071630\n",
      "  Step 2, Current reward: 0.073534\n",
      "  Step 3, Current reward: 0.069120\n",
      "  Step 4, Current reward: 0.067336\n",
      "  Step 5, Current reward: 0.067701\n",
      "  Step 6, Current reward: 0.066856\n",
      "  Step 7, Current reward: 0.064685\n",
      "  Step 8, Current reward: 0.062673\n",
      "  Step 9, Current reward: 0.060878\n",
      "  Step 10, Current reward: 0.058296\n",
      "  Step 11, Current reward: 0.055362\n",
      "  Step 12, Current reward: 0.052774\n",
      "  Step 13, Current reward: 0.051084\n",
      "Episode 38/100 complete - Max Reward: 0.073534\n",
      "Starting episode 39/100\n",
      "  Step 1, Current reward: 0.002110\n",
      "  Step 2, Current reward: 0.002110\n",
      "  Step 3, Current reward: 0.002110\n",
      "  Step 4, Current reward: 0.002110\n",
      "  Step 5, Current reward: 0.002110\n",
      "  Step 6, Current reward: 0.002110\n",
      "  Step 7, Current reward: 0.002110\n",
      "  Step 8, Current reward: 0.002110\n",
      "  Step 9, Current reward: 0.002110\n",
      "  Step 10, Current reward: 0.002110\n",
      "  Step 11, Current reward: 0.002110\n",
      "  Step 12, Current reward: 0.002110\n",
      "Episode 39/100 complete - Max Reward: 0.002110\n",
      "Starting episode 40/100\n",
      "  Step 1, Current reward: 0.020035\n",
      "  Step 2, Current reward: 0.020347\n",
      "  Step 3, Current reward: 0.020625\n",
      "  Step 4, Current reward: 0.020855\n",
      "  Step 5, Current reward: 0.021030\n",
      "  Step 6, Current reward: 0.021152\n",
      "  Step 7, Current reward: 0.021221\n",
      "  Step 8, Current reward: 0.021236\n",
      "  Step 9, Current reward: 0.021198\n",
      "  Step 10, Current reward: 0.021109\n",
      "  Step 11, Current reward: 0.020970\n",
      "  Step 12, Current reward: 0.020787\n",
      "  Step 13, Current reward: 0.020564\n",
      "  Step 14, Current reward: 0.020306\n",
      "  Step 15, Current reward: 0.020017\n",
      "  Step 16, Current reward: 0.019704\n",
      "  Step 17, Current reward: 0.019372\n",
      "  Step 18, Current reward: 0.014965\n",
      "  Step 19, Current reward: 0.013606\n",
      "Episode 40/100 complete - Max Reward: 0.021236\n",
      "Starting episode 41/100\n",
      "  Step 1, Current reward: 0.022432\n",
      "  Step 2, Current reward: 0.021446\n",
      "  Step 3, Current reward: 0.022432\n",
      "  Step 4, Current reward: 0.021446\n",
      "  Step 5, Current reward: 0.022432\n",
      "  Step 6, Current reward: 0.021446\n",
      "  Step 7, Current reward: 0.022432\n",
      "  Step 8, Current reward: 0.021446\n",
      "  Step 9, Current reward: 0.022432\n",
      "  Step 10, Current reward: 0.021446\n",
      "  Step 11, Current reward: 0.022432\n",
      "  Step 12, Current reward: 0.021446\n",
      "Episode 41/100 complete - Max Reward: 0.022432\n",
      "Starting episode 42/100\n",
      "  Step 1, Current reward: 0.010036\n",
      "  Step 2, Current reward: 0.009901\n",
      "  Step 3, Current reward: 0.009771\n",
      "  Step 4, Current reward: 0.009648\n",
      "  Step 5, Current reward: 0.009533\n",
      "  Step 6, Current reward: 0.009424\n",
      "  Step 7, Current reward: 0.009320\n",
      "  Step 8, Current reward: 0.009228\n",
      "  Step 9, Current reward: 0.009165\n",
      "  Step 10, Current reward: 0.009160\n",
      "  Step 11, Current reward: 0.009241\n",
      "  Step 12, Current reward: 0.009421\n",
      "Episode 42/100 complete - Max Reward: 0.010036\n",
      "Starting episode 43/100\n",
      "  Step 1, Current reward: 0.001039\n",
      "  Step 2, Current reward: 0.001243\n",
      "  Step 3, Current reward: 0.001400\n",
      "  Step 4, Current reward: 0.001511\n",
      "  Step 5, Current reward: 0.001554\n",
      "  Step 6, Current reward: 0.001513\n",
      "  Step 7, Current reward: 0.001391\n",
      "  Step 8, Current reward: 0.001197\n",
      "  Step 9, Current reward: 0.000946\n",
      "  Step 10, Current reward: 0.000661\n",
      "  Step 11, Current reward: 0.000383\n",
      "  Step 12, Current reward: 0.000166\n",
      "  Step 13, Current reward: 0.000061\n",
      "  Step 14, Current reward: 0.000051\n",
      "  Step 15, Current reward: 0.000052\n",
      "  Step 16, Current reward: 0.000053\n",
      "Episode 43/100 complete - Max Reward: 0.001554\n",
      "Starting episode 44/100\n",
      "  Step 1, Current reward: 0.013440\n",
      "  Step 2, Current reward: 0.013270\n",
      "  Step 3, Current reward: 0.013047\n",
      "  Step 4, Current reward: 0.012776\n",
      "  Step 5, Current reward: 0.012466\n",
      "  Step 6, Current reward: 0.012127\n",
      "  Step 7, Current reward: 0.011769\n",
      "  Step 8, Current reward: 0.011402\n",
      "  Step 9, Current reward: 0.011035\n",
      "  Step 10, Current reward: 0.010669\n",
      "  Step 11, Current reward: 0.010301\n",
      "  Step 12, Current reward: 0.009918\n",
      "Episode 44/100 complete - Max Reward: 0.013440\n",
      "Starting episode 45/100\n",
      "  Step 1, Current reward: 0.000351\n",
      "  Step 2, Current reward: 0.000335\n",
      "  Step 3, Current reward: 0.000338\n",
      "  Step 4, Current reward: 0.000342\n",
      "  Step 5, Current reward: 0.000355\n",
      "  Step 6, Current reward: 0.000291\n",
      "  Step 7, Current reward: 0.000256\n",
      "  Step 8, Current reward: 0.000285\n",
      "  Step 9, Current reward: 0.000276\n",
      "  Step 10, Current reward: 0.000260\n",
      "  Step 11, Current reward: 0.000264\n",
      "  Step 12, Current reward: 0.000267\n",
      "  Step 13, Current reward: 0.000271\n",
      "  Step 14, Current reward: 0.000277\n",
      "  Step 15, Current reward: 0.000285\n",
      "  Step 16, Current reward: 0.000296\n",
      "Episode 45/100 complete - Max Reward: 0.000355\n",
      "Starting episode 46/100\n",
      "  Step 1, Current reward: 0.003062\n",
      "  Step 2, Current reward: 0.003024\n",
      "  Step 3, Current reward: 0.002975\n",
      "  Step 4, Current reward: 0.002915\n",
      "  Step 5, Current reward: 0.002847\n",
      "  Step 6, Current reward: 0.002773\n",
      "  Step 7, Current reward: 0.002741\n",
      "  Step 8, Current reward: 0.002702\n",
      "  Step 9, Current reward: 0.002656\n",
      "  Step 10, Current reward: 0.002605\n",
      "  Step 11, Current reward: 0.002552\n",
      "  Step 12, Current reward: 0.002496\n",
      "Episode 46/100 complete - Max Reward: 0.003062\n",
      "Starting episode 47/100\n",
      "  Step 1, Current reward: 0.001318\n",
      "  Step 2, Current reward: 0.001321\n",
      "  Step 3, Current reward: 0.001325\n",
      "  Step 4, Current reward: 0.001332\n",
      "  Step 5, Current reward: 0.001342\n",
      "  Step 6, Current reward: 0.001358\n",
      "  Step 7, Current reward: 0.001378\n",
      "  Step 8, Current reward: 0.001358\n",
      "  Step 9, Current reward: 0.001378\n",
      "  Step 10, Current reward: 0.001358\n",
      "  Step 11, Current reward: 0.001378\n",
      "  Step 12, Current reward: 0.001358\n",
      "  Step 13, Current reward: 0.001378\n",
      "  Step 14, Current reward: 0.001358\n",
      "  Step 15, Current reward: 0.001378\n",
      "  Step 16, Current reward: 0.001358\n",
      "  Step 17, Current reward: 0.001378\n",
      "  Step 18, Current reward: 0.001358\n",
      "Episode 47/100 complete - Max Reward: 0.001378\n",
      "Starting episode 48/100\n",
      "  Step 1, Current reward: 0.000123\n",
      "  Step 2, Current reward: 0.000123\n",
      "  Step 3, Current reward: 0.000123\n",
      "  Step 4, Current reward: 0.000124\n",
      "  Step 5, Current reward: 0.000081\n",
      "  Step 6, Current reward: 0.000016\n",
      "  Step 7, Current reward: 0.000015\n",
      "  Step 8, Current reward: 0.000017\n",
      "  Step 9, Current reward: 0.000020\n",
      "  Step 10, Current reward: 0.000026\n",
      "  Step 11, Current reward: 0.000036\n",
      "  Step 12, Current reward: 0.000054\n",
      "  Step 13, Current reward: 0.000082\n",
      "  Step 14, Current reward: 0.000122\n",
      "  Step 15, Current reward: 0.000173\n",
      "  Step 16, Current reward: 0.000237\n",
      "  Step 17, Current reward: 0.000314\n",
      "  Step 18, Current reward: 0.000402\n",
      "  Step 19, Current reward: 0.000497\n",
      "  Step 20, Current reward: 0.000597\n",
      "  Step 21, Current reward: 0.000698\n",
      "  Step 22, Current reward: 0.000801\n",
      "  Step 23, Current reward: 0.000905\n",
      "  Step 24, Current reward: 0.001012\n",
      "  Step 25, Current reward: 0.001123\n",
      "  Step 26, Current reward: 0.001240\n",
      "  Step 27, Current reward: 0.001361\n",
      "  Step 28, Current reward: 0.001483\n",
      "  Step 29, Current reward: 0.001599\n",
      "  Step 30, Current reward: 0.001690\n",
      "  Step 31, Current reward: 0.001690\n",
      "  Step 32, Current reward: 0.001690\n",
      "  Step 33, Current reward: 0.001690\n",
      "  Step 34, Current reward: 0.001690\n",
      "  Step 35, Current reward: 0.001690\n",
      "  Step 36, Current reward: 0.001690\n",
      "  Step 37, Current reward: 0.001690\n",
      "  Step 38, Current reward: 0.001690\n",
      "  Step 39, Current reward: 0.001690\n",
      "  Step 40, Current reward: 0.001690\n",
      "  Step 41, Current reward: 0.001690\n",
      "Episode 48/100 complete - Max Reward: 0.001690\n",
      "Starting episode 49/100\n",
      "  Step 1, Current reward: 0.001631\n",
      "  Step 2, Current reward: 0.001612\n",
      "  Step 3, Current reward: 0.001591\n",
      "  Step 4, Current reward: 0.001570\n",
      "  Step 5, Current reward: 0.001549\n",
      "  Step 6, Current reward: 0.000398\n",
      "  Step 7, Current reward: 0.000356\n",
      "  Step 8, Current reward: 0.000356\n",
      "  Step 9, Current reward: 0.000356\n",
      "  Step 10, Current reward: 0.000356\n",
      "  Step 11, Current reward: 0.000356\n",
      "  Step 12, Current reward: 0.000356\n",
      "Episode 49/100 complete - Max Reward: 0.001631\n",
      "Starting episode 50/100\n",
      "  Step 1, Current reward: 0.025055\n",
      "  Step 2, Current reward: 0.025726\n",
      "  Step 3, Current reward: 0.029837\n",
      "  Step 4, Current reward: 0.037259\n",
      "  Step 5, Current reward: 0.045439\n",
      "  Step 6, Current reward: 0.045439\n",
      "  Step 7, Current reward: 0.045439\n",
      "  Step 8, Current reward: 0.045439\n",
      "  Step 9, Current reward: 0.045439\n",
      "  Step 10, Current reward: 0.045439\n",
      "  Step 11, Current reward: 0.045439\n",
      "  Step 12, Current reward: 0.045439\n",
      "  Step 13, Current reward: 0.045439\n",
      "  Step 14, Current reward: 0.045439\n",
      "  Step 15, Current reward: 0.045439\n",
      "  Step 16, Current reward: 0.045439\n",
      "Episode 50/100 complete - Max Reward: 0.045439\n",
      "Starting episode 51/100\n",
      "  Step 1, Current reward: 0.109021\n",
      "  Step 2, Current reward: 0.109011\n",
      "  Step 3, Current reward: 0.108991\n",
      "  Step 4, Current reward: 0.108996\n",
      "  Step 5, Current reward: 0.109057\n",
      "  Step 6, Current reward: 0.109192\n",
      "  Step 7, Current reward: 0.109400\n",
      "  Step 8, Current reward: 0.109670\n",
      "  Step 9, Current reward: 0.109978\n",
      "  Step 10, Current reward: 0.110366\n",
      "  Step 11, Current reward: 0.110936\n",
      "  Step 12, Current reward: 0.111776\n",
      "  Step 13, Current reward: 0.112975\n",
      "  Step 14, Current reward: 0.114633\n",
      "  Step 15, Current reward: 0.116796\n",
      "  Step 16, Current reward: 0.119459\n",
      "  Step 17, Current reward: 0.122543\n",
      "  Step 18, Current reward: 0.128029\n",
      "  Step 19, Current reward: 0.131514\n",
      "  Step 20, Current reward: 0.135276\n",
      "  Step 21, Current reward: 0.139281\n",
      "  Step 22, Current reward: 0.143525\n",
      "  Step 23, Current reward: 0.148016\n",
      "  Step 24, Current reward: 0.152767\n",
      "  Step 25, Current reward: 0.157784\n",
      "  Step 26, Current reward: 0.163057\n",
      "  Step 27, Current reward: 0.168558\n",
      "  Step 28, Current reward: 0.174304\n",
      "  Step 29, Current reward: 0.180268\n",
      "  Step 30, Current reward: 0.174801\n",
      "  Step 31, Current reward: 0.169822\n",
      "  Step 32, Current reward: 0.165260\n",
      "  Step 33, Current reward: 0.161079\n",
      "  Step 34, Current reward: 0.157264\n",
      "  Step 35, Current reward: 0.153813\n",
      "  Step 36, Current reward: 0.150747\n",
      "  Step 37, Current reward: 0.148091\n",
      "  Step 38, Current reward: 0.145856\n",
      "  Step 39, Current reward: 0.144027\n",
      "  Step 40, Current reward: 0.142560\n",
      "Episode 51/100 complete - Max Reward: 0.180268\n",
      "Starting episode 52/100\n",
      "  Step 1, Current reward: 0.004536\n",
      "  Step 2, Current reward: 0.004536\n",
      "  Step 3, Current reward: 0.004536\n",
      "  Step 4, Current reward: 0.004536\n",
      "  Step 5, Current reward: 0.004536\n",
      "  Step 6, Current reward: 0.004536\n",
      "  Step 7, Current reward: 0.004536\n",
      "  Step 8, Current reward: 0.004536\n",
      "  Step 9, Current reward: 0.004536\n",
      "  Step 10, Current reward: 0.004536\n",
      "  Step 11, Current reward: 0.004536\n",
      "  Step 12, Current reward: 0.004536\n",
      "Episode 52/100 complete - Max Reward: 0.004536\n",
      "Starting episode 53/100\n",
      "  Step 1, Current reward: 0.155427\n",
      "  Step 2, Current reward: 0.099006\n",
      "  Step 3, Current reward: 0.059521\n",
      "  Step 4, Current reward: 0.046134\n",
      "  Step 5, Current reward: 0.045410\n",
      "  Step 6, Current reward: 0.045441\n",
      "  Step 7, Current reward: 0.045495\n",
      "  Step 8, Current reward: 0.045534\n",
      "  Step 9, Current reward: 0.045549\n",
      "  Step 10, Current reward: 0.045546\n",
      "  Step 11, Current reward: 0.045538\n",
      "  Step 12, Current reward: 0.045538\n",
      "Episode 53/100 complete - Max Reward: 0.155427\n",
      "Starting episode 54/100\n",
      "  Step 1, Current reward: 0.001104\n",
      "  Step 2, Current reward: 0.001104\n",
      "  Step 3, Current reward: 0.001104\n",
      "  Step 4, Current reward: 0.001104\n",
      "  Step 5, Current reward: 0.001104\n",
      "  Step 6, Current reward: 0.001104\n",
      "  Step 7, Current reward: 0.001104\n",
      "  Step 8, Current reward: 0.001104\n",
      "  Step 9, Current reward: 0.001104\n",
      "  Step 10, Current reward: 0.001104\n",
      "  Step 11, Current reward: 0.001104\n",
      "  Step 12, Current reward: 0.001104\n",
      "Episode 54/100 complete - Max Reward: 0.001104\n",
      "Starting episode 55/100\n",
      "  Step 1, Current reward: 0.004221\n",
      "  Step 2, Current reward: 0.004309\n",
      "  Step 3, Current reward: 0.006117\n",
      "  Step 4, Current reward: 0.008605\n",
      "  Step 5, Current reward: 0.011835\n",
      "  Step 6, Current reward: 0.011422\n",
      "  Step 7, Current reward: 0.012032\n",
      "  Step 8, Current reward: 0.012714\n",
      "  Step 9, Current reward: 0.017313\n",
      "  Step 10, Current reward: 0.022488\n",
      "  Step 11, Current reward: 0.022488\n",
      "  Step 12, Current reward: 0.022488\n",
      "  Step 13, Current reward: 0.022488\n",
      "  Step 14, Current reward: 0.022488\n",
      "  Step 15, Current reward: 0.022488\n",
      "  Step 16, Current reward: 0.022488\n",
      "  Step 17, Current reward: 0.022488\n",
      "  Step 18, Current reward: 0.022488\n",
      "  Step 19, Current reward: 0.022488\n",
      "  Step 20, Current reward: 0.022488\n",
      "  Step 21, Current reward: 0.022488\n",
      "Episode 55/100 complete - Max Reward: 0.022488\n",
      "Starting episode 56/100\n",
      "  Step 1, Current reward: 0.055943\n",
      "  Step 2, Current reward: 0.056664\n",
      "  Step 3, Current reward: 0.057223\n",
      "  Step 4, Current reward: 0.057598\n",
      "  Step 5, Current reward: 0.057763\n",
      "  Step 6, Current reward: 0.057719\n",
      "  Step 7, Current reward: 0.057763\n",
      "  Step 8, Current reward: 0.057719\n",
      "  Step 9, Current reward: 0.057763\n",
      "  Step 10, Current reward: 0.057719\n",
      "  Step 11, Current reward: 0.057763\n",
      "  Step 12, Current reward: 0.057719\n",
      "  Step 13, Current reward: 0.057763\n",
      "  Step 14, Current reward: 0.057719\n",
      "  Step 15, Current reward: 0.057763\n",
      "  Step 16, Current reward: 0.057719\n",
      "Episode 56/100 complete - Max Reward: 0.057763\n",
      "Starting episode 57/100\n",
      "  Step 1, Current reward: 0.008701\n",
      "  Step 2, Current reward: 0.008280\n",
      "  Step 3, Current reward: 0.007616\n",
      "  Step 4, Current reward: 0.006777\n",
      "  Step 5, Current reward: 0.006401\n",
      "  Step 6, Current reward: 0.005744\n",
      "  Step 7, Current reward: 0.005790\n",
      "  Step 8, Current reward: 0.004751\n",
      "  Step 9, Current reward: 0.004778\n",
      "  Step 10, Current reward: 0.004794\n",
      "  Step 11, Current reward: 0.004141\n",
      "  Step 12, Current reward: 0.004054\n",
      "Episode 57/100 complete - Max Reward: 0.008701\n",
      "Starting episode 58/100\n",
      "  Step 1, Current reward: 0.013226\n",
      "  Step 2, Current reward: 0.012826\n",
      "  Step 3, Current reward: 0.013356\n",
      "  Step 4, Current reward: 0.012625\n",
      "  Step 5, Current reward: 0.010149\n",
      "  Step 6, Current reward: 0.009097\n",
      "  Step 7, Current reward: 0.009104\n",
      "  Step 8, Current reward: 0.009143\n",
      "  Step 9, Current reward: 0.009181\n",
      "  Step 10, Current reward: 0.009353\n",
      "  Step 11, Current reward: 0.009391\n",
      "  Step 12, Current reward: 0.009414\n",
      "  Step 13, Current reward: 0.009418\n",
      "  Step 14, Current reward: 0.009406\n",
      "Episode 58/100 complete - Max Reward: 0.013356\n",
      "Starting episode 59/100\n",
      "  Step 1, Current reward: 0.000042\n",
      "  Step 2, Current reward: 0.000044\n",
      "  Step 3, Current reward: 0.000046\n",
      "  Step 4, Current reward: 0.000047\n",
      "  Step 5, Current reward: 0.000050\n",
      "  Step 6, Current reward: 0.000052\n",
      "  Step 7, Current reward: 0.000055\n",
      "  Step 8, Current reward: 0.000058\n",
      "  Step 9, Current reward: 0.000062\n",
      "  Step 10, Current reward: 0.000066\n",
      "  Step 11, Current reward: 0.000071\n",
      "  Step 12, Current reward: 0.000076\n",
      "  Step 13, Current reward: 0.000082\n",
      "  Step 14, Current reward: 0.000087\n",
      "  Step 15, Current reward: 0.000093\n",
      "  Step 16, Current reward: 0.000098\n",
      "  Step 17, Current reward: 0.000102\n",
      "  Step 18, Current reward: 0.000106\n",
      "  Step 19, Current reward: 0.000110\n",
      "  Step 20, Current reward: 0.000114\n",
      "  Step 21, Current reward: 0.000118\n",
      "  Step 22, Current reward: 0.000122\n",
      "  Step 23, Current reward: 0.000126\n",
      "  Step 24, Current reward: 0.000130\n",
      "  Step 25, Current reward: 0.000133\n",
      "  Step 26, Current reward: 0.000136\n",
      "  Step 27, Current reward: 0.000138\n",
      "  Step 28, Current reward: 0.000139\n",
      "  Step 29, Current reward: 0.000139\n",
      "  Step 30, Current reward: 0.000139\n",
      "  Step 31, Current reward: 0.000138\n",
      "  Step 32, Current reward: 0.000136\n",
      "  Step 33, Current reward: 0.000133\n",
      "  Step 34, Current reward: 0.000130\n",
      "  Step 35, Current reward: 0.000126\n",
      "  Step 36, Current reward: 0.000121\n",
      "  Step 37, Current reward: 0.000103\n",
      "  Step 38, Current reward: 0.000085\n",
      "  Step 39, Current reward: 0.000069\n",
      "  Step 40, Current reward: 0.000054\n",
      "Episode 59/100 complete - Max Reward: 0.000139\n",
      "Starting episode 60/100\n",
      "  Step 1, Current reward: 0.002771\n",
      "  Step 2, Current reward: 0.002771\n",
      "  Step 3, Current reward: 0.002771\n",
      "  Step 4, Current reward: 0.002771\n",
      "  Step 5, Current reward: 0.002771\n",
      "  Step 6, Current reward: 0.002771\n",
      "  Step 7, Current reward: 0.002771\n",
      "  Step 8, Current reward: 0.002771\n",
      "  Step 9, Current reward: 0.002771\n",
      "  Step 10, Current reward: 0.002771\n",
      "  Step 11, Current reward: 0.002771\n",
      "  Step 12, Current reward: 0.002771\n",
      "Episode 60/100 complete - Max Reward: 0.002771\n",
      "Starting episode 61/100\n",
      "  Step 1, Current reward: 0.008729\n",
      "  Step 2, Current reward: 0.009412\n",
      "  Step 3, Current reward: 0.008986\n",
      "  Step 4, Current reward: 0.002941\n",
      "  Step 5, Current reward: 0.002827\n",
      "  Step 6, Current reward: 0.003754\n",
      "  Step 7, Current reward: 0.003620\n",
      "  Step 8, Current reward: 0.003483\n",
      "  Step 9, Current reward: 0.005081\n",
      "  Step 10, Current reward: 0.010950\n",
      "  Step 11, Current reward: 0.010399\n",
      "  Step 12, Current reward: 0.009823\n",
      "  Step 13, Current reward: 0.009251\n",
      "  Step 14, Current reward: 0.008735\n",
      "  Step 15, Current reward: 0.008343\n",
      "  Step 16, Current reward: 0.008133\n",
      "  Step 17, Current reward: 0.008127\n",
      "  Step 18, Current reward: 0.008311\n",
      "  Step 19, Current reward: 0.008641\n",
      "  Step 20, Current reward: 0.009063\n",
      "  Step 21, Current reward: 0.009508\n",
      "Episode 61/100 complete - Max Reward: 0.010950\n",
      "Starting episode 62/100\n",
      "  Step 1, Current reward: 0.000499\n",
      "  Step 2, Current reward: 0.000508\n",
      "  Step 3, Current reward: 0.000475\n",
      "  Step 4, Current reward: 0.000455\n",
      "  Step 5, Current reward: 0.000492\n",
      "  Step 6, Current reward: 0.000764\n",
      "  Step 7, Current reward: 0.001251\n",
      "  Step 8, Current reward: 0.000799\n",
      "  Step 9, Current reward: 0.001251\n",
      "  Step 10, Current reward: 0.000799\n",
      "  Step 11, Current reward: 0.001251\n",
      "  Step 12, Current reward: 0.000799\n",
      "  Step 13, Current reward: 0.001251\n",
      "  Step 14, Current reward: 0.000799\n",
      "  Step 15, Current reward: 0.001251\n",
      "  Step 16, Current reward: 0.000799\n",
      "  Step 17, Current reward: 0.001251\n",
      "  Step 18, Current reward: 0.000799\n",
      "Episode 62/100 complete - Max Reward: 0.001251\n",
      "Starting episode 63/100\n",
      "  Step 1, Current reward: 0.000227\n",
      "  Step 2, Current reward: 0.000224\n",
      "  Step 3, Current reward: 0.000222\n",
      "  Step 4, Current reward: 0.000222\n",
      "  Step 5, Current reward: 0.000222\n",
      "  Step 6, Current reward: 0.000223\n",
      "  Step 7, Current reward: 0.000219\n",
      "  Step 8, Current reward: 0.000214\n",
      "  Step 9, Current reward: 0.000210\n",
      "  Step 10, Current reward: 0.000208\n",
      "  Step 11, Current reward: 0.000205\n",
      "  Step 12, Current reward: 0.000203\n",
      "Episode 63/100 complete - Max Reward: 0.000227\n",
      "Starting episode 64/100\n",
      "  Step 1, Current reward: 0.033686\n",
      "  Step 2, Current reward: 0.029010\n",
      "  Step 3, Current reward: 0.025318\n",
      "  Step 4, Current reward: 0.022736\n",
      "  Step 5, Current reward: 0.021258\n",
      "  Step 6, Current reward: 0.020750\n",
      "  Step 7, Current reward: 0.020994\n",
      "  Step 8, Current reward: 0.021735\n",
      "  Step 9, Current reward: 0.016527\n",
      "  Step 10, Current reward: 0.011299\n",
      "  Step 11, Current reward: 0.008184\n",
      "  Step 12, Current reward: 0.008596\n",
      "Episode 64/100 complete - Max Reward: 0.033686\n",
      "Starting episode 65/100\n",
      "  Step 1, Current reward: 0.000278\n",
      "  Step 2, Current reward: 0.000279\n",
      "  Step 3, Current reward: 0.000284\n",
      "  Step 4, Current reward: 0.000288\n",
      "  Step 5, Current reward: 0.000292\n",
      "  Step 6, Current reward: 0.000296\n",
      "  Step 7, Current reward: 0.000299\n",
      "  Step 8, Current reward: 0.000301\n",
      "  Step 9, Current reward: 0.000347\n",
      "  Step 10, Current reward: 0.000813\n",
      "  Step 11, Current reward: 0.001791\n",
      "  Step 12, Current reward: 0.003044\n",
      "  Step 13, Current reward: 0.004280\n",
      "  Step 14, Current reward: 0.005246\n",
      "  Step 15, Current reward: 0.005787\n",
      "  Step 16, Current reward: 0.005758\n",
      "  Step 17, Current reward: 0.005758\n",
      "  Step 18, Current reward: 0.005786\n",
      "  Step 19, Current reward: 0.005804\n",
      "  Step 20, Current reward: 0.005963\n",
      "  Step 21, Current reward: 0.006159\n",
      "  Step 22, Current reward: 0.006302\n",
      "  Step 23, Current reward: 0.006597\n",
      "  Step 24, Current reward: 0.006951\n",
      "  Step 25, Current reward: 0.007231\n",
      "  Step 26, Current reward: 0.007515\n",
      "  Step 27, Current reward: 0.007789\n",
      "  Step 28, Current reward: 0.008388\n",
      "  Step 29, Current reward: 0.008668\n",
      "  Step 30, Current reward: 0.009384\n",
      "  Step 31, Current reward: 0.009325\n",
      "  Step 32, Current reward: 0.009384\n",
      "  Step 33, Current reward: 0.009325\n",
      "  Step 34, Current reward: 0.009384\n",
      "  Step 35, Current reward: 0.009325\n",
      "  Step 36, Current reward: 0.009384\n",
      "  Step 37, Current reward: 0.009325\n",
      "  Step 38, Current reward: 0.009384\n",
      "  Step 39, Current reward: 0.009325\n",
      "  Step 40, Current reward: 0.009384\n",
      "  Step 41, Current reward: 0.009325\n",
      "Episode 65/100 complete - Max Reward: 0.009384\n",
      "Starting episode 66/100\n",
      "  Step 1, Current reward: 0.000761\n",
      "  Step 2, Current reward: 0.000847\n",
      "  Step 3, Current reward: 0.000861\n",
      "  Step 4, Current reward: 0.000807\n",
      "  Step 5, Current reward: 0.000815\n",
      "  Step 6, Current reward: 0.000818\n",
      "  Step 7, Current reward: 0.000819\n",
      "  Step 8, Current reward: 0.000818\n",
      "  Step 9, Current reward: 0.000819\n",
      "  Step 10, Current reward: 0.000824\n",
      "  Step 11, Current reward: 0.000836\n",
      "  Step 12, Current reward: 0.000858\n",
      "  Step 13, Current reward: 0.000890\n",
      "  Step 14, Current reward: 0.000929\n",
      "  Step 15, Current reward: 0.000972\n",
      "  Step 16, Current reward: 0.001018\n",
      "  Step 17, Current reward: 0.001063\n",
      "  Step 18, Current reward: 0.001108\n",
      "  Step 19, Current reward: 0.001156\n",
      "  Step 20, Current reward: 0.001217\n",
      "  Step 21, Current reward: 0.001217\n",
      "  Step 22, Current reward: 0.001217\n",
      "  Step 23, Current reward: 0.001217\n",
      "  Step 24, Current reward: 0.001217\n",
      "  Step 25, Current reward: 0.001217\n",
      "  Step 26, Current reward: 0.001217\n",
      "  Step 27, Current reward: 0.001217\n",
      "  Step 28, Current reward: 0.001217\n",
      "  Step 29, Current reward: 0.001217\n",
      "  Step 30, Current reward: 0.001217\n",
      "  Step 31, Current reward: 0.001217\n",
      "Episode 66/100 complete - Max Reward: 0.001217\n",
      "Starting episode 67/100\n",
      "  Step 1, Current reward: 0.018546\n",
      "  Step 2, Current reward: 0.018827\n",
      "  Step 3, Current reward: 0.014971\n",
      "  Step 4, Current reward: 0.015205\n",
      "  Step 5, Current reward: 0.015428\n",
      "  Step 6, Current reward: 0.015637\n",
      "  Step 7, Current reward: 0.015825\n",
      "  Step 8, Current reward: 0.015987\n",
      "  Step 9, Current reward: 0.016119\n",
      "  Step 10, Current reward: 0.016216\n",
      "  Step 11, Current reward: 0.016275\n",
      "  Step 12, Current reward: 0.016296\n",
      "  Step 13, Current reward: 0.016274\n",
      "Episode 67/100 complete - Max Reward: 0.018827\n",
      "Starting episode 68/100\n",
      "  Step 1, Current reward: 0.000125\n",
      "  Step 2, Current reward: 0.000145\n",
      "  Step 3, Current reward: 0.000133\n",
      "  Step 4, Current reward: 0.000138\n",
      "  Step 5, Current reward: 0.000137\n",
      "  Step 6, Current reward: 0.000138\n",
      "  Step 7, Current reward: 0.000136\n",
      "  Step 8, Current reward: 0.000137\n",
      "  Step 9, Current reward: 0.000219\n",
      "  Step 10, Current reward: 0.000222\n",
      "  Step 11, Current reward: 0.000224\n",
      "  Step 12, Current reward: 0.000227\n",
      "  Step 13, Current reward: 0.000229\n",
      "  Step 14, Current reward: 0.000230\n",
      "  Step 15, Current reward: 0.000231\n",
      "  Step 16, Current reward: 0.000230\n",
      "  Step 17, Current reward: 0.000229\n",
      "  Step 18, Current reward: 0.000227\n",
      "  Step 19, Current reward: 0.000225\n",
      "  Step 20, Current reward: 0.000225\n",
      "  Step 21, Current reward: 0.000225\n",
      "  Step 22, Current reward: 0.000225\n",
      "  Step 23, Current reward: 0.000225\n",
      "  Step 24, Current reward: 0.000225\n",
      "  Step 25, Current reward: 0.000225\n",
      "  Step 26, Current reward: 0.000225\n",
      "Episode 68/100 complete - Max Reward: 0.000231\n",
      "Starting episode 69/100\n",
      "  Step 1, Current reward: 0.011599\n",
      "  Step 2, Current reward: 0.011380\n",
      "  Step 3, Current reward: 0.011189\n",
      "  Step 4, Current reward: 0.011187\n",
      "  Step 5, Current reward: 0.011103\n",
      "  Step 6, Current reward: 0.010970\n",
      "  Step 7, Current reward: 0.010793\n",
      "  Step 8, Current reward: 0.010579\n",
      "  Step 9, Current reward: 0.013209\n",
      "  Step 10, Current reward: 0.013036\n",
      "  Step 11, Current reward: 0.013069\n",
      "  Step 12, Current reward: 0.012927\n",
      "  Step 13, Current reward: 0.012814\n",
      "  Step 14, Current reward: 0.012393\n",
      "  Step 15, Current reward: 0.011973\n",
      "  Step 16, Current reward: 0.011566\n",
      "  Step 17, Current reward: 0.011175\n",
      "  Step 18, Current reward: 0.010791\n",
      "  Step 19, Current reward: 0.011175\n",
      "  Step 20, Current reward: 0.010791\n",
      "Episode 69/100 complete - Max Reward: 0.013209\n",
      "Starting episode 70/100\n",
      "  Step 1, Current reward: 0.001077\n",
      "  Step 2, Current reward: 0.001088\n",
      "  Step 3, Current reward: 0.001103\n",
      "  Step 4, Current reward: 0.001122\n",
      "  Step 5, Current reward: 0.001145\n",
      "  Step 6, Current reward: 0.001173\n",
      "  Step 7, Current reward: 0.001207\n",
      "  Step 8, Current reward: 0.001249\n",
      "  Step 9, Current reward: 0.001299\n",
      "  Step 10, Current reward: 0.001358\n",
      "  Step 11, Current reward: 0.001429\n",
      "  Step 12, Current reward: 0.001511\n",
      "  Step 13, Current reward: 0.001609\n",
      "  Step 14, Current reward: 0.001728\n",
      "  Step 15, Current reward: 0.001878\n",
      "  Step 16, Current reward: 0.002071\n",
      "  Step 17, Current reward: 0.002325\n",
      "  Step 18, Current reward: 0.002661\n",
      "  Step 19, Current reward: 0.003109\n",
      "  Step 20, Current reward: 0.003702\n",
      "  Step 21, Current reward: 0.004482\n",
      "  Step 22, Current reward: 0.005495\n",
      "  Step 23, Current reward: 0.006780\n",
      "  Step 24, Current reward: 0.008354\n",
      "  Step 25, Current reward: 0.010184\n",
      "  Step 26, Current reward: 0.012129\n",
      "  Step 27, Current reward: 0.013872\n",
      "  Step 28, Current reward: 0.014896\n",
      "  Step 29, Current reward: 0.014524\n",
      "  Step 30, Current reward: 0.012263\n",
      "  Step 31, Current reward: 0.012263\n",
      "  Step 32, Current reward: 0.012263\n",
      "  Step 33, Current reward: 0.012263\n",
      "  Step 34, Current reward: 0.012263\n",
      "  Step 35, Current reward: 0.012263\n",
      "  Step 36, Current reward: 0.012263\n",
      "  Step 37, Current reward: 0.012263\n",
      "  Step 38, Current reward: 0.012263\n",
      "  Step 39, Current reward: 0.012263\n",
      "Episode 70/100 complete - Max Reward: 0.014896\n",
      "Starting episode 71/100\n",
      "  Step 1, Current reward: 0.063792\n",
      "  Step 2, Current reward: 0.063120\n",
      "  Step 3, Current reward: 0.062400\n",
      "  Step 4, Current reward: 0.062400\n",
      "  Step 5, Current reward: 0.062400\n",
      "  Step 6, Current reward: 0.062400\n",
      "  Step 7, Current reward: 0.062400\n",
      "  Step 8, Current reward: 0.062400\n",
      "  Step 9, Current reward: 0.062400\n",
      "  Step 10, Current reward: 0.062400\n",
      "  Step 11, Current reward: 0.062400\n",
      "  Step 12, Current reward: 0.062400\n",
      "Episode 71/100 complete - Max Reward: 0.063792\n",
      "Starting episode 72/100\n",
      "  Step 1, Current reward: 0.059737\n",
      "  Step 2, Current reward: 0.060896\n",
      "  Step 3, Current reward: 0.061334\n",
      "  Step 4, Current reward: 0.061183\n",
      "  Step 5, Current reward: 0.060491\n",
      "  Step 6, Current reward: 0.071212\n",
      "  Step 7, Current reward: 0.072123\n",
      "  Step 8, Current reward: 0.077914\n",
      "  Step 9, Current reward: 0.084034\n",
      "  Step 10, Current reward: 0.090045\n",
      "  Step 11, Current reward: 0.095153\n",
      "  Step 12, Current reward: 0.095153\n",
      "  Step 13, Current reward: 0.095153\n",
      "  Step 14, Current reward: 0.095153\n",
      "  Step 15, Current reward: 0.095153\n",
      "  Step 16, Current reward: 0.095153\n",
      "  Step 17, Current reward: 0.095153\n",
      "  Step 18, Current reward: 0.095153\n",
      "  Step 19, Current reward: 0.095153\n",
      "  Step 20, Current reward: 0.095153\n",
      "  Step 21, Current reward: 0.095153\n",
      "  Step 22, Current reward: 0.095153\n",
      "Episode 72/100 complete - Max Reward: 0.095153\n",
      "Starting episode 73/100\n",
      "  Step 1, Current reward: 0.000435\n",
      "  Step 2, Current reward: 0.000407\n",
      "  Step 3, Current reward: 0.000384\n",
      "  Step 4, Current reward: 0.000365\n",
      "  Step 5, Current reward: 0.000352\n",
      "  Step 6, Current reward: 0.000343\n",
      "  Step 7, Current reward: 0.000338\n",
      "  Step 8, Current reward: 0.000337\n",
      "  Step 9, Current reward: 0.000337\n",
      "  Step 10, Current reward: 0.000340\n",
      "  Step 11, Current reward: 0.000342\n",
      "  Step 12, Current reward: 0.000345\n",
      "Episode 73/100 complete - Max Reward: 0.000435\n",
      "Starting episode 74/100\n",
      "  Step 1, Current reward: 0.000547\n",
      "  Step 2, Current reward: 0.000474\n",
      "  Step 3, Current reward: 0.000515\n",
      "  Step 4, Current reward: 0.000518\n",
      "  Step 5, Current reward: 0.000527\n",
      "  Step 6, Current reward: 0.000549\n",
      "  Step 7, Current reward: 0.000702\n",
      "  Step 8, Current reward: 0.000935\n",
      "  Step 9, Current reward: 0.000935\n",
      "  Step 10, Current reward: 0.000935\n",
      "  Step 11, Current reward: 0.000935\n",
      "  Step 12, Current reward: 0.000935\n",
      "  Step 13, Current reward: 0.000935\n",
      "  Step 14, Current reward: 0.000935\n",
      "  Step 15, Current reward: 0.000935\n",
      "  Step 16, Current reward: 0.000935\n",
      "  Step 17, Current reward: 0.000935\n",
      "  Step 18, Current reward: 0.000935\n",
      "  Step 19, Current reward: 0.000935\n",
      "Episode 74/100 complete - Max Reward: 0.000935\n",
      "Starting episode 75/100\n",
      "  Step 1, Current reward: 0.011537\n",
      "  Step 2, Current reward: 0.013613\n",
      "  Step 3, Current reward: 0.015883\n",
      "  Step 4, Current reward: 0.018308\n",
      "  Step 5, Current reward: 0.020873\n",
      "  Step 6, Current reward: 0.023591\n",
      "  Step 7, Current reward: 0.026485\n",
      "  Step 8, Current reward: 0.029586\n",
      "  Step 9, Current reward: 0.032916\n",
      "  Step 10, Current reward: 0.023340\n",
      "  Step 11, Current reward: 0.023340\n",
      "  Step 12, Current reward: 0.023340\n",
      "  Step 13, Current reward: 0.023340\n",
      "  Step 14, Current reward: 0.023340\n",
      "  Step 15, Current reward: 0.023340\n",
      "  Step 16, Current reward: 0.023340\n",
      "  Step 17, Current reward: 0.023340\n",
      "  Step 18, Current reward: 0.023340\n",
      "  Step 19, Current reward: 0.023340\n",
      "  Step 20, Current reward: 0.023340\n",
      "Episode 75/100 complete - Max Reward: 0.032916\n",
      "Starting episode 76/100\n",
      "  Step 1, Current reward: 0.041638\n",
      "  Step 2, Current reward: 0.032617\n",
      "  Step 3, Current reward: 0.031846\n",
      "  Step 4, Current reward: 0.031899\n",
      "  Step 5, Current reward: 0.031953\n",
      "  Step 6, Current reward: 0.032024\n",
      "  Step 7, Current reward: 0.032119\n",
      "  Step 8, Current reward: 0.032236\n",
      "  Step 9, Current reward: 0.031605\n",
      "  Step 10, Current reward: 0.032179\n",
      "  Step 11, Current reward: 0.032390\n",
      "  Step 12, Current reward: 0.032799\n",
      "Episode 76/100 complete - Max Reward: 0.041638\n",
      "Starting episode 77/100\n",
      "  Step 1, Current reward: 0.002027\n",
      "  Step 2, Current reward: 0.001965\n",
      "  Step 3, Current reward: 0.001896\n",
      "  Step 4, Current reward: 0.001824\n",
      "  Step 5, Current reward: 0.001752\n",
      "  Step 6, Current reward: 0.001685\n",
      "  Step 7, Current reward: 0.001643\n",
      "  Step 8, Current reward: 0.001668\n",
      "  Step 9, Current reward: 0.001726\n",
      "  Step 10, Current reward: 0.001846\n",
      "  Step 11, Current reward: 0.002268\n",
      "  Step 12, Current reward: 0.003013\n",
      "  Step 13, Current reward: 0.003237\n",
      "  Step 14, Current reward: 0.002413\n",
      "  Step 15, Current reward: 0.001543\n",
      "  Step 16, Current reward: 0.001541\n",
      "  Step 17, Current reward: 0.001541\n",
      "  Step 18, Current reward: 0.001541\n",
      "  Step 19, Current reward: 0.001541\n",
      "  Step 20, Current reward: 0.001541\n",
      "  Step 21, Current reward: 0.001541\n",
      "  Step 22, Current reward: 0.001541\n",
      "  Step 23, Current reward: 0.001541\n",
      "  Step 24, Current reward: 0.001541\n",
      "Episode 77/100 complete - Max Reward: 0.003237\n",
      "Starting episode 78/100\n",
      "  Step 1, Current reward: 0.000033\n",
      "  Step 2, Current reward: 0.000033\n",
      "  Step 3, Current reward: 0.000033\n",
      "  Step 4, Current reward: 0.000033\n",
      "  Step 5, Current reward: 0.000033\n",
      "  Step 6, Current reward: 0.000033\n",
      "  Step 7, Current reward: 0.000033\n",
      "  Step 8, Current reward: 0.000033\n",
      "  Step 9, Current reward: 0.000033\n",
      "  Step 10, Current reward: 0.000033\n",
      "  Step 11, Current reward: 0.000033\n",
      "  Step 12, Current reward: 0.000033\n",
      "Episode 78/100 complete - Max Reward: 0.000033\n",
      "Starting episode 79/100\n",
      "  Step 1, Current reward: 0.000150\n",
      "  Step 2, Current reward: 0.000177\n",
      "  Step 3, Current reward: 0.000175\n",
      "  Step 4, Current reward: 0.000156\n",
      "  Step 5, Current reward: 0.000163\n",
      "  Step 6, Current reward: 0.000167\n",
      "  Step 7, Current reward: 0.000165\n",
      "  Step 8, Current reward: 0.000162\n",
      "  Step 9, Current reward: 0.000158\n",
      "  Step 10, Current reward: 0.000152\n",
      "  Step 11, Current reward: 0.000144\n",
      "  Step 12, Current reward: 0.000134\n",
      "  Step 13, Current reward: 0.000124\n",
      "Episode 79/100 complete - Max Reward: 0.000177\n",
      "Starting episode 80/100\n",
      "  Step 1, Current reward: 0.041531\n",
      "  Step 2, Current reward: 0.041784\n",
      "  Step 3, Current reward: 0.039622\n",
      "  Step 4, Current reward: 0.039085\n",
      "  Step 5, Current reward: 0.035358\n",
      "  Step 6, Current reward: 0.030607\n",
      "  Step 7, Current reward: 0.035993\n",
      "  Step 8, Current reward: 0.029478\n",
      "  Step 9, Current reward: 0.023409\n",
      "  Step 10, Current reward: 0.018389\n",
      "  Step 11, Current reward: 0.014738\n",
      "  Step 12, Current reward: 0.012400\n",
      "  Step 13, Current reward: 0.010959\n",
      "Episode 80/100 complete - Max Reward: 0.041784\n",
      "Starting episode 81/100\n",
      "  Step 1, Current reward: 0.009642\n",
      "  Step 2, Current reward: 0.009079\n",
      "  Step 3, Current reward: 0.008499\n",
      "  Step 4, Current reward: 0.008143\n",
      "  Step 5, Current reward: 0.008365\n",
      "  Step 6, Current reward: 0.009240\n",
      "  Step 7, Current reward: 0.010625\n",
      "  Step 8, Current reward: 0.013614\n",
      "  Step 9, Current reward: 0.013561\n",
      "  Step 10, Current reward: 0.013651\n",
      "  Step 11, Current reward: 0.012347\n",
      "  Step 12, Current reward: 0.016851\n",
      "  Step 13, Current reward: 0.015458\n",
      "  Step 14, Current reward: 0.014177\n",
      "  Step 15, Current reward: 0.013017\n",
      "  Step 16, Current reward: 0.011984\n",
      "  Step 17, Current reward: 0.010850\n",
      "  Step 18, Current reward: 0.010036\n",
      "  Step 19, Current reward: 0.009334\n",
      "  Step 20, Current reward: 0.008736\n",
      "  Step 21, Current reward: 0.008230\n",
      "  Step 22, Current reward: 0.006359\n",
      "  Step 23, Current reward: 0.004889\n",
      "Episode 81/100 complete - Max Reward: 0.016851\n",
      "Starting episode 82/100\n",
      "  Step 1, Current reward: 0.000550\n",
      "  Step 2, Current reward: 0.000550\n",
      "  Step 3, Current reward: 0.000550\n",
      "  Step 4, Current reward: 0.000550\n",
      "  Step 5, Current reward: 0.000550\n",
      "  Step 6, Current reward: 0.000550\n",
      "  Step 7, Current reward: 0.000550\n",
      "  Step 8, Current reward: 0.000550\n",
      "  Step 9, Current reward: 0.000550\n",
      "  Step 10, Current reward: 0.000550\n",
      "  Step 11, Current reward: 0.000550\n",
      "  Step 12, Current reward: 0.000550\n",
      "Episode 82/100 complete - Max Reward: 0.000550\n",
      "Starting episode 83/100\n",
      "  Step 1, Current reward: 0.012140\n",
      "  Step 2, Current reward: 0.019334\n",
      "  Step 3, Current reward: 0.024407\n",
      "  Step 4, Current reward: 0.025944\n",
      "  Step 5, Current reward: 0.023827\n",
      "  Step 6, Current reward: 0.019052\n",
      "  Step 7, Current reward: 0.018741\n",
      "  Step 8, Current reward: 0.018493\n",
      "  Step 9, Current reward: 0.017163\n",
      "  Step 10, Current reward: 0.017415\n",
      "  Step 11, Current reward: 0.017941\n",
      "  Step 12, Current reward: 0.017648\n",
      "  Step 13, Current reward: 0.017850\n",
      "  Step 14, Current reward: 0.017843\n",
      "  Step 15, Current reward: 0.017849\n",
      "Episode 83/100 complete - Max Reward: 0.025944\n",
      "Starting episode 84/100\n",
      "  Step 1, Current reward: 0.007127\n",
      "  Step 2, Current reward: 0.007252\n",
      "  Step 3, Current reward: 0.006259\n",
      "  Step 4, Current reward: 0.006375\n",
      "  Step 5, Current reward: 0.006468\n",
      "  Step 6, Current reward: 0.006579\n",
      "  Step 7, Current reward: 0.006712\n",
      "  Step 8, Current reward: 0.006862\n",
      "  Step 9, Current reward: 0.007021\n",
      "  Step 10, Current reward: 0.007182\n",
      "  Step 11, Current reward: 0.007339\n",
      "  Step 12, Current reward: 0.007488\n",
      "  Step 13, Current reward: 0.005862\n",
      "  Step 14, Current reward: 0.006015\n",
      "  Step 15, Current reward: 0.011062\n",
      "  Step 16, Current reward: 0.010992\n",
      "  Step 17, Current reward: 0.010823\n",
      "  Step 18, Current reward: 0.010578\n",
      "  Step 19, Current reward: 0.010279\n",
      "  Step 20, Current reward: 0.009948\n",
      "  Step 21, Current reward: 0.009600\n",
      "  Step 22, Current reward: 0.009250\n",
      "  Step 23, Current reward: 0.008908\n",
      "  Step 24, Current reward: 0.008582\n",
      "  Step 25, Current reward: 0.008277\n",
      "  Step 26, Current reward: 0.007996\n",
      "Episode 84/100 complete - Max Reward: 0.011062\n",
      "Starting episode 85/100\n",
      "  Step 1, Current reward: 0.000237\n",
      "  Step 2, Current reward: 0.000271\n",
      "  Step 3, Current reward: 0.000271\n",
      "  Step 4, Current reward: 0.000271\n",
      "  Step 5, Current reward: 0.000271\n",
      "  Step 6, Current reward: 0.000271\n",
      "  Step 7, Current reward: 0.000271\n",
      "  Step 8, Current reward: 0.000271\n",
      "  Step 9, Current reward: 0.000271\n",
      "  Step 10, Current reward: 0.000271\n",
      "  Step 11, Current reward: 0.000271\n",
      "  Step 12, Current reward: 0.000271\n",
      "  Step 13, Current reward: 0.000271\n",
      "Episode 85/100 complete - Max Reward: 0.000271\n",
      "Starting episode 86/100\n",
      "  Step 1, Current reward: 0.009566\n",
      "  Step 2, Current reward: 0.010442\n",
      "  Step 3, Current reward: 0.011190\n",
      "  Step 4, Current reward: 0.011674\n",
      "  Step 5, Current reward: 0.011716\n",
      "  Step 6, Current reward: 0.011716\n",
      "  Step 7, Current reward: 0.011716\n",
      "  Step 8, Current reward: 0.011716\n",
      "  Step 9, Current reward: 0.011716\n",
      "  Step 10, Current reward: 0.011716\n",
      "  Step 11, Current reward: 0.011716\n",
      "  Step 12, Current reward: 0.011716\n",
      "  Step 13, Current reward: 0.011716\n",
      "  Step 14, Current reward: 0.011716\n",
      "  Step 15, Current reward: 0.011716\n",
      "  Step 16, Current reward: 0.011716\n",
      "Episode 86/100 complete - Max Reward: 0.011716\n",
      "Starting episode 87/100\n",
      "  Step 1, Current reward: 0.014626\n",
      "  Step 2, Current reward: 0.018184\n",
      "  Step 3, Current reward: 0.020332\n",
      "  Step 4, Current reward: 0.020747\n",
      "  Step 5, Current reward: 0.019734\n",
      "  Step 6, Current reward: 0.018062\n",
      "  Step 7, Current reward: 0.015642\n",
      "  Step 8, Current reward: 0.013257\n",
      "  Step 9, Current reward: 0.011148\n",
      "  Step 10, Current reward: 0.009397\n",
      "  Step 11, Current reward: 0.007997\n",
      "  Step 12, Current reward: 0.006902\n",
      "  Step 13, Current reward: 0.005925\n",
      "  Step 14, Current reward: 0.005978\n",
      "  Step 15, Current reward: 0.006464\n",
      "Episode 87/100 complete - Max Reward: 0.020747\n",
      "Starting episode 88/100\n",
      "  Step 1, Current reward: 0.000426\n",
      "  Step 2, Current reward: 0.000441\n",
      "  Step 3, Current reward: 0.000456\n",
      "  Step 4, Current reward: 0.000470\n",
      "  Step 5, Current reward: 0.000479\n",
      "  Step 6, Current reward: 0.000479\n",
      "  Step 7, Current reward: 0.000466\n",
      "  Step 8, Current reward: 0.000441\n",
      "  Step 9, Current reward: 0.000405\n",
      "  Step 10, Current reward: 0.000362\n",
      "  Step 11, Current reward: 0.000296\n",
      "  Step 12, Current reward: 0.000296\n",
      "  Step 13, Current reward: 0.000296\n",
      "  Step 14, Current reward: 0.000296\n",
      "  Step 15, Current reward: 0.000296\n",
      "  Step 16, Current reward: 0.000296\n",
      "Episode 88/100 complete - Max Reward: 0.000479\n",
      "Starting episode 89/100\n",
      "  Step 1, Current reward: 0.000077\n",
      "  Step 2, Current reward: 0.000087\n",
      "  Step 3, Current reward: 0.000115\n",
      "  Step 4, Current reward: 0.000134\n",
      "  Step 5, Current reward: 0.000161\n",
      "  Step 6, Current reward: 0.000207\n",
      "  Step 7, Current reward: 0.000252\n",
      "  Step 8, Current reward: 0.000272\n",
      "  Step 9, Current reward: 0.000254\n",
      "  Step 10, Current reward: 0.000201\n",
      "  Step 11, Current reward: 0.000136\n",
      "  Step 12, Current reward: 0.000088\n",
      "  Step 13, Current reward: 0.000074\n",
      "  Step 14, Current reward: 0.000085\n",
      "  Step 15, Current reward: 0.000091\n",
      "  Step 16, Current reward: 0.000069\n",
      "  Step 17, Current reward: 0.000030\n",
      "  Step 18, Current reward: 0.000007\n",
      "  Step 19, Current reward: 0.000004\n",
      "Episode 89/100 complete - Max Reward: 0.000272\n",
      "Starting episode 90/100\n",
      "  Step 1, Current reward: 0.202864\n",
      "  Step 2, Current reward: 0.198680\n",
      "  Step 3, Current reward: 0.194049\n",
      "  Step 4, Current reward: 0.189515\n",
      "  Step 5, Current reward: 0.185527\n",
      "  Step 6, Current reward: 0.182396\n",
      "  Step 7, Current reward: 0.178914\n",
      "  Step 8, Current reward: 0.177789\n",
      "  Step 9, Current reward: 0.177735\n",
      "  Step 10, Current reward: 0.178701\n",
      "  Step 11, Current reward: 0.180570\n",
      "  Step 12, Current reward: 0.183186\n",
      "Episode 90/100 complete - Max Reward: 0.202864\n",
      "Starting episode 91/100\n",
      "  Step 1, Current reward: 0.009888\n",
      "  Step 2, Current reward: 0.012711\n",
      "  Step 3, Current reward: 0.012344\n",
      "  Step 4, Current reward: 0.017172\n",
      "  Step 5, Current reward: 0.016079\n",
      "  Step 6, Current reward: 0.019082\n",
      "  Step 7, Current reward: 0.019001\n",
      "  Step 8, Current reward: 0.015461\n",
      "  Step 9, Current reward: 0.009942\n",
      "  Step 10, Current reward: 0.005445\n",
      "  Step 11, Current reward: 0.004692\n",
      "  Step 12, Current reward: 0.007851\n",
      "  Step 13, Current reward: 0.008632\n",
      "  Step 14, Current reward: 0.013010\n",
      "  Step 15, Current reward: 0.014317\n",
      "  Step 16, Current reward: 0.010752\n",
      "  Step 17, Current reward: 0.010122\n",
      "Episode 91/100 complete - Max Reward: 0.019082\n",
      "Starting episode 92/100\n",
      "  Step 1, Current reward: 0.013651\n",
      "  Step 2, Current reward: 0.014821\n",
      "  Step 3, Current reward: 0.015996\n",
      "  Step 4, Current reward: 0.016979\n",
      "  Step 5, Current reward: 0.017517\n",
      "  Step 6, Current reward: 0.017350\n",
      "  Step 7, Current reward: 0.017097\n",
      "  Step 8, Current reward: 0.016080\n",
      "  Step 9, Current reward: 0.015666\n",
      "  Step 10, Current reward: 0.014717\n",
      "  Step 11, Current reward: 0.014325\n",
      "  Step 12, Current reward: 0.013948\n",
      "  Step 13, Current reward: 0.013605\n",
      "  Step 14, Current reward: 0.013289\n",
      "  Step 15, Current reward: 0.012999\n",
      "  Step 16, Current reward: 0.012767\n",
      "Episode 92/100 complete - Max Reward: 0.017517\n",
      "Starting episode 93/100\n",
      "  Step 1, Current reward: 0.002984\n",
      "  Step 2, Current reward: 0.003553\n",
      "  Step 3, Current reward: 0.006897\n",
      "  Step 4, Current reward: 0.012080\n",
      "  Step 5, Current reward: 0.015559\n",
      "  Step 6, Current reward: 0.013927\n",
      "  Step 7, Current reward: 0.007980\n",
      "  Step 8, Current reward: 0.003182\n",
      "  Step 9, Current reward: 0.003094\n",
      "  Step 10, Current reward: 0.004130\n",
      "  Step 11, Current reward: 0.008555\n",
      "  Step 12, Current reward: 0.009279\n",
      "  Step 13, Current reward: 0.005200\n",
      "  Step 14, Current reward: 0.002256\n",
      "  Step 15, Current reward: 0.001968\n",
      "  Step 16, Current reward: 0.002081\n",
      "Episode 93/100 complete - Max Reward: 0.015559\n",
      "Starting episode 94/100\n",
      "  Step 1, Current reward: 0.028762\n",
      "  Step 2, Current reward: 0.031131\n",
      "  Step 3, Current reward: 0.035031\n",
      "  Step 4, Current reward: 0.038148\n",
      "  Step 5, Current reward: 0.041360\n",
      "  Step 6, Current reward: 0.044558\n",
      "  Step 7, Current reward: 0.047586\n",
      "  Step 8, Current reward: 0.050253\n",
      "  Step 9, Current reward: 0.052311\n",
      "  Step 10, Current reward: 0.053546\n",
      "  Step 11, Current reward: 0.053729\n",
      "  Step 12, Current reward: 0.052705\n",
      "  Step 13, Current reward: 0.050482\n",
      "  Step 14, Current reward: 0.057234\n",
      "  Step 15, Current reward: 0.064638\n",
      "  Step 16, Current reward: 0.071822\n",
      "  Step 17, Current reward: 0.055372\n",
      "  Step 18, Current reward: 0.059992\n",
      "  Step 19, Current reward: 0.055600\n",
      "  Step 20, Current reward: 0.049601\n",
      "  Step 21, Current reward: 0.048329\n",
      "  Step 22, Current reward: 0.049267\n",
      "  Step 23, Current reward: 0.040438\n",
      "  Step 24, Current reward: 0.030551\n",
      "  Step 25, Current reward: 0.021091\n",
      "  Step 26, Current reward: 0.021091\n",
      "  Step 27, Current reward: 0.021091\n",
      "Episode 94/100 complete - Max Reward: 0.071822\n",
      "Starting episode 95/100\n",
      "  Step 1, Current reward: 0.002203\n",
      "  Step 2, Current reward: 0.001938\n",
      "  Step 3, Current reward: 0.001947\n",
      "  Step 4, Current reward: 0.001917\n",
      "  Step 5, Current reward: 0.001926\n",
      "  Step 6, Current reward: 0.001934\n",
      "  Step 7, Current reward: 0.001946\n",
      "  Step 8, Current reward: 0.001961\n",
      "  Step 9, Current reward: 0.001978\n",
      "  Step 10, Current reward: 0.001995\n",
      "  Step 11, Current reward: 0.002014\n",
      "  Step 12, Current reward: 0.002036\n",
      "Episode 95/100 complete - Max Reward: 0.002203\n",
      "Starting episode 96/100\n",
      "  Step 1, Current reward: 0.002961\n",
      "  Step 2, Current reward: 0.002985\n",
      "  Step 3, Current reward: 0.003035\n",
      "  Step 4, Current reward: 0.003094\n",
      "  Step 5, Current reward: 0.003159\n",
      "  Step 6, Current reward: 0.003225\n",
      "  Step 7, Current reward: 0.003292\n",
      "  Step 8, Current reward: 0.003288\n",
      "  Step 9, Current reward: 0.003288\n",
      "  Step 10, Current reward: 0.003288\n",
      "  Step 11, Current reward: 0.003288\n",
      "  Step 12, Current reward: 0.003288\n",
      "  Step 13, Current reward: 0.003288\n",
      "  Step 14, Current reward: 0.003288\n",
      "  Step 15, Current reward: 0.003288\n",
      "  Step 16, Current reward: 0.003288\n",
      "  Step 17, Current reward: 0.003288\n",
      "  Step 18, Current reward: 0.003288\n",
      "Episode 96/100 complete - Max Reward: 0.003292\n",
      "Starting episode 97/100\n",
      "  Step 1, Current reward: 0.001813\n",
      "  Step 2, Current reward: 0.001856\n",
      "  Step 3, Current reward: 0.001818\n",
      "  Step 4, Current reward: 0.001686\n",
      "  Step 5, Current reward: 0.001458\n",
      "  Step 6, Current reward: 0.001458\n",
      "  Step 7, Current reward: 0.001458\n",
      "  Step 8, Current reward: 0.001458\n",
      "  Step 9, Current reward: 0.001458\n",
      "  Step 10, Current reward: 0.001458\n",
      "  Step 11, Current reward: 0.001458\n",
      "  Step 12, Current reward: 0.001458\n",
      "  Step 13, Current reward: 0.001458\n",
      "Episode 97/100 complete - Max Reward: 0.001856\n",
      "Starting episode 98/100\n",
      "  Step 1, Current reward: 0.045365\n",
      "  Step 2, Current reward: 0.044353\n",
      "  Step 3, Current reward: 0.043432\n",
      "  Step 4, Current reward: 0.042150\n",
      "  Step 5, Current reward: 0.041594\n",
      "  Step 6, Current reward: 0.040453\n",
      "  Step 7, Current reward: 0.038739\n",
      "  Step 8, Current reward: 0.036586\n",
      "  Step 9, Current reward: 0.034285\n",
      "  Step 10, Current reward: 0.032421\n",
      "  Step 11, Current reward: 0.032421\n",
      "  Step 12, Current reward: 0.032421\n",
      "Episode 98/100 complete - Max Reward: 0.045365\n",
      "Starting episode 99/100\n",
      "  Step 1, Current reward: 0.000566\n",
      "  Step 2, Current reward: 0.000566\n",
      "  Step 3, Current reward: 0.000566\n",
      "  Step 4, Current reward: 0.000566\n",
      "  Step 5, Current reward: 0.000566\n",
      "  Step 6, Current reward: 0.000566\n",
      "  Step 7, Current reward: 0.000566\n",
      "  Step 8, Current reward: 0.000566\n",
      "  Step 9, Current reward: 0.000566\n",
      "  Step 10, Current reward: 0.000566\n",
      "  Step 11, Current reward: 0.000566\n",
      "  Step 12, Current reward: 0.000566\n",
      "Episode 99/100 complete - Max Reward: 0.000566\n",
      "Starting episode 100/100\n",
      "  Step 1, Current reward: 0.008518\n",
      "  Step 2, Current reward: 0.009640\n",
      "  Step 3, Current reward: 0.010918\n",
      "  Step 4, Current reward: 0.011514\n",
      "  Step 5, Current reward: 0.012111\n",
      "  Step 6, Current reward: 0.012688\n",
      "  Step 7, Current reward: 0.013226\n",
      "  Step 8, Current reward: 0.012688\n",
      "  Step 9, Current reward: 0.013226\n",
      "  Step 10, Current reward: 0.012688\n",
      "  Step 11, Current reward: 0.013226\n",
      "  Step 12, Current reward: 0.012688\n",
      "  Step 13, Current reward: 0.013226\n",
      "  Step 14, Current reward: 0.012688\n",
      "  Step 15, Current reward: 0.013226\n",
      "  Step 16, Current reward: 0.012688\n",
      "  Step 17, Current reward: 0.013226\n",
      "  Step 18, Current reward: 0.012688\n",
      "Episode 100/100 complete - Max Reward: 0.013226\n"
     ]
    }
   ],
   "source": [
    "ib_all_ep_rewards, ib_best_rewards, ib_optimal_states_all = ib_dqn.evaluate(num_episodes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebafda3-15e2-454e-8cf0-2f40717f63b6",
   "metadata": {},
   "source": [
    "## Advection Diffusion Reaction Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06c84785-a4a4-42b6-8229-818b2a210fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "adr_config = ADRConfig()\n",
    "adr_eq = ADR(adr_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c6d97136-dc0c-4a13-8539-dedb6f809d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "gym_config = OEDGymConfig()\n",
    "gym_config.n_sensor = 2\n",
    "\n",
    "adr_dqn = DQN_OED(seed, pde_system=adr_eq, gym_config=gym_config, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e260d9d-a765-4e42-8f64-ea053f7e7987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tensorboard/DQN_22\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | -inf     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 756      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 1766     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 47.6     |\n",
      "|    n_updates        | 416      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.4     |\n",
      "|    ep_rew_mean      | -inf     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 710      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 3505     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 40.3     |\n",
      "|    n_updates        | 851      |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = \"adr_dqn_1\"\n",
    "adr_dqn.train(model_name, total_timesteps=5000, log_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e2c56954-0e02-4018-a189-1549a4317d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 5)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adr_dqn.env.modes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02581272-63ca-4cb2-8583-c96352087e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode 1/100\n",
      "  Step 1, Current reward: -41.005670\n",
      "  Step 2, Current reward: -40.732275\n",
      "  Step 3, Current reward: -40.541639\n",
      "  Step 4, Current reward: -40.431932\n",
      "  Step 5, Current reward: -40.402407\n",
      "  Step 6, Current reward: -40.453516\n",
      "  Step 7, Current reward: -40.587195\n",
      "  Step 8, Current reward: -40.807415\n",
      "  Step 9, Current reward: -41.121207\n",
      "  Step 10, Current reward: -41.540662\n",
      "  Step 11, Current reward: -42.087122\n",
      "  Step 12, Current reward: -42.801279\n",
      "  Step 13, Current reward: -43.772962\n",
      "  Step 14, Current reward: -45.268624\n",
      "  Step 15, Current reward: -49.426770\n",
      "  Step 16, Current reward: -46.616453\n",
      "Episode 1/100 complete - Max Reward: -40.402407\n",
      "Starting episode 2/100\n",
      "  Step 1, Current reward: -49.024111\n",
      "  Step 2, Current reward: -49.554146\n",
      "  Step 3, Current reward: -50.165037\n",
      "  Step 4, Current reward: -50.862308\n",
      "  Step 5, Current reward: -51.654561\n",
      "  Step 6, Current reward: -52.555369\n",
      "  Step 7, Current reward: -53.587158\n",
      "  Step 8, Current reward: -54.790270\n",
      "  Step 9, Current reward: -56.248781\n",
      "  Step 10, Current reward: -58.194027\n",
      "  Step 11, Current reward: -62.029433\n",
      "  Step 12, Current reward: -61.217171\n",
      "Episode 2/100 complete - Max Reward: -49.024111\n",
      "Starting episode 3/100\n",
      "  Step 1, Current reward: -63.618922\n",
      "  Step 2, Current reward: -63.713662\n",
      "  Step 3, Current reward: -63.834976\n",
      "  Step 4, Current reward: -63.972515\n",
      "  Step 5, Current reward: -64.102906\n",
      "  Step 6, Current reward: -64.188598\n",
      "  Step 7, Current reward: -64.186034\n",
      "  Step 8, Current reward: -64.066316\n",
      "  Step 9, Current reward: -63.835544\n",
      "  Step 10, Current reward: -63.533785\n",
      "  Step 11, Current reward: -63.214327\n",
      "  Step 12, Current reward: -62.924872\n",
      "  Step 13, Current reward: -62.701586\n",
      "  Step 14, Current reward: -62.572039\n",
      "  Step 15, Current reward: -62.561281\n",
      "  Step 16, Current reward: -62.699422\n",
      "  Step 17, Current reward: -63.033537\n",
      "  Step 18, Current reward: -63.655968\n",
      "  Step 19, Current reward: -64.810767\n",
      "  Step 20, Current reward: -67.915640\n",
      "  Step 21, Current reward: -66.534152\n",
      "  Step 22, Current reward: -65.459647\n",
      "  Step 23, Current reward: -66.136351\n",
      "  Step 24, Current reward: -66.951221\n",
      "  Step 25, Current reward: -63.486254\n",
      "  Step 26, Current reward: -61.899787\n",
      "  Step 27, Current reward: -60.830577\n",
      "  Step 28, Current reward: -60.036972\n",
      "  Step 29, Current reward: -59.426515\n",
      "  Step 30, Current reward: -58.952670\n",
      "  Step 31, Current reward: -58.588226\n",
      "  Step 32, Current reward: -58.315660\n",
      "  Step 33, Current reward: -58.122903\n",
      "  Step 34, Current reward: -58.001215\n",
      "  Step 35, Current reward: -57.944007\n",
      "  Step 36, Current reward: -57.946160\n",
      "  Step 37, Current reward: -58.003586\n",
      "  Step 38, Current reward: -58.112955\n",
      "  Step 39, Current reward: -58.112955\n",
      "  Step 40, Current reward: -58.112955\n",
      "  Step 41, Current reward: -58.112955\n",
      "  Step 42, Current reward: -58.112955\n",
      "  Step 43, Current reward: -58.112955\n",
      "  Step 44, Current reward: -58.112955\n",
      "  Step 45, Current reward: -58.112955\n",
      "  Step 46, Current reward: -58.112955\n",
      "Episode 3/100 complete - Max Reward: -57.944007\n",
      "Starting episode 4/100\n",
      "  Step 1, Current reward: -51.794913\n",
      "  Step 2, Current reward: -49.885785\n",
      "  Step 3, Current reward: -47.975964\n",
      "  Step 4, Current reward: -46.978536\n",
      "  Step 5, Current reward: -46.341317\n",
      "  Step 6, Current reward: -45.922805\n",
      "  Step 7, Current reward: -45.666704\n",
      "  Step 8, Current reward: -45.546847\n",
      "  Step 9, Current reward: -45.551363\n",
      "  Step 10, Current reward: -45.677178\n",
      "  Step 11, Current reward: -45.928485\n",
      "  Step 12, Current reward: -46.317751\n",
      "  Step 13, Current reward: -46.870034\n",
      "  Step 14, Current reward: -47.634872\n",
      "  Step 15, Current reward: -48.723619\n",
      "  Step 16, Current reward: -50.484748\n",
      "  Step 17, Current reward: -inf\n",
      "  Step 18, Current reward: -51.595145\n",
      "  Step 19, Current reward: -51.018464\n",
      "Episode 4/100 complete - Max Reward: -45.546847\n",
      "Starting episode 5/100\n",
      "  Step 1, Current reward: -46.865192\n",
      "  Step 2, Current reward: -47.220486\n",
      "  Step 3, Current reward: -47.814432\n",
      "  Step 4, Current reward: -48.809139\n",
      "  Step 5, Current reward: -50.917427\n",
      "  Step 6, Current reward: -51.610796\n",
      "  Step 7, Current reward: -49.425738\n",
      "  Step 8, Current reward: -48.644558\n",
      "  Step 9, Current reward: -48.300224\n",
      "  Step 10, Current reward: -48.200870\n",
      "  Step 11, Current reward: -48.275867\n",
      "  Step 12, Current reward: -48.493652\n",
      "Episode 5/100 complete - Max Reward: -46.865192\n",
      "Starting episode 6/100\n",
      "  Step 1, Current reward: -45.912462\n",
      "  Step 2, Current reward: -45.489316\n",
      "  Step 3, Current reward: -45.096985\n",
      "  Step 4, Current reward: -44.741403\n",
      "  Step 5, Current reward: -44.426357\n",
      "  Step 6, Current reward: -44.154212\n",
      "  Step 7, Current reward: -43.926443\n",
      "  Step 8, Current reward: -43.744007\n",
      "  Step 9, Current reward: -43.607601\n",
      "  Step 10, Current reward: -43.517840\n",
      "  Step 11, Current reward: -43.475397\n",
      "  Step 12, Current reward: -43.481115\n",
      "  Step 13, Current reward: -43.536124\n",
      "  Step 14, Current reward: -43.641975\n",
      "  Step 15, Current reward: -43.800812\n",
      "  Step 16, Current reward: -44.015630\n",
      "  Step 17, Current reward: -44.290673\n",
      "  Step 18, Current reward: -44.632100\n",
      "  Step 19, Current reward: -45.049150\n",
      "  Step 20, Current reward: -45.556389\n",
      "  Step 21, Current reward: -46.178483\n",
      "  Step 22, Current reward: -46.961935\n",
      "Episode 6/100 complete - Max Reward: -43.475397\n",
      "Starting episode 7/100\n",
      "  Step 1, Current reward: -55.311944\n",
      "  Step 2, Current reward: -56.042431\n",
      "  Step 3, Current reward: -58.518253\n",
      "  Step 4, Current reward: -56.832061\n",
      "  Step 5, Current reward: -54.818175\n",
      "  Step 6, Current reward: -53.750510\n",
      "  Step 7, Current reward: -53.043743\n",
      "  Step 8, Current reward: -52.549517\n",
      "  Step 9, Current reward: -52.207656\n",
      "  Step 10, Current reward: -51.988559\n",
      "  Step 11, Current reward: -51.876614\n",
      "  Step 12, Current reward: -51.864170\n",
      "  Step 13, Current reward: -51.949293\n",
      "  Step 14, Current reward: -52.135472\n",
      "  Step 15, Current reward: -52.433074\n",
      "  Step 16, Current reward: -52.863692\n",
      "  Step 17, Current reward: -53.471783\n",
      "  Step 18, Current reward: -54.361390\n",
      "  Step 19, Current reward: -55.870263\n",
      "  Step 20, Current reward: -55.870263\n",
      "  Step 21, Current reward: -55.870263\n",
      "  Step 22, Current reward: -55.870263\n",
      "  Step 23, Current reward: -55.870263\n",
      "Episode 7/100 complete - Max Reward: -51.864170\n",
      "Starting episode 8/100\n",
      "  Step 1, Current reward: -42.058847\n",
      "  Step 2, Current reward: -42.103245\n",
      "  Step 3, Current reward: -42.169235\n",
      "  Step 4, Current reward: -42.262234\n",
      "  Step 5, Current reward: -42.386266\n",
      "  Step 6, Current reward: -42.541428\n",
      "  Step 7, Current reward: -42.719241\n",
      "  Step 8, Current reward: -42.894978\n",
      "  Step 9, Current reward: -43.018656\n",
      "  Step 10, Current reward: -43.015526\n",
      "  Step 11, Current reward: -42.815867\n",
      "  Step 12, Current reward: -42.406456\n",
      "Episode 8/100 complete - Max Reward: -42.058847\n",
      "Starting episode 9/100\n",
      "  Step 1, Current reward: -56.760577\n",
      "  Step 2, Current reward: -53.080349\n",
      "  Step 3, Current reward: -51.479838\n",
      "  Step 4, Current reward: -50.412457\n",
      "  Step 5, Current reward: -49.629902\n",
      "  Step 6, Current reward: -49.043874\n",
      "  Step 7, Current reward: -48.616139\n",
      "  Step 8, Current reward: -48.331436\n",
      "  Step 9, Current reward: -48.189031\n",
      "  Step 10, Current reward: -48.201833\n",
      "  Step 11, Current reward: -48.402762\n",
      "  Step 12, Current reward: -48.868148\n",
      "  Step 13, Current reward: -49.814633\n",
      "  Step 14, Current reward: -52.506247\n",
      "  Step 15, Current reward: -51.042307\n",
      "  Step 16, Current reward: -49.258460\n",
      "  Step 17, Current reward: -48.433192\n",
      "  Step 18, Current reward: -47.984304\n",
      "  Step 19, Current reward: -47.767005\n",
      "  Step 20, Current reward: -47.725600\n",
      "  Step 21, Current reward: -47.836704\n",
      "  Step 22, Current reward: -48.094174\n",
      "  Step 23, Current reward: -48.506124\n",
      "  Step 24, Current reward: -49.099811\n",
      "  Step 25, Current reward: -49.941487\n",
      "  Step 26, Current reward: -51.215163\n",
      "  Step 27, Current reward: -53.830701\n",
      "  Step 28, Current reward: -53.847173\n",
      "  Step 29, Current reward: -52.188467\n",
      "  Step 30, Current reward: -51.686977\n",
      "  Step 31, Current reward: -51.591816\n",
      "Episode 9/100 complete - Max Reward: -47.725600\n",
      "Starting episode 10/100\n",
      "  Step 1, Current reward: -50.210279\n",
      "  Step 2, Current reward: -47.869811\n",
      "  Step 3, Current reward: -46.739164\n",
      "  Step 4, Current reward: -46.032129\n",
      "  Step 5, Current reward: -45.590966\n",
      "  Step 6, Current reward: -45.376030\n",
      "  Step 7, Current reward: -45.407375\n",
      "  Step 8, Current reward: -45.790564\n",
      "  Step 9, Current reward: -46.949309\n",
      "  Step 10, Current reward: -49.928335\n",
      "  Step 11, Current reward: -45.685356\n",
      "  Step 12, Current reward: -44.222595\n",
      "  Step 13, Current reward: -43.298802\n",
      "  Step 14, Current reward: -42.640471\n",
      "  Step 15, Current reward: -42.154099\n",
      "  Step 16, Current reward: -41.796141\n",
      "  Step 17, Current reward: -41.542755\n",
      "  Step 18, Current reward: -41.379588\n",
      "  Step 19, Current reward: -41.297531\n",
      "  Step 20, Current reward: -41.290735\n",
      "  Step 21, Current reward: -41.355614\n",
      "  Step 22, Current reward: -41.490364\n",
      "  Step 23, Current reward: -41.694801\n",
      "  Step 24, Current reward: -41.970446\n",
      "  Step 25, Current reward: -42.320910\n",
      "  Step 26, Current reward: -42.752710\n",
      "  Step 27, Current reward: -43.276905\n",
      "  Step 28, Current reward: -43.912510\n",
      "  Step 29, Current reward: -44.694427\n",
      "  Step 30, Current reward: -45.695480\n",
      "  Step 31, Current reward: -47.109998\n",
      "Episode 10/100 complete - Max Reward: -41.290735\n",
      "Starting episode 11/100\n",
      "  Step 1, Current reward: -54.162735\n",
      "  Step 2, Current reward: -54.164031\n",
      "  Step 3, Current reward: -54.168612\n",
      "  Step 4, Current reward: -54.180658\n",
      "  Step 5, Current reward: -54.207322\n",
      "  Step 6, Current reward: -54.259797\n",
      "  Step 7, Current reward: -54.354706\n",
      "  Step 8, Current reward: -54.516493\n",
      "  Step 9, Current reward: -54.782805\n",
      "  Step 10, Current reward: -55.218938\n",
      "  Step 11, Current reward: -55.966463\n",
      "  Step 12, Current reward: -57.508741\n",
      "Episode 11/100 complete - Max Reward: -54.162735\n",
      "Starting episode 12/100\n",
      "  Step 1, Current reward: -37.738860\n",
      "  Step 2, Current reward: -37.752769\n",
      "  Step 3, Current reward: -37.864736\n",
      "  Step 4, Current reward: -38.080718\n",
      "  Step 5, Current reward: -38.409143\n",
      "  Step 6, Current reward: -38.862399\n",
      "  Step 7, Current reward: -39.459767\n",
      "  Step 8, Current reward: -40.233822\n",
      "  Step 9, Current reward: -41.247012\n",
      "  Step 10, Current reward: -42.647881\n",
      "  Step 11, Current reward: -45.003075\n",
      "  Step 12, Current reward: -47.309268\n",
      "Episode 12/100 complete - Max Reward: -37.738860\n",
      "Starting episode 13/100\n",
      "  Step 1, Current reward: -56.427867\n",
      "  Step 2, Current reward: -57.039808\n",
      "  Step 3, Current reward: -62.495676\n",
      "  Step 4, Current reward: -55.687557\n",
      "  Step 5, Current reward: -53.919735\n",
      "  Step 6, Current reward: -52.781644\n",
      "  Step 7, Current reward: -51.945397\n",
      "  Step 8, Current reward: -51.302494\n",
      "  Step 9, Current reward: -50.802629\n",
      "  Step 10, Current reward: -50.418179\n",
      "  Step 11, Current reward: -50.132428\n",
      "  Step 12, Current reward: -49.934704\n",
      "  Step 13, Current reward: -49.818084\n",
      "  Step 14, Current reward: -49.778240\n",
      "  Step 15, Current reward: -49.812873\n",
      "  Step 16, Current reward: -49.921500\n",
      "  Step 17, Current reward: -50.105557\n",
      "  Step 18, Current reward: -50.368828\n",
      "  Step 19, Current reward: -50.718428\n",
      "  Step 20, Current reward: -51.166805\n",
      "  Step 21, Current reward: -51.736093\n",
      "  Step 22, Current reward: -52.468734\n",
      "  Step 23, Current reward: -53.459449\n",
      "  Step 24, Current reward: -54.996501\n",
      "  Step 25, Current reward: -59.866714\n",
      "Episode 13/100 complete - Max Reward: -49.778240\n",
      "Starting episode 14/100\n",
      "  Step 1, Current reward: -42.495044\n",
      "  Step 2, Current reward: -43.142949\n",
      "  Step 3, Current reward: -44.201845\n",
      "  Step 4, Current reward: -46.499440\n",
      "  Step 5, Current reward: -46.641505\n",
      "  Step 6, Current reward: -44.659433\n",
      "  Step 7, Current reward: -43.905123\n",
      "  Step 8, Current reward: -43.553576\n",
      "  Step 9, Current reward: -43.426071\n",
      "  Step 10, Current reward: -43.453394\n",
      "  Step 11, Current reward: -43.601734\n",
      "  Step 12, Current reward: -43.852671\n",
      "Episode 14/100 complete - Max Reward: -42.495044\n",
      "Starting episode 15/100\n",
      "  Step 1, Current reward: -54.355496\n",
      "  Step 2, Current reward: -54.356343\n",
      "  Step 3, Current reward: -54.360116\n",
      "  Step 4, Current reward: -54.370669\n",
      "  Step 5, Current reward: -54.394216\n",
      "  Step 6, Current reward: -54.439360\n",
      "  Step 7, Current reward: -54.516263\n",
      "  Step 8, Current reward: -54.634434\n",
      "  Step 9, Current reward: -54.797809\n",
      "  Step 10, Current reward: -54.994295\n",
      "  Step 11, Current reward: -55.175872\n",
      "  Step 12, Current reward: -55.235740\n",
      "Episode 15/100 complete - Max Reward: -54.355496\n",
      "Starting episode 16/100\n",
      "  Step 1, Current reward: -43.750072\n",
      "  Step 2, Current reward: -43.748836\n",
      "  Step 3, Current reward: -43.746789\n",
      "  Step 4, Current reward: -43.744393\n",
      "  Step 5, Current reward: -43.743449\n",
      "  Step 6, Current reward: -43.747953\n",
      "  Step 7, Current reward: -43.764873\n",
      "  Step 8, Current reward: -43.804663\n",
      "  Step 9, Current reward: -43.881487\n",
      "  Step 10, Current reward: -44.013300\n",
      "  Step 11, Current reward: -44.221992\n",
      "  Step 12, Current reward: -44.533409\n",
      "  Step 13, Current reward: -44.975181\n",
      "  Step 14, Current reward: -45.562552\n",
      "  Step 15, Current reward: -46.232492\n",
      "  Step 16, Current reward: -46.648093\n",
      "Episode 16/100 complete - Max Reward: -43.743449\n",
      "Starting episode 17/100\n",
      "  Step 1, Current reward: -57.904944\n",
      "  Step 2, Current reward: -56.724611\n",
      "  Step 3, Current reward: -55.760722\n",
      "  Step 4, Current reward: -54.968905\n",
      "  Step 5, Current reward: -54.318666\n",
      "  Step 6, Current reward: -53.790239\n",
      "  Step 7, Current reward: -53.370797\n",
      "  Step 8, Current reward: -53.051953\n",
      "  Step 9, Current reward: -52.828260\n",
      "  Step 10, Current reward: -52.696363\n",
      "  Step 11, Current reward: -52.654576\n",
      "  Step 12, Current reward: -52.702757\n",
      "  Step 13, Current reward: -52.842444\n",
      "  Step 14, Current reward: -53.077320\n",
      "  Step 15, Current reward: -53.414174\n",
      "  Step 16, Current reward: -53.864806\n",
      "  Step 17, Current reward: -54.450052\n",
      "  Step 18, Current reward: -55.209359\n",
      "  Step 19, Current reward: -56.228597\n",
      "  Step 20, Current reward: -57.755446\n",
      "  Step 21, Current reward: -61.513493\n",
      "  Step 22, Current reward: -59.532667\n",
      "Episode 17/100 complete - Max Reward: -52.654576\n",
      "Starting episode 18/100\n",
      "  Step 1, Current reward: -37.757057\n",
      "  Step 2, Current reward: -inf\n",
      "  Step 3, Current reward: -37.981836\n",
      "  Step 4, Current reward: -36.837359\n",
      "  Step 5, Current reward: -36.364998\n",
      "  Step 6, Current reward: -36.239154\n",
      "  Step 7, Current reward: -36.377931\n",
      "  Step 8, Current reward: -36.780854\n",
      "  Step 9, Current reward: -37.528908\n",
      "  Step 10, Current reward: -38.946923\n",
      "  Step 11, Current reward: -38.946923\n",
      "  Step 12, Current reward: -38.946923\n",
      "  Step 13, Current reward: -38.946923\n",
      "  Step 14, Current reward: -38.946923\n",
      "  Step 15, Current reward: -38.946923\n",
      "  Step 16, Current reward: -38.946923\n",
      "  Step 17, Current reward: -38.946923\n",
      "Episode 18/100 complete - Max Reward: -36.239154\n",
      "Starting episode 19/100\n",
      "  Step 1, Current reward: -50.397963\n",
      "  Step 2, Current reward: -51.104551\n",
      "  Step 3, Current reward: -51.892873\n",
      "  Step 4, Current reward: -52.763228\n",
      "  Step 5, Current reward: -53.718684\n",
      "  Step 6, Current reward: -54.766213\n",
      "  Step 7, Current reward: -55.919539\n",
      "  Step 8, Current reward: -57.206311\n",
      "  Step 9, Current reward: -58.688607\n",
      "  Step 10, Current reward: -60.539849\n",
      "  Step 11, Current reward: -63.615453\n",
      "  Step 12, Current reward: -64.277484\n",
      "Episode 19/100 complete - Max Reward: -50.397963\n",
      "Starting episode 20/100\n",
      "  Step 1, Current reward: -67.473138\n",
      "  Step 2, Current reward: -66.472030\n",
      "  Step 3, Current reward: -66.268460\n",
      "  Step 4, Current reward: -67.296899\n",
      "  Step 5, Current reward: -67.405227\n",
      "  Step 6, Current reward: -64.254247\n",
      "  Step 7, Current reward: -62.655081\n",
      "  Step 8, Current reward: -61.532201\n",
      "  Step 9, Current reward: -60.675402\n",
      "  Step 10, Current reward: -60.004531\n",
      "  Step 11, Current reward: -59.480912\n",
      "  Step 12, Current reward: -59.084170\n",
      "  Step 13, Current reward: -58.804097\n",
      "  Step 14, Current reward: -58.637578\n",
      "  Step 15, Current reward: -58.587983\n",
      "  Step 16, Current reward: -58.666656\n",
      "  Step 17, Current reward: -58.897834\n",
      "  Step 18, Current reward: -59.332351\n",
      "  Step 19, Current reward: -60.093203\n",
      "  Step 20, Current reward: -61.616880\n",
      "  Step 21, Current reward: -64.903656\n",
      "  Step 22, Current reward: -61.043384\n",
      "  Step 23, Current reward: -59.935508\n",
      "  Step 24, Current reward: -59.372118\n",
      "  Step 25, Current reward: -59.086104\n",
      "  Step 26, Current reward: -58.990700\n",
      "Episode 20/100 complete - Max Reward: -58.587983\n",
      "Starting episode 21/100\n",
      "  Step 1, Current reward: -54.404877\n",
      "  Step 2, Current reward: -53.918528\n",
      "  Step 3, Current reward: -53.535055\n",
      "  Step 4, Current reward: -53.249295\n",
      "  Step 5, Current reward: -53.061037\n",
      "  Step 6, Current reward: -52.973495\n",
      "  Step 7, Current reward: -52.992755\n",
      "  Step 8, Current reward: -53.128047\n",
      "  Step 9, Current reward: -53.392898\n",
      "  Step 10, Current reward: -53.807644\n",
      "  Step 11, Current reward: -54.404633\n",
      "  Step 12, Current reward: -55.240025\n",
      "  Step 13, Current reward: -56.425653\n",
      "  Step 14, Current reward: -58.247573\n",
      "  Step 15, Current reward: -62.209118\n",
      "  Step 16, Current reward: -62.589652\n",
      "  Step 17, Current reward: -62.311171\n",
      "Episode 21/100 complete - Max Reward: -52.973495\n",
      "Starting episode 22/100\n",
      "  Step 1, Current reward: -47.344922\n",
      "  Step 2, Current reward: -48.532661\n",
      "  Step 3, Current reward: -50.648678\n",
      "  Step 4, Current reward: -46.927660\n",
      "  Step 5, Current reward: -45.487504\n",
      "  Step 6, Current reward: -44.565998\n",
      "  Step 7, Current reward: -43.911813\n",
      "  Step 8, Current reward: -43.437368\n",
      "  Step 9, Current reward: -43.102218\n",
      "  Step 10, Current reward: -42.885085\n",
      "  Step 11, Current reward: -42.774391\n",
      "  Step 12, Current reward: -42.764480\n",
      "  Step 13, Current reward: -42.854179\n",
      "  Step 14, Current reward: -43.046666\n",
      "  Step 15, Current reward: -43.350579\n",
      "  Step 16, Current reward: -43.783106\n",
      "  Step 17, Current reward: -44.377713\n",
      "  Step 18, Current reward: -45.205990\n",
      "  Step 19, Current reward: -46.460831\n",
      "  Step 20, Current reward: -49.119558\n",
      "  Step 21, Current reward: -48.834327\n",
      "  Step 22, Current reward: -47.167845\n",
      "  Step 23, Current reward: -46.591747\n",
      "Episode 22/100 complete - Max Reward: -42.764480\n",
      "Starting episode 23/100\n",
      "  Step 1, Current reward: -57.409561\n",
      "  Step 2, Current reward: -57.409561\n",
      "  Step 3, Current reward: -57.409561\n",
      "  Step 4, Current reward: -57.409561\n",
      "  Step 5, Current reward: -57.409561\n",
      "  Step 6, Current reward: -57.409561\n",
      "  Step 7, Current reward: -57.409561\n",
      "  Step 8, Current reward: -57.409561\n",
      "  Step 9, Current reward: -57.409561\n",
      "  Step 10, Current reward: -57.409561\n",
      "  Step 11, Current reward: -57.409561\n",
      "  Step 12, Current reward: -57.409561\n",
      "Episode 23/100 complete - Max Reward: -57.409561\n",
      "Starting episode 24/100\n",
      "  Step 1, Current reward: -47.162775\n",
      "  Step 2, Current reward: -47.159608\n",
      "  Step 3, Current reward: -47.164065\n",
      "  Step 4, Current reward: -47.188542\n",
      "  Step 5, Current reward: -47.253408\n",
      "  Step 6, Current reward: -47.390099\n",
      "  Step 7, Current reward: -47.648597\n",
      "  Step 8, Current reward: -48.120524\n",
      "  Step 9, Current reward: -49.032863\n",
      "  Step 10, Current reward: -51.590465\n",
      "  Step 11, Current reward: -50.294851\n",
      "  Step 12, Current reward: -48.466863\n",
      "  Step 13, Current reward: -47.697218\n",
      "Episode 24/100 complete - Max Reward: -47.159608\n",
      "Starting episode 25/100\n",
      "  Step 1, Current reward: -55.377336\n",
      "  Step 2, Current reward: -57.691981\n",
      "  Step 3, Current reward: -58.092428\n",
      "  Step 4, Current reward: -56.095846\n",
      "  Step 5, Current reward: -55.367569\n",
      "  Step 6, Current reward: -55.037642\n",
      "  Step 7, Current reward: -54.923059\n",
      "  Step 8, Current reward: -54.953837\n",
      "  Step 9, Current reward: -55.096058\n",
      "  Step 10, Current reward: -55.331174\n",
      "  Step 11, Current reward: -55.648536\n",
      "  Step 12, Current reward: -56.042240\n",
      "  Step 13, Current reward: -56.509743\n",
      "  Step 14, Current reward: -57.051392\n",
      "  Step 15, Current reward: -57.670608\n",
      "  Step 16, Current reward: -58.374832\n",
      "  Step 17, Current reward: -59.177779\n",
      "  Step 18, Current reward: -60.104599\n",
      "Episode 25/100 complete - Max Reward: -54.923059\n",
      "Starting episode 26/100\n",
      "  Step 1, Current reward: -75.468860\n",
      "  Step 2, Current reward: -76.844140\n",
      "  Step 3, Current reward: -78.636494\n",
      "  Step 4, Current reward: -81.537190\n",
      "  Step 5, Current reward: -83.417412\n",
      "  Step 6, Current reward: -82.198017\n",
      "  Step 7, Current reward: -82.705624\n",
      "  Step 8, Current reward: -84.157208\n",
      "  Step 9, Current reward: -87.520528\n",
      "  Step 10, Current reward: -88.796816\n",
      "  Step 11, Current reward: -88.035737\n",
      "  Step 12, Current reward: -84.696617\n",
      "Episode 26/100 complete - Max Reward: -75.468860\n",
      "Starting episode 27/100\n",
      "  Step 1, Current reward: -52.471746\n",
      "  Step 2, Current reward: -52.934000\n",
      "  Step 3, Current reward: -53.459898\n",
      "  Step 4, Current reward: -54.048598\n",
      "  Step 5, Current reward: -54.700049\n",
      "  Step 6, Current reward: -55.415071\n",
      "  Step 7, Current reward: -56.195517\n",
      "  Step 8, Current reward: -57.044566\n",
      "  Step 9, Current reward: -57.967234\n",
      "  Step 10, Current reward: -58.971263\n",
      "  Step 11, Current reward: -60.068798\n",
      "  Step 12, Current reward: -61.279773\n",
      "Episode 27/100 complete - Max Reward: -52.471746\n",
      "Starting episode 28/100\n",
      "  Step 1, Current reward: -48.095369\n",
      "  Step 2, Current reward: -48.095369\n",
      "  Step 3, Current reward: -48.095369\n",
      "  Step 4, Current reward: -48.095369\n",
      "  Step 5, Current reward: -48.095369\n",
      "  Step 6, Current reward: -48.095369\n",
      "  Step 7, Current reward: -48.095369\n",
      "  Step 8, Current reward: -48.095369\n",
      "  Step 9, Current reward: -48.095369\n",
      "  Step 10, Current reward: -48.095369\n",
      "  Step 11, Current reward: -48.095369\n",
      "  Step 12, Current reward: -48.095369\n",
      "Episode 28/100 complete - Max Reward: -48.095369\n",
      "Starting episode 29/100\n",
      "  Step 1, Current reward: -43.911081\n",
      "  Step 2, Current reward: -43.350166\n",
      "  Step 3, Current reward: -42.889262\n",
      "  Step 4, Current reward: -42.523214\n",
      "  Step 5, Current reward: -42.249434\n",
      "  Step 6, Current reward: -42.067691\n",
      "  Step 7, Current reward: -41.980047\n",
      "  Step 8, Current reward: -41.991141\n",
      "  Step 9, Current reward: -42.109088\n",
      "  Step 10, Current reward: -42.347488\n",
      "  Step 11, Current reward: -42.729892\n",
      "  Step 12, Current reward: -43.300833\n",
      "  Step 13, Current reward: -44.159277\n",
      "  Step 14, Current reward: -45.609273\n",
      "  Step 15, Current reward: -51.067374\n",
      "  Step 16, Current reward: -46.393091\n",
      "  Step 17, Current reward: -45.261837\n",
      "  Step 18, Current reward: -44.833554\n",
      "Episode 29/100 complete - Max Reward: -41.980047\n",
      "Starting episode 30/100\n",
      "  Step 1, Current reward: -45.736194\n",
      "  Step 2, Current reward: -44.591276\n",
      "  Step 3, Current reward: -43.545972\n",
      "  Step 4, Current reward: -42.645076\n",
      "  Step 5, Current reward: -41.882901\n",
      "  Step 6, Current reward: -41.245123\n",
      "  Step 7, Current reward: -40.718844\n",
      "  Step 8, Current reward: -40.294216\n",
      "  Step 9, Current reward: -39.964144\n",
      "  Step 10, Current reward: -39.723731\n",
      "  Step 11, Current reward: -39.569855\n",
      "  Step 12, Current reward: -39.500934\n",
      "  Step 13, Current reward: -39.516887\n",
      "  Step 14, Current reward: -39.619331\n",
      "  Step 15, Current reward: -39.812071\n",
      "  Step 16, Current reward: -40.102103\n",
      "  Step 17, Current reward: -40.501611\n",
      "  Step 18, Current reward: -41.032211\n",
      "  Step 19, Current reward: -41.735198\n",
      "  Step 20, Current reward: -42.701952\n",
      "  Step 21, Current reward: -44.205170\n",
      "  Step 22, Current reward: -48.536352\n",
      "  Step 23, Current reward: -45.489042\n",
      "Episode 30/100 complete - Max Reward: -39.500934\n",
      "Starting episode 31/100\n",
      "  Step 1, Current reward: -50.037414\n",
      "  Step 2, Current reward: -50.166025\n",
      "  Step 3, Current reward: -50.388579\n",
      "  Step 4, Current reward: -50.707775\n",
      "  Step 5, Current reward: -51.128774\n",
      "  Step 6, Current reward: -51.660147\n",
      "  Step 7, Current reward: -52.315646\n",
      "  Step 8, Current reward: -53.117688\n",
      "  Step 9, Current reward: -54.104888\n",
      "  Step 10, Current reward: -55.351128\n",
      "  Step 11, Current reward: -57.028793\n",
      "  Step 12, Current reward: -59.780391\n",
      "Episode 31/100 complete - Max Reward: -50.037414\n",
      "Starting episode 32/100\n",
      "  Step 1, Current reward: -74.070894\n",
      "  Step 2, Current reward: -75.662607\n",
      "  Step 3, Current reward: -77.585249\n",
      "  Step 4, Current reward: -80.045962\n",
      "  Step 5, Current reward: -83.308257\n",
      "  Step 6, Current reward: -84.533957\n",
      "  Step 7, Current reward: -82.922527\n",
      "  Step 8, Current reward: -82.087520\n",
      "  Step 9, Current reward: -81.880690\n",
      "  Step 10, Current reward: -82.105082\n",
      "  Step 11, Current reward: -82.705428\n",
      "  Step 12, Current reward: -83.758292\n",
      "Episode 32/100 complete - Max Reward: -74.070894\n",
      "Starting episode 33/100\n",
      "  Step 1, Current reward: -55.648388\n",
      "  Step 2, Current reward: -52.826322\n",
      "  Step 3, Current reward: -51.902839\n",
      "  Step 4, Current reward: -51.540391\n",
      "  Step 5, Current reward: -51.563027\n",
      "  Step 6, Current reward: -52.000881\n",
      "  Step 7, Current reward: -53.170511\n",
      "  Step 8, Current reward: -60.622498\n",
      "  Step 9, Current reward: -52.976280\n",
      "  Step 10, Current reward: -51.747725\n",
      "  Step 11, Current reward: -51.226084\n",
      "  Step 12, Current reward: -51.124299\n",
      "  Step 13, Current reward: -51.438349\n",
      "  Step 14, Current reward: -52.445059\n",
      "  Step 15, Current reward: -59.395407\n",
      "  Step 16, Current reward: -52.163676\n",
      "  Step 17, Current reward: -50.679591\n",
      "  Step 18, Current reward: -49.865036\n",
      "  Step 19, Current reward: -49.361083\n",
      "  Step 20, Current reward: -49.055551\n",
      "  Step 21, Current reward: -48.898745\n",
      "  Step 22, Current reward: -48.865117\n",
      "  Step 23, Current reward: -48.941159\n",
      "  Step 24, Current reward: -49.120910\n",
      "  Step 25, Current reward: -49.404553\n",
      "  Step 26, Current reward: -49.799039\n",
      "  Step 27, Current reward: -50.321257\n",
      "  Step 28, Current reward: -51.006774\n",
      "  Step 29, Current reward: -51.935967\n",
      "  Step 30, Current reward: -53.341262\n",
      "  Step 31, Current reward: -56.722628\n",
      "  Step 32, Current reward: -55.063857\n",
      "  Step 33, Current reward: -55.063857\n",
      "Episode 33/100 complete - Max Reward: -48.865117\n",
      "Starting episode 34/100\n",
      "  Step 1, Current reward: -46.714645\n",
      "  Step 2, Current reward: -46.337280\n",
      "  Step 3, Current reward: -46.256329\n",
      "  Step 4, Current reward: -46.374311\n",
      "  Step 5, Current reward: -46.645462\n",
      "  Step 6, Current reward: -47.042144\n",
      "  Step 7, Current reward: -47.542400\n",
      "  Step 8, Current reward: -48.123326\n",
      "  Step 9, Current reward: -48.757178\n",
      "  Step 10, Current reward: -49.411623\n",
      "  Step 11, Current reward: -50.058105\n",
      "  Step 12, Current reward: -50.690211\n",
      "  Step 13, Current reward: -51.346652\n",
      "  Step 14, Current reward: -52.138923\n",
      "Episode 34/100 complete - Max Reward: -46.256329\n",
      "Starting episode 35/100\n",
      "  Step 1, Current reward: -51.959219\n",
      "  Step 2, Current reward: -48.239838\n",
      "  Step 3, Current reward: -47.393471\n",
      "  Step 4, Current reward: -47.081463\n",
      "  Step 5, Current reward: -47.027875\n",
      "  Step 6, Current reward: -47.139330\n",
      "  Step 7, Current reward: -47.372765\n",
      "  Step 8, Current reward: -47.704896\n",
      "  Step 9, Current reward: -48.121954\n",
      "  Step 10, Current reward: -48.615452\n",
      "  Step 11, Current reward: -49.180201\n",
      "  Step 12, Current reward: -49.813319\n",
      "  Step 13, Current reward: -50.513733\n",
      "  Step 14, Current reward: -51.281992\n",
      "  Step 15, Current reward: -52.120307\n",
      "  Step 16, Current reward: -53.032841\n",
      "Episode 35/100 complete - Max Reward: -47.027875\n",
      "Starting episode 36/100\n",
      "  Step 1, Current reward: -57.835317\n",
      "  Step 2, Current reward: -57.816229\n",
      "  Step 3, Current reward: -57.760662\n",
      "  Step 4, Current reward: -57.664716\n",
      "  Step 5, Current reward: -57.557653\n",
      "  Step 6, Current reward: -57.510734\n",
      "  Step 7, Current reward: -57.652654\n",
      "  Step 8, Current reward: -58.282748\n",
      "  Step 9, Current reward: -61.531509\n",
      "  Step 10, Current reward: -57.905051\n",
      "  Step 11, Current reward: -55.858832\n",
      "  Step 12, Current reward: -54.586902\n",
      "  Step 13, Current reward: -53.645402\n",
      "  Step 14, Current reward: -52.909678\n",
      "  Step 15, Current reward: -52.327683\n",
      "  Step 16, Current reward: -51.874046\n",
      "  Step 17, Current reward: -51.536423\n",
      "  Step 18, Current reward: -51.310704\n",
      "  Step 19, Current reward: -51.199817\n",
      "  Step 20, Current reward: -51.215068\n",
      "  Step 21, Current reward: -51.381272\n",
      "  Step 22, Current reward: -51.751467\n",
      "  Step 23, Current reward: -52.457143\n",
      "  Step 24, Current reward: -53.989666\n",
      "  Step 25, Current reward: -56.271472\n",
      "  Step 26, Current reward: -52.911934\n",
      "  Step 27, Current reward: -51.738538\n",
      "  Step 28, Current reward: -51.061117\n",
      "  Step 29, Current reward: -50.633072\n",
      "  Step 30, Current reward: -50.367989\n",
      "  Step 31, Current reward: -50.225471\n",
      "  Step 32, Current reward: -50.183607\n",
      "  Step 33, Current reward: -50.229519\n",
      "  Step 34, Current reward: -50.355449\n",
      "  Step 35, Current reward: -50.556950\n",
      "  Step 36, Current reward: -50.832056\n",
      "  Step 37, Current reward: -51.180999\n",
      "  Step 38, Current reward: -51.606356\n",
      "  Step 39, Current reward: -52.113681\n",
      "  Step 40, Current reward: -52.712925\n",
      "  Step 41, Current reward: -53.421493\n",
      "  Step 42, Current reward: -54.271291\n",
      "  Step 43, Current reward: -55.327868\n",
      "Episode 36/100 complete - Max Reward: -50.183607\n",
      "Starting episode 37/100\n",
      "  Step 1, Current reward: -57.802836\n",
      "  Step 2, Current reward: -51.126904\n",
      "  Step 3, Current reward: -48.954414\n",
      "  Step 4, Current reward: -47.515210\n",
      "  Step 5, Current reward: -46.428106\n",
      "  Step 6, Current reward: -45.571596\n",
      "  Step 7, Current reward: -44.890501\n",
      "  Step 8, Current reward: -44.356160\n",
      "  Step 9, Current reward: -43.953914\n",
      "  Step 10, Current reward: -43.678618\n",
      "  Step 11, Current reward: -43.533751\n",
      "  Step 12, Current reward: -43.533572\n",
      "  Step 13, Current reward: -43.710653\n",
      "  Step 14, Current reward: -44.138956\n",
      "  Step 15, Current reward: -45.025353\n",
      "  Step 16, Current reward: -47.511901\n",
      "  Step 17, Current reward: -46.322675\n",
      "  Step 18, Current reward: -44.406921\n",
      "  Step 19, Current reward: -43.493587\n",
      "  Step 20, Current reward: -42.958313\n",
      "  Step 21, Current reward: -42.651120\n",
      "  Step 22, Current reward: -42.515706\n",
      "  Step 23, Current reward: -42.529721\n",
      "  Step 24, Current reward: -42.689550\n",
      "  Step 25, Current reward: -43.008461\n",
      "  Step 26, Current reward: -43.525317\n",
      "  Step 27, Current reward: -44.338874\n",
      "  Step 28, Current reward: -45.773232\n",
      "  Step 29, Current reward: -53.344920\n",
      "  Step 30, Current reward: -46.194121\n",
      "  Step 31, Current reward: -45.030036\n",
      "  Step 32, Current reward: -44.516741\n",
      "  Step 33, Current reward: -44.303645\n",
      "Episode 37/100 complete - Max Reward: -42.515706\n",
      "Starting episode 38/100\n",
      "  Step 1, Current reward: -48.009080\n",
      "  Step 2, Current reward: -49.442661\n",
      "  Step 3, Current reward: -51.746610\n",
      "  Step 4, Current reward: -52.843555\n",
      "  Step 5, Current reward: -50.535500\n",
      "  Step 6, Current reward: -49.659656\n",
      "  Step 7, Current reward: -49.194223\n",
      "  Step 8, Current reward: -48.960679\n",
      "  Step 9, Current reward: -48.899470\n",
      "  Step 10, Current reward: -48.986628\n",
      "  Step 11, Current reward: -49.214832\n",
      "  Step 12, Current reward: -49.589749\n",
      "Episode 38/100 complete - Max Reward: -48.009080\n",
      "Starting episode 39/100\n",
      "  Step 1, Current reward: -35.418101\n",
      "  Step 2, Current reward: -35.226869\n",
      "  Step 3, Current reward: -35.154344\n",
      "  Step 4, Current reward: -35.185825\n",
      "  Step 5, Current reward: -35.312078\n",
      "  Step 6, Current reward: -35.527277\n",
      "  Step 7, Current reward: -35.828015\n",
      "  Step 8, Current reward: -36.212889\n",
      "  Step 9, Current reward: -36.682461\n",
      "  Step 10, Current reward: -37.239566\n",
      "  Step 11, Current reward: -37.890108\n",
      "  Step 12, Current reward: -38.644690\n",
      "  Step 13, Current reward: -39.522077\n",
      "  Step 14, Current reward: -40.557284\n",
      "Episode 39/100 complete - Max Reward: -35.154344\n",
      "Starting episode 40/100\n",
      "  Step 1, Current reward: -44.143139\n",
      "  Step 2, Current reward: -44.143139\n",
      "  Step 3, Current reward: -44.143139\n",
      "  Step 4, Current reward: -44.143139\n",
      "  Step 5, Current reward: -44.143139\n",
      "  Step 6, Current reward: -44.143139\n",
      "  Step 7, Current reward: -44.143139\n",
      "  Step 8, Current reward: -44.143139\n",
      "  Step 9, Current reward: -44.143139\n",
      "  Step 10, Current reward: -44.143139\n",
      "  Step 11, Current reward: -44.143139\n",
      "  Step 12, Current reward: -44.143139\n",
      "Episode 40/100 complete - Max Reward: -44.143139\n",
      "Starting episode 41/100\n",
      "  Step 1, Current reward: -54.034460\n",
      "  Step 2, Current reward: -54.439310\n",
      "  Step 3, Current reward: -55.163737\n",
      "  Step 4, Current reward: -56.625864\n",
      "  Step 5, Current reward: -61.127539\n",
      "  Step 6, Current reward: -56.591439\n",
      "  Step 7, Current reward: -55.889490\n",
      "  Step 8, Current reward: -56.527645\n",
      "  Step 9, Current reward: -57.948779\n",
      "  Step 10, Current reward: -54.082763\n",
      "  Step 11, Current reward: -52.388193\n",
      "  Step 12, Current reward: -51.228763\n",
      "  Step 13, Current reward: -50.348970\n",
      "  Step 14, Current reward: -49.655003\n",
      "  Step 15, Current reward: -49.101086\n",
      "  Step 16, Current reward: -48.661255\n",
      "  Step 17, Current reward: -48.319369\n",
      "  Step 18, Current reward: -48.064798\n",
      "  Step 19, Current reward: -47.890309\n",
      "  Step 20, Current reward: -47.790954\n",
      "  Step 21, Current reward: -47.763459\n",
      "  Step 22, Current reward: -47.805908\n",
      "  Step 23, Current reward: -47.917621\n",
      "  Step 24, Current reward: -48.099199\n",
      "  Step 25, Current reward: -48.352749\n",
      "  Step 26, Current reward: -48.682360\n",
      "  Step 27, Current reward: -49.095025\n",
      "  Step 28, Current reward: -49.602420\n",
      "  Step 29, Current reward: -50.224604\n",
      "  Step 30, Current reward: -50.998715\n",
      "  Step 31, Current reward: -52.003653\n",
      "  Step 32, Current reward: -53.457855\n",
      "Episode 41/100 complete - Max Reward: -47.763459\n",
      "Starting episode 42/100\n",
      "  Step 1, Current reward: -47.063243\n",
      "  Step 2, Current reward: -48.312742\n",
      "  Step 3, Current reward: -46.073194\n",
      "  Step 4, Current reward: -45.382358\n",
      "  Step 5, Current reward: -45.140528\n",
      "  Step 6, Current reward: -45.142196\n",
      "  Step 7, Current reward: -45.311192\n",
      "  Step 8, Current reward: -45.611154\n",
      "  Step 9, Current reward: -46.022526\n",
      "  Step 10, Current reward: -46.534577\n",
      "  Step 11, Current reward: -47.142308\n",
      "  Step 12, Current reward: -47.845530\n",
      "  Step 13, Current reward: -48.649444\n",
      "  Step 14, Current reward: -49.567144\n",
      "  Step 15, Current reward: -50.626152\n",
      "  Step 16, Current reward: -51.886541\n",
      "Episode 42/100 complete - Max Reward: -45.140528\n",
      "Starting episode 43/100\n",
      "  Step 1, Current reward: -53.911010\n",
      "  Step 2, Current reward: -54.001849\n",
      "  Step 3, Current reward: -54.244835\n",
      "  Step 4, Current reward: -54.771410\n",
      "  Step 5, Current reward: -56.009283\n",
      "  Step 6, Current reward: -59.430769\n",
      "  Step 7, Current reward: -54.978665\n",
      "  Step 8, Current reward: -53.549220\n",
      "  Step 9, Current reward: -52.670277\n",
      "  Step 10, Current reward: -52.068656\n",
      "  Step 11, Current reward: -51.659466\n",
      "  Step 12, Current reward: -51.412672\n",
      "  Step 13, Current reward: -51.325776\n",
      "  Step 14, Current reward: -51.421933\n",
      "  Step 15, Current reward: -51.769554\n",
      "  Step 16, Current reward: -52.573671\n",
      "  Step 17, Current reward: -55.004532\n",
      "  Step 18, Current reward: -53.616034\n",
      "  Step 19, Current reward: -51.594560\n",
      "  Step 20, Current reward: -50.541676\n",
      "  Step 21, Current reward: -49.841128\n",
      "  Step 22, Current reward: -49.339354\n",
      "  Step 23, Current reward: -48.973448\n",
      "  Step 24, Current reward: -48.711133\n",
      "  Step 25, Current reward: -48.533459\n",
      "  Step 26, Current reward: -48.428241\n",
      "  Step 27, Current reward: -48.387110\n",
      "  Step 28, Current reward: -48.404015\n",
      "  Step 29, Current reward: -48.474404\n",
      "  Step 30, Current reward: -48.594738\n",
      "  Step 31, Current reward: -48.762189\n",
      "  Step 32, Current reward: -48.762189\n",
      "  Step 33, Current reward: -48.762189\n",
      "  Step 34, Current reward: -48.762189\n",
      "  Step 35, Current reward: -48.762189\n",
      "  Step 36, Current reward: -48.762189\n",
      "  Step 37, Current reward: -48.762189\n",
      "  Step 38, Current reward: -48.762189\n",
      "Episode 43/100 complete - Max Reward: -48.387110\n",
      "Starting episode 44/100\n",
      "  Step 1, Current reward: -43.130009\n",
      "  Step 2, Current reward: -43.005561\n",
      "  Step 3, Current reward: -43.430357\n",
      "  Step 4, Current reward: -45.459691\n",
      "  Step 5, Current reward: -44.018644\n",
      "  Step 6, Current reward: -41.721068\n",
      "  Step 7, Current reward: -40.458786\n",
      "  Step 8, Current reward: -39.585188\n",
      "  Step 9, Current reward: -38.943112\n",
      "  Step 10, Current reward: -38.469496\n",
      "  Step 11, Current reward: -38.132951\n",
      "  Step 12, Current reward: -37.915941\n",
      "  Step 13, Current reward: -37.808151\n",
      "  Step 14, Current reward: -37.803638\n",
      "  Step 15, Current reward: -37.899590\n",
      "  Step 16, Current reward: -38.095942\n",
      "  Step 17, Current reward: -38.395633\n",
      "  Step 18, Current reward: -38.805631\n",
      "  Step 19, Current reward: -39.339315\n",
      "  Step 20, Current reward: -40.021918\n",
      "  Step 21, Current reward: -40.904602\n",
      "  Step 22, Current reward: -42.110484\n",
      "  Step 23, Current reward: -44.078413\n",
      "  Step 24, Current reward: -47.729757\n",
      "  Step 25, Current reward: -44.340630\n",
      "Episode 44/100 complete - Max Reward: -37.803638\n",
      "Starting episode 45/100\n",
      "  Step 1, Current reward: -36.708978\n",
      "  Step 2, Current reward: -37.121355\n",
      "  Step 3, Current reward: -37.612317\n",
      "  Step 4, Current reward: -38.186014\n",
      "  Step 5, Current reward: -38.848525\n",
      "  Step 6, Current reward: -39.608798\n",
      "  Step 7, Current reward: -40.480368\n",
      "  Step 8, Current reward: -41.484822\n",
      "  Step 9, Current reward: -42.659698\n",
      "  Step 10, Current reward: -44.080344\n",
      "  Step 11, Current reward: -45.942782\n",
      "  Step 12, Current reward: -49.224414\n",
      "Episode 45/100 complete - Max Reward: -36.708978\n",
      "Starting episode 46/100\n",
      "  Step 1, Current reward: -88.255430\n",
      "  Step 2, Current reward: -inf\n",
      "  Step 3, Current reward: -inf\n",
      "  Step 4, Current reward: -inf\n",
      "  Step 5, Current reward: -88.461513\n",
      "  Step 6, Current reward: -89.449521\n",
      "  Step 7, Current reward: -inf\n",
      "  Step 8, Current reward: -inf\n",
      "  Step 9, Current reward: -inf\n",
      "  Step 10, Current reward: -89.700289\n",
      "  Step 11, Current reward: -88.462051\n",
      "  Step 12, Current reward: -89.404573\n",
      "Episode 46/100 complete - Max Reward: -88.255430\n",
      "Starting episode 47/100\n",
      "  Step 1, Current reward: -50.336671\n",
      "  Step 2, Current reward: -50.979652\n",
      "  Step 3, Current reward: -51.698199\n",
      "  Step 4, Current reward: -52.493104\n",
      "  Step 5, Current reward: -53.368045\n",
      "  Step 6, Current reward: -54.331297\n",
      "  Step 7, Current reward: -55.399951\n",
      "  Step 8, Current reward: -56.610850\n",
      "  Step 9, Current reward: -58.054320\n",
      "  Step 10, Current reward: -60.026073\n",
      "  Step 11, Current reward: -65.985195\n",
      "  Step 12, Current reward: -61.614233\n",
      "Episode 47/100 complete - Max Reward: -50.336671\n",
      "Starting episode 48/100\n",
      "  Step 1, Current reward: -58.306019\n",
      "  Step 2, Current reward: -58.310179\n",
      "  Step 3, Current reward: -58.318095\n",
      "  Step 4, Current reward: -58.331890\n",
      "  Step 5, Current reward: -58.354146\n",
      "  Step 6, Current reward: -58.387622\n",
      "  Step 7, Current reward: -58.434695\n",
      "  Step 8, Current reward: -58.496420\n",
      "  Step 9, Current reward: -58.571058\n",
      "  Step 10, Current reward: -58.651903\n",
      "  Step 11, Current reward: -58.724507\n",
      "  Step 12, Current reward: -58.764300\n",
      "Episode 48/100 complete - Max Reward: -58.306019\n",
      "Starting episode 49/100\n",
      "  Step 1, Current reward: -55.651839\n",
      "  Step 2, Current reward: -55.648904\n",
      "  Step 3, Current reward: -55.642083\n",
      "  Step 4, Current reward: -55.627961\n",
      "  Step 5, Current reward: -55.601695\n",
      "  Step 6, Current reward: -55.557633\n",
      "  Step 7, Current reward: -55.490979\n",
      "  Step 8, Current reward: -55.400450\n",
      "  Step 9, Current reward: -55.291216\n",
      "  Step 10, Current reward: -55.177092\n",
      "  Step 11, Current reward: -55.081637\n",
      "  Step 12, Current reward: -55.039574\n",
      "  Step 13, Current reward: -55.102646\n",
      "  Step 14, Current reward: -55.361435\n",
      "  Step 15, Current reward: -56.037067\n",
      "  Step 16, Current reward: -58.297546\n",
      "  Step 17, Current reward: -56.787294\n",
      "  Step 18, Current reward: -54.584527\n",
      "  Step 19, Current reward: -53.356187\n",
      "  Step 20, Current reward: -52.485091\n",
      "  Step 21, Current reward: -51.821292\n",
      "  Step 22, Current reward: -51.306053\n",
      "  Step 23, Current reward: -50.911859\n",
      "  Step 24, Current reward: -50.625606\n",
      "  Step 25, Current reward: -50.442841\n",
      "  Step 26, Current reward: -50.366186\n",
      "  Step 27, Current reward: -50.406473\n",
      "  Step 28, Current reward: -50.587573\n",
      "  Step 29, Current reward: -50.960282\n",
      "  Step 30, Current reward: -51.649016\n",
      "  Step 31, Current reward: -53.102841\n",
      "  Step 32, Current reward: -56.015033\n",
      "  Step 33, Current reward: -52.210828\n",
      "  Step 34, Current reward: -50.966817\n",
      "  Step 35, Current reward: -50.233915\n",
      "  Step 36, Current reward: -49.747457\n",
      "  Step 37, Current reward: -49.416343\n",
      "  Step 38, Current reward: -49.197946\n",
      "  Step 39, Current reward: -49.068699\n",
      "  Step 40, Current reward: -49.014090\n",
      "  Step 41, Current reward: -49.024482\n",
      "  Step 42, Current reward: -49.093093\n",
      "  Step 43, Current reward: -49.214936\n",
      "  Step 44, Current reward: -49.386206\n",
      "  Step 45, Current reward: -49.386206\n",
      "  Step 46, Current reward: -49.386206\n",
      "  Step 47, Current reward: -49.386206\n",
      "  Step 48, Current reward: -49.386206\n",
      "  Step 49, Current reward: -49.386206\n",
      "  Step 50, Current reward: -49.386206\n",
      "  Step 51, Current reward: -49.386206\n",
      "Episode 49/100 complete - Max Reward: -49.014090\n",
      "Starting episode 50/100\n",
      "  Step 1, Current reward: -65.811695\n",
      "  Step 2, Current reward: -66.441107\n",
      "  Step 3, Current reward: -67.837452\n",
      "  Step 4, Current reward: -72.092540\n",
      "  Step 5, Current reward: -71.393691\n",
      "  Step 6, Current reward: -66.102845\n",
      "  Step 7, Current reward: -63.593772\n",
      "  Step 8, Current reward: -61.860254\n",
      "  Step 9, Current reward: -60.528129\n",
      "  Step 10, Current reward: -59.454699\n",
      "  Step 11, Current reward: -58.569684\n",
      "  Step 12, Current reward: -57.833423\n",
      "  Step 13, Current reward: -57.221745\n",
      "  Step 14, Current reward: -56.719391\n",
      "  Step 15, Current reward: -56.316807\n",
      "  Step 16, Current reward: -56.008514\n",
      "  Step 17, Current reward: -55.792354\n",
      "  Step 18, Current reward: -55.669366\n",
      "  Step 19, Current reward: -55.644321\n",
      "  Step 20, Current reward: -55.727254\n",
      "  Step 21, Current reward: -55.937041\n",
      "  Step 22, Current reward: -56.310096\n",
      "  Step 23, Current reward: -56.925471\n",
      "  Step 24, Current reward: -58.005340\n",
      "  Step 25, Current reward: -60.881118\n",
      "  Step 26, Current reward: -59.322765\n",
      "  Step 27, Current reward: -57.618602\n",
      "  Step 28, Current reward: -56.822349\n",
      "  Step 29, Current reward: -56.368941\n",
      "  Step 30, Current reward: -56.113173\n",
      "Episode 50/100 complete - Max Reward: -55.644321\n",
      "Starting episode 51/100\n",
      "  Step 1, Current reward: -58.761385\n",
      "  Step 2, Current reward: -58.754962\n",
      "  Step 3, Current reward: -58.742440\n",
      "  Step 4, Current reward: -58.722545\n",
      "  Step 5, Current reward: -58.696738\n",
      "  Step 6, Current reward: -58.671069\n",
      "  Step 7, Current reward: -58.657458\n",
      "  Step 8, Current reward: -58.674230\n",
      "  Step 9, Current reward: -58.746504\n",
      "  Step 10, Current reward: -58.907980\n",
      "  Step 11, Current reward: -59.207075\n",
      "  Step 12, Current reward: -59.725389\n",
      "  Step 13, Current reward: -60.643032\n",
      "  Step 14, Current reward: -62.648508\n",
      "  Step 15, Current reward: -63.781963\n",
      "  Step 16, Current reward: -61.763989\n",
      "  Step 17, Current reward: -61.909159\n",
      "  Step 18, Current reward: -64.864535\n",
      "Episode 51/100 complete - Max Reward: -58.657458\n",
      "Starting episode 52/100\n",
      "  Step 1, Current reward: -38.797118\n",
      "  Step 2, Current reward: -39.296593\n",
      "  Step 3, Current reward: -39.895535\n",
      "  Step 4, Current reward: -40.607815\n",
      "  Step 5, Current reward: -41.459157\n",
      "  Step 6, Current reward: -42.501196\n",
      "  Step 7, Current reward: -43.857347\n",
      "  Step 8, Current reward: -45.965182\n",
      "  Step 9, Current reward: -49.793426\n",
      "  Step 10, Current reward: -46.506224\n",
      "  Step 11, Current reward: -45.937534\n",
      "  Step 12, Current reward: -45.894142\n",
      "Episode 52/100 complete - Max Reward: -38.797118\n",
      "Starting episode 53/100\n",
      "  Step 1, Current reward: -49.304959\n",
      "  Step 2, Current reward: -50.695263\n",
      "  Step 3, Current reward: -52.643177\n",
      "  Step 4, Current reward: -56.673440\n",
      "  Step 5, Current reward: -59.173213\n",
      "  Step 6, Current reward: -54.396121\n",
      "  Step 7, Current reward: -52.053067\n",
      "  Step 8, Current reward: -50.846258\n",
      "  Step 9, Current reward: -50.228486\n",
      "  Step 10, Current reward: -50.116267\n",
      "  Step 11, Current reward: -50.741068\n",
      "  Step 12, Current reward: -56.236188\n",
      "Episode 53/100 complete - Max Reward: -49.304959\n",
      "Starting episode 54/100\n",
      "  Step 1, Current reward: -42.575779\n",
      "  Step 2, Current reward: -42.485178\n",
      "  Step 3, Current reward: -42.487552\n",
      "  Step 4, Current reward: -42.590535\n",
      "  Step 5, Current reward: -42.807778\n",
      "  Step 6, Current reward: -43.163918\n",
      "  Step 7, Current reward: -43.707094\n",
      "  Step 8, Current reward: -44.548408\n",
      "  Step 9, Current reward: -46.054442\n",
      "  Step 10, Current reward: -52.005776\n",
      "  Step 11, Current reward: -46.142190\n",
      "  Step 12, Current reward: -45.034024\n",
      "  Step 13, Current reward: -44.525215\n",
      "Episode 54/100 complete - Max Reward: -42.485178\n",
      "Starting episode 55/100\n",
      "  Step 1, Current reward: -63.958912\n",
      "  Step 2, Current reward: -63.949524\n",
      "  Step 3, Current reward: -63.920039\n",
      "  Step 4, Current reward: -63.846373\n",
      "  Step 5, Current reward: -63.693877\n",
      "  Step 6, Current reward: -63.428350\n",
      "  Step 7, Current reward: -63.036025\n",
      "  Step 8, Current reward: -62.536273\n",
      "  Step 9, Current reward: -61.972965\n",
      "  Step 10, Current reward: -61.394161\n",
      "  Step 11, Current reward: -60.838160\n",
      "  Step 12, Current reward: -60.330462\n",
      "  Step 13, Current reward: -59.886493\n",
      "  Step 14, Current reward: -59.515384\n",
      "  Step 15, Current reward: -59.223015\n",
      "  Step 16, Current reward: -59.014126\n",
      "  Step 17, Current reward: -58.893831\n",
      "  Step 18, Current reward: -58.868890\n",
      "  Step 19, Current reward: -58.949141\n",
      "  Step 20, Current reward: -59.149620\n",
      "  Step 21, Current reward: -59.494414\n",
      "  Step 22, Current reward: -60.024892\n",
      "  Step 23, Current reward: -60.820887\n",
      "  Step 24, Current reward: -62.073537\n",
      "  Step 25, Current reward: -64.559835\n",
      "  Step 26, Current reward: -65.715298\n",
      "  Step 27, Current reward: -64.631463\n",
      "  Step 28, Current reward: -69.124878\n",
      "  Step 29, Current reward: -63.202331\n",
      "Episode 55/100 complete - Max Reward: -58.868890\n",
      "Starting episode 56/100\n",
      "  Step 1, Current reward: -41.204258\n",
      "  Step 2, Current reward: -42.180372\n",
      "  Step 3, Current reward: -43.702580\n",
      "  Step 4, Current reward: -48.568841\n",
      "  Step 5, Current reward: -44.748222\n",
      "  Step 6, Current reward: -43.596127\n",
      "  Step 7, Current reward: -43.143278\n",
      "  Step 8, Current reward: -42.987854\n",
      "  Step 9, Current reward: -43.013194\n",
      "  Step 10, Current reward: -43.170555\n",
      "  Step 11, Current reward: -43.436652\n",
      "  Step 12, Current reward: -43.800795\n",
      "Episode 56/100 complete - Max Reward: -41.204258\n",
      "Starting episode 57/100\n",
      "  Step 1, Current reward: -37.028699\n",
      "  Step 2, Current reward: -36.675753\n",
      "  Step 3, Current reward: -36.517354\n",
      "  Step 4, Current reward: -36.551979\n",
      "  Step 5, Current reward: -36.807708\n",
      "  Step 6, Current reward: -37.368293\n",
      "  Step 7, Current reward: -38.504931\n",
      "  Step 8, Current reward: -42.627165\n",
      "  Step 9, Current reward: -39.073124\n",
      "  Step 10, Current reward: -37.636367\n",
      "  Step 11, Current reward: -36.956314\n",
      "  Step 12, Current reward: -36.608904\n",
      "  Step 13, Current reward: -36.471999\n",
      "  Step 14, Current reward: -36.494115\n",
      "  Step 15, Current reward: -36.650161\n",
      "  Step 16, Current reward: -36.928185\n",
      "  Step 17, Current reward: -37.324870\n",
      "  Step 18, Current reward: -37.844791\n",
      "  Step 19, Current reward: -38.502763\n",
      "  Step 20, Current reward: -39.331616\n",
      "  Step 21, Current reward: -40.405797\n",
      "  Step 22, Current reward: -41.935532\n",
      "  Step 23, Current reward: -45.116791\n",
      "  Step 24, Current reward: -44.379371\n",
      "Episode 57/100 complete - Max Reward: -36.471999\n",
      "Starting episode 58/100\n",
      "  Step 1, Current reward: -59.411949\n",
      "  Step 2, Current reward: -59.351200\n",
      "  Step 3, Current reward: -59.343184\n",
      "  Step 4, Current reward: -59.520517\n",
      "  Step 5, Current reward: -60.245611\n",
      "  Step 6, Current reward: -67.389354\n",
      "  Step 7, Current reward: -59.111724\n",
      "  Step 8, Current reward: -57.159571\n",
      "  Step 9, Current reward: -55.851358\n",
      "  Step 10, Current reward: -54.840426\n",
      "  Step 11, Current reward: -54.020233\n",
      "  Step 12, Current reward: -53.343991\n",
      "  Step 13, Current reward: -52.787436\n",
      "  Step 14, Current reward: -52.337182\n",
      "  Step 15, Current reward: -51.986274\n",
      "  Step 16, Current reward: -51.732478\n",
      "  Step 17, Current reward: -51.577965\n",
      "  Step 18, Current reward: -51.530220\n",
      "  Step 19, Current reward: -51.604770\n",
      "  Step 20, Current reward: -51.832031\n",
      "  Step 21, Current reward: -52.276261\n",
      "  Step 22, Current reward: -53.104324\n",
      "  Step 23, Current reward: -55.056197\n",
      "  Step 24, Current reward: -55.394116\n",
      "  Step 25, Current reward: -53.028324\n",
      "  Step 26, Current reward: -52.002753\n",
      "  Step 27, Current reward: -51.388874\n",
      "  Step 28, Current reward: -50.997827\n",
      "  Step 29, Current reward: -50.758378\n",
      "  Step 30, Current reward: -50.636558\n",
      "  Step 31, Current reward: -50.614376\n",
      "  Step 32, Current reward: -50.682277\n",
      "  Step 33, Current reward: -50.836150\n",
      "  Step 34, Current reward: -51.076305\n",
      "  Step 35, Current reward: -51.407754\n",
      "  Step 36, Current reward: -51.841951\n",
      "  Step 37, Current reward: -52.401305\n",
      "  Step 38, Current reward: -53.130901\n",
      "  Step 39, Current reward: -54.135293\n",
      "  Step 40, Current reward: -55.752652\n",
      "  Step 41, Current reward: -55.752652\n",
      "  Step 42, Current reward: -55.752652\n",
      "Episode 58/100 complete - Max Reward: -50.614376\n",
      "Starting episode 59/100\n",
      "  Step 1, Current reward: -40.309137\n",
      "  Step 2, Current reward: -38.612444\n",
      "  Step 3, Current reward: -37.213935\n",
      "  Step 4, Current reward: -36.103780\n",
      "  Step 5, Current reward: -35.209994\n",
      "  Step 6, Current reward: -34.482546\n",
      "  Step 7, Current reward: -33.891106\n",
      "  Step 8, Current reward: -33.417939\n",
      "  Step 9, Current reward: -33.053147\n",
      "  Step 10, Current reward: -32.791924\n",
      "  Step 11, Current reward: -32.633151\n",
      "  Step 12, Current reward: -32.578915\n",
      "  Step 13, Current reward: -32.634877\n",
      "  Step 14, Current reward: -32.811717\n",
      "  Step 15, Current reward: -33.128623\n",
      "  Step 16, Current reward: -33.621795\n",
      "  Step 17, Current reward: -34.368752\n",
      "  Step 18, Current reward: -35.584305\n",
      "  Step 19, Current reward: -38.497873\n",
      "  Step 20, Current reward: -37.382492\n",
      "  Step 21, Current reward: -35.829505\n",
      "  Step 22, Current reward: -35.237997\n",
      "  Step 23, Current reward: -35.012868\n",
      "Episode 59/100 complete - Max Reward: -32.578915\n",
      "Starting episode 60/100\n",
      "  Step 1, Current reward: -60.999677\n",
      "  Step 2, Current reward: -56.499301\n",
      "  Step 3, Current reward: -56.032510\n",
      "  Step 4, Current reward: -57.913912\n",
      "  Step 5, Current reward: -55.416016\n",
      "  Step 6, Current reward: -53.006887\n",
      "  Step 7, Current reward: -51.563457\n",
      "  Step 8, Current reward: -50.508588\n",
      "  Step 9, Current reward: -49.685014\n",
      "  Step 10, Current reward: -49.024860\n",
      "  Step 11, Current reward: -48.492202\n",
      "  Step 12, Current reward: -48.065748\n",
      "  Step 13, Current reward: -47.732024\n",
      "  Step 14, Current reward: -47.482252\n",
      "  Step 15, Current reward: -47.310776\n",
      "  Step 16, Current reward: -47.214251\n",
      "  Step 17, Current reward: -47.191273\n",
      "  Step 18, Current reward: -47.242322\n",
      "  Step 19, Current reward: -47.370026\n",
      "  Step 20, Current reward: -47.579853\n",
      "  Step 21, Current reward: -47.881563\n",
      "  Step 22, Current reward: -48.292268\n",
      "  Step 23, Current reward: -48.843476\n",
      "  Step 24, Current reward: -49.600168\n",
      "  Step 25, Current reward: -50.729645\n",
      "  Step 26, Current reward: -52.971999\n",
      "  Step 27, Current reward: -53.590183\n",
      "  Step 28, Current reward: -51.492977\n",
      "Episode 60/100 complete - Max Reward: -47.191273\n",
      "Starting episode 61/100\n",
      "  Step 1, Current reward: -52.983284\n",
      "  Step 2, Current reward: -52.207053\n",
      "  Step 3, Current reward: -51.631889\n",
      "  Step 4, Current reward: -51.215064\n",
      "  Step 5, Current reward: -50.937349\n",
      "  Step 6, Current reward: -50.792628\n",
      "  Step 7, Current reward: -50.785265\n",
      "  Step 8, Current reward: -50.932307\n",
      "  Step 9, Current reward: -51.273168\n",
      "  Step 10, Current reward: -51.901699\n",
      "  Step 11, Current reward: -53.111802\n",
      "  Step 12, Current reward: -57.979172\n",
      "  Step 13, Current reward: -53.502130\n",
      "  Step 14, Current reward: -52.108797\n",
      "  Step 15, Current reward: -51.419286\n",
      "  Step 16, Current reward: -51.041353\n",
      "  Step 17, Current reward: -50.859169\n",
      "  Step 18, Current reward: -50.823560\n",
      "Episode 61/100 complete - Max Reward: -50.785265\n",
      "Starting episode 62/100\n",
      "  Step 1, Current reward: -49.659437\n",
      "  Step 2, Current reward: -49.216009\n",
      "  Step 3, Current reward: -48.859954\n",
      "  Step 4, Current reward: -48.588975\n",
      "  Step 5, Current reward: -48.402232\n",
      "  Step 6, Current reward: -48.300527\n",
      "  Step 7, Current reward: -48.286652\n",
      "  Step 8, Current reward: -48.366095\n",
      "  Step 9, Current reward: -48.548457\n",
      "  Step 10, Current reward: -48.850393\n",
      "  Step 11, Current reward: -49.302311\n",
      "  Step 12, Current reward: -49.966301\n",
      "  Step 13, Current reward: -50.999352\n",
      "  Step 14, Current reward: -53.059834\n",
      "  Step 15, Current reward: -54.106789\n",
      "  Step 16, Current reward: -51.784840\n",
      "  Step 17, Current reward: -50.963916\n",
      "  Step 18, Current reward: -50.574932\n",
      "Episode 62/100 complete - Max Reward: -48.286652\n",
      "Starting episode 63/100\n",
      "  Step 1, Current reward: -43.606540\n",
      "  Step 2, Current reward: -43.352780\n",
      "  Step 3, Current reward: -43.188176\n",
      "  Step 4, Current reward: -43.112348\n",
      "  Step 5, Current reward: -43.125959\n",
      "  Step 6, Current reward: -43.230780\n",
      "  Step 7, Current reward: -43.429929\n",
      "  Step 8, Current reward: -43.728392\n",
      "  Step 9, Current reward: -44.134001\n",
      "  Step 10, Current reward: -44.659385\n",
      "  Step 11, Current reward: -45.326214\n",
      "  Step 12, Current reward: -46.175814\n",
      "  Step 13, Current reward: -47.302160\n",
      "  Step 14, Current reward: -49.003563\n",
      "  Step 15, Current reward: -54.871617\n",
      "Episode 63/100 complete - Max Reward: -43.112348\n",
      "Starting episode 64/100\n",
      "  Step 1, Current reward: -47.953855\n",
      "  Step 2, Current reward: -47.643457\n",
      "  Step 3, Current reward: -47.416764\n",
      "  Step 4, Current reward: -47.274326\n",
      "  Step 5, Current reward: -47.217436\n",
      "  Step 6, Current reward: -47.248193\n",
      "  Step 7, Current reward: -47.369730\n",
      "  Step 8, Current reward: -47.586674\n",
      "  Step 9, Current reward: -47.905966\n",
      "  Step 10, Current reward: -48.338402\n",
      "  Step 11, Current reward: -48.901713\n",
      "  Step 12, Current reward: -49.627501\n",
      "  Step 13, Current reward: -50.579793\n",
      "  Step 14, Current reward: -51.921023\n",
      "  Step 15, Current reward: -54.348639\n",
      "  Step 16, Current reward: -55.479919\n",
      "Episode 64/100 complete - Max Reward: -47.217436\n",
      "Starting episode 65/100\n",
      "  Step 1, Current reward: -53.681035\n",
      "  Step 2, Current reward: -53.647210\n",
      "  Step 3, Current reward: -53.801604\n",
      "  Step 4, Current reward: -54.087428\n",
      "  Step 5, Current reward: -54.475371\n",
      "  Step 6, Current reward: -54.948455\n",
      "  Step 7, Current reward: -55.496209\n",
      "  Step 8, Current reward: -56.112106\n",
      "  Step 9, Current reward: -56.792412\n",
      "  Step 10, Current reward: -57.535860\n",
      "  Step 11, Current reward: -58.344032\n",
      "  Step 12, Current reward: -59.222710\n",
      "  Step 13, Current reward: -60.185114\n",
      "Episode 65/100 complete - Max Reward: -53.647210\n",
      "Starting episode 66/100\n",
      "  Step 1, Current reward: -43.329831\n",
      "  Step 2, Current reward: -42.583845\n",
      "  Step 3, Current reward: -41.993486\n",
      "  Step 4, Current reward: -41.522518\n",
      "  Step 5, Current reward: -41.155561\n",
      "  Step 6, Current reward: -40.888132\n",
      "  Step 7, Current reward: -40.721788\n",
      "  Step 8, Current reward: -40.662151\n",
      "  Step 9, Current reward: -40.718812\n",
      "  Step 10, Current reward: -40.907006\n",
      "  Step 11, Current reward: -41.252144\n",
      "  Step 12, Current reward: -41.801499\n",
      "  Step 13, Current reward: -42.660536\n",
      "  Step 14, Current reward: -44.163551\n",
      "  Step 15, Current reward: -53.472339\n",
      "  Step 16, Current reward: -44.684045\n",
      "  Step 17, Current reward: -43.633406\n",
      "  Step 18, Current reward: -43.231134\n",
      "  Step 19, Current reward: -43.123992\n",
      "Episode 66/100 complete - Max Reward: -40.662151\n",
      "Starting episode 67/100\n",
      "  Step 1, Current reward: -47.777074\n",
      "  Step 2, Current reward: -47.771070\n",
      "  Step 3, Current reward: -47.752368\n",
      "  Step 4, Current reward: -47.713185\n",
      "  Step 5, Current reward: -47.649103\n",
      "  Step 6, Current reward: -47.563961\n",
      "  Step 7, Current reward: -47.473148\n",
      "  Step 8, Current reward: -47.404214\n",
      "  Step 9, Current reward: -47.396857\n",
      "  Step 10, Current reward: -47.507868\n",
      "  Step 11, Current reward: -47.834113\n",
      "  Step 12, Current reward: -48.613581\n",
      "  Step 13, Current reward: -51.216284\n",
      "  Step 14, Current reward: -49.288534\n",
      "  Step 15, Current reward: -47.306807\n",
      "  Step 16, Current reward: -46.245309\n",
      "  Step 17, Current reward: -45.555723\n",
      "  Step 18, Current reward: -45.106882\n",
      "  Step 19, Current reward: -44.859481\n",
      "  Step 20, Current reward: -44.818248\n",
      "  Step 21, Current reward: -45.036847\n",
      "  Step 22, Current reward: -45.690599\n",
      "  Step 23, Current reward: -47.673912\n",
      "  Step 24, Current reward: -47.105991\n",
      "  Step 25, Current reward: -44.803942\n",
      "  Step 26, Current reward: -43.655232\n",
      "  Step 27, Current reward: -42.896902\n",
      "  Step 28, Current reward: -42.356676\n",
      "  Step 29, Current reward: -41.966638\n",
      "  Step 30, Current reward: -41.693012\n",
      "  Step 31, Current reward: -41.516754\n",
      "  Step 32, Current reward: -41.426408\n",
      "  Step 33, Current reward: -41.414998\n",
      "  Step 34, Current reward: -41.478583\n",
      "  Step 35, Current reward: -41.615606\n",
      "  Step 36, Current reward: -41.826742\n",
      "  Step 37, Current reward: -42.115188\n",
      "  Step 38, Current reward: -42.487508\n",
      "  Step 39, Current reward: -42.955499\n",
      "  Step 40, Current reward: -43.540267\n",
      "  Step 41, Current reward: -44.282127\n",
      "  Step 42, Current reward: -45.269884\n",
      "  Step 43, Current reward: -46.765460\n",
      "  Step 44, Current reward: -50.800839\n",
      "Episode 67/100 complete - Max Reward: -41.414998\n",
      "Starting episode 68/100\n",
      "  Step 1, Current reward: -41.791896\n",
      "  Step 2, Current reward: -44.959403\n",
      "  Step 3, Current reward: -44.261320\n",
      "  Step 4, Current reward: -43.054584\n",
      "  Step 5, Current reward: -42.862768\n",
      "  Step 6, Current reward: -43.077156\n",
      "  Step 7, Current reward: -43.528196\n",
      "  Step 8, Current reward: -44.095999\n",
      "  Step 9, Current reward: -44.619323\n",
      "  Step 10, Current reward: -44.902384\n",
      "  Step 11, Current reward: -44.863404\n",
      "  Step 12, Current reward: -44.618981\n",
      "Episode 68/100 complete - Max Reward: -41.791896\n",
      "Starting episode 69/100\n",
      "  Step 1, Current reward: -60.797699\n",
      "  Step 2, Current reward: -59.469017\n",
      "  Step 3, Current reward: -66.977238\n",
      "  Step 4, Current reward: -57.085281\n",
      "  Step 5, Current reward: -54.890276\n",
      "  Step 6, Current reward: -53.426012\n",
      "  Step 7, Current reward: -52.312684\n",
      "  Step 8, Current reward: -51.423691\n",
      "  Step 9, Current reward: -50.699928\n",
      "  Step 10, Current reward: -50.109077\n",
      "  Step 11, Current reward: -49.632001\n",
      "  Step 12, Current reward: -49.257124\n",
      "  Step 13, Current reward: -48.977834\n",
      "  Step 14, Current reward: -48.791318\n",
      "  Step 15, Current reward: -48.698249\n",
      "  Step 16, Current reward: -48.703231\n",
      "  Step 17, Current reward: -48.816298\n",
      "  Step 18, Current reward: -49.056477\n",
      "  Step 19, Current reward: -49.460511\n",
      "  Step 20, Current reward: -50.108066\n",
      "  Step 21, Current reward: -51.222815\n",
      "  Step 22, Current reward: -54.150684\n",
      "  Step 23, Current reward: -52.596281\n",
      "  Step 24, Current reward: -50.939357\n",
      "  Step 25, Current reward: -50.191123\n",
      "  Step 26, Current reward: -49.791993\n",
      "Episode 69/100 complete - Max Reward: -48.698249\n",
      "Starting episode 70/100\n",
      "  Step 1, Current reward: -53.145427\n",
      "  Step 2, Current reward: -52.944345\n",
      "  Step 3, Current reward: -52.873653\n",
      "  Step 4, Current reward: -52.912140\n",
      "  Step 5, Current reward: -53.046803\n",
      "  Step 6, Current reward: -53.269323\n",
      "  Step 7, Current reward: -53.574416\n",
      "  Step 8, Current reward: -53.959065\n",
      "  Step 9, Current reward: -54.422236\n",
      "  Step 10, Current reward: -54.964966\n",
      "  Step 11, Current reward: -55.590832\n",
      "  Step 12, Current reward: -56.307013\n",
      "  Step 13, Current reward: -57.126494\n",
      "  Step 14, Current reward: -58.072873\n",
      "Episode 70/100 complete - Max Reward: -52.873653\n",
      "Starting episode 71/100\n",
      "  Step 1, Current reward: -55.333837\n",
      "  Step 2, Current reward: -55.304788\n",
      "  Step 3, Current reward: -55.424112\n",
      "  Step 4, Current reward: -55.738413\n",
      "  Step 5, Current reward: -56.359230\n",
      "  Step 6, Current reward: -57.663308\n",
      "  Step 7, Current reward: -62.675402\n",
      "  Step 8, Current reward: -57.222902\n",
      "  Step 9, Current reward: -55.908883\n",
      "  Step 10, Current reward: -55.177810\n",
      "  Step 11, Current reward: -54.722947\n",
      "  Step 12, Current reward: -54.444552\n",
      "  Step 13, Current reward: -54.297645\n",
      "  Step 14, Current reward: -54.258371\n",
      "  Step 15, Current reward: -54.312950\n",
      "  Step 16, Current reward: -54.453218\n",
      "  Step 17, Current reward: -54.674611\n",
      "  Step 18, Current reward: -54.975259\n",
      "  Step 19, Current reward: -55.355701\n",
      "  Step 20, Current reward: -55.819078\n",
      "  Step 21, Current reward: -56.371903\n",
      "  Step 22, Current reward: -57.025786\n",
      "  Step 23, Current reward: -57.801206\n",
      "  Step 24, Current reward: -58.736549\n",
      "  Step 25, Current reward: -59.914163\n",
      "Episode 71/100 complete - Max Reward: -54.258371\n",
      "Starting episode 72/100\n",
      "  Step 1, Current reward: -37.554665\n",
      "  Step 2, Current reward: -38.073488\n",
      "  Step 3, Current reward: -38.704262\n",
      "  Step 4, Current reward: -39.457494\n",
      "  Step 5, Current reward: -40.352161\n",
      "  Step 6, Current reward: -41.422878\n",
      "  Step 7, Current reward: -42.738402\n",
      "  Step 8, Current reward: -44.463345\n",
      "  Step 9, Current reward: -47.218696\n",
      "  Step 10, Current reward: -49.768768\n",
      "  Step 11, Current reward: -48.584582\n",
      "  Step 12, Current reward: -51.107902\n",
      "Episode 72/100 complete - Max Reward: -37.554665\n",
      "Starting episode 73/100\n",
      "  Step 1, Current reward: -52.871318\n",
      "  Step 2, Current reward: -56.302447\n",
      "  Step 3, Current reward: -51.692853\n",
      "  Step 4, Current reward: -50.183803\n",
      "  Step 5, Current reward: -49.226830\n",
      "  Step 6, Current reward: -48.539403\n",
      "  Step 7, Current reward: -48.027459\n",
      "  Step 8, Current reward: -47.648707\n",
      "  Step 9, Current reward: -47.381482\n",
      "  Step 10, Current reward: -47.214526\n",
      "  Step 11, Current reward: -47.143085\n",
      "  Step 12, Current reward: -47.167631\n",
      "  Step 13, Current reward: -47.294239\n",
      "  Step 14, Current reward: -47.536894\n",
      "  Step 15, Current reward: -47.923683\n",
      "  Step 16, Current reward: -48.513923\n",
      "  Step 17, Current reward: -49.458491\n",
      "  Step 18, Current reward: -51.377045\n",
      "  Step 19, Current reward: -52.592934\n",
      "  Step 20, Current reward: -50.054400\n",
      "  Step 21, Current reward: -49.106227\n",
      "  Step 22, Current reward: -48.590877\n",
      "Episode 73/100 complete - Max Reward: -47.143085\n",
      "Starting episode 74/100\n",
      "  Step 1, Current reward: -50.965625\n",
      "  Step 2, Current reward: -55.375999\n",
      "  Step 3, Current reward: -51.189580\n",
      "  Step 4, Current reward: -51.265144\n",
      "  Step 5, Current reward: -55.563536\n",
      "  Step 6, Current reward: -49.777706\n",
      "  Step 7, Current reward: -48.232901\n",
      "  Step 8, Current reward: -47.373474\n",
      "  Step 9, Current reward: -46.866517\n",
      "  Step 10, Current reward: -46.597760\n",
      "  Step 11, Current reward: -46.515491\n",
      "  Step 12, Current reward: -46.595618\n",
      "  Step 13, Current reward: -46.831477\n",
      "  Step 14, Current reward: -47.233250\n",
      "  Step 15, Current reward: -47.837044\n",
      "  Step 16, Current reward: -48.739544\n",
      "  Step 17, Current reward: -50.265663\n",
      "  Step 18, Current reward: -58.590209\n",
      "  Step 19, Current reward: -50.811204\n",
      "  Step 20, Current reward: -50.811204\n",
      "  Step 21, Current reward: -50.811204\n",
      "  Step 22, Current reward: -50.811204\n",
      "Episode 74/100 complete - Max Reward: -46.515491\n",
      "Starting episode 75/100\n",
      "  Step 1, Current reward: -54.516282\n",
      "  Step 2, Current reward: -50.864390\n",
      "  Step 3, Current reward: -48.801161\n",
      "  Step 4, Current reward: -47.268239\n",
      "  Step 5, Current reward: -46.044951\n",
      "  Step 6, Current reward: -45.041172\n",
      "  Step 7, Current reward: -44.209682\n",
      "  Step 8, Current reward: -43.522699\n",
      "  Step 9, Current reward: -42.963297\n",
      "  Step 10, Current reward: -42.521758\n",
      "  Step 11, Current reward: -42.194101\n",
      "  Step 12, Current reward: -41.981970\n",
      "  Step 13, Current reward: -41.893959\n",
      "  Step 14, Current reward: -41.949497\n",
      "  Step 15, Current reward: -42.189070\n",
      "  Step 16, Current reward: -42.705577\n",
      "  Step 17, Current reward: -43.782788\n",
      "  Step 18, Current reward: -48.061508\n",
      "  Step 19, Current reward: -44.062412\n",
      "  Step 20, Current reward: -42.519571\n",
      "  Step 21, Current reward: -41.704859\n",
      "  Step 22, Current reward: -41.209874\n",
      "  Step 23, Current reward: -40.917992\n",
      "  Step 24, Current reward: -40.782351\n",
      "  Step 25, Current reward: -40.783306\n",
      "  Step 26, Current reward: -40.916570\n",
      "  Step 27, Current reward: -41.191216\n",
      "  Step 28, Current reward: -41.634915\n",
      "  Step 29, Current reward: -42.313845\n",
      "  Step 30, Current reward: -43.411123\n",
      "  Step 31, Current reward: -45.829566\n",
      "  Step 32, Current reward: -45.668725\n",
      "  Step 33, Current reward: -43.785110\n",
      "  Step 34, Current reward: -43.047150\n",
      "  Step 35, Current reward: -42.696618\n",
      "Episode 75/100 complete - Max Reward: -40.782351\n",
      "Starting episode 76/100\n",
      "  Step 1, Current reward: -50.572904\n",
      "  Step 2, Current reward: -50.560550\n",
      "  Step 3, Current reward: -50.535766\n",
      "  Step 4, Current reward: -50.503384\n",
      "  Step 5, Current reward: -50.483106\n",
      "  Step 6, Current reward: -50.514382\n",
      "  Step 7, Current reward: -50.664396\n",
      "  Step 8, Current reward: -51.060173\n",
      "  Step 9, Current reward: -52.060628\n",
      "  Step 10, Current reward: -63.117145\n",
      "  Step 11, Current reward: -51.401655\n",
      "  Step 12, Current reward: -49.780998\n",
      "  Step 13, Current reward: -48.800869\n",
      "  Step 14, Current reward: -48.131925\n",
      "  Step 15, Current reward: -47.679795\n",
      "  Step 16, Current reward: -47.415165\n",
      "  Step 17, Current reward: -47.343641\n",
      "  Step 18, Current reward: -47.510837\n",
      "  Step 19, Current reward: -48.055776\n",
      "  Step 20, Current reward: -49.562173\n",
      "  Step 21, Current reward: -50.679307\n",
      "  Step 22, Current reward: -47.706291\n",
      "  Step 23, Current reward: -46.442608\n",
      "  Step 24, Current reward: -45.641437\n",
      "  Step 25, Current reward: -45.084785\n",
      "  Step 26, Current reward: -44.693120\n",
      "  Step 27, Current reward: -44.428648\n",
      "  Step 28, Current reward: -44.270836\n",
      "  Step 29, Current reward: -44.207810\n",
      "  Step 30, Current reward: -44.232756\n",
      "  Step 31, Current reward: -44.342282\n",
      "  Step 32, Current reward: -44.535717\n",
      "  Step 33, Current reward: -44.814994\n",
      "  Step 34, Current reward: -45.185027\n",
      "  Step 35, Current reward: -45.654770\n",
      "  Step 36, Current reward: -46.239468\n",
      "  Step 37, Current reward: -46.965597\n",
      "  Step 38, Current reward: -47.883034\n",
      "  Step 39, Current reward: -49.102437\n",
      "  Step 40, Current reward: -50.970334\n",
      "Episode 76/100 complete - Max Reward: -44.207810\n",
      "Starting episode 77/100\n",
      "  Step 1, Current reward: -47.880783\n",
      "  Step 2, Current reward: -47.804327\n",
      "  Step 3, Current reward: -47.981597\n",
      "  Step 4, Current reward: -48.335806\n",
      "  Step 5, Current reward: -48.828435\n",
      "  Step 6, Current reward: -49.434594\n",
      "  Step 7, Current reward: -50.132221\n",
      "  Step 8, Current reward: -50.894202\n",
      "  Step 9, Current reward: -51.680375\n",
      "  Step 10, Current reward: -52.431010\n",
      "  Step 11, Current reward: -53.070456\n",
      "  Step 12, Current reward: -53.532111\n",
      "  Step 13, Current reward: -53.793748\n",
      "Episode 77/100 complete - Max Reward: -47.804327\n",
      "Starting episode 78/100\n",
      "  Step 1, Current reward: -49.131078\n",
      "  Step 2, Current reward: -49.412363\n",
      "  Step 3, Current reward: -50.336068\n",
      "  Step 4, Current reward: -54.275969\n",
      "  Step 5, Current reward: -48.875665\n",
      "  Step 6, Current reward: -47.089651\n",
      "  Step 7, Current reward: -45.861927\n",
      "  Step 8, Current reward: -44.899935\n",
      "  Step 9, Current reward: -44.108634\n",
      "  Step 10, Current reward: -43.445328\n",
      "  Step 11, Current reward: -42.887391\n",
      "  Step 12, Current reward: -42.421733\n",
      "  Step 13, Current reward: -42.040600\n",
      "  Step 14, Current reward: -41.739722\n",
      "  Step 15, Current reward: -41.517518\n",
      "  Step 16, Current reward: -41.374935\n",
      "  Step 17, Current reward: -41.315810\n",
      "  Step 18, Current reward: -41.347952\n",
      "  Step 19, Current reward: -41.485532\n",
      "  Step 20, Current reward: -41.754521\n",
      "  Step 21, Current reward: -42.206706\n",
      "  Step 22, Current reward: -42.965470\n",
      "  Step 23, Current reward: -44.467588\n",
      "  Step 24, Current reward: -47.700169\n",
      "  Step 25, Current reward: -43.781985\n",
      "  Step 26, Current reward: -42.584827\n",
      "  Step 27, Current reward: -41.904764\n",
      "  Step 28, Current reward: -41.470988\n",
      "Episode 78/100 complete - Max Reward: -41.315810\n",
      "Starting episode 79/100\n",
      "  Step 1, Current reward: -44.081254\n",
      "  Step 2, Current reward: -42.957976\n",
      "  Step 3, Current reward: -42.074520\n",
      "  Step 4, Current reward: -41.366352\n",
      "  Step 5, Current reward: -40.799032\n",
      "  Step 6, Current reward: -40.352942\n",
      "  Step 7, Current reward: -40.016758\n",
      "  Step 8, Current reward: -39.784375\n",
      "  Step 9, Current reward: -39.653485\n",
      "  Step 10, Current reward: -39.625149\n",
      "  Step 11, Current reward: -39.704203\n",
      "  Step 12, Current reward: -39.900791\n",
      "  Step 13, Current reward: -40.234018\n",
      "  Step 14, Current reward: -40.740952\n",
      "  Step 15, Current reward: -41.502785\n",
      "  Step 16, Current reward: -42.751242\n",
      "  Step 17, Current reward: -45.961809\n",
      "  Step 18, Current reward: -44.232327\n",
      "  Step 19, Current reward: -42.753082\n",
      "  Step 20, Current reward: -42.146836\n",
      "  Step 21, Current reward: -41.882478\n",
      "Episode 79/100 complete - Max Reward: -39.625149\n",
      "Starting episode 80/100\n",
      "  Step 1, Current reward: -47.463721\n",
      "  Step 2, Current reward: -47.334233\n",
      "  Step 3, Current reward: -47.391446\n",
      "  Step 4, Current reward: -47.779075\n",
      "  Step 5, Current reward: -49.010906\n",
      "  Step 6, Current reward: -50.741666\n",
      "  Step 7, Current reward: -47.179678\n",
      "  Step 8, Current reward: -45.685832\n",
      "  Step 9, Current reward: -44.680679\n",
      "  Step 10, Current reward: -43.926611\n",
      "  Step 11, Current reward: -43.342597\n",
      "  Step 12, Current reward: -42.894057\n",
      "  Step 13, Current reward: -42.566374\n",
      "  Step 14, Current reward: -42.356516\n",
      "  Step 15, Current reward: -42.271056\n",
      "  Step 16, Current reward: -42.328604\n",
      "  Step 17, Current reward: -42.569443\n",
      "  Step 18, Current reward: -43.086932\n",
      "  Step 19, Current reward: -44.168335\n",
      "  Step 20, Current reward: -48.590903\n",
      "  Step 21, Current reward: -44.389988\n",
      "  Step 22, Current reward: -42.844427\n",
      "  Step 23, Current reward: -42.013281\n",
      "  Step 24, Current reward: -41.493325\n",
      "  Step 25, Current reward: -41.167471\n",
      "  Step 26, Current reward: -40.987040\n",
      "  Step 27, Current reward: -40.929401\n",
      "  Step 28, Current reward: -40.985437\n",
      "  Step 29, Current reward: -41.155795\n",
      "  Step 30, Current reward: -41.451569\n",
      "  Step 31, Current reward: -41.900148\n",
      "  Step 32, Current reward: -42.563711\n",
      "  Step 33, Current reward: -43.608044\n",
      "  Step 34, Current reward: -45.777324\n",
      "  Step 35, Current reward: -46.288137\n",
      "  Step 36, Current reward: -44.127556\n",
      "  Step 37, Current reward: -43.289060\n",
      "  Step 38, Current reward: -42.850730\n",
      "Episode 80/100 complete - Max Reward: -40.929401\n",
      "Starting episode 81/100\n",
      "  Step 1, Current reward: -47.793956\n",
      "  Step 2, Current reward: -47.710414\n",
      "  Step 3, Current reward: -47.881840\n",
      "  Step 4, Current reward: -48.489579\n",
      "  Step 5, Current reward: -50.433913\n",
      "  Step 6, Current reward: -49.822605\n",
      "  Step 7, Current reward: -47.498157\n",
      "  Step 8, Current reward: -46.337714\n",
      "  Step 9, Current reward: -45.583307\n",
      "  Step 10, Current reward: -45.066983\n",
      "  Step 11, Current reward: -44.726365\n",
      "  Step 12, Current reward: -44.535426\n",
      "  Step 13, Current reward: -44.486756\n",
      "  Step 14, Current reward: -44.587775\n",
      "  Step 15, Current reward: -44.865428\n",
      "  Step 16, Current reward: -45.386351\n",
      "  Step 17, Current reward: -46.338147\n",
      "  Step 18, Current reward: -48.675232\n",
      "  Step 19, Current reward: -48.169711\n",
      "  Step 20, Current reward: -46.192649\n",
      "  Step 21, Current reward: -45.319253\n",
      "  Step 22, Current reward: -44.827188\n",
      "  Step 23, Current reward: -44.549780\n",
      "  Step 24, Current reward: -44.421178\n",
      "  Step 25, Current reward: -44.408836\n",
      "  Step 26, Current reward: -44.494731\n",
      "  Step 27, Current reward: -44.668449\n",
      "  Step 28, Current reward: -44.924260\n",
      "  Step 29, Current reward: -45.259851\n",
      "  Step 30, Current reward: -45.675963\n",
      "  Step 31, Current reward: -46.176734\n",
      "  Step 32, Current reward: -46.770934\n",
      "  Step 33, Current reward: -47.474860\n",
      "  Step 34, Current reward: -48.319167\n",
      "  Step 35, Current reward: -49.367473\n",
      "  Step 36, Current reward: -50.783047\n",
      "Episode 81/100 complete - Max Reward: -44.408836\n",
      "Starting episode 82/100\n",
      "  Step 1, Current reward: -43.646020\n",
      "  Step 2, Current reward: -43.201277\n",
      "  Step 3, Current reward: -42.569725\n",
      "  Step 4, Current reward: -41.841030\n",
      "  Step 5, Current reward: -41.096685\n",
      "  Step 6, Current reward: -40.386845\n",
      "  Step 7, Current reward: -39.736039\n",
      "  Step 8, Current reward: -39.154084\n",
      "  Step 9, Current reward: -38.643638\n",
      "  Step 10, Current reward: -38.204294\n",
      "  Step 11, Current reward: -37.834593\n",
      "  Step 12, Current reward: -37.532998\n",
      "  Step 13, Current reward: -37.298370\n",
      "  Step 14, Current reward: -37.130236\n",
      "  Step 15, Current reward: -37.029013\n",
      "  Step 16, Current reward: -36.996273\n",
      "  Step 17, Current reward: -37.035145\n",
      "  Step 18, Current reward: -37.151020\n",
      "  Step 19, Current reward: -37.352815\n",
      "  Step 20, Current reward: -37.655491\n",
      "  Step 21, Current reward: -38.085529\n",
      "  Step 22, Current reward: -38.694887\n",
      "  Step 23, Current reward: -39.606322\n",
      "  Step 24, Current reward: -41.251105\n",
      "  Step 25, Current reward: -44.756177\n",
      "  Step 26, Current reward: -40.898476\n",
      "  Step 27, Current reward: -39.841459\n",
      "Episode 82/100 complete - Max Reward: -36.996273\n",
      "Starting episode 83/100\n",
      "  Step 1, Current reward: -41.124008\n",
      "  Step 2, Current reward: -41.095017\n",
      "  Step 3, Current reward: -41.208753\n",
      "  Step 4, Current reward: -41.501909\n",
      "  Step 5, Current reward: -42.055635\n",
      "  Step 6, Current reward: -43.101493\n",
      "  Step 7, Current reward: -46.108647\n",
      "  Step 8, Current reward: -44.205621\n",
      "  Step 9, Current reward: -42.543088\n",
      "  Step 10, Current reward: -41.762931\n",
      "  Step 11, Current reward: -41.332991\n",
      "  Step 12, Current reward: -41.113318\n",
      "  Step 13, Current reward: -41.046245\n",
      "  Step 14, Current reward: -41.102805\n",
      "  Step 15, Current reward: -41.266946\n",
      "  Step 16, Current reward: -41.529536\n",
      "  Step 17, Current reward: -41.885742\n",
      "  Step 18, Current reward: -42.333821\n",
      "  Step 19, Current reward: -42.874615\n",
      "  Step 20, Current reward: -43.511453\n",
      "  Step 21, Current reward: -44.250379\n",
      "  Step 22, Current reward: -45.100654\n",
      "  Step 23, Current reward: -46.075562\n",
      "  Step 24, Current reward: -47.193449\n",
      "Episode 83/100 complete - Max Reward: -41.046245\n",
      "Starting episode 84/100\n",
      "  Step 1, Current reward: -43.215442\n",
      "  Step 2, Current reward: -43.127409\n",
      "  Step 3, Current reward: -43.137323\n",
      "  Step 4, Current reward: -43.251848\n",
      "  Step 5, Current reward: -43.481362\n",
      "  Step 6, Current reward: -43.842705\n",
      "  Step 7, Current reward: -44.365340\n",
      "  Step 8, Current reward: -45.107464\n",
      "  Step 9, Current reward: -46.210711\n",
      "  Step 10, Current reward: -48.219829\n",
      "  Step 11, Current reward: -50.321958\n",
      "  Step 12, Current reward: -47.726633\n",
      "  Step 13, Current reward: -47.034044\n",
      "Episode 84/100 complete - Max Reward: -43.127409\n",
      "Starting episode 85/100\n",
      "  Step 1, Current reward: -56.135939\n",
      "  Step 2, Current reward: -58.114542\n",
      "  Step 3, Current reward: -58.114542\n",
      "  Step 4, Current reward: -58.114542\n",
      "  Step 5, Current reward: -58.114542\n",
      "  Step 6, Current reward: -58.114542\n",
      "  Step 7, Current reward: -58.114542\n",
      "  Step 8, Current reward: -58.114542\n",
      "  Step 9, Current reward: -58.114542\n",
      "  Step 10, Current reward: -58.114542\n",
      "  Step 11, Current reward: -58.114542\n",
      "  Step 12, Current reward: -58.114542\n",
      "Episode 85/100 complete - Max Reward: -56.135939\n",
      "Starting episode 86/100\n",
      "  Step 1, Current reward: -45.670373\n",
      "  Step 2, Current reward: -45.869188\n",
      "  Step 3, Current reward: -46.283093\n",
      "  Step 4, Current reward: -47.038334\n",
      "  Step 5, Current reward: -48.611655\n",
      "  Step 6, Current reward: -51.126314\n",
      "  Step 7, Current reward: -47.732196\n",
      "  Step 8, Current reward: -46.620401\n",
      "  Step 9, Current reward: -46.012580\n",
      "  Step 10, Current reward: -45.656872\n",
      "  Step 11, Current reward: -45.465407\n",
      "  Step 12, Current reward: -45.397251\n",
      "  Step 13, Current reward: -45.430365\n",
      "  Step 14, Current reward: -45.552040\n",
      "  Step 15, Current reward: -45.754943\n",
      "  Step 16, Current reward: -46.035329\n",
      "  Step 17, Current reward: -46.392261\n",
      "  Step 18, Current reward: -46.827435\n",
      "  Step 19, Current reward: -47.345522\n",
      "  Step 20, Current reward: -47.955179\n",
      "  Step 21, Current reward: -48.671267\n",
      "  Step 22, Current reward: -49.519762\n",
      "  Step 23, Current reward: -50.550000\n",
      "Episode 86/100 complete - Max Reward: -45.397251\n",
      "Starting episode 87/100\n",
      "  Step 1, Current reward: -58.149762\n",
      "  Step 2, Current reward: -58.149762\n",
      "  Step 3, Current reward: -58.149762\n",
      "  Step 4, Current reward: -58.149762\n",
      "  Step 5, Current reward: -58.149762\n",
      "  Step 6, Current reward: -58.149762\n",
      "  Step 7, Current reward: -58.149762\n",
      "  Step 8, Current reward: -58.149762\n",
      "  Step 9, Current reward: -58.149762\n",
      "  Step 10, Current reward: -58.149762\n",
      "  Step 11, Current reward: -58.149762\n",
      "  Step 12, Current reward: -58.149762\n",
      "Episode 87/100 complete - Max Reward: -58.149762\n",
      "Starting episode 88/100\n",
      "  Step 1, Current reward: -47.373411\n",
      "  Step 2, Current reward: -46.718512\n",
      "  Step 3, Current reward: -46.339370\n",
      "  Step 4, Current reward: -46.189328\n",
      "  Step 5, Current reward: -46.284966\n",
      "  Step 6, Current reward: -46.728721\n",
      "  Step 7, Current reward: -47.935397\n",
      "  Step 8, Current reward: -51.139127\n",
      "  Step 9, Current reward: -46.827282\n",
      "  Step 10, Current reward: -45.403535\n",
      "  Step 11, Current reward: -44.518050\n",
      "  Step 12, Current reward: -43.892599\n",
      "  Step 13, Current reward: -43.432058\n",
      "  Step 14, Current reward: -43.091798\n",
      "  Step 15, Current reward: -42.846988\n",
      "  Step 16, Current reward: -42.682214\n",
      "  Step 17, Current reward: -42.587152\n",
      "  Step 18, Current reward: -42.554475\n",
      "  Step 19, Current reward: -42.578750\n",
      "  Step 20, Current reward: -42.655801\n",
      "  Step 21, Current reward: -42.782328\n",
      "  Step 22, Current reward: -42.955651\n",
      "  Step 23, Current reward: -42.955651\n",
      "  Step 24, Current reward: -42.955651\n",
      "  Step 25, Current reward: -42.955651\n",
      "  Step 26, Current reward: -42.955651\n",
      "  Step 27, Current reward: -42.955651\n",
      "  Step 28, Current reward: -42.955651\n",
      "  Step 29, Current reward: -42.955651\n",
      "Episode 88/100 complete - Max Reward: -42.554475\n",
      "Starting episode 89/100\n",
      "  Step 1, Current reward: -39.881708\n",
      "  Step 2, Current reward: -39.304169\n",
      "  Step 3, Current reward: -38.818217\n",
      "  Step 4, Current reward: -38.418851\n",
      "  Step 5, Current reward: -38.103310\n",
      "  Step 6, Current reward: -37.870202\n",
      "  Step 7, Current reward: -37.718957\n",
      "  Step 8, Current reward: -37.649515\n",
      "  Step 9, Current reward: -37.662176\n",
      "  Step 10, Current reward: -37.757568\n",
      "  Step 11, Current reward: -37.936726\n",
      "  Step 12, Current reward: -38.201345\n",
      "  Step 13, Current reward: -38.554363\n",
      "  Step 14, Current reward: -39.001246\n",
      "  Step 15, Current reward: -39.552932\n",
      "  Step 16, Current reward: -40.232973\n",
      "  Step 17, Current reward: -41.097356\n",
      "  Step 18, Current reward: -42.306237\n",
      "  Step 19, Current reward: -44.620158\n",
      "Episode 89/100 complete - Max Reward: -37.649515\n",
      "Starting episode 90/100\n",
      "  Step 1, Current reward: -42.873693\n",
      "  Step 2, Current reward: -43.514879\n",
      "  Step 3, Current reward: -44.919251\n",
      "  Step 4, Current reward: -48.315403\n",
      "  Step 5, Current reward: -44.231889\n",
      "  Step 6, Current reward: -43.047124\n",
      "  Step 7, Current reward: -42.423413\n",
      "  Step 8, Current reward: -42.086425\n",
      "  Step 9, Current reward: -41.944648\n",
      "  Step 10, Current reward: -41.957316\n",
      "  Step 11, Current reward: -42.104158\n",
      "  Step 12, Current reward: -42.375646\n",
      "  Step 13, Current reward: -42.769637\n",
      "  Step 14, Current reward: -43.291071\n",
      "  Step 15, Current reward: -43.954477\n",
      "  Step 16, Current reward: -44.791749\n",
      "  Step 17, Current reward: -45.875562\n",
      "  Step 18, Current reward: -47.412501\n",
      "  Step 19, Current reward: -50.575181\n",
      "  Step 20, Current reward: -49.897255\n",
      "Episode 90/100 complete - Max Reward: -41.944648\n",
      "Starting episode 91/100\n",
      "  Step 1, Current reward: -39.091427\n",
      "  Step 2, Current reward: -39.343557\n",
      "  Step 3, Current reward: -39.719245\n",
      "  Step 4, Current reward: -40.240315\n",
      "  Step 5, Current reward: -40.951903\n",
      "  Step 6, Current reward: -41.959217\n",
      "  Step 7, Current reward: -43.601749\n",
      "  Step 8, Current reward: -43.601749\n",
      "  Step 9, Current reward: -43.601749\n",
      "  Step 10, Current reward: -43.601749\n",
      "  Step 11, Current reward: -43.601749\n",
      "  Step 12, Current reward: -43.601749\n",
      "Episode 91/100 complete - Max Reward: -39.091427\n",
      "Starting episode 92/100\n",
      "  Step 1, Current reward: -56.059094\n",
      "  Step 2, Current reward: -55.426561\n",
      "  Step 3, Current reward: -54.839531\n",
      "  Step 4, Current reward: -54.313337\n",
      "  Step 5, Current reward: -53.854514\n",
      "  Step 6, Current reward: -53.465265\n",
      "  Step 7, Current reward: -53.145874\n",
      "  Step 8, Current reward: -52.895935\n",
      "  Step 9, Current reward: -52.714942\n",
      "  Step 10, Current reward: -52.602578\n",
      "  Step 11, Current reward: -52.558880\n",
      "  Step 12, Current reward: -52.584353\n",
      "  Step 13, Current reward: -52.680092\n",
      "  Step 14, Current reward: -52.847953\n",
      "  Step 15, Current reward: -53.090803\n",
      "  Step 16, Current reward: -53.412926\n",
      "  Step 17, Current reward: -53.820686\n",
      "  Step 18, Current reward: -54.323702\n",
      "  Step 19, Current reward: -54.937056\n",
      "  Step 20, Current reward: -55.685939\n",
      "  Step 21, Current reward: -56.616855\n",
      "  Step 22, Current reward: -57.831432\n",
      "Episode 92/100 complete - Max Reward: -52.558880\n",
      "Starting episode 93/100\n",
      "  Step 1, Current reward: -44.037284\n",
      "  Step 2, Current reward: -43.859924\n",
      "  Step 3, Current reward: -43.830867\n",
      "  Step 4, Current reward: -43.965132\n",
      "  Step 5, Current reward: -44.303398\n",
      "  Step 6, Current reward: -44.947347\n",
      "  Step 7, Current reward: -46.230591\n",
      "  Step 8, Current reward: -55.805978\n",
      "  Step 9, Current reward: -46.282490\n",
      "  Step 10, Current reward: -45.006050\n",
      "  Step 11, Current reward: -44.390406\n",
      "  Step 12, Current reward: -44.102159\n",
      "  Step 13, Current reward: -44.052261\n",
      "  Step 14, Current reward: -44.226607\n",
      "Episode 93/100 complete - Max Reward: -43.830867\n",
      "Starting episode 94/100\n",
      "  Step 1, Current reward: -41.342492\n",
      "  Step 2, Current reward: -40.907377\n",
      "  Step 3, Current reward: -40.598366\n",
      "  Step 4, Current reward: -40.411341\n",
      "  Step 5, Current reward: -40.350159\n",
      "  Step 6, Current reward: -40.427970\n",
      "  Step 7, Current reward: -40.672315\n",
      "  Step 8, Current reward: -41.140101\n",
      "  Step 9, Current reward: -41.969314\n",
      "  Step 10, Current reward: -43.673651\n",
      "  Step 11, Current reward: -45.906620\n",
      "  Step 12, Current reward: -42.892755\n",
      "  Step 13, Current reward: -41.994014\n",
      "  Step 14, Current reward: -41.645460\n",
      "  Step 15, Current reward: -41.629446\n",
      "  Step 16, Current reward: -41.899782\n",
      "Episode 94/100 complete - Max Reward: -40.350159\n",
      "Starting episode 95/100\n",
      "  Step 1, Current reward: -48.501803\n",
      "  Step 2, Current reward: -49.717306\n",
      "  Step 3, Current reward: -53.838652\n",
      "  Step 4, Current reward: -50.153452\n",
      "  Step 5, Current reward: -48.518492\n",
      "  Step 6, Current reward: -47.558911\n",
      "  Step 7, Current reward: -46.862753\n",
      "  Step 8, Current reward: -46.319314\n",
      "  Step 9, Current reward: -45.886760\n",
      "  Step 10, Current reward: -45.546913\n",
      "  Step 11, Current reward: -45.291425\n",
      "  Step 12, Current reward: -45.116714\n",
      "  Step 13, Current reward: -45.022078\n",
      "  Step 14, Current reward: -45.009216\n",
      "  Step 15, Current reward: -45.082585\n",
      "  Step 16, Current reward: -45.250631\n",
      "  Step 17, Current reward: -45.528498\n",
      "  Step 18, Current reward: -45.944169\n",
      "  Step 19, Current reward: -46.554593\n",
      "  Step 20, Current reward: -47.500560\n",
      "  Step 21, Current reward: -49.328449\n",
      "  Step 22, Current reward: -51.187850\n",
      "  Step 23, Current reward: -48.363001\n",
      "  Step 24, Current reward: -47.395786\n",
      "  Step 25, Current reward: -46.886264\n",
      "Episode 95/100 complete - Max Reward: -45.009216\n",
      "Starting episode 96/100\n",
      "  Step 1, Current reward: -42.862472\n",
      "  Step 2, Current reward: -43.504171\n",
      "  Step 3, Current reward: -44.343581\n",
      "  Step 4, Current reward: -45.461894\n",
      "  Step 5, Current reward: -47.038982\n",
      "  Step 6, Current reward: -49.651059\n",
      "  Step 7, Current reward: -54.405047\n",
      "  Step 8, Current reward: -54.230482\n",
      "  Step 9, Current reward: -49.334767\n",
      "  Step 10, Current reward: -49.334767\n",
      "  Step 11, Current reward: -49.334767\n",
      "  Step 12, Current reward: -49.334767\n",
      "Episode 96/100 complete - Max Reward: -42.862472\n",
      "Starting episode 97/100\n",
      "  Step 1, Current reward: -42.020860\n",
      "  Step 2, Current reward: -41.782748\n",
      "  Step 3, Current reward: -41.642862\n",
      "  Step 4, Current reward: -41.593796\n",
      "  Step 5, Current reward: -41.631187\n",
      "  Step 6, Current reward: -41.753213\n",
      "  Step 7, Current reward: -41.960554\n",
      "  Step 8, Current reward: -42.256812\n",
      "  Step 9, Current reward: -42.649623\n",
      "  Step 10, Current reward: -43.153058\n",
      "  Step 11, Current reward: -43.793066\n",
      "  Step 12, Current reward: -44.621438\n",
      "  Step 13, Current reward: -45.761375\n",
      "  Step 14, Current reward: -47.647285\n",
      "  Step 15, Current reward: -51.334505\n",
      "Episode 97/100 complete - Max Reward: -41.593796\n",
      "Starting episode 98/100\n",
      "  Step 1, Current reward: -48.284057\n",
      "  Step 2, Current reward: -50.217579\n",
      "  Step 3, Current reward: -50.217579\n",
      "  Step 4, Current reward: -50.217579\n",
      "  Step 5, Current reward: -50.217579\n",
      "  Step 6, Current reward: -50.217579\n",
      "  Step 7, Current reward: -50.217579\n",
      "  Step 8, Current reward: -50.217579\n",
      "  Step 9, Current reward: -50.217579\n",
      "  Step 10, Current reward: -50.217579\n",
      "  Step 11, Current reward: -50.217579\n",
      "  Step 12, Current reward: -50.217579\n",
      "Episode 98/100 complete - Max Reward: -48.284057\n",
      "Starting episode 99/100\n",
      "  Step 1, Current reward: -44.426738\n",
      "  Step 2, Current reward: -44.359274\n",
      "  Step 3, Current reward: -44.477700\n",
      "  Step 4, Current reward: -44.771940\n",
      "  Step 5, Current reward: -45.250914\n",
      "  Step 6, Current reward: -45.947048\n",
      "  Step 7, Current reward: -46.939871\n",
      "  Step 8, Current reward: -48.456993\n",
      "  Step 9, Current reward: -51.857832\n",
      "  Step 10, Current reward: -50.835287\n",
      "  Step 11, Current reward: -49.830307\n",
      "  Step 12, Current reward: -49.885202\n",
      "  Step 13, Current reward: -50.548421\n",
      "Episode 99/100 complete - Max Reward: -44.359274\n",
      "Starting episode 100/100\n",
      "  Step 1, Current reward: -44.075560\n",
      "  Step 2, Current reward: -43.869315\n",
      "  Step 3, Current reward: -43.722690\n",
      "  Step 4, Current reward: -43.722690\n",
      "  Step 5, Current reward: -43.722690\n",
      "  Step 6, Current reward: -43.722690\n",
      "  Step 7, Current reward: -43.722690\n",
      "  Step 8, Current reward: -43.722690\n",
      "  Step 9, Current reward: -43.722690\n",
      "  Step 10, Current reward: -43.722690\n",
      "  Step 11, Current reward: -43.722690\n",
      "  Step 12, Current reward: -43.722690\n",
      "  Step 13, Current reward: -43.722690\n",
      "  Step 14, Current reward: -43.722690\n",
      "Episode 100/100 complete - Max Reward: -43.722690\n"
     ]
    }
   ],
   "source": [
    "adr_all_ep_rewards, adr_best_rewards, adr_optimal_states_all = adr_dqn.evaluate(num_episodes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e1b74-a7c8-4c10-a18c-002c8affecd7",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0f438e9e-3ec7-4c67-9b39-d4aff4a3fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(adr_best_rewards, bins=20, color='skyblue', edgecolor='black', alpha=0.75)\n",
    "plt.xlabel('Episode Best Reward')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Episode Best Rewards')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b423b4ec-30cf-4eb2-93f3-45d725b2a842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute sum of optimal_states over all episodes\n",
    "# Assumes that each info[\"optimal_states\"] is a numpy array of the same shape\n",
    "optimal_states_stack = np.array(adr_optimal_states_all)\n",
    "mean_optimal_states = np.sum(optimal_states_stack, axis=0)\n",
    "\n",
    "# Plot grid of mean optimal_states\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(mean_optimal_states, cmap='viridis', interpolation='nearest')\n",
    "plt.title('Total placements in optimal States over Episodes')\n",
    "plt.colorbar(label='Total placements')\n",
    "plt.xlabel('Grid X')\n",
    "plt.ylabel('Grid Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dfdad9-eac8-46de-a50a-d54c89c7af40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9347c4d-5c87-44b2-a38b-74dffa515a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b487e-c9e4-494b-b754-2bda895b9fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb889038-091d-475e-af7d-49b795e13677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088770d9-c3ad-4d39-be49-2820cf201665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs234_a3]",
   "language": "python",
   "name": "conda-env-cs234_a3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
